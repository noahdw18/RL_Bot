Created new wandb run! c1ffq7tk
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07136
Policy Entropy: 0.84271
Value Function Loss:     nan

Mean KL Divergence: -0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.10650
Value Function Update Magnitude: 0.10459

Collected Steps per Second: 7344.26224
Overall Steps per Second: 5308.44307

Timestep Collection Time: 6.81457
Timestep Consumption Time: 2.61343
PPO Batch Consumption Time: 1.13446
Total Iteration Time: 9.42800

Cumulative Model Updates: 1
Cumulative Timesteps: 50048

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07552
Policy Entropy: 0.83570
Value Function Loss: 0.91427

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.00673
Policy Update Magnitude: 0.13805
Value Function Update Magnitude: 0.14993

Collected Steps per Second: 11152.38573
Overall Steps per Second: 8613.01534

Timestep Collection Time: 4.48496
Timestep Consumption Time: 1.32230
PPO Batch Consumption Time: 0.08688
Total Iteration Time: 5.80726

Cumulative Model Updates: 3
Cumulative Timesteps: 100066

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 100066...
Checkpoint 100066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00296
Policy Entropy: 0.84033
Value Function Loss: 1.19332

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05055
Policy Update Magnitude: 0.17250
Value Function Update Magnitude: 0.23932

Collected Steps per Second: 12173.59801
Overall Steps per Second: 9451.34827

Timestep Collection Time: 4.11021
Timestep Consumption Time: 1.18385
PPO Batch Consumption Time: 0.07332
Total Iteration Time: 5.29406

Cumulative Model Updates: 6
Cumulative Timesteps: 150102

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02169
Policy Entropy: 0.85018
Value Function Loss: 1.92152

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.01895
Policy Update Magnitude: 0.16316
Value Function Update Magnitude: 0.23732

Collected Steps per Second: 12007.56656
Overall Steps per Second: 9373.91608

Timestep Collection Time: 4.16471
Timestep Consumption Time: 1.17010
PPO Batch Consumption Time: 0.06382
Total Iteration Time: 5.33480

Cumulative Model Updates: 9
Cumulative Timesteps: 200110

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 200110...
Checkpoint 200110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01753
Policy Entropy: 0.85996
Value Function Loss: 1.97731

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01079
Policy Update Magnitude: 0.16005
Value Function Update Magnitude: 0.24042

Collected Steps per Second: 10664.02151
Overall Steps per Second: 8663.94976

Timestep Collection Time: 4.69110
Timestep Consumption Time: 1.08294
PPO Batch Consumption Time: 0.09353
Total Iteration Time: 5.77404

Cumulative Model Updates: 12
Cumulative Timesteps: 250136

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02406
Policy Entropy: 0.86851
Value Function Loss: 2.84719

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.15665
Value Function Update Magnitude: 0.24676

Collected Steps per Second: 10808.21970
Overall Steps per Second: 8786.57662

Timestep Collection Time: 4.62703
Timestep Consumption Time: 1.06460
PPO Batch Consumption Time: 0.06401
Total Iteration Time: 5.69164

Cumulative Model Updates: 15
Cumulative Timesteps: 300146

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 300146...
Checkpoint 300146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00940
Policy Entropy: 0.87889
Value Function Loss: 3.30822

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.03144
Policy Update Magnitude: 0.16005
Value Function Update Magnitude: 0.25622

Collected Steps per Second: 10869.29363
Overall Steps per Second: 8757.01194

Timestep Collection Time: 4.60288
Timestep Consumption Time: 1.11026
PPO Batch Consumption Time: 0.08157
Total Iteration Time: 5.71314

Cumulative Model Updates: 18
Cumulative Timesteps: 350176

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06152
Policy Entropy: 0.89268
Value Function Loss: 4.04291

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.16874
Value Function Update Magnitude: 0.27118

Collected Steps per Second: 12070.99391
Overall Steps per Second: 9604.61399

Timestep Collection Time: 4.14349
Timestep Consumption Time: 1.06401
PPO Batch Consumption Time: 0.06404
Total Iteration Time: 5.20750

Cumulative Model Updates: 21
Cumulative Timesteps: 400192

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 400192...
Checkpoint 400192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02551
Policy Entropy: 0.90452
Value Function Loss: 3.94643

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.03552
Policy Update Magnitude: 0.17611
Value Function Update Magnitude: 0.28050

Collected Steps per Second: 10392.78379
Overall Steps per Second: 8386.43865

Timestep Collection Time: 4.81334
Timestep Consumption Time: 1.15153
PPO Batch Consumption Time: 0.08119
Total Iteration Time: 5.96487

Cumulative Model Updates: 24
Cumulative Timesteps: 450216

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00988
Policy Entropy: 0.90993
Value Function Loss: 3.51557

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 0.18099
Value Function Update Magnitude: 0.28728

Collected Steps per Second: 12277.53338
Overall Steps per Second: 9958.95603

Timestep Collection Time: 4.07590
Timestep Consumption Time: 0.94892
PPO Batch Consumption Time: 0.05797
Total Iteration Time: 5.02482

Cumulative Model Updates: 27
Cumulative Timesteps: 500258

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 500258...
Checkpoint 500258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04374
Policy Entropy: 0.92471
Value Function Loss: 3.02407

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.03726
Policy Update Magnitude: 0.18730
Value Function Update Magnitude: 0.28724

Collected Steps per Second: 11357.23586
Overall Steps per Second: 8955.96866

Timestep Collection Time: 4.40530
Timestep Consumption Time: 1.18114
PPO Batch Consumption Time: 0.07327
Total Iteration Time: 5.58644

Cumulative Model Updates: 30
Cumulative Timesteps: 550290

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02760
Policy Entropy: 0.94047
Value Function Loss: 3.13929

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.18604
Value Function Update Magnitude: 0.28258

Collected Steps per Second: 12360.82209
Overall Steps per Second: 9819.73890

Timestep Collection Time: 4.04714
Timestep Consumption Time: 1.04729
PPO Batch Consumption Time: 0.06081
Total Iteration Time: 5.09443

Cumulative Model Updates: 33
Cumulative Timesteps: 600316

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 600316...
Checkpoint 600316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01569
Policy Entropy: 0.95572
Value Function Loss: 3.77398

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08259
Policy Update Magnitude: 0.18969
Value Function Update Magnitude: 0.28555

Collected Steps per Second: 11719.73552
Overall Steps per Second: 9540.22611

Timestep Collection Time: 4.26767
Timestep Consumption Time: 0.97497
PPO Batch Consumption Time: 0.06341
Total Iteration Time: 5.24264

Cumulative Model Updates: 36
Cumulative Timesteps: 650332

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01982
Policy Entropy: 0.96883
Value Function Loss: 4.04913

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.19426
Value Function Update Magnitude: 0.27753

Collected Steps per Second: 11889.15397
Overall Steps per Second: 9393.54809

Timestep Collection Time: 4.20568
Timestep Consumption Time: 1.11733
PPO Batch Consumption Time: 0.08405
Total Iteration Time: 5.32302

Cumulative Model Updates: 39
Cumulative Timesteps: 700334

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 700334...
Checkpoint 700334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01639
Policy Entropy: 0.98494
Value Function Loss: 3.63948

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.19751
Value Function Update Magnitude: 0.27454

Collected Steps per Second: 11436.81516
Overall Steps per Second: 9180.64321

Timestep Collection Time: 4.37342
Timestep Consumption Time: 1.07478
PPO Batch Consumption Time: 0.09184
Total Iteration Time: 5.44820

Cumulative Model Updates: 42
Cumulative Timesteps: 750352

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04064
Policy Entropy: 0.99872
Value Function Loss: 3.45330

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.18682
Value Function Update Magnitude: 0.26927

Collected Steps per Second: 12575.41599
Overall Steps per Second: 10000.80594

Timestep Collection Time: 3.97649
Timestep Consumption Time: 1.02371
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 5.00020

Cumulative Model Updates: 45
Cumulative Timesteps: 800358

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 800358...
Checkpoint 800358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02702
Policy Entropy: 1.01051
Value Function Loss: 3.03043

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.17335
Value Function Update Magnitude: 0.25657

Collected Steps per Second: 11594.52413
Overall Steps per Second: 9207.87962

Timestep Collection Time: 4.31618
Timestep Consumption Time: 1.11873
PPO Batch Consumption Time: 0.07109
Total Iteration Time: 5.43491

Cumulative Model Updates: 48
Cumulative Timesteps: 850402

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02688
Policy Entropy: 1.02151
Value Function Loss: 2.94650

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.16958
Value Function Update Magnitude: 0.23912

Collected Steps per Second: 12000.97637
Overall Steps per Second: 9763.97475

Timestep Collection Time: 4.16799
Timestep Consumption Time: 0.95492
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 5.12291

Cumulative Model Updates: 51
Cumulative Timesteps: 900422

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 900422...
Checkpoint 900422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06062
Policy Entropy: 1.04105
Value Function Loss: 2.96384

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.17289
Value Function Update Magnitude: 0.21974

Collected Steps per Second: 11940.48619
Overall Steps per Second: 9199.61996

Timestep Collection Time: 4.19062
Timestep Consumption Time: 1.24852
PPO Batch Consumption Time: 0.12895
Total Iteration Time: 5.43914

Cumulative Model Updates: 54
Cumulative Timesteps: 950460

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07475
Policy Entropy: 1.04716
Value Function Loss: 3.69016

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.17311
Value Function Update Magnitude: 0.22171

Collected Steps per Second: 12638.80402
Overall Steps per Second: 10050.66500

Timestep Collection Time: 3.95623
Timestep Consumption Time: 1.01877
PPO Batch Consumption Time: 0.05661
Total Iteration Time: 4.97499

Cumulative Model Updates: 57
Cumulative Timesteps: 1000462

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 1000462...
Checkpoint 1000462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04575
Policy Entropy: 1.04977
Value Function Loss: 3.91893

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.16632
Value Function Update Magnitude: 0.22035

Collected Steps per Second: 11466.33742
Overall Steps per Second: 8905.69745

Timestep Collection Time: 4.36181
Timestep Consumption Time: 1.25414
PPO Batch Consumption Time: 0.10576
Total Iteration Time: 5.61596

Cumulative Model Updates: 60
Cumulative Timesteps: 1050476

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00149
Policy Entropy: 1.05390
Value Function Loss: 4.52798

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.16519
Value Function Update Magnitude: 0.21541

Collected Steps per Second: 12738.17748
Overall Steps per Second: 9971.26538

Timestep Collection Time: 3.92599
Timestep Consumption Time: 1.08942
PPO Batch Consumption Time: 0.06163
Total Iteration Time: 5.01541

Cumulative Model Updates: 63
Cumulative Timesteps: 1100486

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 1100486...
Checkpoint 1100486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03880
Policy Entropy: 1.05708
Value Function Loss: 3.40714

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08115
Policy Update Magnitude: 0.15571
Value Function Update Magnitude: 0.17281

Collected Steps per Second: 11691.20031
Overall Steps per Second: 9427.08254

Timestep Collection Time: 4.27741
Timestep Consumption Time: 1.02731
PPO Batch Consumption Time: 0.08954
Total Iteration Time: 5.30472

Cumulative Model Updates: 66
Cumulative Timesteps: 1150494

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02444
Policy Entropy: 1.05783
Value Function Loss: 2.59785

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.17075
Value Function Update Magnitude: 0.13481

Collected Steps per Second: 12485.65015
Overall Steps per Second: 9815.49602

Timestep Collection Time: 4.00604
Timestep Consumption Time: 1.08978
PPO Batch Consumption Time: 0.06533
Total Iteration Time: 5.09582

Cumulative Model Updates: 69
Cumulative Timesteps: 1200512

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 1200512...
Checkpoint 1200512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00812
Policy Entropy: 1.02916
Value Function Loss: 1.25601

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.22755
Policy Update Magnitude: 0.18557
Value Function Update Magnitude: 0.11187

Collected Steps per Second: 11225.07860
Overall Steps per Second: 8735.79953

Timestep Collection Time: 4.45698
Timestep Consumption Time: 1.27002
PPO Batch Consumption Time: 0.12008
Total Iteration Time: 5.72701

Cumulative Model Updates: 72
Cumulative Timesteps: 1250542

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01859
Policy Entropy: 1.03975
Value Function Loss: 1.11241

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.19905
Policy Update Magnitude: 0.18696
Value Function Update Magnitude: 0.10567

Collected Steps per Second: 12932.82230
Overall Steps per Second: 10123.15945

Timestep Collection Time: 3.86876
Timestep Consumption Time: 1.07377
PPO Batch Consumption Time: 0.05842
Total Iteration Time: 4.94253

Cumulative Model Updates: 75
Cumulative Timesteps: 1300576

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 1300576...
Checkpoint 1300576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01435
Policy Entropy: 1.01073
Value Function Loss: 0.91066

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.21517
Policy Update Magnitude: 0.18172
Value Function Update Magnitude: 0.11345

Collected Steps per Second: 11941.88059
Overall Steps per Second: 9470.55756

Timestep Collection Time: 4.19013
Timestep Consumption Time: 1.09341
PPO Batch Consumption Time: 0.07886
Total Iteration Time: 5.28353

Cumulative Model Updates: 78
Cumulative Timesteps: 1350614

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02686
Policy Entropy: 1.01757
Value Function Loss: 0.75830

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15861
Policy Update Magnitude: 0.16968
Value Function Update Magnitude: 0.11308

Collected Steps per Second: 11757.20262
Overall Steps per Second: 9432.14444

Timestep Collection Time: 4.25662
Timestep Consumption Time: 1.04927
PPO Batch Consumption Time: 0.08816
Total Iteration Time: 5.30590

Cumulative Model Updates: 81
Cumulative Timesteps: 1400660

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 1400660...
Checkpoint 1400660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00266
Policy Entropy: 1.02130
Value Function Loss: 0.71189

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.16356
Value Function Update Magnitude: 0.11103

Collected Steps per Second: 12634.73339
Overall Steps per Second: 9925.85322

Timestep Collection Time: 3.95940
Timestep Consumption Time: 1.08057
PPO Batch Consumption Time: 0.06228
Total Iteration Time: 5.03997

Cumulative Model Updates: 84
Cumulative Timesteps: 1450686

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03201
Policy Entropy: 0.99443
Value Function Loss: 0.59648

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.15155
Value Function Update Magnitude: 0.11093

Collected Steps per Second: 11254.45534
Overall Steps per Second: 8946.63506

Timestep Collection Time: 4.44375
Timestep Consumption Time: 1.14628
PPO Batch Consumption Time: 0.07184
Total Iteration Time: 5.59003

Cumulative Model Updates: 87
Cumulative Timesteps: 1500698

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 1500698...
Checkpoint 1500698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01067
Policy Entropy: 1.00238
Value Function Loss: 0.51397

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05439
Policy Update Magnitude: 0.14478
Value Function Update Magnitude: 0.11344

Collected Steps per Second: 12281.81436
Overall Steps per Second: 9733.08650

Timestep Collection Time: 4.07171
Timestep Consumption Time: 1.06623
PPO Batch Consumption Time: 0.05927
Total Iteration Time: 5.13794

Cumulative Model Updates: 90
Cumulative Timesteps: 1550706

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09008
Policy Entropy: 1.00555
Value Function Loss: 0.42082

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 0.13867
Value Function Update Magnitude: 0.10441

Collected Steps per Second: 11760.23077
Overall Steps per Second: 9197.57319

Timestep Collection Time: 4.25230
Timestep Consumption Time: 1.18479
PPO Batch Consumption Time: 0.08315
Total Iteration Time: 5.43709

Cumulative Model Updates: 93
Cumulative Timesteps: 1600714

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 1600714...
Checkpoint 1600714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05039
Policy Entropy: 0.98501
Value Function Loss: 0.35319

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03302
Policy Update Magnitude: 0.12950
Value Function Update Magnitude: 0.10976

Collected Steps per Second: 12642.73592
Overall Steps per Second: 10189.51713

Timestep Collection Time: 3.95721
Timestep Consumption Time: 0.95273
PPO Batch Consumption Time: 0.05836
Total Iteration Time: 4.90995

Cumulative Model Updates: 96
Cumulative Timesteps: 1650744

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00493
Policy Entropy: 0.98080
Value Function Loss: 0.32526

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03014
Policy Update Magnitude: 0.12108
Value Function Update Magnitude: 0.10053

Collected Steps per Second: 11735.77234
Overall Steps per Second: 9474.73054

Timestep Collection Time: 4.26099
Timestep Consumption Time: 1.01684
PPO Batch Consumption Time: 0.05872
Total Iteration Time: 5.27783

Cumulative Model Updates: 99
Cumulative Timesteps: 1700750

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 1700750...
Checkpoint 1700750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03677
Policy Entropy: 0.98516
Value Function Loss: 0.27543

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.00541
Policy Update Magnitude: 0.11696
Value Function Update Magnitude: 0.10192

Collected Steps per Second: 11882.22056
Overall Steps per Second: 9324.54469

Timestep Collection Time: 4.21167
Timestep Consumption Time: 1.15524
PPO Batch Consumption Time: 0.09170
Total Iteration Time: 5.36691

Cumulative Model Updates: 102
Cumulative Timesteps: 1750794

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02216
Policy Entropy: 0.97464
Value Function Loss: 0.26059

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.01179
Policy Update Magnitude: 0.11673
Value Function Update Magnitude: 0.09057

Collected Steps per Second: 12911.36588
Overall Steps per Second: 10185.02134

Timestep Collection Time: 3.87395
Timestep Consumption Time: 1.03699
PPO Batch Consumption Time: 0.06096
Total Iteration Time: 4.91094

Cumulative Model Updates: 105
Cumulative Timesteps: 1800812

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 1800812...
Checkpoint 1800812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02713
Policy Entropy: 0.95752
Value Function Loss: 0.22686

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.10192
Value Function Update Magnitude: 0.09254

Collected Steps per Second: 12245.78003
Overall Steps per Second: 9724.99856

Timestep Collection Time: 4.08337
Timestep Consumption Time: 1.05843
PPO Batch Consumption Time: 0.06610
Total Iteration Time: 5.14180

Cumulative Model Updates: 108
Cumulative Timesteps: 1850816

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04535
Policy Entropy: 0.95807
Value Function Loss: 0.21648

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01176
Policy Update Magnitude: 0.09585
Value Function Update Magnitude: 0.08437

Collected Steps per Second: 11206.01791
Overall Steps per Second: 9131.92920

Timestep Collection Time: 4.46332
Timestep Consumption Time: 1.01373
PPO Batch Consumption Time: 0.07744
Total Iteration Time: 5.47705

Cumulative Model Updates: 111
Cumulative Timesteps: 1900832

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 1900832...
Checkpoint 1900832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02930
Policy Entropy: 0.96550
Value Function Loss: 0.18365

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.00331
Policy Update Magnitude: 0.09066
Value Function Update Magnitude: 0.07968

Collected Steps per Second: 12697.06317
Overall Steps per Second: 10062.19427

Timestep Collection Time: 3.93949
Timestep Consumption Time: 1.03159
PPO Batch Consumption Time: 0.06580
Total Iteration Time: 4.97108

Cumulative Model Updates: 114
Cumulative Timesteps: 1950852

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01635
Policy Entropy: 0.96033
Value Function Loss: 0.17068

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.00452
Policy Update Magnitude: 0.09109
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 12596.65434
Overall Steps per Second: 10028.70674

Timestep Collection Time: 3.96963
Timestep Consumption Time: 1.01646
PPO Batch Consumption Time: 0.06703
Total Iteration Time: 4.98609

Cumulative Model Updates: 117
Cumulative Timesteps: 2000856

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 2000856...
Checkpoint 2000856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09034
Policy Entropy: 0.94446
Value Function Loss: 0.15114

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.01906
Policy Update Magnitude: 0.08484
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 12889.04461
Overall Steps per Second: 10140.48436

Timestep Collection Time: 3.88330
Timestep Consumption Time: 1.05256
PPO Batch Consumption Time: 0.06545
Total Iteration Time: 4.93586

Cumulative Model Updates: 120
Cumulative Timesteps: 2050908

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02315
Policy Entropy: 0.93594
Value Function Loss: 0.13340

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.07548
Value Function Update Magnitude: 0.05760

Collected Steps per Second: 10879.94068
Overall Steps per Second: 8829.93299

Timestep Collection Time: 4.59782
Timestep Consumption Time: 1.06746
PPO Batch Consumption Time: 0.07567
Total Iteration Time: 5.66528

Cumulative Model Updates: 123
Cumulative Timesteps: 2100932

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 2100932...
Checkpoint 2100932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02998
Policy Entropy: 0.93585
Value Function Loss: 0.10749

Mean KL Divergence: 0.00101
SB3 Clip Fraction: 0.00157
Policy Update Magnitude: 0.07245
Value Function Update Magnitude: 0.05651

Collected Steps per Second: 12418.72520
Overall Steps per Second: 10074.95227

Timestep Collection Time: 4.02811
Timestep Consumption Time: 0.93707
PPO Batch Consumption Time: 0.06438
Total Iteration Time: 4.96518

Cumulative Model Updates: 126
Cumulative Timesteps: 2150956

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05620
Policy Entropy: 0.92515
Value Function Loss: 0.08398

Mean KL Divergence: 0.00114
SB3 Clip Fraction: 0.00215
Policy Update Magnitude: 0.07642
Value Function Update Magnitude: 0.04803

Collected Steps per Second: 12991.14559
Overall Steps per Second: 10239.93749

Timestep Collection Time: 3.85185
Timestep Consumption Time: 1.03489
PPO Batch Consumption Time: 0.06106
Total Iteration Time: 4.88675

Cumulative Model Updates: 129
Cumulative Timesteps: 2200996

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 2200996...
Checkpoint 2200996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04130
Policy Entropy: 0.90508
Value Function Loss: 0.07264

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04218
Policy Update Magnitude: 0.06639
Value Function Update Magnitude: 0.04702

Collected Steps per Second: 10472.28420
Overall Steps per Second: 8572.86661

Timestep Collection Time: 4.77565
Timestep Consumption Time: 1.05810
PPO Batch Consumption Time: 0.07122
Total Iteration Time: 5.83375

Cumulative Model Updates: 132
Cumulative Timesteps: 2251008

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02629
Policy Entropy: 0.90460
Value Function Loss: 0.08151

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01577
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.04129

Collected Steps per Second: 11652.88745
Overall Steps per Second: 9278.43093

Timestep Collection Time: 4.29353
Timestep Consumption Time: 1.09876
PPO Batch Consumption Time: 0.08170
Total Iteration Time: 5.39229

Cumulative Model Updates: 135
Cumulative Timesteps: 2301040

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 2301040...
Checkpoint 2301040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01213
Policy Entropy: 0.91304
Value Function Loss: 0.07513

Mean KL Divergence: 0.00112
SB3 Clip Fraction: 0.00087
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.04202

Collected Steps per Second: 11916.98061
Overall Steps per Second: 9472.47302

Timestep Collection Time: 4.19586
Timestep Consumption Time: 1.08280
PPO Batch Consumption Time: 0.08169
Total Iteration Time: 5.27866

Cumulative Model Updates: 138
Cumulative Timesteps: 2351042

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04635
Policy Entropy: 0.91206
Value Function Loss: 0.08570

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00381
Policy Update Magnitude: 0.05670
Value Function Update Magnitude: 0.03646

Collected Steps per Second: 12760.48186
Overall Steps per Second: 10315.22980

Timestep Collection Time: 3.92086
Timestep Consumption Time: 0.92945
PPO Batch Consumption Time: 0.06050
Total Iteration Time: 4.85030

Cumulative Model Updates: 141
Cumulative Timesteps: 2401074

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 2401074...
Checkpoint 2401074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03239
Policy Entropy: 0.89875
Value Function Loss: 0.07608

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01038
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.04214

Collected Steps per Second: 11038.18773
Overall Steps per Second: 8875.85818

Timestep Collection Time: 4.53281
Timestep Consumption Time: 1.10428
PPO Batch Consumption Time: 0.06718
Total Iteration Time: 5.63709

Cumulative Model Updates: 144
Cumulative Timesteps: 2451108

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02597
Policy Entropy: 0.89449
Value Function Loss: 0.08312

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01000
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.03886

Collected Steps per Second: 11487.27716
Overall Steps per Second: 9136.25070

Timestep Collection Time: 4.35299
Timestep Consumption Time: 1.12015
PPO Batch Consumption Time: 0.07494
Total Iteration Time: 5.47314

Cumulative Model Updates: 147
Cumulative Timesteps: 2501112

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 2501112...
Checkpoint 2501112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01059
Policy Entropy: 0.89264
Value Function Loss: 0.09112

Mean KL Divergence: 0.00076
SB3 Clip Fraction: 0.00057
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.04259

Collected Steps per Second: 10188.02784
Overall Steps per Second: 7847.49045

Timestep Collection Time: 4.90988
Timestep Consumption Time: 1.46439
PPO Batch Consumption Time: 0.08656
Total Iteration Time: 6.37427

Cumulative Model Updates: 150
Cumulative Timesteps: 2551134

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00933
Policy Entropy: 0.87960
Value Function Loss: 0.08112

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.00615
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.03319

Collected Steps per Second: 11133.42742
Overall Steps per Second: 8946.70197

Timestep Collection Time: 4.49134
Timestep Consumption Time: 1.09776
PPO Batch Consumption Time: 0.03696
Total Iteration Time: 5.58910

Cumulative Model Updates: 153
Cumulative Timesteps: 2601138

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 2601138...
Checkpoint 2601138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02327
Policy Entropy: 0.85963
Value Function Loss: 0.06591

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04588
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.03223

Collected Steps per Second: 10928.62442
Overall Steps per Second: 9239.66892

Timestep Collection Time: 4.57862
Timestep Consumption Time: 0.83694
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 5.41556

Cumulative Model Updates: 156
Cumulative Timesteps: 2651176

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00804
Policy Entropy: 0.86566
Value Function Loss: 0.04170

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.00364
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.02808

Collected Steps per Second: 12129.42314
Overall Steps per Second: 9928.89683

Timestep Collection Time: 4.12320
Timestep Consumption Time: 0.91382
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 5.03701

Cumulative Model Updates: 159
Cumulative Timesteps: 2701188

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 2701188...
Checkpoint 2701188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00083
Policy Entropy: 0.87851
Value Function Loss: 0.05392

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.00487
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.02891

Collected Steps per Second: 12825.65788
Overall Steps per Second: 10308.81846

Timestep Collection Time: 3.89890
Timestep Consumption Time: 0.95190
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 4.85080

Cumulative Model Updates: 162
Cumulative Timesteps: 2751194

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07999
Policy Entropy: 0.87968
Value Function Loss: 0.08425

Mean KL Divergence: 0.00147
SB3 Clip Fraction: 0.00377
Policy Update Magnitude: 0.04363
Value Function Update Magnitude: 0.02484

Collected Steps per Second: 12723.38762
Overall Steps per Second: 10330.39610

Timestep Collection Time: 3.93103
Timestep Consumption Time: 0.91061
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 4.84163

Cumulative Model Updates: 165
Cumulative Timesteps: 2801210

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 2801210...
Checkpoint 2801210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00150
Policy Entropy: 0.86998
Value Function Loss: 0.10178

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.00226
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.02702

Collected Steps per Second: 11869.53002
Overall Steps per Second: 9600.19867

Timestep Collection Time: 4.21466
Timestep Consumption Time: 0.99628
PPO Batch Consumption Time: 0.03007
Total Iteration Time: 5.21093

Cumulative Model Updates: 168
Cumulative Timesteps: 2851236

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00517
Policy Entropy: 0.86851
Value Function Loss: 0.10249

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.01011
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.02461

Collected Steps per Second: 10848.93421
Overall Steps per Second: 8935.49769

Timestep Collection Time: 4.61004
Timestep Consumption Time: 0.98719
PPO Batch Consumption Time: 0.03128
Total Iteration Time: 5.59723

Cumulative Model Updates: 171
Cumulative Timesteps: 2901250

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 2901250...
Checkpoint 2901250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01870
Policy Entropy: 0.86957
Value Function Loss: 0.08551

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01007
Policy Update Magnitude: 0.04306
Value Function Update Magnitude: 0.03135

Collected Steps per Second: 10623.02104
Overall Steps per Second: 8774.68526

Timestep Collection Time: 4.71052
Timestep Consumption Time: 0.99224
PPO Batch Consumption Time: 0.02898
Total Iteration Time: 5.70277

Cumulative Model Updates: 174
Cumulative Timesteps: 2951290

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03430
Policy Entropy: 0.85266
Value Function Loss: 0.07717

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02085
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.01903

Collected Steps per Second: 11408.30789
Overall Steps per Second: 9371.13124

Timestep Collection Time: 4.38347
Timestep Consumption Time: 0.95292
PPO Batch Consumption Time: 0.02978
Total Iteration Time: 5.33639

Cumulative Model Updates: 177
Cumulative Timesteps: 3001298

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 3001298...
Checkpoint 3001298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01786
Policy Entropy: 0.83623
Value Function Loss: 0.06677

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05235
Policy Update Magnitude: 0.03742
Value Function Update Magnitude: 0.02557

Collected Steps per Second: 12337.53123
Overall Steps per Second: 10240.18793

Timestep Collection Time: 4.05349
Timestep Consumption Time: 0.83021
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 4.88370

Cumulative Model Updates: 180
Cumulative Timesteps: 3051308

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02235
Policy Entropy: 0.84162
Value Function Loss: 0.05967

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.00615
Policy Update Magnitude: 0.04283
Value Function Update Magnitude: 0.02167

Collected Steps per Second: 13033.06681
Overall Steps per Second: 10400.53052

Timestep Collection Time: 3.83931
Timestep Consumption Time: 0.97179
PPO Batch Consumption Time: 0.02939
Total Iteration Time: 4.81110

Cumulative Model Updates: 183
Cumulative Timesteps: 3101346

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 3101346...
Checkpoint 3101346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02456
Policy Entropy: 0.85449
Value Function Loss: 0.06226

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02451
Policy Update Magnitude: 0.03710
Value Function Update Magnitude: 0.02332

Collected Steps per Second: 12384.50625
Overall Steps per Second: 10086.54491

Timestep Collection Time: 4.03843
Timestep Consumption Time: 0.92005
PPO Batch Consumption Time: 0.02911
Total Iteration Time: 4.95849

Cumulative Model Updates: 186
Cumulative Timesteps: 3151360

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01984
Policy Entropy: 0.85246
Value Function Loss: 0.06345

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01060
Policy Update Magnitude: 0.03848
Value Function Update Magnitude: 0.02018

Collected Steps per Second: 13410.79088
Overall Steps per Second: 10733.19705

Timestep Collection Time: 3.72864
Timestep Consumption Time: 0.93018
PPO Batch Consumption Time: 0.02815
Total Iteration Time: 4.65882

Cumulative Model Updates: 189
Cumulative Timesteps: 3201364

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 3201364...
Checkpoint 3201364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00361
Policy Entropy: 0.84658
Value Function Loss: 0.07773

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.00807
Policy Update Magnitude: 0.04028
Value Function Update Magnitude: 0.02333

Collected Steps per Second: 12939.62304
Overall Steps per Second: 10450.10444

Timestep Collection Time: 3.86549
Timestep Consumption Time: 0.92087
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 4.78636

Cumulative Model Updates: 192
Cumulative Timesteps: 3251382

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00120
Policy Entropy: 0.84916
Value Function Loss: 0.06894

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01639
Policy Update Magnitude: 0.03930
Value Function Update Magnitude: 0.02031

Collected Steps per Second: 12942.41437
Overall Steps per Second: 10567.72871

Timestep Collection Time: 3.86558
Timestep Consumption Time: 0.86864
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 4.73422

Cumulative Model Updates: 195
Cumulative Timesteps: 3301412

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 3301412...
Checkpoint 3301412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04209
Policy Entropy: 0.85514
Value Function Loss: 0.07068

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.00833
Policy Update Magnitude: 0.03509
Value Function Update Magnitude: 0.02148

Collected Steps per Second: 11369.87300
Overall Steps per Second: 9281.87050

Timestep Collection Time: 4.39970
Timestep Consumption Time: 0.98973
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 5.38943

Cumulative Model Updates: 198
Cumulative Timesteps: 3351436

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00341
Policy Entropy: 0.84315
Value Function Loss: 0.06083

Mean KL Divergence: 0.00122
SB3 Clip Fraction: 0.00067
Policy Update Magnitude: 0.04236
Value Function Update Magnitude: 0.01688

Collected Steps per Second: 11910.81312
Overall Steps per Second: 9696.36793

Timestep Collection Time: 4.20022
Timestep Consumption Time: 0.95924
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 5.15946

Cumulative Model Updates: 201
Cumulative Timesteps: 3401464

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 3401464...
Checkpoint 3401464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02985
Policy Entropy: 0.82238
Value Function Loss: 0.05953

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04107
Policy Update Magnitude: 0.03434
Value Function Update Magnitude: 0.02052

Collected Steps per Second: 11716.69135
Overall Steps per Second: 9582.95623

Timestep Collection Time: 4.26810
Timestep Consumption Time: 0.95033
PPO Batch Consumption Time: 0.02923
Total Iteration Time: 5.21843

Cumulative Model Updates: 204
Cumulative Timesteps: 3451472

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01835
Policy Entropy: 0.82294
Value Function Loss: 0.05034

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01421
Policy Update Magnitude: 0.03491
Value Function Update Magnitude: 0.01901

Collected Steps per Second: 12659.33516
Overall Steps per Second: 10244.15464

Timestep Collection Time: 3.95123
Timestep Consumption Time: 0.93155
PPO Batch Consumption Time: 0.03151
Total Iteration Time: 4.88278

Cumulative Model Updates: 207
Cumulative Timesteps: 3501492

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 3501492...
Checkpoint 3501492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03433
Policy Entropy: 0.83340
Value Function Loss: 0.03685

Mean KL Divergence: 0.00087
SB3 Clip Fraction: 0.00037
Policy Update Magnitude: 0.03230
Value Function Update Magnitude: 0.02216

Collected Steps per Second: 12759.83694
Overall Steps per Second: 10416.75354

Timestep Collection Time: 3.92105
Timestep Consumption Time: 0.88198
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 4.80303

Cumulative Model Updates: 210
Cumulative Timesteps: 3551524

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02395
Policy Entropy: 0.82970
Value Function Loss: 0.06995

Mean KL Divergence: 0.00081
SB3 Clip Fraction: 0.00067
Policy Update Magnitude: 0.03585
Value Function Update Magnitude: 0.01702

Collected Steps per Second: 12918.18927
Overall Steps per Second: 10474.89919

Timestep Collection Time: 3.87113
Timestep Consumption Time: 0.90295
PPO Batch Consumption Time: 0.02561
Total Iteration Time: 4.77408

Cumulative Model Updates: 213
Cumulative Timesteps: 3601532

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 3601532...
Checkpoint 3601532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01342
Policy Entropy: 0.81086
Value Function Loss: 0.08856

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01991
Policy Update Magnitude: 0.03709
Value Function Update Magnitude: 0.01889

Collected Steps per Second: 12624.00516
Overall Steps per Second: 10212.81298

Timestep Collection Time: 3.96087
Timestep Consumption Time: 0.93514
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 4.89601

Cumulative Model Updates: 216
Cumulative Timesteps: 3651534

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03073
Policy Entropy: 0.79790
Value Function Loss: 0.09720

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05389
Policy Update Magnitude: 0.03229
Value Function Update Magnitude: 0.01638

Collected Steps per Second: 13287.34101
Overall Steps per Second: 10657.92918

Timestep Collection Time: 3.76449
Timestep Consumption Time: 0.92873
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 4.69322

Cumulative Model Updates: 219
Cumulative Timesteps: 3701554

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 3701554...
Checkpoint 3701554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01220
Policy Entropy: 0.79641
Value Function Loss: 0.06574

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.03461
Value Function Update Magnitude: 0.01916

Collected Steps per Second: 12493.23097
Overall Steps per Second: 9967.78093

Timestep Collection Time: 4.00249
Timestep Consumption Time: 1.01408
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 5.01656

Cumulative Model Updates: 222
Cumulative Timesteps: 3751558

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01382
Policy Entropy: 0.78253
Value Function Loss: 0.04976

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.00615
Policy Update Magnitude: 0.04082
Value Function Update Magnitude: 0.01444

Collected Steps per Second: 11283.78105
Overall Steps per Second: 9458.70506

Timestep Collection Time: 4.43486
Timestep Consumption Time: 0.85572
PPO Batch Consumption Time: 0.02882
Total Iteration Time: 5.29058

Cumulative Model Updates: 225
Cumulative Timesteps: 3801600

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 3801600...
Checkpoint 3801600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01404
Policy Entropy: 0.76741
Value Function Loss: 0.04101

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05783
Policy Update Magnitude: 0.03266
Value Function Update Magnitude: 0.01813

Collected Steps per Second: 12285.22634
Overall Steps per Second: 9968.27519

Timestep Collection Time: 4.07302
Timestep Consumption Time: 0.94670
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 5.01972

Cumulative Model Updates: 228
Cumulative Timesteps: 3851638

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02546
Policy Entropy: 0.77687
Value Function Loss: 0.06536

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.00923
Policy Update Magnitude: 0.03684
Value Function Update Magnitude: 0.01404

Collected Steps per Second: 12290.70023
Overall Steps per Second: 10015.63685

Timestep Collection Time: 4.06909
Timestep Consumption Time: 0.92430
PPO Batch Consumption Time: 0.02931
Total Iteration Time: 4.99339

Cumulative Model Updates: 231
Cumulative Timesteps: 3901650

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 3901650...
Checkpoint 3901650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00547
Policy Entropy: 0.79293
Value Function Loss: 0.06652

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.03353
Value Function Update Magnitude: 0.01731

Collected Steps per Second: 12681.26609
Overall Steps per Second: 10234.85351

Timestep Collection Time: 3.94314
Timestep Consumption Time: 0.94252
PPO Batch Consumption Time: 0.02904
Total Iteration Time: 4.88566

Cumulative Model Updates: 234
Cumulative Timesteps: 3951654

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02960
Policy Entropy: 0.79107
Value Function Loss: 0.08120

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.00703
Policy Update Magnitude: 0.03859
Value Function Update Magnitude: 0.01483

Collected Steps per Second: 12488.79022
Overall Steps per Second: 9995.78247

Timestep Collection Time: 4.00519
Timestep Consumption Time: 0.99892
PPO Batch Consumption Time: 0.02828
Total Iteration Time: 5.00411

Cumulative Model Updates: 237
Cumulative Timesteps: 4001674

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 4001674...
Checkpoint 4001674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00496
Policy Entropy: 0.77585
Value Function Loss: 0.05768

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.01096
Policy Update Magnitude: 0.03672
Value Function Update Magnitude: 0.01840

Collected Steps per Second: 12057.42768
Overall Steps per Second: 9956.41496

Timestep Collection Time: 4.14682
Timestep Consumption Time: 0.87507
PPO Batch Consumption Time: 0.02972
Total Iteration Time: 5.02189

Cumulative Model Updates: 240
Cumulative Timesteps: 4051674

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04025
Policy Entropy: 0.77230
Value Function Loss: 0.05923

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.01687
Policy Update Magnitude: 0.03611
Value Function Update Magnitude: 0.01490

Collected Steps per Second: 12470.16509
Overall Steps per Second: 10043.71682

Timestep Collection Time: 4.01149
Timestep Consumption Time: 0.96913
PPO Batch Consumption Time: 0.02822
Total Iteration Time: 4.98063

Cumulative Model Updates: 243
Cumulative Timesteps: 4101698

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 4101698...
Checkpoint 4101698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05873
Policy Entropy: 0.77937
Value Function Loss: 0.05332

Mean KL Divergence: 0.00097
SB3 Clip Fraction: 0.00060
Policy Update Magnitude: 0.03658
Value Function Update Magnitude: 0.01879

Collected Steps per Second: 12756.00074
Overall Steps per Second: 10345.48097

Timestep Collection Time: 3.92019
Timestep Consumption Time: 0.91341
PPO Batch Consumption Time: 0.02931
Total Iteration Time: 4.83361

Cumulative Model Updates: 246
Cumulative Timesteps: 4151704

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03604
Policy Entropy: 0.78063
Value Function Loss: 0.04992

Mean KL Divergence: 0.00126
SB3 Clip Fraction: 0.00259
Policy Update Magnitude: 0.03752
Value Function Update Magnitude: 0.01608

Collected Steps per Second: 12769.81240
Overall Steps per Second: 10288.26321

Timestep Collection Time: 3.91689
Timestep Consumption Time: 0.94476
PPO Batch Consumption Time: 0.03145
Total Iteration Time: 4.86166

Cumulative Model Updates: 249
Cumulative Timesteps: 4201722

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 4201722...
Checkpoint 4201722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02991
Policy Entropy: 0.76929
Value Function Loss: 0.06712

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.00390
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.01956

Collected Steps per Second: 12013.36381
Overall Steps per Second: 9802.90193

Timestep Collection Time: 4.16470
Timestep Consumption Time: 0.93910
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 5.10379

Cumulative Model Updates: 252
Cumulative Timesteps: 4251754

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01446
Policy Entropy: 0.76165
Value Function Loss: 0.06745

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02200
Policy Update Magnitude: 0.03882
Value Function Update Magnitude: 0.01781

Collected Steps per Second: 12458.50674
Overall Steps per Second: 10283.70784

Timestep Collection Time: 4.01605
Timestep Consumption Time: 0.84931
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 4.86537

Cumulative Model Updates: 255
Cumulative Timesteps: 4301788

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 4301788...
Checkpoint 4301788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04138
Policy Entropy: 0.75941
Value Function Loss: 0.08455

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.01551
Policy Update Magnitude: 0.03864
Value Function Update Magnitude: 0.02115

Collected Steps per Second: 12506.53071
Overall Steps per Second: 10143.26943

Timestep Collection Time: 3.99807
Timestep Consumption Time: 0.93150
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 4.92957

Cumulative Model Updates: 258
Cumulative Timesteps: 4351790

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05118
Policy Entropy: 0.74609
Value Function Loss: 0.10592

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.00839
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.01590

Collected Steps per Second: 12006.79535
Overall Steps per Second: 9826.07684

Timestep Collection Time: 4.16647
Timestep Consumption Time: 0.92467
PPO Batch Consumption Time: 0.02930
Total Iteration Time: 5.09115

Cumulative Model Updates: 261
Cumulative Timesteps: 4401816

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 4401816...
Checkpoint 4401816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00762
Policy Entropy: 0.72300
Value Function Loss: 0.09569

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.02106

Collected Steps per Second: 12418.62119
Overall Steps per Second: 10099.42553

Timestep Collection Time: 4.02686
Timestep Consumption Time: 0.92471
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 4.95157

Cumulative Model Updates: 264
Cumulative Timesteps: 4451824

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01630
Policy Entropy: 0.72265
Value Function Loss: 0.08706

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.04336
Value Function Update Magnitude: 0.02095

Collected Steps per Second: 12518.52766
Overall Steps per Second: 10049.42058

Timestep Collection Time: 3.99552
Timestep Consumption Time: 0.98168
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 4.97720

Cumulative Model Updates: 267
Cumulative Timesteps: 4501842

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 4501842...
Checkpoint 4501842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01155
Policy Entropy: 0.73176
Value Function Loss: 0.03768

Mean KL Divergence: 0.00131
SB3 Clip Fraction: 0.00321
Policy Update Magnitude: 0.03669
Value Function Update Magnitude: 0.02127

Collected Steps per Second: 12394.49876
Overall Steps per Second: 10256.02706

Timestep Collection Time: 4.03582
Timestep Consumption Time: 0.84150
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 4.87733

Cumulative Model Updates: 270
Cumulative Timesteps: 4551864

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00597
Policy Entropy: 0.72715
Value Function Loss: 0.05189

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00227
Policy Update Magnitude: 0.03703
Value Function Update Magnitude: 0.01546

Collected Steps per Second: 12372.04190
Overall Steps per Second: 9990.27479

Timestep Collection Time: 4.04476
Timestep Consumption Time: 0.96431
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 5.00907

Cumulative Model Updates: 273
Cumulative Timesteps: 4601906

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 4601906...
Checkpoint 4601906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01484
Policy Entropy: 0.71174
Value Function Loss: 0.05407

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.00850
Policy Update Magnitude: 0.03253
Value Function Update Magnitude: 0.01727

Collected Steps per Second: 12619.57371
Overall Steps per Second: 10223.42654

Timestep Collection Time: 3.96273
Timestep Consumption Time: 0.92878
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 4.89151

Cumulative Model Updates: 276
Cumulative Timesteps: 4651914

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01723
Policy Entropy: 0.70761
Value Function Loss: 0.07233

Mean KL Divergence: 0.00218
SB3 Clip Fraction: 0.01601
Policy Update Magnitude: 0.03246
Value Function Update Magnitude: 0.01482

Collected Steps per Second: 11957.74755
Overall Steps per Second: 9767.63472

Timestep Collection Time: 4.18223
Timestep Consumption Time: 0.93774
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 5.11997

Cumulative Model Updates: 279
Cumulative Timesteps: 4701924

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 4701924...
Checkpoint 4701924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03311
Policy Entropy: 0.71711
Value Function Loss: 0.09467

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.00307
Policy Update Magnitude: 0.03530
Value Function Update Magnitude: 0.02159

Collected Steps per Second: 12475.82722
Overall Steps per Second: 10114.03814

Timestep Collection Time: 4.01080
Timestep Consumption Time: 0.93658
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 4.94738

Cumulative Model Updates: 282
Cumulative Timesteps: 4751962

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03807
Policy Entropy: 0.72777
Value Function Loss: 0.08596

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01353
Policy Update Magnitude: 0.03299
Value Function Update Magnitude: 0.01774

Collected Steps per Second: 12616.55119
Overall Steps per Second: 10361.85377

Timestep Collection Time: 3.96368
Timestep Consumption Time: 0.86248
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 4.82616

Cumulative Model Updates: 285
Cumulative Timesteps: 4801970

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 4801970...
Checkpoint 4801970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01289
Policy Entropy: 0.73056
Value Function Loss: 0.06453

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.00572
Policy Update Magnitude: 0.03479
Value Function Update Magnitude: 0.02156

Collected Steps per Second: 12616.92906
Overall Steps per Second: 10244.47952

Timestep Collection Time: 3.96372
Timestep Consumption Time: 0.91793
PPO Batch Consumption Time: 0.02795
Total Iteration Time: 4.88165

Cumulative Model Updates: 288
Cumulative Timesteps: 4851980

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02684
Policy Entropy: 0.73870
Value Function Loss: 0.02789

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.00392
Policy Update Magnitude: 0.03689
Value Function Update Magnitude: 0.01981

Collected Steps per Second: 12011.71800
Overall Steps per Second: 9827.01592

Timestep Collection Time: 4.16393
Timestep Consumption Time: 0.92571
PPO Batch Consumption Time: 0.02822
Total Iteration Time: 5.08964

Cumulative Model Updates: 291
Cumulative Timesteps: 4901996

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 4901996...
Checkpoint 4901996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00343
Policy Entropy: 0.75366
Value Function Loss: 0.03604

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01519
Policy Update Magnitude: 0.03103
Value Function Update Magnitude: 0.02354

Collected Steps per Second: 12906.74829
Overall Steps per Second: 10398.20595

Timestep Collection Time: 3.87549
Timestep Consumption Time: 0.93495
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 4.81045

Cumulative Model Updates: 294
Cumulative Timesteps: 4952016

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04268
Policy Entropy: 0.75948
Value Function Loss: 0.05472

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.01076
Policy Update Magnitude: 0.02916
Value Function Update Magnitude: 0.01744

Collected Steps per Second: 12454.45223
Overall Steps per Second: 10063.01281

Timestep Collection Time: 4.01607
Timestep Consumption Time: 0.95441
PPO Batch Consumption Time: 0.03017
Total Iteration Time: 4.97048

Cumulative Model Updates: 297
Cumulative Timesteps: 5002034

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 5002034...
Checkpoint 5002034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02439
Policy Entropy: 0.75556
Value Function Loss: 0.07919

Mean KL Divergence: 0.00116
SB3 Clip Fraction: 0.00145
Policy Update Magnitude: 0.03176
Value Function Update Magnitude: 0.02184

Collected Steps per Second: 12529.86325
Overall Steps per Second: 10153.49633

Timestep Collection Time: 3.99382
Timestep Consumption Time: 0.93473
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 4.92855

Cumulative Model Updates: 300
Cumulative Timesteps: 5052076

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02282
Policy Entropy: 0.75746
Value Function Loss: 0.05991

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.00701
Policy Update Magnitude: 0.03528
Value Function Update Magnitude: 0.01972

Collected Steps per Second: 12042.68466
Overall Steps per Second: 9717.49189

Timestep Collection Time: 4.15240
Timestep Consumption Time: 0.99358
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 5.14598

Cumulative Model Updates: 303
Cumulative Timesteps: 5102082

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 5102082...
Checkpoint 5102082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02069
Policy Entropy: 0.76604
Value Function Loss: 0.05407

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.00939
Policy Update Magnitude: 0.03672
Value Function Update Magnitude: 0.02427

Collected Steps per Second: 11756.63778
Overall Steps per Second: 9582.12903

Timestep Collection Time: 4.25394
Timestep Consumption Time: 0.96536
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 5.21930

Cumulative Model Updates: 306
Cumulative Timesteps: 5152094

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04951
Policy Entropy: 0.76426
Value Function Loss: 0.04487

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.00373
Policy Update Magnitude: 0.03776
Value Function Update Magnitude: 0.02297

Collected Steps per Second: 12286.18783
Overall Steps per Second: 10079.17619

Timestep Collection Time: 4.07108
Timestep Consumption Time: 0.89143
PPO Batch Consumption Time: 0.02935
Total Iteration Time: 4.96251

Cumulative Model Updates: 309
Cumulative Timesteps: 5202112

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 5202112...
Checkpoint 5202112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00917
Policy Entropy: 0.75047
Value Function Loss: 0.06632

Mean KL Divergence: 0.00137
SB3 Clip Fraction: 0.00195
Policy Update Magnitude: 0.03775
Value Function Update Magnitude: 0.02792

Collected Steps per Second: 12331.08872
Overall Steps per Second: 9992.77220

Timestep Collection Time: 4.05804
Timestep Consumption Time: 0.94958
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 5.00762

Cumulative Model Updates: 312
Cumulative Timesteps: 5252152

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03022
Policy Entropy: 0.74125
Value Function Loss: 0.06699

Mean KL Divergence: 0.00160
SB3 Clip Fraction: 0.00497
Policy Update Magnitude: 0.03951
Value Function Update Magnitude: 0.02072

Collected Steps per Second: 11969.68125
Overall Steps per Second: 9715.82559

Timestep Collection Time: 4.17839
Timestep Consumption Time: 0.96929
PPO Batch Consumption Time: 0.03171
Total Iteration Time: 5.14768

Cumulative Model Updates: 315
Cumulative Timesteps: 5302166

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 5302166...
Checkpoint 5302166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04336
Policy Entropy: 0.73863
Value Function Loss: 0.06054

Mean KL Divergence: 0.00132
SB3 Clip Fraction: 0.00279
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.02365

Collected Steps per Second: 12165.81929
Overall Steps per Second: 9883.71359

Timestep Collection Time: 4.11037
Timestep Consumption Time: 0.94907
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 5.05943

Cumulative Model Updates: 318
Cumulative Timesteps: 5352172

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00845
Policy Entropy: 0.72730
Value Function Loss: 0.05770

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.01509
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.01872

Collected Steps per Second: 12690.28032
Overall Steps per Second: 10232.44195

Timestep Collection Time: 3.94207
Timestep Consumption Time: 0.94689
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 4.88896

Cumulative Model Updates: 321
Cumulative Timesteps: 5402198

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 5402198...
Checkpoint 5402198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00626
Policy Entropy: 0.71632
Value Function Loss: 0.07548

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 0.04363
Value Function Update Magnitude: 0.02180

Collected Steps per Second: 11984.23830
Overall Steps per Second: 9874.42507

Timestep Collection Time: 4.17265
Timestep Consumption Time: 0.89155
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 5.06419

Cumulative Model Updates: 324
Cumulative Timesteps: 5452204

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03849
Policy Entropy: 0.72062
Value Function Loss: 0.08518

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.00477
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.02197

Collected Steps per Second: 10948.40504
Overall Steps per Second: 9046.58527

Timestep Collection Time: 4.57071
Timestep Consumption Time: 0.96088
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 5.53159

Cumulative Model Updates: 327
Cumulative Timesteps: 5502246

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 5502246...
Checkpoint 5502246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09713
Policy Entropy: 0.72369
Value Function Loss: 0.09457

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01575
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.02561

Collected Steps per Second: 11901.57435
Overall Steps per Second: 9737.17611

Timestep Collection Time: 4.20112
Timestep Consumption Time: 0.93383
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 5.13496

Cumulative Model Updates: 330
Cumulative Timesteps: 5552246

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03380
Policy Entropy: 0.71175
Value Function Loss: 0.07340

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05048
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.02214

Collected Steps per Second: 12724.84804
Overall Steps per Second: 10281.82352

Timestep Collection Time: 3.92948
Timestep Consumption Time: 0.93367
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 4.86315

Cumulative Model Updates: 333
Cumulative Timesteps: 5602248

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 5602248...
Checkpoint 5602248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02512
Policy Entropy: 0.71018
Value Function Loss: 0.06666

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.00975
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.02422

Collected Steps per Second: 12492.19614
Overall Steps per Second: 10101.56216

Timestep Collection Time: 4.00666
Timestep Consumption Time: 0.94822
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 4.95488

Cumulative Model Updates: 336
Cumulative Timesteps: 5652300

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00028
Policy Entropy: 0.72391
Value Function Loss: 0.06027

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.01893

Collected Steps per Second: 12428.12799
Overall Steps per Second: 10246.32618

Timestep Collection Time: 4.02329
Timestep Consumption Time: 0.85670
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 4.87999

Cumulative Model Updates: 339
Cumulative Timesteps: 5702302

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 5702302...
Checkpoint 5702302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03146
Policy Entropy: 0.72855
Value Function Loss: 0.06835

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03391
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.02107

Collected Steps per Second: 12446.84442
Overall Steps per Second: 9994.97831

Timestep Collection Time: 4.02062
Timestep Consumption Time: 0.98630
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 5.00691

Cumulative Model Updates: 342
Cumulative Timesteps: 5752346

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07985
Policy Entropy: 0.71360
Value Function Loss: 0.08649

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.01746
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.01895

Collected Steps per Second: 12514.39092
Overall Steps per Second: 10209.84971

Timestep Collection Time: 3.99540
Timestep Consumption Time: 0.90183
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 4.89723

Cumulative Model Updates: 345
Cumulative Timesteps: 5802346

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 5802346...
Checkpoint 5802346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00750
Policy Entropy: 0.71129
Value Function Loss: 0.08676

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.03817
Policy Update Magnitude: 0.04229
Value Function Update Magnitude: 0.02247

Collected Steps per Second: 12574.91854
Overall Steps per Second: 10166.59870

Timestep Collection Time: 3.97887
Timestep Consumption Time: 0.94254
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 4.92141

Cumulative Model Updates: 348
Cumulative Timesteps: 5852380

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02786
Policy Entropy: 0.73512
Value Function Loss: 0.07764

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04464
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.02038

Collected Steps per Second: 11124.77775
Overall Steps per Second: 9051.72681

Timestep Collection Time: 4.49681
Timestep Consumption Time: 1.02987
PPO Batch Consumption Time: 0.02973
Total Iteration Time: 5.52668

Cumulative Model Updates: 351
Cumulative Timesteps: 5902406

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 5902406...
Checkpoint 5902406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02565
Policy Entropy: 0.74296
Value Function Loss: 0.05976

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04855
Policy Update Magnitude: 0.04486
Value Function Update Magnitude: 0.02305

Collected Steps per Second: 11993.81784
Overall Steps per Second: 9846.76949

Timestep Collection Time: 4.17032
Timestep Consumption Time: 0.90932
PPO Batch Consumption Time: 0.02866
Total Iteration Time: 5.07964

Cumulative Model Updates: 354
Cumulative Timesteps: 5952424

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06367
Policy Entropy: 0.72042
Value Function Loss: 0.05612

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05759
Policy Update Magnitude: 0.03788
Value Function Update Magnitude: 0.01894

Collected Steps per Second: 12648.35361
Overall Steps per Second: 10141.42984

Timestep Collection Time: 3.95735
Timestep Consumption Time: 0.97824
PPO Batch Consumption Time: 0.02983
Total Iteration Time: 4.93560

Cumulative Model Updates: 357
Cumulative Timesteps: 6002478

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 6002478...
Checkpoint 6002478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00530
Policy Entropy: 0.72620
Value Function Loss: 0.08846

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.03295
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.02411

Collected Steps per Second: 11994.71536
Overall Steps per Second: 9707.34262

Timestep Collection Time: 4.17117
Timestep Consumption Time: 0.98287
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 5.15404

Cumulative Model Updates: 360
Cumulative Timesteps: 6052510

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00880
Policy Entropy: 0.74333
Value Function Loss: 0.11540

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06388
Policy Update Magnitude: 0.04434
Value Function Update Magnitude: 0.02626

Collected Steps per Second: 11451.48180
Overall Steps per Second: 9346.56632

Timestep Collection Time: 4.36904
Timestep Consumption Time: 0.98394
PPO Batch Consumption Time: 0.03052
Total Iteration Time: 5.35298

Cumulative Model Updates: 363
Cumulative Timesteps: 6102542

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 6102542...
Checkpoint 6102542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03079
Policy Entropy: 0.71651
Value Function Loss: 0.14211

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06427
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.03614

Collected Steps per Second: 10907.44717
Overall Steps per Second: 8947.23829

Timestep Collection Time: 4.58641
Timestep Consumption Time: 1.00481
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 5.59122

Cumulative Model Updates: 366
Cumulative Timesteps: 6152568

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03559
Policy Entropy: 0.70098
Value Function Loss: 0.13667

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.03819

Collected Steps per Second: 11340.76954
Overall Steps per Second: 9317.26442

Timestep Collection Time: 4.41046
Timestep Consumption Time: 0.95785
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 5.36831

Cumulative Model Updates: 369
Cumulative Timesteps: 6202586

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 6202586...
Checkpoint 6202586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00331
Policy Entropy: 0.71663
Value Function Loss: 0.11901

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.05279
Value Function Update Magnitude: 0.04286

Collected Steps per Second: 12232.93733
Overall Steps per Second: 9936.01008

Timestep Collection Time: 4.08749
Timestep Consumption Time: 0.94491
PPO Batch Consumption Time: 0.02914
Total Iteration Time: 5.03240

Cumulative Model Updates: 372
Cumulative Timesteps: 6252588

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03580
Policy Entropy: 0.70475
Value Function Loss: 0.09390

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03059
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.03470

Collected Steps per Second: 12555.56879
Overall Steps per Second: 10159.25177

Timestep Collection Time: 3.98469
Timestep Consumption Time: 0.93989
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 4.92458

Cumulative Model Updates: 375
Cumulative Timesteps: 6302618

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 6302618...
Checkpoint 6302618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04692
Policy Entropy: 0.69542
Value Function Loss: 0.09253

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05685
Policy Update Magnitude: 0.04458
Value Function Update Magnitude: 0.03097

Collected Steps per Second: 10470.28068
Overall Steps per Second: 8691.78253

Timestep Collection Time: 4.77771
Timestep Consumption Time: 0.97761
PPO Batch Consumption Time: 0.03136
Total Iteration Time: 5.75532

Cumulative Model Updates: 378
Cumulative Timesteps: 6352642

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00145
Policy Entropy: 0.70745
Value Function Loss: 0.10393

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.01213
Policy Update Magnitude: 0.04513
Value Function Update Magnitude: 0.02772

Collected Steps per Second: 10512.80037
Overall Steps per Second: 8617.28417

Timestep Collection Time: 4.75991
Timestep Consumption Time: 1.04702
PPO Batch Consumption Time: 0.03257
Total Iteration Time: 5.80693

Cumulative Model Updates: 381
Cumulative Timesteps: 6402682

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 6402682...
Checkpoint 6402682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00064
Policy Entropy: 0.71360
Value Function Loss: 0.09281

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.03118

Collected Steps per Second: 12135.25154
Overall Steps per Second: 9956.15012

Timestep Collection Time: 4.12303
Timestep Consumption Time: 0.90241
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 5.02544

Cumulative Model Updates: 384
Cumulative Timesteps: 6452716

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16766
Policy Entropy: 0.71202
Value Function Loss: 0.10709

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.00665
Policy Update Magnitude: 0.04947
Value Function Update Magnitude: 0.02882

Collected Steps per Second: 12869.34125
Overall Steps per Second: 10414.11123

Timestep Collection Time: 3.88536
Timestep Consumption Time: 0.91601
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 4.80137

Cumulative Model Updates: 387
Cumulative Timesteps: 6502718

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 6502718...
Checkpoint 6502718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04924
Policy Entropy: 0.71546
Value Function Loss: 0.11693

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.03867

Collected Steps per Second: 12875.19539
Overall Steps per Second: 10389.93293

Timestep Collection Time: 3.88344
Timestep Consumption Time: 0.92891
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 4.81235

Cumulative Model Updates: 390
Cumulative Timesteps: 6552718

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01893
Policy Entropy: 0.71836
Value Function Loss: 0.12852

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01901
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.04104

Collected Steps per Second: 12311.35047
Overall Steps per Second: 10044.38742

Timestep Collection Time: 4.06503
Timestep Consumption Time: 0.91745
PPO Batch Consumption Time: 0.02954
Total Iteration Time: 4.98248

Cumulative Model Updates: 393
Cumulative Timesteps: 6602764

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 6602764...
Checkpoint 6602764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04886
Policy Entropy: 0.71947
Value Function Loss: 0.11547

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01747
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.04995

Collected Steps per Second: 13081.71787
Overall Steps per Second: 10539.91038

Timestep Collection Time: 3.82564
Timestep Consumption Time: 0.92259
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 4.74824

Cumulative Model Updates: 396
Cumulative Timesteps: 6652810

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07393
Policy Entropy: 0.72629
Value Function Loss: 0.10940

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.03602

Collected Steps per Second: 12886.69805
Overall Steps per Second: 10435.99657

Timestep Collection Time: 3.88044
Timestep Consumption Time: 0.91125
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 4.79168

Cumulative Model Updates: 399
Cumulative Timesteps: 6702816

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 6702816...
Checkpoint 6702816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02731
Policy Entropy: 0.73948
Value Function Loss: 0.11005

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.03782
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.03703

Collected Steps per Second: 12882.42977
Overall Steps per Second: 10606.62320

Timestep Collection Time: 3.88141
Timestep Consumption Time: 0.83281
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 4.71422

Cumulative Model Updates: 402
Cumulative Timesteps: 6752818

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04236
Policy Entropy: 0.74435
Value Function Loss: 0.09942

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.03396

Collected Steps per Second: 13301.95092
Overall Steps per Second: 10571.10664

Timestep Collection Time: 3.76005
Timestep Consumption Time: 0.97134
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 4.73139

Cumulative Model Updates: 405
Cumulative Timesteps: 6802834

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 6802834...
Checkpoint 6802834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02131
Policy Entropy: 0.75179
Value Function Loss: 0.10639

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01451
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.03401

Collected Steps per Second: 12920.65673
Overall Steps per Second: 10476.60722

Timestep Collection Time: 3.87271
Timestep Consumption Time: 0.90345
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 4.77616

Cumulative Model Updates: 408
Cumulative Timesteps: 6852872

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03258
Policy Entropy: 0.78199
Value Function Loss: 0.10927

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.03110

Collected Steps per Second: 13363.93664
Overall Steps per Second: 10750.98078

Timestep Collection Time: 3.74141
Timestep Consumption Time: 0.90933
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 4.65074

Cumulative Model Updates: 411
Cumulative Timesteps: 6902872

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 6902872...
Checkpoint 6902872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01518
Policy Entropy: 0.78523
Value Function Loss: 0.09212

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05425
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.03383

Collected Steps per Second: 12791.21467
Overall Steps per Second: 10341.07156

Timestep Collection Time: 3.90909
Timestep Consumption Time: 0.92619
PPO Batch Consumption Time: 0.02881
Total Iteration Time: 4.83528

Cumulative Model Updates: 414
Cumulative Timesteps: 6952874

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05478
Policy Entropy: 0.77368
Value Function Loss: 0.07344

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.00721
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.02705

Collected Steps per Second: 13260.23100
Overall Steps per Second: 10819.03940

Timestep Collection Time: 3.77067
Timestep Consumption Time: 0.85081
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 4.62148

Cumulative Model Updates: 417
Cumulative Timesteps: 7002874

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 7002874...
Checkpoint 7002874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02568
Policy Entropy: 0.78901
Value Function Loss: 0.06462

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02070
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.03331

Collected Steps per Second: 12878.71926
Overall Steps per Second: 10399.56730

Timestep Collection Time: 3.88626
Timestep Consumption Time: 0.92644
PPO Batch Consumption Time: 0.02862
Total Iteration Time: 4.81270

Cumulative Model Updates: 420
Cumulative Timesteps: 7052924

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01624
Policy Entropy: 0.81365
Value Function Loss: 0.05869

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.02873

Collected Steps per Second: 12990.24260
Overall Steps per Second: 10545.55094

Timestep Collection Time: 3.85012
Timestep Consumption Time: 0.89254
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 4.74266

Cumulative Model Updates: 423
Cumulative Timesteps: 7102938

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 7102938...
Checkpoint 7102938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01305
Policy Entropy: 0.79902
Value Function Loss: 0.04079

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02383
Policy Update Magnitude: 0.05742
Value Function Update Magnitude: 0.03062

Collected Steps per Second: 13383.69938
Overall Steps per Second: 10771.30033

Timestep Collection Time: 3.73798
Timestep Consumption Time: 0.90658
PPO Batch Consumption Time: 0.02933
Total Iteration Time: 4.64456

Cumulative Model Updates: 426
Cumulative Timesteps: 7152966

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02368
Policy Entropy: 0.80533
Value Function Loss: 0.04632

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.06113
Value Function Update Magnitude: 0.02966

Collected Steps per Second: 13018.01269
Overall Steps per Second: 10499.12220

Timestep Collection Time: 3.84237
Timestep Consumption Time: 0.92184
PPO Batch Consumption Time: 0.02964
Total Iteration Time: 4.76421

Cumulative Model Updates: 429
Cumulative Timesteps: 7202986

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 7202986...
Checkpoint 7202986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01179
Policy Entropy: 0.83890
Value Function Loss: 0.07099

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.03063

Collected Steps per Second: 12559.86197
Overall Steps per Second: 10220.94453

Timestep Collection Time: 3.98109
Timestep Consumption Time: 0.91102
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 4.89211

Cumulative Model Updates: 432
Cumulative Timesteps: 7252988

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03706
Policy Entropy: 0.82385
Value Function Loss: 0.10101

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.02642

Collected Steps per Second: 13120.01617
Overall Steps per Second: 10518.65692

Timestep Collection Time: 3.81189
Timestep Consumption Time: 0.94271
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 4.75460

Cumulative Model Updates: 435
Cumulative Timesteps: 7303000

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 7303000...
Checkpoint 7303000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00406
Policy Entropy: 0.81142
Value Function Loss: 0.08849

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04710
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.03295

Collected Steps per Second: 12903.91040
Overall Steps per Second: 10405.20733

Timestep Collection Time: 3.87495
Timestep Consumption Time: 0.93053
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 4.80548

Cumulative Model Updates: 438
Cumulative Timesteps: 7353002

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00300
Policy Entropy: 0.82745
Value Function Loss: 0.07672

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.00917
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.03119

Collected Steps per Second: 12942.79452
Overall Steps per Second: 10645.49604

Timestep Collection Time: 3.86578
Timestep Consumption Time: 0.83424
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 4.70002

Cumulative Model Updates: 441
Cumulative Timesteps: 7403036

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 7403036...
Checkpoint 7403036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02359
Policy Entropy: 0.81677
Value Function Loss: 0.07592

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.01028
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.02865

Collected Steps per Second: 13051.14746
Overall Steps per Second: 10505.78876

Timestep Collection Time: 3.83353
Timestep Consumption Time: 0.92879
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 4.76233

Cumulative Model Updates: 444
Cumulative Timesteps: 7453068

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03911
Policy Entropy: 0.82066
Value Function Loss: 0.08772

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.00689
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.02503

Collected Steps per Second: 12886.97219
Overall Steps per Second: 10282.19306

Timestep Collection Time: 3.88144
Timestep Consumption Time: 0.98328
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 4.86472

Cumulative Model Updates: 447
Cumulative Timesteps: 7503088

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 7503088...
Checkpoint 7503088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03801
Policy Entropy: 0.83717
Value Function Loss: 0.07924

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03123
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.02730

Collected Steps per Second: 13335.50025
Overall Steps per Second: 10719.57473

Timestep Collection Time: 3.75209
Timestep Consumption Time: 0.91563
PPO Batch Consumption Time: 0.03018
Total Iteration Time: 4.66772

Cumulative Model Updates: 450
Cumulative Timesteps: 7553124

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01429
Policy Entropy: 0.80605
Value Function Loss: 0.05605

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04827
Policy Update Magnitude: 0.05064
Value Function Update Magnitude: 0.02255

Collected Steps per Second: 12990.42619
Overall Steps per Second: 10487.40520

Timestep Collection Time: 3.85207
Timestep Consumption Time: 0.91937
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 4.77144

Cumulative Model Updates: 453
Cumulative Timesteps: 7603164

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 7603164...
Checkpoint 7603164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00621
Policy Entropy: 0.81966
Value Function Loss: 0.05440

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04045
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.02729

Collected Steps per Second: 13338.49232
Overall Steps per Second: 10934.86322

Timestep Collection Time: 3.75050
Timestep Consumption Time: 0.82441
PPO Batch Consumption Time: 0.02894
Total Iteration Time: 4.57491

Cumulative Model Updates: 456
Cumulative Timesteps: 7653190

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02162
Policy Entropy: 0.83374
Value Function Loss: 0.08002

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.02895

Collected Steps per Second: 12881.71733
Overall Steps per Second: 10404.69649

Timestep Collection Time: 3.88256
Timestep Consumption Time: 0.92431
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 4.80687

Cumulative Model Updates: 459
Cumulative Timesteps: 7703204

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 7703204...
Checkpoint 7703204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04522
Policy Entropy: 0.80335
Value Function Loss: 0.09774

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.05025
Value Function Update Magnitude: 0.04206

Collected Steps per Second: 11463.57753
Overall Steps per Second: 9522.74107

Timestep Collection Time: 4.36373
Timestep Consumption Time: 0.88938
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 5.25311

Cumulative Model Updates: 462
Cumulative Timesteps: 7753228

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02707
Policy Entropy: 0.80528
Value Function Loss: 0.09635

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.07061
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.04708

Collected Steps per Second: 13030.04649
Overall Steps per Second: 10459.87638

Timestep Collection Time: 3.84097
Timestep Consumption Time: 0.94379
PPO Batch Consumption Time: 0.02869
Total Iteration Time: 4.78476

Cumulative Model Updates: 465
Cumulative Timesteps: 7803276

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 7803276...
Checkpoint 7803276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00531
Policy Entropy: 0.80857
Value Function Loss: 0.08149

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.01442
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.03979

Collected Steps per Second: 13015.41962
Overall Steps per Second: 10420.80791

Timestep Collection Time: 3.84375
Timestep Consumption Time: 0.95703
PPO Batch Consumption Time: 0.03589
Total Iteration Time: 4.80078

Cumulative Model Updates: 468
Cumulative Timesteps: 7853304

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01358
Policy Entropy: 0.79380
Value Function Loss: 0.06539

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.01149
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.02960

Collected Steps per Second: 13070.36265
Overall Steps per Second: 10689.42410

Timestep Collection Time: 3.82805
Timestep Consumption Time: 0.85265
PPO Batch Consumption Time: 0.03086
Total Iteration Time: 4.68070

Cumulative Model Updates: 471
Cumulative Timesteps: 7903338

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 7903338...
Checkpoint 7903338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04614
Policy Entropy: 0.79365
Value Function Loss: 0.06254

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.00828
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.02851

Collected Steps per Second: 13035.39418
Overall Steps per Second: 10452.53017

Timestep Collection Time: 3.83847
Timestep Consumption Time: 0.94850
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 4.78697

Cumulative Model Updates: 474
Cumulative Timesteps: 7953374

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00574
Policy Entropy: 0.78238
Value Function Loss: 0.04495

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.00881
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.02484

Collected Steps per Second: 12148.63456
Overall Steps per Second: 9960.00091

Timestep Collection Time: 4.11964
Timestep Consumption Time: 0.90526
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 5.02490

Cumulative Model Updates: 477
Cumulative Timesteps: 8003422

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 8003422...
Checkpoint 8003422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09082
Policy Entropy: 0.78772
Value Function Loss: 0.08450

Mean KL Divergence: 0.00166
SB3 Clip Fraction: 0.00515
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.02824

Collected Steps per Second: 13305.13823
Overall Steps per Second: 10732.90699

Timestep Collection Time: 3.75945
Timestep Consumption Time: 0.90098
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 4.66043

Cumulative Model Updates: 480
Cumulative Timesteps: 8053442

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06279
Policy Entropy: 0.81234
Value Function Loss: 0.08538

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.04659
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.02826

Collected Steps per Second: 13230.37529
Overall Steps per Second: 10684.38334

Timestep Collection Time: 3.78024
Timestep Consumption Time: 0.90080
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 4.68104

Cumulative Model Updates: 483
Cumulative Timesteps: 8103456

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 8103456...
Checkpoint 8103456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01998
Policy Entropy: 0.79459
Value Function Loss: 0.08274

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04956
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.03498

Collected Steps per Second: 13252.65271
Overall Steps per Second: 10810.69459

Timestep Collection Time: 3.77600
Timestep Consumption Time: 0.85294
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 4.62893

Cumulative Model Updates: 486
Cumulative Timesteps: 8153498

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02155
Policy Entropy: 0.78550
Value Function Loss: 0.04198

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05913
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.02961

Collected Steps per Second: 12659.58755
Overall Steps per Second: 10093.29505

Timestep Collection Time: 3.95084
Timestep Consumption Time: 1.00453
PPO Batch Consumption Time: 0.02883
Total Iteration Time: 4.95537

Cumulative Model Updates: 489
Cumulative Timesteps: 8203514

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 8203514...
Checkpoint 8203514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00961
Policy Entropy: 0.80563
Value Function Loss: 0.06534

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04521
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.02893

Collected Steps per Second: 12803.30965
Overall Steps per Second: 10389.74966

Timestep Collection Time: 3.90587
Timestep Consumption Time: 0.90734
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 4.81321

Cumulative Model Updates: 492
Cumulative Timesteps: 8253522

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02957
Policy Entropy: 0.78876
Value Function Loss: 0.09983

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.02925

Collected Steps per Second: 13223.49188
Overall Steps per Second: 10583.73283

Timestep Collection Time: 3.78191
Timestep Consumption Time: 0.94327
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 4.72518

Cumulative Model Updates: 495
Cumulative Timesteps: 8303532

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 8303532...
Checkpoint 8303532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00093
Policy Entropy: 0.78017
Value Function Loss: 0.10667

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05518
Policy Update Magnitude: 0.06222
Value Function Update Magnitude: 0.04129

Collected Steps per Second: 12901.83184
Overall Steps per Second: 10373.47979

Timestep Collection Time: 3.87945
Timestep Consumption Time: 0.94555
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 4.82500

Cumulative Model Updates: 498
Cumulative Timesteps: 8353584

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11508
Policy Entropy: 0.78864
Value Function Loss: 0.09341

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.00986
Policy Update Magnitude: 0.06257
Value Function Update Magnitude: 0.04080

Collected Steps per Second: 12504.86714
Overall Steps per Second: 9985.55630

Timestep Collection Time: 4.00004
Timestep Consumption Time: 1.00919
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 5.00924

Cumulative Model Updates: 501
Cumulative Timesteps: 8403604

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 8403604...
Checkpoint 8403604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01852
Policy Entropy: 0.77695
Value Function Loss: 0.08675

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01539
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.04627

Collected Steps per Second: 12066.11885
Overall Steps per Second: 9814.35884

Timestep Collection Time: 4.14549
Timestep Consumption Time: 0.95112
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 5.09661

Cumulative Model Updates: 504
Cumulative Timesteps: 8453624

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02314
Policy Entropy: 0.78908
Value Function Loss: 0.08714

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.04368

Collected Steps per Second: 13033.74282
Overall Steps per Second: 10335.87528

Timestep Collection Time: 3.84034
Timestep Consumption Time: 1.00240
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 4.84274

Cumulative Model Updates: 507
Cumulative Timesteps: 8503678

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 8503678...
Checkpoint 8503678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05991
Policy Entropy: 0.79846
Value Function Loss: 0.10578

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.01852
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.04946

Collected Steps per Second: 13289.98963
Overall Steps per Second: 10668.27411

Timestep Collection Time: 3.76223
Timestep Consumption Time: 0.92456
PPO Batch Consumption Time: 0.02973
Total Iteration Time: 4.68679

Cumulative Model Updates: 510
Cumulative Timesteps: 8553678

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01341
Policy Entropy: 0.78297
Value Function Loss: 0.07888

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04267
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.03987

Collected Steps per Second: 12940.05596
Overall Steps per Second: 10447.82889

Timestep Collection Time: 3.86675
Timestep Consumption Time: 0.92238
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 4.78913

Cumulative Model Updates: 513
Cumulative Timesteps: 8603714

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 8603714...
Checkpoint 8603714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03358
Policy Entropy: 0.82859
Value Function Loss: 0.07695

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.03658

Collected Steps per Second: 11773.19731
Overall Steps per Second: 9695.27848

Timestep Collection Time: 4.24880
Timestep Consumption Time: 0.91062
PPO Batch Consumption Time: 0.02893
Total Iteration Time: 5.15942

Cumulative Model Updates: 516
Cumulative Timesteps: 8653736

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04132
Policy Entropy: 0.83717
Value Function Loss: 0.04140

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.03528

Collected Steps per Second: 12326.05033
Overall Steps per Second: 9977.67557

Timestep Collection Time: 4.05791
Timestep Consumption Time: 0.95508
PPO Batch Consumption Time: 0.02904
Total Iteration Time: 5.01299

Cumulative Model Updates: 519
Cumulative Timesteps: 8703754

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 8703754...
Checkpoint 8703754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01465
Policy Entropy: 0.83210
Value Function Loss: 0.06199

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.03519
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.04189

Collected Steps per Second: 9908.78205
Overall Steps per Second: 8302.12896

Timestep Collection Time: 5.04926
Timestep Consumption Time: 0.97715
PPO Batch Consumption Time: 0.02960
Total Iteration Time: 6.02641

Cumulative Model Updates: 522
Cumulative Timesteps: 8753786

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04424
Policy Entropy: 0.84628
Value Function Loss: 0.09149

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.03325

Collected Steps per Second: 13040.17146
Overall Steps per Second: 10130.31857

Timestep Collection Time: 3.83645
Timestep Consumption Time: 1.10199
PPO Batch Consumption Time: 0.03050
Total Iteration Time: 4.93844

Cumulative Model Updates: 525
Cumulative Timesteps: 8803814

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 8803814...
Checkpoint 8803814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02972
Policy Entropy: 0.84369
Value Function Loss: 0.09293

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.03567
Policy Update Magnitude: 0.07166
Value Function Update Magnitude: 0.03448

Collected Steps per Second: 12041.49899
Overall Steps per Second: 9636.61030

Timestep Collection Time: 4.15430
Timestep Consumption Time: 1.03674
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 5.19104

Cumulative Model Updates: 528
Cumulative Timesteps: 8853838

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03469
Policy Entropy: 0.87235
Value Function Loss: 0.10288

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06568
Policy Update Magnitude: 0.07307
Value Function Update Magnitude: 0.03102

Collected Steps per Second: 11439.40905
Overall Steps per Second: 9443.25498

Timestep Collection Time: 4.37435
Timestep Consumption Time: 0.92467
PPO Batch Consumption Time: 0.02988
Total Iteration Time: 5.29902

Cumulative Model Updates: 531
Cumulative Timesteps: 8903878

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 8903878...
Checkpoint 8903878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01629
Policy Entropy: 0.87131
Value Function Loss: 0.10298

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05919
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.04147

Collected Steps per Second: 11394.88323
Overall Steps per Second: 9364.89832

Timestep Collection Time: 4.38881
Timestep Consumption Time: 0.95134
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 5.34015

Cumulative Model Updates: 534
Cumulative Timesteps: 8953888

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02375
Policy Entropy: 0.86768
Value Function Loss: 0.10171

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03683
Policy Update Magnitude: 0.06353
Value Function Update Magnitude: 0.04421

Collected Steps per Second: 12435.46956
Overall Steps per Second: 9928.46532

Timestep Collection Time: 4.02301
Timestep Consumption Time: 1.01584
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 5.03885

Cumulative Model Updates: 537
Cumulative Timesteps: 9003916

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 9003916...
Checkpoint 9003916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01645
Policy Entropy: 0.88910
Value Function Loss: 0.07488

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.04935
Policy Update Magnitude: 0.06770
Value Function Update Magnitude: 0.05789

Collected Steps per Second: 11985.35920
Overall Steps per Second: 9806.41227

Timestep Collection Time: 4.17209
Timestep Consumption Time: 0.92702
PPO Batch Consumption Time: 0.03215
Total Iteration Time: 5.09911

Cumulative Model Updates: 540
Cumulative Timesteps: 9053920

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01760
Policy Entropy: 0.90134
Value Function Loss: 0.05552

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.07306
Value Function Update Magnitude: 0.04547

Collected Steps per Second: 12186.08099
Overall Steps per Second: 9766.98107

Timestep Collection Time: 4.10518
Timestep Consumption Time: 1.01678
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 5.12195

Cumulative Model Updates: 543
Cumulative Timesteps: 9103946

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 9103946...
Checkpoint 9103946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01472
Policy Entropy: 0.87930
Value Function Loss: 0.06589

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05547
Policy Update Magnitude: 0.07334
Value Function Update Magnitude: 0.04570

Collected Steps per Second: 12755.14353
Overall Steps per Second: 10524.72784

Timestep Collection Time: 3.92124
Timestep Consumption Time: 0.83100
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 4.75224

Cumulative Model Updates: 546
Cumulative Timesteps: 9153962

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10477
Policy Entropy: 0.90055
Value Function Loss: 0.09097

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02085
Policy Update Magnitude: 0.07425
Value Function Update Magnitude: 0.04050

Collected Steps per Second: 12737.63635
Overall Steps per Second: 10322.38029

Timestep Collection Time: 3.92742
Timestep Consumption Time: 0.91895
PPO Batch Consumption Time: 0.02784
Total Iteration Time: 4.84636

Cumulative Model Updates: 549
Cumulative Timesteps: 9203988

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 9203988...
Checkpoint 9203988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03488
Policy Entropy: 0.89351
Value Function Loss: 0.07740

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.01627
Policy Update Magnitude: 0.07517
Value Function Update Magnitude: 0.04660

Collected Steps per Second: 11286.09035
Overall Steps per Second: 9347.15651

Timestep Collection Time: 4.43076
Timestep Consumption Time: 0.91910
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 5.34986

Cumulative Model Updates: 552
Cumulative Timesteps: 9253994

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03650
Policy Entropy: 0.90268
Value Function Loss: 0.06495

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.08140
Value Function Update Magnitude: 0.04540

Collected Steps per Second: 11339.85299
Overall Steps per Second: 9274.90944

Timestep Collection Time: 4.40993
Timestep Consumption Time: 0.98182
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 5.39175

Cumulative Model Updates: 555
Cumulative Timesteps: 9304002

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 9304002...
Checkpoint 9304002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04023
Policy Entropy: 0.90312
Value Function Loss: 0.06415

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02970
Policy Update Magnitude: 0.08268
Value Function Update Magnitude: 0.04389

Collected Steps per Second: 12399.30762
Overall Steps per Second: 9924.50802

Timestep Collection Time: 4.03361
Timestep Consumption Time: 1.00583
PPO Batch Consumption Time: 0.03320
Total Iteration Time: 5.03944

Cumulative Model Updates: 558
Cumulative Timesteps: 9354016

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00503
Policy Entropy: 0.88589
Value Function Loss: 0.06938

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.07448
Value Function Update Magnitude: 0.03617

Collected Steps per Second: 11502.17555
Overall Steps per Second: 9436.36741

Timestep Collection Time: 4.34979
Timestep Consumption Time: 0.95225
PPO Batch Consumption Time: 0.02923
Total Iteration Time: 5.30204

Cumulative Model Updates: 561
Cumulative Timesteps: 9404048

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 9404048...
Checkpoint 9404048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01048
Policy Entropy: 0.90939
Value Function Loss: 0.07139

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.06718
Value Function Update Magnitude: 0.03464

Collected Steps per Second: 12885.21644
Overall Steps per Second: 10358.29274

Timestep Collection Time: 3.88197
Timestep Consumption Time: 0.94701
PPO Batch Consumption Time: 0.03137
Total Iteration Time: 4.82898

Cumulative Model Updates: 564
Cumulative Timesteps: 9454068

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01609
Policy Entropy: 0.89903
Value Function Loss: 0.06942

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06643
Policy Update Magnitude: 0.06670
Value Function Update Magnitude: 0.03723

Collected Steps per Second: 12006.84171
Overall Steps per Second: 9782.10140

Timestep Collection Time: 4.16579
Timestep Consumption Time: 0.94742
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 5.11322

Cumulative Model Updates: 567
Cumulative Timesteps: 9504086

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 9504086...
Checkpoint 9504086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02660
Policy Entropy: 0.91689
Value Function Loss: 0.06293

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.07000
Value Function Update Magnitude: 0.04740

Collected Steps per Second: 11540.62638
Overall Steps per Second: 9534.73362

Timestep Collection Time: 4.33443
Timestep Consumption Time: 0.91187
PPO Batch Consumption Time: 0.03035
Total Iteration Time: 5.24629

Cumulative Model Updates: 570
Cumulative Timesteps: 9554108

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01753
Policy Entropy: 0.90668
Value Function Loss: 0.07103

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03503
Policy Update Magnitude: 0.07259
Value Function Update Magnitude: 0.04521

Collected Steps per Second: 12291.96485
Overall Steps per Second: 10013.90922

Timestep Collection Time: 4.06933
Timestep Consumption Time: 0.92573
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 4.99505

Cumulative Model Updates: 573
Cumulative Timesteps: 9604128

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 9604128...
Checkpoint 9604128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03926
Policy Entropy: 0.92078
Value Function Loss: 0.04705

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.07124
Value Function Update Magnitude: 0.04817

Collected Steps per Second: 13376.46546
Overall Steps per Second: 10826.35713

Timestep Collection Time: 3.73895
Timestep Consumption Time: 0.88070
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 4.61965

Cumulative Model Updates: 576
Cumulative Timesteps: 9654142

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00747
Policy Entropy: 0.93362
Value Function Loss: 0.03695

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.06839
Value Function Update Magnitude: 0.04304

Collected Steps per Second: 13395.28888
Overall Steps per Second: 10769.43585

Timestep Collection Time: 3.73519
Timestep Consumption Time: 0.91073
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 4.64593

Cumulative Model Updates: 579
Cumulative Timesteps: 9704176

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 9704176...
Checkpoint 9704176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02762
Policy Entropy: 0.92464
Value Function Loss: 0.03889

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.07313
Policy Update Magnitude: 0.06557
Value Function Update Magnitude: 0.03785

Collected Steps per Second: 12060.93364
Overall Steps per Second: 9911.66200

Timestep Collection Time: 4.14827
Timestep Consumption Time: 0.89952
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 5.04779

Cumulative Model Updates: 582
Cumulative Timesteps: 9754208

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01408
Policy Entropy: 0.91717
Value Function Loss: 0.05443

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.06325
Value Function Update Magnitude: 0.03234

Collected Steps per Second: 11994.74882
Overall Steps per Second: 9801.45413

Timestep Collection Time: 4.17032
Timestep Consumption Time: 0.93320
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 5.10353

Cumulative Model Updates: 585
Cumulative Timesteps: 9804230

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 9804230...
Checkpoint 9804230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01626
Policy Entropy: 0.95073
Value Function Loss: 0.05500

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.03286

Collected Steps per Second: 10698.08591
Overall Steps per Second: 8911.52620

Timestep Collection Time: 4.67579
Timestep Consumption Time: 0.93739
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 5.61318

Cumulative Model Updates: 588
Cumulative Timesteps: 9854252

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04131
Policy Entropy: 0.92283
Value Function Loss: 0.06194

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06971
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.02593

Collected Steps per Second: 12476.36961
Overall Steps per Second: 10190.90753

Timestep Collection Time: 4.00886
Timestep Consumption Time: 0.89905
PPO Batch Consumption Time: 0.02831
Total Iteration Time: 4.90790

Cumulative Model Updates: 591
Cumulative Timesteps: 9904268

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 9904268...
Checkpoint 9904268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01940
Policy Entropy: 0.94017
Value Function Loss: 0.06696

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03789
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.02804

Collected Steps per Second: 12884.75389
Overall Steps per Second: 10432.75202

Timestep Collection Time: 3.88226
Timestep Consumption Time: 0.91245
PPO Batch Consumption Time: 0.02903
Total Iteration Time: 4.79471

Cumulative Model Updates: 594
Cumulative Timesteps: 9954290

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00826
Policy Entropy: 0.91730
Value Function Loss: 0.06772

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.02832

Collected Steps per Second: 13255.78726
Overall Steps per Second: 10688.34548

Timestep Collection Time: 3.77465
Timestep Consumption Time: 0.90671
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 4.68136

Cumulative Model Updates: 597
Cumulative Timesteps: 10004326

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 10004326...
Checkpoint 10004326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00783
Policy Entropy: 0.94972
Value Function Loss: 0.07260

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.03453

Collected Steps per Second: 13329.93276
Overall Steps per Second: 10777.02307

Timestep Collection Time: 3.75291
Timestep Consumption Time: 0.88901
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 4.64191

Cumulative Model Updates: 600
Cumulative Timesteps: 10054352

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00414
Policy Entropy: 0.92007
Value Function Loss: 0.08109

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04931
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.03267

Collected Steps per Second: 13749.66647
Overall Steps per Second: 10966.04673

Timestep Collection Time: 3.63878
Timestep Consumption Time: 0.92367
PPO Batch Consumption Time: 0.03158
Total Iteration Time: 4.56245

Cumulative Model Updates: 603
Cumulative Timesteps: 10104384

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 10104384...
Checkpoint 10104384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06699
Policy Entropy: 0.91963
Value Function Loss: 0.10796

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04268
Policy Update Magnitude: 0.06664
Value Function Update Magnitude: 0.03279

Collected Steps per Second: 11727.96144
Overall Steps per Second: 9486.01422

Timestep Collection Time: 4.26383
Timestep Consumption Time: 1.00772
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 5.27155

Cumulative Model Updates: 606
Cumulative Timesteps: 10154390

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03992
Policy Entropy: 0.90259
Value Function Loss: 0.09539

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.06770
Value Function Update Magnitude: 0.02972

Collected Steps per Second: 11776.13818
Overall Steps per Second: 9778.20396

Timestep Collection Time: 4.24689
Timestep Consumption Time: 0.86775
PPO Batch Consumption Time: 0.02686
Total Iteration Time: 5.11464

Cumulative Model Updates: 609
Cumulative Timesteps: 10204402

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 10204402...
Checkpoint 10204402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03572
Policy Entropy: 0.94277
Value Function Loss: 0.07679

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.06785
Value Function Update Magnitude: 0.03014

Collected Steps per Second: 12425.55027
Overall Steps per Second: 9814.86821

Timestep Collection Time: 4.02606
Timestep Consumption Time: 1.07090
PPO Batch Consumption Time: 0.03575
Total Iteration Time: 5.09696

Cumulative Model Updates: 612
Cumulative Timesteps: 10254428

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01503
Policy Entropy: 0.90687
Value Function Loss: 0.06661

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.06147
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.02711

Collected Steps per Second: 11786.52998
Overall Steps per Second: 9719.17758

Timestep Collection Time: 4.24485
Timestep Consumption Time: 0.90292
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 5.14776

Cumulative Model Updates: 615
Cumulative Timesteps: 10304460

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 10304460...
Checkpoint 10304460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02130
Policy Entropy: 0.94018
Value Function Loss: 0.06479

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01636
Policy Update Magnitude: 0.06898
Value Function Update Magnitude: 0.03001

Collected Steps per Second: 12102.51467
Overall Steps per Second: 9802.83311

Timestep Collection Time: 4.13336
Timestep Consumption Time: 0.96966
PPO Batch Consumption Time: 0.03030
Total Iteration Time: 5.10301

Cumulative Model Updates: 618
Cumulative Timesteps: 10354484

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02683
Policy Entropy: 0.89975
Value Function Loss: 0.05954

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.02632

Collected Steps per Second: 12759.85559
Overall Steps per Second: 10151.17520

Timestep Collection Time: 3.92011
Timestep Consumption Time: 1.00740
PPO Batch Consumption Time: 0.02867
Total Iteration Time: 4.92751

Cumulative Model Updates: 621
Cumulative Timesteps: 10404504

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 10404504...
Checkpoint 10404504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00805
Policy Entropy: 0.95352
Value Function Loss: 0.05325

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08639
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.03076

Collected Steps per Second: 12664.66724
Overall Steps per Second: 10311.42245

Timestep Collection Time: 3.95068
Timestep Consumption Time: 0.90161
PPO Batch Consumption Time: 0.03839
Total Iteration Time: 4.85229

Cumulative Model Updates: 624
Cumulative Timesteps: 10454538

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01553
Policy Entropy: 0.92297
Value Function Loss: 0.06558

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05845
Policy Update Magnitude: 0.06457
Value Function Update Magnitude: 0.03338

Collected Steps per Second: 12036.03344
Overall Steps per Second: 9680.72588

Timestep Collection Time: 4.15502
Timestep Consumption Time: 1.01091
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 5.16593

Cumulative Model Updates: 627
Cumulative Timesteps: 10504548

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 10504548...
Checkpoint 10504548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01759
Policy Entropy: 0.93042
Value Function Loss: 0.10625

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.07008
Value Function Update Magnitude: 0.03741

Collected Steps per Second: 11965.07988
Overall Steps per Second: 9849.19962

Timestep Collection Time: 4.17983
Timestep Consumption Time: 0.89794
PPO Batch Consumption Time: 0.02666
Total Iteration Time: 5.07777

Cumulative Model Updates: 630
Cumulative Timesteps: 10554560

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00149
Policy Entropy: 0.90107
Value Function Loss: 0.12265

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.07128
Value Function Update Magnitude: 0.03960

Collected Steps per Second: 11644.87692
Overall Steps per Second: 9352.34194

Timestep Collection Time: 4.29494
Timestep Consumption Time: 1.05282
PPO Batch Consumption Time: 0.02585
Total Iteration Time: 5.34775

Cumulative Model Updates: 633
Cumulative Timesteps: 10604574

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 10604574...
Checkpoint 10604574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02523
Policy Entropy: 0.94097
Value Function Loss: 0.11225

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.07787
Value Function Update Magnitude: 0.04532

Collected Steps per Second: 12133.96768
Overall Steps per Second: 9812.38605

Timestep Collection Time: 4.12248
Timestep Consumption Time: 0.97537
PPO Batch Consumption Time: 0.02958
Total Iteration Time: 5.09784

Cumulative Model Updates: 636
Cumulative Timesteps: 10654596

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03895
Policy Entropy: 0.91944
Value Function Loss: 0.07888

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.03472
Policy Update Magnitude: 0.07046
Value Function Update Magnitude: 0.04040

Collected Steps per Second: 12899.47802
Overall Steps per Second: 10588.13717

Timestep Collection Time: 3.87923
Timestep Consumption Time: 0.84682
PPO Batch Consumption Time: 0.03008
Total Iteration Time: 4.72604

Cumulative Model Updates: 639
Cumulative Timesteps: 10704636

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 10704636...
Checkpoint 10704636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.17851
Policy Entropy: 0.94462
Value Function Loss: 0.07741

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.03902
Policy Update Magnitude: 0.07244
Value Function Update Magnitude: 0.04325

Collected Steps per Second: 13144.73255
Overall Steps per Second: 10601.13792

Timestep Collection Time: 3.80563
Timestep Consumption Time: 0.91311
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 4.71874

Cumulative Model Updates: 642
Cumulative Timesteps: 10754660

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03179
Policy Entropy: 0.91799
Value Function Loss: 0.06708

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.03876

Collected Steps per Second: 12734.78017
Overall Steps per Second: 10359.13238

Timestep Collection Time: 3.93065
Timestep Consumption Time: 0.90141
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 4.83206

Cumulative Model Updates: 645
Cumulative Timesteps: 10804716

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 10804716...
Checkpoint 10804716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02938
Policy Entropy: 0.94132
Value Function Loss: 0.05354

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.03858

Collected Steps per Second: 13213.28929
Overall Steps per Second: 10658.38602

Timestep Collection Time: 3.78770
Timestep Consumption Time: 0.90794
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 4.69565

Cumulative Model Updates: 648
Cumulative Timesteps: 10854764

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02755
Policy Entropy: 0.93795
Value Function Loss: 0.02788

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.06797
Value Function Update Magnitude: 0.03657

Collected Steps per Second: 13400.41976
Overall Steps per Second: 10734.75647

Timestep Collection Time: 3.73436
Timestep Consumption Time: 0.92732
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 4.66168

Cumulative Model Updates: 651
Cumulative Timesteps: 10904806

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 10904806...
Checkpoint 10904806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03425
Policy Entropy: 0.93050
Value Function Loss: 0.02806

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03138
Policy Update Magnitude: 0.06610
Value Function Update Magnitude: 0.03996

Collected Steps per Second: 13412.61352
Overall Steps per Second: 10956.63782

Timestep Collection Time: 3.72813
Timestep Consumption Time: 0.83568
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 4.56381

Cumulative Model Updates: 654
Cumulative Timesteps: 10954810

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04586
Policy Entropy: 0.91682
Value Function Loss: 0.06819

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04145
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.03578

Collected Steps per Second: 13573.80813
Overall Steps per Second: 10874.55833

Timestep Collection Time: 3.68710
Timestep Consumption Time: 0.91520
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 4.60230

Cumulative Model Updates: 657
Cumulative Timesteps: 11004858

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 11004858...
Checkpoint 11004858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03757
Policy Entropy: 0.92612
Value Function Loss: 0.11754

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.07157
Value Function Update Magnitude: 0.04269

Collected Steps per Second: 12625.42799
Overall Steps per Second: 10264.74478

Timestep Collection Time: 3.96121
Timestep Consumption Time: 0.91100
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 4.87221

Cumulative Model Updates: 660
Cumulative Timesteps: 11054870

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01481
Policy Entropy: 0.92264
Value Function Loss: 0.12630

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04567
Policy Update Magnitude: 0.07498
Value Function Update Magnitude: 0.04537

Collected Steps per Second: 13162.98047
Overall Steps per Second: 10606.54743

Timestep Collection Time: 3.79884
Timestep Consumption Time: 0.91561
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 4.71445

Cumulative Model Updates: 663
Cumulative Timesteps: 11104874

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 11104874...
Checkpoint 11104874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01295
Policy Entropy: 0.90989
Value Function Loss: 0.09451

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.07459
Value Function Update Magnitude: 0.04502

Collected Steps per Second: 13218.79158
Overall Steps per Second: 10653.98197

Timestep Collection Time: 3.78476
Timestep Consumption Time: 0.91113
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 4.69590

Cumulative Model Updates: 666
Cumulative Timesteps: 11154904

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02293
Policy Entropy: 0.92890
Value Function Loss: 0.05187

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04210
Policy Update Magnitude: 0.07085
Value Function Update Magnitude: 0.03575

Collected Steps per Second: 13394.42973
Overall Steps per Second: 10793.39655

Timestep Collection Time: 3.73484
Timestep Consumption Time: 0.90003
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 4.63487

Cumulative Model Updates: 669
Cumulative Timesteps: 11204930

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 11204930...
Checkpoint 11204930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03626
Policy Entropy: 0.93109
Value Function Loss: 0.04842

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.07279
Value Function Update Magnitude: 0.03688

Collected Steps per Second: 13487.00409
Overall Steps per Second: 10761.98744

Timestep Collection Time: 3.70979
Timestep Consumption Time: 0.93935
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 4.64914

Cumulative Model Updates: 672
Cumulative Timesteps: 11254964

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05013
Policy Entropy: 0.93247
Value Function Loss: 0.07145

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.07341
Value Function Update Magnitude: 0.03752

Collected Steps per Second: 12898.49871
Overall Steps per Second: 10395.01413

Timestep Collection Time: 3.88030
Timestep Consumption Time: 0.93451
PPO Batch Consumption Time: 0.02924
Total Iteration Time: 4.81481

Cumulative Model Updates: 675
Cumulative Timesteps: 11305014

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 11305014...
Checkpoint 11305014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05464
Policy Entropy: 0.92229
Value Function Loss: 0.09641

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.07305
Value Function Update Magnitude: 0.03759

Collected Steps per Second: 13284.50302
Overall Steps per Second: 10845.64852

Timestep Collection Time: 3.76499
Timestep Consumption Time: 0.84663
PPO Batch Consumption Time: 0.02961
Total Iteration Time: 4.61162

Cumulative Model Updates: 678
Cumulative Timesteps: 11355030

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01587
Policy Entropy: 0.95038
Value Function Loss: 0.10402

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06819
Policy Update Magnitude: 0.07009
Value Function Update Magnitude: 0.03514

Collected Steps per Second: 13195.41292
Overall Steps per Second: 10586.63192

Timestep Collection Time: 3.79132
Timestep Consumption Time: 0.93426
PPO Batch Consumption Time: 0.02912
Total Iteration Time: 4.72558

Cumulative Model Updates: 681
Cumulative Timesteps: 11405058

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 11405058...
Checkpoint 11405058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00379
Policy Entropy: 0.92894
Value Function Loss: 0.08926

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.06912
Value Function Update Magnitude: 0.03737

Collected Steps per Second: 13340.93665
Overall Steps per Second: 10785.14478

Timestep Collection Time: 3.74816
Timestep Consumption Time: 0.88821
PPO Batch Consumption Time: 0.02586
Total Iteration Time: 4.63638

Cumulative Model Updates: 684
Cumulative Timesteps: 11455062

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07729
Policy Entropy: 0.94852
Value Function Loss: 0.07500

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.06357
Value Function Update Magnitude: 0.03200

Collected Steps per Second: 13073.83984
Overall Steps per Second: 10469.81946

Timestep Collection Time: 3.82780
Timestep Consumption Time: 0.95204
PPO Batch Consumption Time: 0.03338
Total Iteration Time: 4.77983

Cumulative Model Updates: 687
Cumulative Timesteps: 11505106

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 11505106...
Checkpoint 11505106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03525
Policy Entropy: 0.94601
Value Function Loss: 0.10117

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.17032
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.03520

Collected Steps per Second: 13142.98483
Overall Steps per Second: 10614.62937

Timestep Collection Time: 3.80720
Timestep Consumption Time: 0.90686
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 4.71406

Cumulative Model Updates: 690
Cumulative Timesteps: 11555144

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04509
Policy Entropy: 0.96231
Value Function Loss: 0.11115

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.03676

Collected Steps per Second: 13161.29551
Overall Steps per Second: 10853.12400

Timestep Collection Time: 3.80008
Timestep Consumption Time: 0.80818
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 4.60826

Cumulative Model Updates: 693
Cumulative Timesteps: 11605158

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 11605158...
Checkpoint 11605158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04590
Policy Entropy: 0.94251
Value Function Loss: 0.10835

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06769
Policy Update Magnitude: 0.05907
Value Function Update Magnitude: 0.04203

Collected Steps per Second: 13311.90463
Overall Steps per Second: 10690.54815

Timestep Collection Time: 3.75799
Timestep Consumption Time: 0.92147
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 4.67946

Cumulative Model Updates: 696
Cumulative Timesteps: 11655184

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03817
Policy Entropy: 0.97311
Value Function Loss: 0.08096

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.03795

Collected Steps per Second: 13171.29251
Overall Steps per Second: 10672.62779

Timestep Collection Time: 3.79826
Timestep Consumption Time: 0.88924
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 4.68751

Cumulative Model Updates: 699
Cumulative Timesteps: 11705212

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 11705212...
Checkpoint 11705212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01126
Policy Entropy: 0.97133
Value Function Loss: 0.05324

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.05914
Value Function Update Magnitude: 0.04261

Collected Steps per Second: 12678.69077
Overall Steps per Second: 10302.14498

Timestep Collection Time: 3.94441
Timestep Consumption Time: 0.90992
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 4.85433

Cumulative Model Updates: 702
Cumulative Timesteps: 11755222

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03436
Policy Entropy: 0.97418
Value Function Loss: 0.05363

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06605
Policy Update Magnitude: 0.06015
Value Function Update Magnitude: 0.04243

Collected Steps per Second: 13277.56989
Overall Steps per Second: 10657.43326

Timestep Collection Time: 3.76921
Timestep Consumption Time: 0.92666
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 4.69588

Cumulative Model Updates: 705
Cumulative Timesteps: 11805268

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 11805268...
Checkpoint 11805268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04988
Policy Entropy: 0.99932
Value Function Loss: 0.06097

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.06347
Value Function Update Magnitude: 0.04724

Collected Steps per Second: 13071.83523
Overall Steps per Second: 10739.94343

Timestep Collection Time: 3.82731
Timestep Consumption Time: 0.83100
PPO Batch Consumption Time: 0.02843
Total Iteration Time: 4.65831

Cumulative Model Updates: 708
Cumulative Timesteps: 11855298

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00654
Policy Entropy: 0.99526
Value Function Loss: 0.07796

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.06832
Value Function Update Magnitude: 0.04544

Collected Steps per Second: 13134.72248
Overall Steps per Second: 10591.15752

Timestep Collection Time: 3.81036
Timestep Consumption Time: 0.91509
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 4.72545

Cumulative Model Updates: 711
Cumulative Timesteps: 11905346

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 11905346...
Checkpoint 11905346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00740
Policy Entropy: 0.99989
Value Function Loss: 0.08037

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06221
Policy Update Magnitude: 0.07232
Value Function Update Magnitude: 0.04852

Collected Steps per Second: 13434.53703
Overall Steps per Second: 10745.49387

Timestep Collection Time: 3.72384
Timestep Consumption Time: 0.93188
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 4.65572

Cumulative Model Updates: 714
Cumulative Timesteps: 11955374

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02683
Policy Entropy: 0.98979
Value Function Loss: 0.05762

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.04148

Collected Steps per Second: 12813.46834
Overall Steps per Second: 10276.71463

Timestep Collection Time: 3.90261
Timestep Consumption Time: 0.96334
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 4.86595

Cumulative Model Updates: 717
Cumulative Timesteps: 12005380

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 12005380...
Checkpoint 12005380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04957
Policy Entropy: 1.00006
Value Function Loss: 0.04229

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.06608
Value Function Update Magnitude: 0.03881

Collected Steps per Second: 13351.89518
Overall Steps per Second: 10736.10735

Timestep Collection Time: 3.74853
Timestep Consumption Time: 0.91331
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.66184

Cumulative Model Updates: 720
Cumulative Timesteps: 12055430

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04274
Policy Entropy: 1.01364
Value Function Loss: 0.06902

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.06715
Value Function Update Magnitude: 0.03607

Collected Steps per Second: 13110.49031
Overall Steps per Second: 10624.09596

Timestep Collection Time: 3.81466
Timestep Consumption Time: 0.89276
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 4.70741

Cumulative Model Updates: 723
Cumulative Timesteps: 12105442

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 12105442...
Checkpoint 12105442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08011
Policy Entropy: 1.01813
Value Function Loss: 0.09743

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.06299
Value Function Update Magnitude: 0.04031

Collected Steps per Second: 13589.71706
Overall Steps per Second: 10857.26934

Timestep Collection Time: 3.68293
Timestep Consumption Time: 0.92688
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 4.60981

Cumulative Model Updates: 726
Cumulative Timesteps: 12155492

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00509
Policy Entropy: 1.00563
Value Function Loss: 0.12012

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.07004
Value Function Update Magnitude: 0.04244

Collected Steps per Second: 12913.81716
Overall Steps per Second: 10396.84379

Timestep Collection Time: 3.87306
Timestep Consumption Time: 0.93763
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 4.81069

Cumulative Model Updates: 729
Cumulative Timesteps: 12205508

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 12205508...
Checkpoint 12205508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06292
Policy Entropy: 1.02409
Value Function Loss: 0.06988

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.06815
Value Function Update Magnitude: 0.04614

Collected Steps per Second: 12966.40265
Overall Steps per Second: 10709.35709

Timestep Collection Time: 3.85890
Timestep Consumption Time: 0.81328
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 4.67218

Cumulative Model Updates: 732
Cumulative Timesteps: 12255544

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05364
Policy Entropy: 1.02865
Value Function Loss: 0.06647

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.06873
Value Function Update Magnitude: 0.03799

Collected Steps per Second: 12987.87414
Overall Steps per Second: 10445.04656

Timestep Collection Time: 3.85175
Timestep Consumption Time: 0.93770
PPO Batch Consumption Time: 0.02620
Total Iteration Time: 4.78945

Cumulative Model Updates: 735
Cumulative Timesteps: 12305570

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 12305570...
Checkpoint 12305570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05490
Policy Entropy: 1.02439
Value Function Loss: 0.05233

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.06655
Value Function Update Magnitude: 0.03756

Collected Steps per Second: 13332.96415
Overall Steps per Second: 10752.03386

Timestep Collection Time: 3.75415
Timestep Consumption Time: 0.90115
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 4.65531

Cumulative Model Updates: 738
Cumulative Timesteps: 12355624

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03936
Policy Entropy: 1.04375
Value Function Loss: 0.06299

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.07033
Value Function Update Magnitude: 0.03438

Collected Steps per Second: 13710.06466
Overall Steps per Second: 10985.49879

Timestep Collection Time: 3.64885
Timestep Consumption Time: 0.90497
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 4.55382

Cumulative Model Updates: 741
Cumulative Timesteps: 12405650

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 12405650...
Checkpoint 12405650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02461
Policy Entropy: 1.06334
Value Function Loss: 0.07007

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.20824
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.03531

Collected Steps per Second: 12461.54363
Overall Steps per Second: 10093.12452

Timestep Collection Time: 4.01475
Timestep Consumption Time: 0.94209
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 4.95684

Cumulative Model Updates: 744
Cumulative Timesteps: 12455680

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04963
Policy Entropy: 1.05341
Value Function Loss: 0.06737

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.06638
Value Function Update Magnitude: 0.03327

Collected Steps per Second: 13116.72625
Overall Steps per Second: 10784.36780

Timestep Collection Time: 3.81437
Timestep Consumption Time: 0.82494
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 4.63931

Cumulative Model Updates: 747
Cumulative Timesteps: 12505712

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 12505712...
Checkpoint 12505712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04841
Policy Entropy: 1.05852
Value Function Loss: 0.07568

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.18824
Policy Update Magnitude: 0.06313
Value Function Update Magnitude: 0.03644

Collected Steps per Second: 13585.37677
Overall Steps per Second: 10869.99550

Timestep Collection Time: 3.68278
Timestep Consumption Time: 0.91998
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 4.60276

Cumulative Model Updates: 750
Cumulative Timesteps: 12555744

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01630
Policy Entropy: 1.10218
Value Function Loss: 0.05811

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.17012
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.03197

Collected Steps per Second: 13199.37763
Overall Steps per Second: 10593.43623

Timestep Collection Time: 3.79124
Timestep Consumption Time: 0.93263
PPO Batch Consumption Time: 0.02986
Total Iteration Time: 4.72387

Cumulative Model Updates: 753
Cumulative Timesteps: 12605786

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 12605786...
Checkpoint 12605786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04865
Policy Entropy: 1.09322
Value Function Loss: 0.08093

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.19532
Policy Update Magnitude: 0.06798
Value Function Update Magnitude: 0.03693

Collected Steps per Second: 12905.37465
Overall Steps per Second: 10426.74920

Timestep Collection Time: 3.87435
Timestep Consumption Time: 0.92100
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 4.79536

Cumulative Model Updates: 756
Cumulative Timesteps: 12655786

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09882
Policy Entropy: 1.10982
Value Function Loss: 0.08104

Mean KL Divergence: 0.01844
SB3 Clip Fraction: 0.23567
Policy Update Magnitude: 0.06514
Value Function Update Magnitude: 0.03616

Collected Steps per Second: 13019.74001
Overall Steps per Second: 10486.44146

Timestep Collection Time: 3.84278
Timestep Consumption Time: 0.92833
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 4.77111

Cumulative Model Updates: 759
Cumulative Timesteps: 12705818

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 12705818...
Checkpoint 12705818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06323
Policy Entropy: 1.11305
Value Function Loss: 0.07975

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.21457
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.04265

Collected Steps per Second: 12934.54612
Overall Steps per Second: 10588.25139

Timestep Collection Time: 3.86964
Timestep Consumption Time: 0.85749
PPO Batch Consumption Time: 0.02919
Total Iteration Time: 4.72713

Cumulative Model Updates: 762
Cumulative Timesteps: 12755870

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03221
Policy Entropy: 1.13599
Value Function Loss: 0.08588

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.04578
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.05347

Collected Steps per Second: 13193.13810
Overall Steps per Second: 10662.98793

Timestep Collection Time: 3.79334
Timestep Consumption Time: 0.90010
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 4.69343

Cumulative Model Updates: 765
Cumulative Timesteps: 12805916

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 12805916...
Checkpoint 12805916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04616
Policy Entropy: 1.12030
Value Function Loss: 0.09343

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.05038

Collected Steps per Second: 13247.86316
Overall Steps per Second: 10734.49775

Timestep Collection Time: 3.77465
Timestep Consumption Time: 0.88379
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 4.65844

Cumulative Model Updates: 768
Cumulative Timesteps: 12855922

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03314
Policy Entropy: 1.13073
Value Function Loss: 0.08991

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.04825

Collected Steps per Second: 13175.31547
Overall Steps per Second: 10564.66191

Timestep Collection Time: 3.79862
Timestep Consumption Time: 0.93868
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 4.73730

Cumulative Model Updates: 771
Cumulative Timesteps: 12905970

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 12905970...
Checkpoint 12905970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02685
Policy Entropy: 1.14523
Value Function Loss: 0.06022

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.05450

Collected Steps per Second: 12986.62247
Overall Steps per Second: 10466.09648

Timestep Collection Time: 3.85119
Timestep Consumption Time: 0.92747
PPO Batch Consumption Time: 0.02897
Total Iteration Time: 4.77867

Cumulative Model Updates: 774
Cumulative Timesteps: 12955984

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01681
Policy Entropy: 1.15788
Value Function Loss: 0.04249

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.04408

Collected Steps per Second: 13265.83893
Overall Steps per Second: 10676.79025

Timestep Collection Time: 3.77089
Timestep Consumption Time: 0.91441
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 4.68530

Cumulative Model Updates: 777
Cumulative Timesteps: 13006008

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 13006008...
Checkpoint 13006008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03848
Policy Entropy: 1.16031
Value Function Loss: 0.03783

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.04390

Collected Steps per Second: 13456.09400
Overall Steps per Second: 10757.83303

Timestep Collection Time: 3.71861
Timestep Consumption Time: 0.93270
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 4.65131

Cumulative Model Updates: 780
Cumulative Timesteps: 13056046

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06481
Policy Entropy: 1.15738
Value Function Loss: 0.03957

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.04374

Collected Steps per Second: 13122.17789
Overall Steps per Second: 10529.23258

Timestep Collection Time: 3.81309
Timestep Consumption Time: 0.93902
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 4.75210

Cumulative Model Updates: 783
Cumulative Timesteps: 13106082

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 13106082...
Checkpoint 13106082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04209
Policy Entropy: 1.15423
Value Function Loss: 0.05973

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11766
Policy Update Magnitude: 0.06549
Value Function Update Magnitude: 0.04734

Collected Steps per Second: 12526.65387
Overall Steps per Second: 10353.47409

Timestep Collection Time: 3.99388
Timestep Consumption Time: 0.83831
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 4.83219

Cumulative Model Updates: 786
Cumulative Timesteps: 13156112

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00544
Policy Entropy: 1.16425
Value Function Loss: 0.06361

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05379
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.03915

Collected Steps per Second: 13390.91446
Overall Steps per Second: 10706.65396

Timestep Collection Time: 3.73447
Timestep Consumption Time: 0.93627
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 4.67074

Cumulative Model Updates: 789
Cumulative Timesteps: 13206120

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 13206120...
Checkpoint 13206120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03784
Policy Entropy: 1.16971
Value Function Loss: 0.06329

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.06633
Value Function Update Magnitude: 0.03604

Collected Steps per Second: 12613.26880
Overall Steps per Second: 10212.00844

Timestep Collection Time: 3.96567
Timestep Consumption Time: 0.93249
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 4.89815

Cumulative Model Updates: 792
Cumulative Timesteps: 13256140

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03532
Policy Entropy: 1.16504
Value Function Loss: 0.03662

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05530
Policy Update Magnitude: 0.07130
Value Function Update Magnitude: 0.03379

Collected Steps per Second: 12801.39785
Overall Steps per Second: 10379.08341

Timestep Collection Time: 3.90879
Timestep Consumption Time: 0.91225
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 4.82104

Cumulative Model Updates: 795
Cumulative Timesteps: 13306178

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 13306178...
Checkpoint 13306178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03212
Policy Entropy: 1.16211
Value Function Loss: 0.03779

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.07575
Value Function Update Magnitude: 0.04488

Collected Steps per Second: 13209.76130
Overall Steps per Second: 10545.83056

Timestep Collection Time: 3.78553
Timestep Consumption Time: 0.95625
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 4.74178

Cumulative Model Updates: 798
Cumulative Timesteps: 13356184

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05494
Policy Entropy: 1.16944
Value Function Loss: 0.05746

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.07668
Value Function Update Magnitude: 0.04465

Collected Steps per Second: 13333.07813
Overall Steps per Second: 10851.15785

Timestep Collection Time: 3.75037
Timestep Consumption Time: 0.85780
PPO Batch Consumption Time: 0.02591
Total Iteration Time: 4.60817

Cumulative Model Updates: 801
Cumulative Timesteps: 13406188

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 13406188...
Checkpoint 13406188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01538
Policy Entropy: 1.18186
Value Function Loss: 0.08262

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.19429
Policy Update Magnitude: 0.07200
Value Function Update Magnitude: 0.04166

Collected Steps per Second: 13255.91949
Overall Steps per Second: 10700.98378

Timestep Collection Time: 3.77235
Timestep Consumption Time: 0.90068
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 4.67303

Cumulative Model Updates: 804
Cumulative Timesteps: 13456194

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06544
Policy Entropy: 1.17107
Value Function Loss: 0.10359

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.07640
Value Function Update Magnitude: 0.03987

Collected Steps per Second: 13113.12582
Overall Steps per Second: 10651.20741

Timestep Collection Time: 3.81343
Timestep Consumption Time: 0.88144
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 4.69487

Cumulative Model Updates: 807
Cumulative Timesteps: 13506200

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 13506200...
Checkpoint 13506200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02476
Policy Entropy: 1.17036
Value Function Loss: 0.10147

Mean KL Divergence: 0.01836
SB3 Clip Fraction: 0.21325
Policy Update Magnitude: 0.07426
Value Function Update Magnitude: 0.04970

Collected Steps per Second: 13386.21785
Overall Steps per Second: 10760.19988

Timestep Collection Time: 3.73772
Timestep Consumption Time: 0.91219
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 4.64991

Cumulative Model Updates: 810
Cumulative Timesteps: 13556234

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00281
Policy Entropy: 1.18213
Value Function Loss: 0.09285

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.06998
Value Function Update Magnitude: 0.04968

Collected Steps per Second: 12565.03112
Overall Steps per Second: 10252.09134

Timestep Collection Time: 3.98153
Timestep Consumption Time: 0.89826
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 4.87978

Cumulative Model Updates: 813
Cumulative Timesteps: 13606262

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 13606262...
Checkpoint 13606262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04083
Policy Entropy: 1.21310
Value Function Loss: 0.08362

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.07160
Value Function Update Magnitude: 0.05136

Collected Steps per Second: 13221.35553
Overall Steps per Second: 10776.30214

Timestep Collection Time: 3.78191
Timestep Consumption Time: 0.85808
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 4.64000

Cumulative Model Updates: 816
Cumulative Timesteps: 13656264

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00782
Policy Entropy: 1.19680
Value Function Loss: 0.09870

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.07771
Value Function Update Magnitude: 0.04843

Collected Steps per Second: 13448.10777
Overall Steps per Second: 10794.81859

Timestep Collection Time: 3.72037
Timestep Consumption Time: 0.91444
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 4.63482

Cumulative Model Updates: 819
Cumulative Timesteps: 13706296

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 13706296...
Checkpoint 13706296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00110
Policy Entropy: 1.19384
Value Function Loss: 0.08113

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.18536
Policy Update Magnitude: 0.06920
Value Function Update Magnitude: 0.05237

Collected Steps per Second: 13406.80070
Overall Steps per Second: 10772.34447

Timestep Collection Time: 3.73005
Timestep Consumption Time: 0.91221
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 4.64226

Cumulative Model Updates: 822
Cumulative Timesteps: 13756304

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03258
Policy Entropy: 1.21084
Value Function Loss: 0.06208

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.04635

Collected Steps per Second: 13479.92024
Overall Steps per Second: 10716.16617

Timestep Collection Time: 3.71130
Timestep Consumption Time: 0.95716
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 4.66846

Cumulative Model Updates: 825
Cumulative Timesteps: 13806332

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 13806332...
Checkpoint 13806332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01095
Policy Entropy: 1.22729
Value Function Loss: 0.04666

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.20035
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.04734

Collected Steps per Second: 12491.82870
Overall Steps per Second: 10123.36920

Timestep Collection Time: 4.00406
Timestep Consumption Time: 0.93679
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 4.94085

Cumulative Model Updates: 828
Cumulative Timesteps: 13856350

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08720
Policy Entropy: 1.20826
Value Function Loss: 0.06247

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.06391
Value Function Update Magnitude: 0.04176

Collected Steps per Second: 13072.79300
Overall Steps per Second: 10600.38125

Timestep Collection Time: 3.82627
Timestep Consumption Time: 0.89243
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 4.71870

Cumulative Model Updates: 831
Cumulative Timesteps: 13906370

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 13906370...
Checkpoint 13906370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00481
Policy Entropy: 1.20842
Value Function Loss: 0.05798

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.21335
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.04237

Collected Steps per Second: 13336.90406
Overall Steps per Second: 10716.39031

Timestep Collection Time: 3.75304
Timestep Consumption Time: 0.91774
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 4.67079

Cumulative Model Updates: 834
Cumulative Timesteps: 13956424

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00273
Policy Entropy: 1.23890
Value Function Loss: 0.04598

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.12226
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.03937

Collected Steps per Second: 12766.27494
Overall Steps per Second: 10448.91660

Timestep Collection Time: 3.92064
Timestep Consumption Time: 0.86952
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 4.79016

Cumulative Model Updates: 837
Cumulative Timesteps: 14006476

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 14006476...
Checkpoint 14006476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00448
Policy Entropy: 1.22451
Value Function Loss: 0.06798

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.25867
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.04071

Collected Steps per Second: 12560.63928
Overall Steps per Second: 10248.69211

Timestep Collection Time: 3.98149
Timestep Consumption Time: 0.89816
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 4.87965

Cumulative Model Updates: 840
Cumulative Timesteps: 14056486

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04444
Policy Entropy: 1.22434
Value Function Loss: 0.07979

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.21725
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.03605

Collected Steps per Second: 13464.18318
Overall Steps per Second: 10804.63794

Timestep Collection Time: 3.71356
Timestep Consumption Time: 0.91409
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 4.62764

Cumulative Model Updates: 843
Cumulative Timesteps: 14106486

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 14106486...
Checkpoint 14106486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02869
Policy Entropy: 1.22472
Value Function Loss: 0.07360

Mean KL Divergence: 0.02394
SB3 Clip Fraction: 0.24733
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.04223

Collected Steps per Second: 13186.86662
Overall Steps per Second: 10827.86444

Timestep Collection Time: 3.79211
Timestep Consumption Time: 0.82616
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 4.61827

Cumulative Model Updates: 846
Cumulative Timesteps: 14156492

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04658
Policy Entropy: 1.24815
Value Function Loss: 0.05429

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.19265
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.03904

Collected Steps per Second: 13580.81215
Overall Steps per Second: 10815.79755

Timestep Collection Time: 3.68476
Timestep Consumption Time: 0.94199
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 4.62675

Cumulative Model Updates: 849
Cumulative Timesteps: 14206534

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 14206534...
Checkpoint 14206534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00103
Policy Entropy: 1.22442
Value Function Loss: 0.04958

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.05156

Collected Steps per Second: 13241.58507
Overall Steps per Second: 10750.48284

Timestep Collection Time: 3.77674
Timestep Consumption Time: 0.87515
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 4.65188

Cumulative Model Updates: 852
Cumulative Timesteps: 14256544

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03467
Policy Entropy: 1.24091
Value Function Loss: 0.05734

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.22477
Policy Update Magnitude: 0.06679
Value Function Update Magnitude: 0.05531

Collected Steps per Second: 12993.84254
Overall Steps per Second: 10522.23642

Timestep Collection Time: 3.84890
Timestep Consumption Time: 0.90408
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 4.75298

Cumulative Model Updates: 855
Cumulative Timesteps: 14306556

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 14306556...
Checkpoint 14306556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00396
Policy Entropy: 1.25077
Value Function Loss: 0.04053

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.05181

Collected Steps per Second: 13642.28258
Overall Steps per Second: 10958.48015

Timestep Collection Time: 3.66522
Timestep Consumption Time: 0.89764
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 4.56286

Cumulative Model Updates: 858
Cumulative Timesteps: 14356558

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02928
Policy Entropy: 1.24358
Value Function Loss: 0.06313

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.06738
Value Function Update Magnitude: 0.03867

Collected Steps per Second: 12995.09141
Overall Steps per Second: 10678.94436

Timestep Collection Time: 3.85068
Timestep Consumption Time: 0.83517
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 4.68586

Cumulative Model Updates: 861
Cumulative Timesteps: 14406598

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 14406598...
Checkpoint 14406598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00569
Policy Entropy: 1.23891
Value Function Loss: 0.06417

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.04567

Collected Steps per Second: 13052.45178
Overall Steps per Second: 10520.41462

Timestep Collection Time: 3.83085
Timestep Consumption Time: 0.92200
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 4.75285

Cumulative Model Updates: 864
Cumulative Timesteps: 14456600

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04228
Policy Entropy: 1.23926
Value Function Loss: 0.08675

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.07114
Value Function Update Magnitude: 0.04943

Collected Steps per Second: 13357.44295
Overall Steps per Second: 10724.87726

Timestep Collection Time: 3.74727
Timestep Consumption Time: 0.91982
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 4.66709

Cumulative Model Updates: 867
Cumulative Timesteps: 14506654

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 14506654...
Checkpoint 14506654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04182
Policy Entropy: 1.23764
Value Function Loss: 0.08579

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07675
Policy Update Magnitude: 0.07715
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 12073.34679
Overall Steps per Second: 10063.33704

Timestep Collection Time: 4.14284
Timestep Consumption Time: 0.82747
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 4.97032

Cumulative Model Updates: 870
Cumulative Timesteps: 14556672

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00932
Policy Entropy: 1.23542
Value Function Loss: 0.07593

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.08021
Value Function Update Magnitude: 0.05943

Collected Steps per Second: 13261.64805
Overall Steps per Second: 10709.55061

Timestep Collection Time: 3.77193
Timestep Consumption Time: 0.89885
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 4.67078

Cumulative Model Updates: 873
Cumulative Timesteps: 14606694

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 14606694...
Checkpoint 14606694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00853
Policy Entropy: 1.24350
Value Function Loss: 0.06266

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.08448
Value Function Update Magnitude: 0.05657

Collected Steps per Second: 12699.91978
Overall Steps per Second: 10368.43859

Timestep Collection Time: 3.93782
Timestep Consumption Time: 0.88547
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 4.82329

Cumulative Model Updates: 876
Cumulative Timesteps: 14656704

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00653
Policy Entropy: 1.24195
Value Function Loss: 0.04718

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.08269
Value Function Update Magnitude: 0.04521

Collected Steps per Second: 13478.91389
Overall Steps per Second: 10843.22776

Timestep Collection Time: 3.71172
Timestep Consumption Time: 0.90222
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 4.61394

Cumulative Model Updates: 879
Cumulative Timesteps: 14706734

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 14706734...
Checkpoint 14706734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01435
Policy Entropy: 1.23875
Value Function Loss: 0.05395

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.07926
Value Function Update Magnitude: 0.04373

Collected Steps per Second: 12480.41808
Overall Steps per Second: 10094.32043

Timestep Collection Time: 4.00660
Timestep Consumption Time: 0.94708
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 4.95368

Cumulative Model Updates: 882
Cumulative Timesteps: 14756738

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06921
Policy Entropy: 1.23870
Value Function Loss: 0.05825

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.07505
Value Function Update Magnitude: 0.04104

Collected Steps per Second: 13173.30206
Overall Steps per Second: 10799.49157

Timestep Collection Time: 3.79768
Timestep Consumption Time: 0.83476
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 4.63244

Cumulative Model Updates: 885
Cumulative Timesteps: 14806766

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 14806766...
Checkpoint 14806766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00211
Policy Entropy: 1.24764
Value Function Loss: 0.05111

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.07714
Value Function Update Magnitude: 0.04962

Collected Steps per Second: 12993.22352
Overall Steps per Second: 10539.38710

Timestep Collection Time: 3.84970
Timestep Consumption Time: 0.89631
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 4.74601

Cumulative Model Updates: 888
Cumulative Timesteps: 14856786

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03121
Policy Entropy: 1.23692
Value Function Loss: 0.09123

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.07709
Value Function Update Magnitude: 0.04647

Collected Steps per Second: 13098.06960
Overall Steps per Second: 10598.91600

Timestep Collection Time: 3.82117
Timestep Consumption Time: 0.90101
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 4.72218

Cumulative Model Updates: 891
Cumulative Timesteps: 14906836

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 14906836...
Checkpoint 14906836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01141
Policy Entropy: 1.19736
Value Function Loss: 0.11404

Mean KL Divergence: 0.03575
SB3 Clip Fraction: 0.26256
Policy Update Magnitude: 0.07728
Value Function Update Magnitude: 0.05168

Collected Steps per Second: 13493.44639
Overall Steps per Second: 10854.87866

Timestep Collection Time: 3.70891
Timestep Consumption Time: 0.90155
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 4.61046

Cumulative Model Updates: 894
Cumulative Timesteps: 14956882

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02616
Policy Entropy: 1.21805
Value Function Loss: 0.11559

Mean KL Divergence: 0.03581
SB3 Clip Fraction: 0.29124
Policy Update Magnitude: 0.07457
Value Function Update Magnitude: 0.05085

Collected Steps per Second: 13385.99337
Overall Steps per Second: 10745.91411

Timestep Collection Time: 3.73719
Timestep Consumption Time: 0.91816
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 4.65535

Cumulative Model Updates: 897
Cumulative Timesteps: 15006908

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 15006908...
Checkpoint 15006908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09345
Policy Entropy: 1.26430
Value Function Loss: 0.06504

Mean KL Divergence: 0.05326
SB3 Clip Fraction: 0.38845
Policy Update Magnitude: 0.06899
Value Function Update Magnitude: 0.05062

Collected Steps per Second: 13141.63032
Overall Steps per Second: 10657.28040

Timestep Collection Time: 3.80592
Timestep Consumption Time: 0.88721
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 4.69313

Cumulative Model Updates: 900
Cumulative Timesteps: 15056924

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08574
Policy Entropy: 1.23432
Value Function Loss: 0.04879

Mean KL Divergence: 0.03024
SB3 Clip Fraction: 0.27323
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.04468

Collected Steps per Second: 13742.30679
Overall Steps per Second: 10985.58543

Timestep Collection Time: 3.63971
Timestep Consumption Time: 0.91335
PPO Batch Consumption Time: 0.02876
Total Iteration Time: 4.55306

Cumulative Model Updates: 903
Cumulative Timesteps: 15106942

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 15106942...
Checkpoint 15106942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02500
Policy Entropy: 1.30998
Value Function Loss: 0.07343

Mean KL Divergence: 0.07972
SB3 Clip Fraction: 0.42974
Policy Update Magnitude: 0.06715
Value Function Update Magnitude: 0.04656

Collected Steps per Second: 13385.28172
Overall Steps per Second: 10744.87438

Timestep Collection Time: 3.73858
Timestep Consumption Time: 0.91871
PPO Batch Consumption Time: 0.03047
Total Iteration Time: 4.65729

Cumulative Model Updates: 906
Cumulative Timesteps: 15156984

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09287
Policy Entropy: 1.25310
Value Function Loss: 0.11588

Mean KL Divergence: 0.03038
SB3 Clip Fraction: 0.24534
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.04510

Collected Steps per Second: 13221.54353
Overall Steps per Second: 10782.56813

Timestep Collection Time: 3.78231
Timestep Consumption Time: 0.85554
PPO Batch Consumption Time: 0.02932
Total Iteration Time: 4.63786

Cumulative Model Updates: 909
Cumulative Timesteps: 15206992

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 15206992...
Checkpoint 15206992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02113
Policy Entropy: 1.30188
Value Function Loss: 0.11344

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15207
Policy Update Magnitude: 0.07135
Value Function Update Magnitude: 0.05165

Collected Steps per Second: 12764.10728
Overall Steps per Second: 10332.70763

Timestep Collection Time: 3.92115
Timestep Consumption Time: 0.92269
PPO Batch Consumption Time: 0.02842
Total Iteration Time: 4.84384

Cumulative Model Updates: 912
Cumulative Timesteps: 15257042

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02425
Policy Entropy: 1.27625
Value Function Loss: 0.07928

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.06841
Value Function Update Magnitude: 0.04771

Collected Steps per Second: 13219.20431
Overall Steps per Second: 10688.09191

Timestep Collection Time: 3.78525
Timestep Consumption Time: 0.89641
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 4.68166

Cumulative Model Updates: 915
Cumulative Timesteps: 15307080

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 15307080...
Checkpoint 15307080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02960
Policy Entropy: 1.29379
Value Function Loss: 0.05201

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.06937
Value Function Update Magnitude: 0.05326

Collected Steps per Second: 13457.83104
Overall Steps per Second: 10835.63909

Timestep Collection Time: 3.71858
Timestep Consumption Time: 0.89988
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 4.61846

Cumulative Model Updates: 918
Cumulative Timesteps: 15357124

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04601
Policy Entropy: 1.27902
Value Function Loss: 0.04211

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.07187
Value Function Update Magnitude: 0.05466

Collected Steps per Second: 13147.38450
Overall Steps per Second: 10652.55648

Timestep Collection Time: 3.80486
Timestep Consumption Time: 0.89110
PPO Batch Consumption Time: 0.02552
Total Iteration Time: 4.69596

Cumulative Model Updates: 921
Cumulative Timesteps: 15407148

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 15407148...
Checkpoint 15407148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00539
Policy Entropy: 1.28206
Value Function Loss: 0.04967

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.07828
Value Function Update Magnitude: 0.05644

Collected Steps per Second: 12967.12437
Overall Steps per Second: 10699.49358

Timestep Collection Time: 3.85745
Timestep Consumption Time: 0.81754
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 4.67499

Cumulative Model Updates: 924
Cumulative Timesteps: 15457168

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02675
Policy Entropy: 1.26956
Value Function Loss: 0.05318

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.07427
Value Function Update Magnitude: 0.04801

Collected Steps per Second: 12291.40278
Overall Steps per Second: 10034.35566

Timestep Collection Time: 4.06967
Timestep Consumption Time: 0.91540
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 4.98507

Cumulative Model Updates: 927
Cumulative Timesteps: 15507190

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 15507190...
Checkpoint 15507190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01959
Policy Entropy: 1.26768
Value Function Loss: 0.05220

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.06972
Value Function Update Magnitude: 0.04805

Collected Steps per Second: 13099.72848
Overall Steps per Second: 10548.42222

Timestep Collection Time: 3.82038
Timestep Consumption Time: 0.92402
PPO Batch Consumption Time: 0.02937
Total Iteration Time: 4.74441

Cumulative Model Updates: 930
Cumulative Timesteps: 15557236

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01500
Policy Entropy: 1.26992
Value Function Loss: 0.06952

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.06521
Value Function Update Magnitude: 0.04738

Collected Steps per Second: 10372.33166
Overall Steps per Second: 8691.96977

Timestep Collection Time: 4.82052
Timestep Consumption Time: 0.93192
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 5.75244

Cumulative Model Updates: 933
Cumulative Timesteps: 15607236

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 15607236...
Checkpoint 15607236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03746
Policy Entropy: 1.28893
Value Function Loss: 0.08195

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04605
Policy Update Magnitude: 0.06866
Value Function Update Magnitude: 0.05457

Collected Steps per Second: 12444.35869
Overall Steps per Second: 10040.45900

Timestep Collection Time: 4.02030
Timestep Consumption Time: 0.96254
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 4.98284

Cumulative Model Updates: 936
Cumulative Timesteps: 15657266

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06087
Policy Entropy: 1.27754
Value Function Loss: 0.07841

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.15347
Policy Update Magnitude: 0.06950
Value Function Update Magnitude: 0.05398

Collected Steps per Second: 11933.84284
Overall Steps per Second: 9863.33879

Timestep Collection Time: 4.19127
Timestep Consumption Time: 0.87983
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 5.07110

Cumulative Model Updates: 939
Cumulative Timesteps: 15707284

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 15707284...
Checkpoint 15707284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01614
Policy Entropy: 1.27184
Value Function Loss: 0.07715

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.19283
Policy Update Magnitude: 0.06983
Value Function Update Magnitude: 0.05765

Collected Steps per Second: 12507.30664
Overall Steps per Second: 10166.10091

Timestep Collection Time: 3.99990
Timestep Consumption Time: 0.92116
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 4.92106

Cumulative Model Updates: 942
Cumulative Timesteps: 15757312

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01578
Policy Entropy: 1.28164
Value Function Loss: 0.05692

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.16693
Policy Update Magnitude: 0.07477
Value Function Update Magnitude: 0.05341

Collected Steps per Second: 13135.31979
Overall Steps per Second: 10467.94773

Timestep Collection Time: 3.81003
Timestep Consumption Time: 0.97085
PPO Batch Consumption Time: 0.02860
Total Iteration Time: 4.78088

Cumulative Model Updates: 945
Cumulative Timesteps: 15807358

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 15807358...
Checkpoint 15807358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02892
Policy Entropy: 1.29127
Value Function Loss: 0.06088

Mean KL Divergence: 0.02090
SB3 Clip Fraction: 0.21004
Policy Update Magnitude: 0.06829
Value Function Update Magnitude: 0.05708

Collected Steps per Second: 13128.43392
Overall Steps per Second: 10592.05828

Timestep Collection Time: 3.81249
Timestep Consumption Time: 0.91294
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 4.72543

Cumulative Model Updates: 948
Cumulative Timesteps: 15857410

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00749
Policy Entropy: 1.27184
Value Function Loss: 0.07062

Mean KL Divergence: 0.02108
SB3 Clip Fraction: 0.18755
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.05342

Collected Steps per Second: 12338.74173
Overall Steps per Second: 10035.98525

Timestep Collection Time: 4.05341
Timestep Consumption Time: 0.93006
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 4.98347

Cumulative Model Updates: 951
Cumulative Timesteps: 15907424

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 15907424...
Checkpoint 15907424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01743
Policy Entropy: 1.27778
Value Function Loss: 0.07053

Mean KL Divergence: 0.02638
SB3 Clip Fraction: 0.21767
Policy Update Magnitude: 0.06716
Value Function Update Magnitude: 0.05489

Collected Steps per Second: 13562.82033
Overall Steps per Second: 11102.08319

Timestep Collection Time: 3.69024
Timestep Consumption Time: 0.81793
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 4.50816

Cumulative Model Updates: 954
Cumulative Timesteps: 15957474

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03490
Policy Entropy: 1.27951
Value Function Loss: 0.06987

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.05174

Collected Steps per Second: 13064.23150
Overall Steps per Second: 10515.02502

Timestep Collection Time: 3.82923
Timestep Consumption Time: 0.92834
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 4.75757

Cumulative Model Updates: 957
Cumulative Timesteps: 16007500

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 16007500...
Checkpoint 16007500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02917
Policy Entropy: 1.26817
Value Function Loss: 0.04291

Mean KL Divergence: 0.02270
SB3 Clip Fraction: 0.18821
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.05419

Collected Steps per Second: 12832.12628
Overall Steps per Second: 10465.42705

Timestep Collection Time: 3.89725
Timestep Consumption Time: 0.88134
PPO Batch Consumption Time: 0.02827
Total Iteration Time: 4.77859

Cumulative Model Updates: 960
Cumulative Timesteps: 16057510

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11220
Policy Entropy: 1.26836
Value Function Loss: 0.07176

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.17978
Policy Update Magnitude: 0.06192
Value Function Update Magnitude: 0.04838

Collected Steps per Second: 13382.68633
Overall Steps per Second: 10678.93244

Timestep Collection Time: 3.73752
Timestep Consumption Time: 0.94629
PPO Batch Consumption Time: 0.03044
Total Iteration Time: 4.68380

Cumulative Model Updates: 963
Cumulative Timesteps: 16107528

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 16107528...
Checkpoint 16107528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03888
Policy Entropy: 1.26875
Value Function Loss: 0.10319

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.19224
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.05694

Collected Steps per Second: 12788.86623
Overall Steps per Second: 10375.61810

Timestep Collection Time: 3.91309
Timestep Consumption Time: 0.91014
PPO Batch Consumption Time: 0.02592
Total Iteration Time: 4.82323

Cumulative Model Updates: 966
Cumulative Timesteps: 16157572

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01129
Policy Entropy: 1.27858
Value Function Loss: 0.09436

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06971
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.06161

Collected Steps per Second: 12896.72007
Overall Steps per Second: 10451.83192

Timestep Collection Time: 3.88114
Timestep Consumption Time: 0.90788
PPO Batch Consumption Time: 0.02858
Total Iteration Time: 4.78902

Cumulative Model Updates: 969
Cumulative Timesteps: 16207626

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 16207626...
Checkpoint 16207626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03488
Policy Entropy: 1.28209
Value Function Loss: 0.08386

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.16105
Policy Update Magnitude: 0.06236
Value Function Update Magnitude: 0.06249

Collected Steps per Second: 13074.26965
Overall Steps per Second: 10540.13223

Timestep Collection Time: 3.82813
Timestep Consumption Time: 0.92039
PPO Batch Consumption Time: 0.02594
Total Iteration Time: 4.74852

Cumulative Model Updates: 972
Cumulative Timesteps: 16257676

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08579
Policy Entropy: 1.27576
Value Function Loss: 0.04401

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.05704

Collected Steps per Second: 10394.04189
Overall Steps per Second: 8426.51787

Timestep Collection Time: 4.81064
Timestep Consumption Time: 1.12325
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 5.93389

Cumulative Model Updates: 975
Cumulative Timesteps: 16307678

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 16307678...
Checkpoint 16307678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02863
Policy Entropy: 1.27814
Value Function Loss: 0.05101

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 12247.44352
Overall Steps per Second: 10161.96162

Timestep Collection Time: 4.08526
Timestep Consumption Time: 0.83839
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 4.92366

Cumulative Model Updates: 978
Cumulative Timesteps: 16357712

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00056
Policy Entropy: 1.28499
Value Function Loss: 0.02682

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.05318

Collected Steps per Second: 12842.78027
Overall Steps per Second: 10281.02910

Timestep Collection Time: 3.89542
Timestep Consumption Time: 0.97063
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 4.86605

Cumulative Model Updates: 981
Cumulative Timesteps: 16407740

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 16407740...
Checkpoint 16407740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00342
Policy Entropy: 1.26751
Value Function Loss: 0.06019

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.04988

Collected Steps per Second: 11563.42420
Overall Steps per Second: 9066.51560

Timestep Collection Time: 4.32450
Timestep Consumption Time: 1.19096
PPO Batch Consumption Time: 0.03083
Total Iteration Time: 5.51546

Cumulative Model Updates: 984
Cumulative Timesteps: 16457746

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04050
Policy Entropy: 1.26712
Value Function Loss: 0.05999

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.04923

Collected Steps per Second: 11243.86230
Overall Steps per Second: 9291.43742

Timestep Collection Time: 4.44989
Timestep Consumption Time: 0.93506
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 5.38496

Cumulative Model Updates: 987
Cumulative Timesteps: 16507780

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 16507780...
Checkpoint 16507780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01546
Policy Entropy: 1.26971
Value Function Loss: 0.09352

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.19329
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.05628

Collected Steps per Second: 12505.63445
Overall Steps per Second: 10085.30522

Timestep Collection Time: 3.99852
Timestep Consumption Time: 0.95959
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 4.95810

Cumulative Model Updates: 990
Cumulative Timesteps: 16557784

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00652
Policy Entropy: 1.28306
Value Function Loss: 0.05745

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11613
Policy Update Magnitude: 0.06493
Value Function Update Magnitude: 0.05420

Collected Steps per Second: 12440.78848
Overall Steps per Second: 10251.60338

Timestep Collection Time: 4.02081
Timestep Consumption Time: 0.85863
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 4.87943

Cumulative Model Updates: 993
Cumulative Timesteps: 16607806

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 16607806...
Checkpoint 16607806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02452
Policy Entropy: 1.28095
Value Function Loss: 0.07218

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.05729

Collected Steps per Second: 13020.65919
Overall Steps per Second: 10460.62980

Timestep Collection Time: 3.84128
Timestep Consumption Time: 0.94008
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 4.78136

Cumulative Model Updates: 996
Cumulative Timesteps: 16657822

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02767
Policy Entropy: 1.27487
Value Function Loss: 0.03941

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.05013

Collected Steps per Second: 12267.77139
Overall Steps per Second: 10067.73604

Timestep Collection Time: 4.07931
Timestep Consumption Time: 0.89142
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 4.97073

Cumulative Model Updates: 999
Cumulative Timesteps: 16707866

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 16707866...
Checkpoint 16707866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00395
Policy Entropy: 1.27027
Value Function Loss: 0.04890

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.05868
Value Function Update Magnitude: 0.05737

Collected Steps per Second: 13183.91635
Overall Steps per Second: 10536.01557

Timestep Collection Time: 3.79341
Timestep Consumption Time: 0.95336
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 4.74677

Cumulative Model Updates: 1002
Cumulative Timesteps: 16757878

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00988
Policy Entropy: 1.27110
Value Function Loss: 0.03401

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.04851

Collected Steps per Second: 12641.99806
Overall Steps per Second: 10174.27720

Timestep Collection Time: 3.95744
Timestep Consumption Time: 0.95986
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 4.91730

Cumulative Model Updates: 1005
Cumulative Timesteps: 16807908

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 16807908...
Checkpoint 16807908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01267
Policy Entropy: 1.28137
Value Function Loss: 0.05032

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06924
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.05783

Collected Steps per Second: 12210.45081
Overall Steps per Second: 9973.02718

Timestep Collection Time: 4.09764
Timestep Consumption Time: 0.91929
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 5.01693

Cumulative Model Updates: 1008
Cumulative Timesteps: 16857942

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02832
Policy Entropy: 1.26653
Value Function Loss: 0.05595

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.04721

Collected Steps per Second: 13196.02466
Overall Steps per Second: 10603.27657

Timestep Collection Time: 3.79084
Timestep Consumption Time: 0.92695
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 4.71779

Cumulative Model Updates: 1011
Cumulative Timesteps: 16907966

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 16907966...
Checkpoint 16907966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03831
Policy Entropy: 1.25865
Value Function Loss: 0.07095

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.18971
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.05286

Collected Steps per Second: 13574.02260
Overall Steps per Second: 10881.12874

Timestep Collection Time: 3.68380
Timestep Consumption Time: 0.91168
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 4.59548

Cumulative Model Updates: 1014
Cumulative Timesteps: 16957970

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02982
Policy Entropy: 1.25292
Value Function Loss: 0.05574

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.18133
Policy Update Magnitude: 0.05989
Value Function Update Magnitude: 0.05107

Collected Steps per Second: 12952.69169
Overall Steps per Second: 10677.82121

Timestep Collection Time: 3.86051
Timestep Consumption Time: 0.82247
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 4.68298

Cumulative Model Updates: 1017
Cumulative Timesteps: 17007974

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 17007974...
Checkpoint 17007974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00316
Policy Entropy: 1.27301
Value Function Loss: 0.07512

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.06029
Value Function Update Magnitude: 0.05251

Collected Steps per Second: 12727.72322
Overall Steps per Second: 10340.24574

Timestep Collection Time: 3.93095
Timestep Consumption Time: 0.90762
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 4.83857

Cumulative Model Updates: 1020
Cumulative Timesteps: 17058006

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00500
Policy Entropy: 1.24010
Value Function Loss: 0.07675

Mean KL Divergence: 0.02789
SB3 Clip Fraction: 0.22389
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.05165

Collected Steps per Second: 13415.73256
Overall Steps per Second: 10853.42758

Timestep Collection Time: 3.72831
Timestep Consumption Time: 0.88019
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 4.60850

Cumulative Model Updates: 1023
Cumulative Timesteps: 17108024

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 17108024...
Checkpoint 17108024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01285
Policy Entropy: 1.25532
Value Function Loss: 0.07905

Mean KL Divergence: 0.03092
SB3 Clip Fraction: 0.24825
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 13447.57970
Overall Steps per Second: 10831.90110

Timestep Collection Time: 3.71948
Timestep Consumption Time: 0.89818
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 4.61766

Cumulative Model Updates: 1026
Cumulative Timesteps: 17158042

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03196
Policy Entropy: 1.25509
Value Function Loss: 0.06738

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.06180
Value Function Update Magnitude: 0.05616

Collected Steps per Second: 13235.80072
Overall Steps per Second: 10674.65440

Timestep Collection Time: 3.77824
Timestep Consumption Time: 0.90650
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 4.68474

Cumulative Model Updates: 1029
Cumulative Timesteps: 17208050

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 17208050...
Checkpoint 17208050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03387
Policy Entropy: 1.25566
Value Function Loss: 0.06146

Mean KL Divergence: 0.03412
SB3 Clip Fraction: 0.26165
Policy Update Magnitude: 0.06147
Value Function Update Magnitude: 0.06056

Collected Steps per Second: 12607.02210
Overall Steps per Second: 10405.78888

Timestep Collection Time: 3.96842
Timestep Consumption Time: 0.83948
PPO Batch Consumption Time: 0.02527
Total Iteration Time: 4.80790

Cumulative Model Updates: 1032
Cumulative Timesteps: 17258080

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02993
Policy Entropy: 1.22987
Value Function Loss: 0.08568

Mean KL Divergence: 0.03589
SB3 Clip Fraction: 0.28690
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.06324

Collected Steps per Second: 13187.10012
Overall Steps per Second: 10601.88411

Timestep Collection Time: 3.79340
Timestep Consumption Time: 0.92500
PPO Batch Consumption Time: 0.02966
Total Iteration Time: 4.71841

Cumulative Model Updates: 1035
Cumulative Timesteps: 17308104

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 17308104...
Checkpoint 17308104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01747
Policy Entropy: 1.25504
Value Function Loss: 0.08231

Mean KL Divergence: 0.03217
SB3 Clip Fraction: 0.24061
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.06882

Collected Steps per Second: 12308.82735
Overall Steps per Second: 9933.20715

Timestep Collection Time: 4.06424
Timestep Consumption Time: 0.97200
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 5.03624

Cumulative Model Updates: 1038
Cumulative Timesteps: 17358130

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00119
Policy Entropy: 1.23711
Value Function Loss: 0.08352

Mean KL Divergence: 0.03320
SB3 Clip Fraction: 0.26818
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.05971

Collected Steps per Second: 12291.07154
Overall Steps per Second: 9925.88015

Timestep Collection Time: 4.07011
Timestep Consumption Time: 0.96985
PPO Batch Consumption Time: 0.02815
Total Iteration Time: 5.03996

Cumulative Model Updates: 1041
Cumulative Timesteps: 17408156

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 17408156...
Checkpoint 17408156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01425
Policy Entropy: 1.22146
Value Function Loss: 0.08075

Mean KL Divergence: 0.03887
SB3 Clip Fraction: 0.23209
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.06512

Collected Steps per Second: 11646.09172
Overall Steps per Second: 9566.36927

Timestep Collection Time: 4.29397
Timestep Consumption Time: 0.93351
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 5.22748

Cumulative Model Updates: 1044
Cumulative Timesteps: 17458164

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07333
Policy Entropy: 1.23029
Value Function Loss: 0.09329

Mean KL Divergence: 0.03119
SB3 Clip Fraction: 0.26175
Policy Update Magnitude: 0.06216
Value Function Update Magnitude: 0.06929

Collected Steps per Second: 12504.02198
Overall Steps per Second: 10275.84373

Timestep Collection Time: 4.00319
Timestep Consumption Time: 0.86804
PPO Batch Consumption Time: 0.02698
Total Iteration Time: 4.87123

Cumulative Model Updates: 1047
Cumulative Timesteps: 17508220

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 17508220...
Checkpoint 17508220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04418
Policy Entropy: 1.22689
Value Function Loss: 0.09107

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.18061
Policy Update Magnitude: 0.05806
Value Function Update Magnitude: 0.07512

Collected Steps per Second: 12642.44190
Overall Steps per Second: 10263.53877

Timestep Collection Time: 3.95794
Timestep Consumption Time: 0.91738
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 4.87532

Cumulative Model Updates: 1050
Cumulative Timesteps: 17558258

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00176
Policy Entropy: 1.22144
Value Function Loss: 0.06530

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.17756
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.06569

Collected Steps per Second: 13329.36803
Overall Steps per Second: 10789.40035

Timestep Collection Time: 3.75202
Timestep Consumption Time: 0.88327
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 4.63529

Cumulative Model Updates: 1053
Cumulative Timesteps: 17608270

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 17608270...
Checkpoint 17608270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05323
Policy Entropy: 1.21496
Value Function Loss: 0.04445

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.06247
Value Function Update Magnitude: 0.06332

Collected Steps per Second: 13564.40422
Overall Steps per Second: 10795.14683

Timestep Collection Time: 3.68907
Timestep Consumption Time: 0.94635
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 4.63542

Cumulative Model Updates: 1056
Cumulative Timesteps: 17658310

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00570
Policy Entropy: 1.21777
Value Function Loss: 0.06129

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.15420
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.05623

Collected Steps per Second: 13205.89460
Overall Steps per Second: 10661.59226

Timestep Collection Time: 3.78664
Timestep Consumption Time: 0.90365
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 4.69029

Cumulative Model Updates: 1059
Cumulative Timesteps: 17708316

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 17708316...
Checkpoint 17708316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05482
Policy Entropy: 1.21598
Value Function Loss: 0.06887

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.17647
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.05510

Collected Steps per Second: 13247.76596
Overall Steps per Second: 10879.37406

Timestep Collection Time: 3.77724
Timestep Consumption Time: 0.82229
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 4.59953

Cumulative Model Updates: 1062
Cumulative Timesteps: 17758356

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00478
Policy Entropy: 1.21473
Value Function Loss: 0.07642

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.05351

Collected Steps per Second: 13395.97482
Overall Steps per Second: 10788.52402

Timestep Collection Time: 3.73291
Timestep Consumption Time: 0.90220
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 4.63511

Cumulative Model Updates: 1065
Cumulative Timesteps: 17808362

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 17808362...
Checkpoint 17808362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02556
Policy Entropy: 1.21418
Value Function Loss: 0.05486

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08831
Policy Update Magnitude: 0.06997
Value Function Update Magnitude: 0.05459

Collected Steps per Second: 13058.80935
Overall Steps per Second: 10576.36386

Timestep Collection Time: 3.83144
Timestep Consumption Time: 0.89930
PPO Batch Consumption Time: 0.02711
Total Iteration Time: 4.73074

Cumulative Model Updates: 1068
Cumulative Timesteps: 17858396

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01762
Policy Entropy: 1.20662
Value Function Loss: 0.05001

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10850
Policy Update Magnitude: 0.07205
Value Function Update Magnitude: 0.05377

Collected Steps per Second: 13714.19492
Overall Steps per Second: 10977.44776

Timestep Collection Time: 3.64921
Timestep Consumption Time: 0.90977
PPO Batch Consumption Time: 0.03000
Total Iteration Time: 4.55898

Cumulative Model Updates: 1071
Cumulative Timesteps: 17908442

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 17908442...
Checkpoint 17908442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02038
Policy Entropy: 1.20244
Value Function Loss: 0.04651

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.06883
Value Function Update Magnitude: 0.05454

Collected Steps per Second: 12889.57747
Overall Steps per Second: 10352.86227

Timestep Collection Time: 3.88050
Timestep Consumption Time: 0.95082
PPO Batch Consumption Time: 0.03447
Total Iteration Time: 4.83132

Cumulative Model Updates: 1074
Cumulative Timesteps: 17958460

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01961
Policy Entropy: 1.20017
Value Function Loss: 0.03297

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.16399
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.04372

Collected Steps per Second: 12793.06049
Overall Steps per Second: 10552.54868

Timestep Collection Time: 3.91259
Timestep Consumption Time: 0.83072
PPO Batch Consumption Time: 0.02911
Total Iteration Time: 4.74331

Cumulative Model Updates: 1077
Cumulative Timesteps: 18008514

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 18008514...
Checkpoint 18008514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01879
Policy Entropy: 1.21147
Value Function Loss: 0.03903

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.04001

Collected Steps per Second: 13185.76388
Overall Steps per Second: 10656.24849

Timestep Collection Time: 3.79394
Timestep Consumption Time: 0.90058
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 4.69452

Cumulative Model Updates: 1080
Cumulative Timesteps: 18058540

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02782
Policy Entropy: 1.21534
Value Function Loss: 0.04731

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.06018
Value Function Update Magnitude: 0.03762

Collected Steps per Second: 13222.84716
Overall Steps per Second: 10683.57535

Timestep Collection Time: 3.78406
Timestep Consumption Time: 0.89939
PPO Batch Consumption Time: 0.02854
Total Iteration Time: 4.68345

Cumulative Model Updates: 1083
Cumulative Timesteps: 18108576

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 18108576...
Checkpoint 18108576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06630
Policy Entropy: 1.21119
Value Function Loss: 0.05514

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16241
Policy Update Magnitude: 0.05905
Value Function Update Magnitude: 0.04919

Collected Steps per Second: 13603.56448
Overall Steps per Second: 10873.52106

Timestep Collection Time: 3.67580
Timestep Consumption Time: 0.92289
PPO Batch Consumption Time: 0.03194
Total Iteration Time: 4.59869

Cumulative Model Updates: 1086
Cumulative Timesteps: 18158580

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01658
Policy Entropy: 1.21002
Value Function Loss: 0.07701

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.05364

Collected Steps per Second: 13156.26346
Overall Steps per Second: 10584.15130

Timestep Collection Time: 3.80260
Timestep Consumption Time: 0.92409
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 4.72669

Cumulative Model Updates: 1089
Cumulative Timesteps: 18208608

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 18208608...
Checkpoint 18208608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00484
Policy Entropy: 1.21290
Value Function Loss: 0.05710

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.18864
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.05207

Collected Steps per Second: 13335.05991
Overall Steps per Second: 10940.93310

Timestep Collection Time: 3.74951
Timestep Consumption Time: 0.82048
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 4.56999

Cumulative Model Updates: 1092
Cumulative Timesteps: 18258608

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10750
Policy Entropy: 1.19328
Value Function Loss: 0.06180

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.14777
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.05812

Collected Steps per Second: 13413.60061
Overall Steps per Second: 10775.21283

Timestep Collection Time: 3.72801
Timestep Consumption Time: 0.91283
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 4.64084

Cumulative Model Updates: 1095
Cumulative Timesteps: 18308614

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 18308614...
Checkpoint 18308614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02007
Policy Entropy: 1.19749
Value Function Loss: 0.03866

Mean KL Divergence: 0.02222
SB3 Clip Fraction: 0.22283
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.06177

Collected Steps per Second: 13357.63680
Overall Steps per Second: 10813.35151

Timestep Collection Time: 3.74542
Timestep Consumption Time: 0.88126
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 4.62669

Cumulative Model Updates: 1098
Cumulative Timesteps: 18358644

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02206
Policy Entropy: 1.21335
Value Function Loss: 0.05541

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.04809

Collected Steps per Second: 13194.27513
Overall Steps per Second: 10626.04558

Timestep Collection Time: 3.78998
Timestep Consumption Time: 0.91601
PPO Batch Consumption Time: 0.02543
Total Iteration Time: 4.70598

Cumulative Model Updates: 1101
Cumulative Timesteps: 18408650

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 18408650...
Checkpoint 18408650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01021
Policy Entropy: 1.22125
Value Function Loss: 0.05271

Mean KL Divergence: 0.02568
SB3 Clip Fraction: 0.23042
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.04977

Collected Steps per Second: 13405.19811
Overall Steps per Second: 10796.84676

Timestep Collection Time: 3.73258
Timestep Consumption Time: 0.90173
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 4.63432

Cumulative Model Updates: 1104
Cumulative Timesteps: 18458686

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01434
Policy Entropy: 1.20141
Value Function Loss: 0.05352

Mean KL Divergence: 0.02259
SB3 Clip Fraction: 0.21168
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.04798

Collected Steps per Second: 13220.87889
Overall Steps per Second: 10780.35940

Timestep Collection Time: 3.78341
Timestep Consumption Time: 0.85651
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 4.63992

Cumulative Model Updates: 1107
Cumulative Timesteps: 18508706

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 18508706...
Checkpoint 18508706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02231
Policy Entropy: 1.22505
Value Function Loss: 0.06664

Mean KL Divergence: 0.03941
SB3 Clip Fraction: 0.26634
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.05160

Collected Steps per Second: 12227.95065
Overall Steps per Second: 9672.33809

Timestep Collection Time: 4.09145
Timestep Consumption Time: 1.08104
PPO Batch Consumption Time: 0.03289
Total Iteration Time: 5.17248

Cumulative Model Updates: 1110
Cumulative Timesteps: 18558736

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01338
Policy Entropy: 1.22323
Value Function Loss: 0.06246

Mean KL Divergence: 0.03149
SB3 Clip Fraction: 0.24170
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.04887

Collected Steps per Second: 12689.59001
Overall Steps per Second: 10175.12239

Timestep Collection Time: 3.94260
Timestep Consumption Time: 0.97429
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 4.91689

Cumulative Model Updates: 1113
Cumulative Timesteps: 18608766

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 18608766...
Checkpoint 18608766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02076
Policy Entropy: 1.20634
Value Function Loss: 0.08612

Mean KL Divergence: 0.02385
SB3 Clip Fraction: 0.17735
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.06158

Collected Steps per Second: 12758.77816
Overall Steps per Second: 10253.73727

Timestep Collection Time: 3.92122
Timestep Consumption Time: 0.95797
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 4.87920

Cumulative Model Updates: 1116
Cumulative Timesteps: 18658796

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01612
Policy Entropy: 1.21892
Value Function Loss: 0.07193

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.22469
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.06228

Collected Steps per Second: 11358.42973
Overall Steps per Second: 9418.44067

Timestep Collection Time: 4.40519
Timestep Consumption Time: 0.90737
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 5.31256

Cumulative Model Updates: 1119
Cumulative Timesteps: 18708832

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 18708832...
Checkpoint 18708832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01718
Policy Entropy: 1.21370
Value Function Loss: 0.07333

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.06810
Value Function Update Magnitude: 0.06432

Collected Steps per Second: 12319.33067
Overall Steps per Second: 10208.67625

Timestep Collection Time: 4.05980
Timestep Consumption Time: 0.83937
PPO Batch Consumption Time: 0.03056
Total Iteration Time: 4.89917

Cumulative Model Updates: 1122
Cumulative Timesteps: 18758846

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00098
Policy Entropy: 1.21131
Value Function Loss: 0.07417

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.06174

Collected Steps per Second: 12665.35040
Overall Steps per Second: 10199.72329

Timestep Collection Time: 3.95015
Timestep Consumption Time: 0.95489
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 4.90504

Cumulative Model Updates: 1125
Cumulative Timesteps: 18808876

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 18808876...
Checkpoint 18808876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02900
Policy Entropy: 1.20737
Value Function Loss: 0.07306

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 12715.20855
Overall Steps per Second: 10352.95527

Timestep Collection Time: 3.93623
Timestep Consumption Time: 0.89814
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 4.83437

Cumulative Model Updates: 1128
Cumulative Timesteps: 18858926

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08861
Policy Entropy: 1.20464
Value Function Loss: 0.09015

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.06262
Value Function Update Magnitude: 0.07128

Collected Steps per Second: 12473.63361
Overall Steps per Second: 10060.52119

Timestep Collection Time: 4.01038
Timestep Consumption Time: 0.96193
PPO Batch Consumption Time: 0.03004
Total Iteration Time: 4.97231

Cumulative Model Updates: 1131
Cumulative Timesteps: 18908950

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 18908950...
Checkpoint 18908950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01696
Policy Entropy: 1.19752
Value Function Loss: 0.06840

Mean KL Divergence: 0.02653
SB3 Clip Fraction: 0.22390
Policy Update Magnitude: 0.06191
Value Function Update Magnitude: 0.07472

Collected Steps per Second: 12787.35858
Overall Steps per Second: 10251.48809

Timestep Collection Time: 3.91136
Timestep Consumption Time: 0.96754
PPO Batch Consumption Time: 0.02871
Total Iteration Time: 4.87890

Cumulative Model Updates: 1134
Cumulative Timesteps: 18958966

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07464
Policy Entropy: 1.20875
Value Function Loss: 0.07985

Mean KL Divergence: 0.03006
SB3 Clip Fraction: 0.19743
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.06914

Collected Steps per Second: 12264.27583
Overall Steps per Second: 10058.26519

Timestep Collection Time: 4.07916
Timestep Consumption Time: 0.89466
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 4.97382

Cumulative Model Updates: 1137
Cumulative Timesteps: 19008994

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 19008994...
Checkpoint 19008994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01510
Policy Entropy: 1.22513
Value Function Loss: 0.06884

Mean KL Divergence: 0.03821
SB3 Clip Fraction: 0.26493
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.07006

Collected Steps per Second: 12694.39730
Overall Steps per Second: 10349.46936

Timestep Collection Time: 3.94001
Timestep Consumption Time: 0.89271
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 4.83271

Cumulative Model Updates: 1140
Cumulative Timesteps: 19059010

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02558
Policy Entropy: 1.18284
Value Function Loss: 0.09358

Mean KL Divergence: 0.03745
SB3 Clip Fraction: 0.25332
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.06589

Collected Steps per Second: 13708.18251
Overall Steps per Second: 11040.45503

Timestep Collection Time: 3.64804
Timestep Consumption Time: 0.88148
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 4.52952

Cumulative Model Updates: 1143
Cumulative Timesteps: 19109018

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 19109018...
Checkpoint 19109018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00971
Policy Entropy: 1.22949
Value Function Loss: 0.08393

Mean KL Divergence: 0.03506
SB3 Clip Fraction: 0.23479
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.07175

Collected Steps per Second: 13727.21975
Overall Steps per Second: 11170.48414

Timestep Collection Time: 3.64487
Timestep Consumption Time: 0.83425
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 4.47913

Cumulative Model Updates: 1146
Cumulative Timesteps: 19159052

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02948
Policy Entropy: 1.19797
Value Function Loss: 0.06832

Mean KL Divergence: 0.05061
SB3 Clip Fraction: 0.28200
Policy Update Magnitude: 0.05756
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 11956.15014
Overall Steps per Second: 9656.76990

Timestep Collection Time: 4.18295
Timestep Consumption Time: 0.99601
PPO Batch Consumption Time: 0.03471
Total Iteration Time: 5.17896

Cumulative Model Updates: 1149
Cumulative Timesteps: 19209064

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 19209064...
Checkpoint 19209064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05993
Policy Entropy: 1.21743
Value Function Loss: 0.06125

Mean KL Divergence: 0.03059
SB3 Clip Fraction: 0.23239
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.06800

Collected Steps per Second: 13281.52656
Overall Steps per Second: 10671.16876

Timestep Collection Time: 3.76583
Timestep Consumption Time: 0.92119
PPO Batch Consumption Time: 0.02853
Total Iteration Time: 4.68702

Cumulative Model Updates: 1152
Cumulative Timesteps: 19259080

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02341
Policy Entropy: 1.21695
Value Function Loss: 0.05588

Mean KL Divergence: 0.02382
SB3 Clip Fraction: 0.18983
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.06116

Collected Steps per Second: 13645.74612
Overall Steps per Second: 10989.87034

Timestep Collection Time: 3.66517
Timestep Consumption Time: 0.88575
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 4.55092

Cumulative Model Updates: 1155
Cumulative Timesteps: 19309094

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 19309094...
Checkpoint 19309094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00336
Policy Entropy: 1.22125
Value Function Loss: 0.06239

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.05859

Collected Steps per Second: 13443.54646
Overall Steps per Second: 10814.12111

Timestep Collection Time: 3.72223
Timestep Consumption Time: 0.90505
PPO Batch Consumption Time: 0.02606
Total Iteration Time: 4.62728

Cumulative Model Updates: 1158
Cumulative Timesteps: 19359134

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00847
Policy Entropy: 1.20871
Value Function Loss: 0.04842

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.05265

Collected Steps per Second: 13267.52509
Overall Steps per Second: 10939.60752

Timestep Collection Time: 3.76875
Timestep Consumption Time: 0.80198
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 4.57073

Cumulative Model Updates: 1161
Cumulative Timesteps: 19409136

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 19409136...
Checkpoint 19409136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01061
Policy Entropy: 1.20171
Value Function Loss: 0.05232

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.05397

Collected Steps per Second: 13454.73228
Overall Steps per Second: 10885.08952

Timestep Collection Time: 3.71646
Timestep Consumption Time: 0.87735
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 4.59381

Cumulative Model Updates: 1164
Cumulative Timesteps: 19459140

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03462
Policy Entropy: 1.20416
Value Function Loss: 0.06843

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10282
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.04941

Collected Steps per Second: 13961.07570
Overall Steps per Second: 11231.80260

Timestep Collection Time: 3.58396
Timestep Consumption Time: 0.87089
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 4.45485

Cumulative Model Updates: 1167
Cumulative Timesteps: 19509176

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 19509176...
Checkpoint 19509176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03262
Policy Entropy: 1.20315
Value Function Loss: 0.05704

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.05733
Value Function Update Magnitude: 0.06288

Collected Steps per Second: 13756.72928
Overall Steps per Second: 11010.33659

Timestep Collection Time: 3.63473
Timestep Consumption Time: 0.90664
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 4.54137

Cumulative Model Updates: 1170
Cumulative Timesteps: 19559178

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03545
Policy Entropy: 1.20210
Value Function Loss: 0.06600

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.05739

Collected Steps per Second: 14242.36140
Overall Steps per Second: 11346.96619

Timestep Collection Time: 3.51192
Timestep Consumption Time: 0.89613
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 4.40805

Cumulative Model Updates: 1173
Cumulative Timesteps: 19609196

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 19609196...
Checkpoint 19609196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00802
Policy Entropy: 1.20751
Value Function Loss: 0.04647

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.06790

Collected Steps per Second: 14013.18646
Overall Steps per Second: 11425.68460

Timestep Collection Time: 3.56864
Timestep Consumption Time: 0.80817
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 4.37681

Cumulative Model Updates: 1176
Cumulative Timesteps: 19659204

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00308
Policy Entropy: 1.20303
Value Function Loss: 0.06055

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.05139

Collected Steps per Second: 13414.25424
Overall Steps per Second: 10773.99681

Timestep Collection Time: 3.72812
Timestep Consumption Time: 0.91361
PPO Batch Consumption Time: 0.02492
Total Iteration Time: 4.64173

Cumulative Model Updates: 1179
Cumulative Timesteps: 19709214

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 19709214...
Checkpoint 19709214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03798
Policy Entropy: 1.18232
Value Function Loss: 0.04979

Mean KL Divergence: 0.02909
SB3 Clip Fraction: 0.23012
Policy Update Magnitude: 0.05925
Value Function Update Magnitude: 0.06112

Collected Steps per Second: 12728.77493
Overall Steps per Second: 10419.64193

Timestep Collection Time: 3.93046
Timestep Consumption Time: 0.87104
PPO Batch Consumption Time: 0.02575
Total Iteration Time: 4.80151

Cumulative Model Updates: 1182
Cumulative Timesteps: 19759244

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02996
Policy Entropy: 1.22002
Value Function Loss: 0.04299

Mean KL Divergence: 0.02342
SB3 Clip Fraction: 0.19479
Policy Update Magnitude: 0.06420
Value Function Update Magnitude: 0.05641

Collected Steps per Second: 13403.93898
Overall Steps per Second: 10825.17100

Timestep Collection Time: 3.73069
Timestep Consumption Time: 0.88872
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 4.61942

Cumulative Model Updates: 1185
Cumulative Timesteps: 19809250

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 19809250...
Checkpoint 19809250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00018
Policy Entropy: 1.21441
Value Function Loss: 0.02705

Mean KL Divergence: 0.03839
SB3 Clip Fraction: 0.25272
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.05451

Collected Steps per Second: 13701.55471
Overall Steps per Second: 10637.23275

Timestep Collection Time: 3.65199
Timestep Consumption Time: 1.05205
PPO Batch Consumption Time: 0.03082
Total Iteration Time: 4.70404

Cumulative Model Updates: 1188
Cumulative Timesteps: 19859288

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00837
Policy Entropy: 1.22636
Value Function Loss: 0.01987

Mean KL Divergence: 0.03098
SB3 Clip Fraction: 0.23964
Policy Update Magnitude: 0.05371
Value Function Update Magnitude: 0.04606

Collected Steps per Second: 12197.93847
Overall Steps per Second: 9942.22657

Timestep Collection Time: 4.09987
Timestep Consumption Time: 0.93019
PPO Batch Consumption Time: 0.03059
Total Iteration Time: 5.03006

Cumulative Model Updates: 1191
Cumulative Timesteps: 19909298

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 19909298...
Checkpoint 19909298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02459
Policy Entropy: 1.22092
Value Function Loss: 0.03753

Mean KL Divergence: 0.03199
SB3 Clip Fraction: 0.23127
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.03848

Collected Steps per Second: 11299.43429
Overall Steps per Second: 9237.03062

Timestep Collection Time: 4.42535
Timestep Consumption Time: 0.98807
PPO Batch Consumption Time: 0.02526
Total Iteration Time: 5.41343

Cumulative Model Updates: 1194
Cumulative Timesteps: 19959302

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01707
Policy Entropy: 1.22539
Value Function Loss: 0.06522

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.05070

Collected Steps per Second: 12168.14045
Overall Steps per Second: 9765.91894

Timestep Collection Time: 4.11172
Timestep Consumption Time: 1.01140
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 5.12312

Cumulative Model Updates: 1197
Cumulative Timesteps: 20009334

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 20009334...
Checkpoint 20009334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01401
Policy Entropy: 1.21426
Value Function Loss: 0.05815

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.06414

Collected Steps per Second: 10665.58759
Overall Steps per Second: 8796.31871

Timestep Collection Time: 4.69135
Timestep Consumption Time: 0.99694
PPO Batch Consumption Time: 0.02859
Total Iteration Time: 5.68829

Cumulative Model Updates: 1200
Cumulative Timesteps: 20059370

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01242
Policy Entropy: 1.20265
Value Function Loss: 0.05877

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14533
Policy Update Magnitude: 0.04919
Value Function Update Magnitude: 0.05943

Collected Steps per Second: 11961.98889
Overall Steps per Second: 9677.32666

Timestep Collection Time: 4.18258
Timestep Consumption Time: 0.98744
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 5.17002

Cumulative Model Updates: 1203
Cumulative Timesteps: 20109402

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 20109402...
Checkpoint 20109402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03380
Policy Entropy: 1.20491
Value Function Loss: 0.05386

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.20161
Policy Update Magnitude: 0.04878
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 10677.51605
Overall Steps per Second: 8630.92942

Timestep Collection Time: 4.68536
Timestep Consumption Time: 1.11100
PPO Batch Consumption Time: 0.02911
Total Iteration Time: 5.79636

Cumulative Model Updates: 1206
Cumulative Timesteps: 20159430

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00267
Policy Entropy: 1.21173
Value Function Loss: 0.07703

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.06164

Collected Steps per Second: 10034.42347
Overall Steps per Second: 8329.73143

Timestep Collection Time: 4.98305
Timestep Consumption Time: 1.01979
PPO Batch Consumption Time: 0.02812
Total Iteration Time: 6.00283

Cumulative Model Updates: 1209
Cumulative Timesteps: 20209432

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 20209432...
Checkpoint 20209432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00528
Policy Entropy: 1.19396
Value Function Loss: 0.09057

Mean KL Divergence: 0.02929
SB3 Clip Fraction: 0.21691
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.07557

Collected Steps per Second: 11469.48353
Overall Steps per Second: 9300.93732

Timestep Collection Time: 4.36027
Timestep Consumption Time: 1.01661
PPO Batch Consumption Time: 0.02883
Total Iteration Time: 5.37688

Cumulative Model Updates: 1212
Cumulative Timesteps: 20259442

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02893
Policy Entropy: 1.16481
Value Function Loss: 0.09203

Mean KL Divergence: 0.03893
SB3 Clip Fraction: 0.26056
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.07327

Collected Steps per Second: 12007.38458
Overall Steps per Second: 9553.59108

Timestep Collection Time: 4.16577
Timestep Consumption Time: 1.06996
PPO Batch Consumption Time: 0.03047
Total Iteration Time: 5.23573

Cumulative Model Updates: 1215
Cumulative Timesteps: 20309462

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 20309462...
Checkpoint 20309462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06486
Policy Entropy: 1.19704
Value Function Loss: 0.07104

Mean KL Divergence: 0.02954
SB3 Clip Fraction: 0.21377
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.07849

Collected Steps per Second: 11139.80285
Overall Steps per Second: 9095.64110

Timestep Collection Time: 4.49164
Timestep Consumption Time: 1.00946
PPO Batch Consumption Time: 0.02978
Total Iteration Time: 5.50110

Cumulative Model Updates: 1218
Cumulative Timesteps: 20359498

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02362
Policy Entropy: 1.19427
Value Function Loss: 0.06421

Mean KL Divergence: 0.02930
SB3 Clip Fraction: 0.22985
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.07803

Collected Steps per Second: 11590.17732
Overall Steps per Second: 9477.02590

Timestep Collection Time: 4.31762
Timestep Consumption Time: 0.96273
PPO Batch Consumption Time: 0.03218
Total Iteration Time: 5.28035

Cumulative Model Updates: 1221
Cumulative Timesteps: 20409540

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 20409540...
Checkpoint 20409540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05601
Policy Entropy: 1.17964
Value Function Loss: 0.07336

Mean KL Divergence: 0.03233
SB3 Clip Fraction: 0.19223
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.08788

Collected Steps per Second: 11789.95305
Overall Steps per Second: 9500.45489

Timestep Collection Time: 4.24293
Timestep Consumption Time: 1.02250
PPO Batch Consumption Time: 0.02887
Total Iteration Time: 5.26543

Cumulative Model Updates: 1224
Cumulative Timesteps: 20459564

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03027
Policy Entropy: 1.18011
Value Function Loss: 0.07228

Mean KL Divergence: 0.02556
SB3 Clip Fraction: 0.21783
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.09093

Collected Steps per Second: 11615.60766
Overall Steps per Second: 9454.23283

Timestep Collection Time: 4.30559
Timestep Consumption Time: 0.98432
PPO Batch Consumption Time: 0.02977
Total Iteration Time: 5.28991

Cumulative Model Updates: 1227
Cumulative Timesteps: 20509576

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 20509576...
Checkpoint 20509576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00084
Policy Entropy: 1.18009
Value Function Loss: 0.07288

Mean KL Divergence: 0.03105
SB3 Clip Fraction: 0.20291
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.09712

Collected Steps per Second: 12021.53891
Overall Steps per Second: 9634.05143

Timestep Collection Time: 4.15920
Timestep Consumption Time: 1.03072
PPO Batch Consumption Time: 0.02940
Total Iteration Time: 5.18992

Cumulative Model Updates: 1230
Cumulative Timesteps: 20559576

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00157
Policy Entropy: 1.19515
Value Function Loss: 0.04497

Mean KL Divergence: 0.02923
SB3 Clip Fraction: 0.23145
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.08346

Collected Steps per Second: 9810.87981
Overall Steps per Second: 7870.38390

Timestep Collection Time: 5.10107
Timestep Consumption Time: 1.25770
PPO Batch Consumption Time: 0.02964
Total Iteration Time: 6.35877

Cumulative Model Updates: 1233
Cumulative Timesteps: 20609622

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 20609622...
Checkpoint 20609622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00749
Policy Entropy: 1.17288
Value Function Loss: 0.05075

Mean KL Divergence: 0.02704
SB3 Clip Fraction: 0.18584
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.07988

Collected Steps per Second: 9923.15982
Overall Steps per Second: 8431.19862

Timestep Collection Time: 5.04073
Timestep Consumption Time: 0.89199
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 5.93273

Cumulative Model Updates: 1236
Cumulative Timesteps: 20659642

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18933
Policy Entropy: 1.19157
Value Function Loss: 0.06270

Mean KL Divergence: 0.02735
SB3 Clip Fraction: 0.22515
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.07320

Collected Steps per Second: 11110.78443
Overall Steps per Second: 9038.38078

Timestep Collection Time: 4.50049
Timestep Consumption Time: 1.03191
PPO Batch Consumption Time: 0.02853
Total Iteration Time: 5.53241

Cumulative Model Updates: 1239
Cumulative Timesteps: 20709646

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 20709646...
Checkpoint 20709646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00674
Policy Entropy: 1.18798
Value Function Loss: 0.07076

Mean KL Divergence: 0.02153
SB3 Clip Fraction: 0.17965
Policy Update Magnitude: 0.05158
Value Function Update Magnitude: 0.07132

Collected Steps per Second: 11778.71160
Overall Steps per Second: 9536.21492

Timestep Collection Time: 4.24512
Timestep Consumption Time: 0.99826
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 5.24338

Cumulative Model Updates: 1242
Cumulative Timesteps: 20759648

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02970
Policy Entropy: 1.18596
Value Function Loss: 0.07933

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.06857

Collected Steps per Second: 11874.10760
Overall Steps per Second: 9590.60084

Timestep Collection Time: 4.21084
Timestep Consumption Time: 1.00259
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 5.21344

Cumulative Model Updates: 1245
Cumulative Timesteps: 20809648

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 20809648...
Checkpoint 20809648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02618
Policy Entropy: 1.18122
Value Function Loss: 0.08630

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.08052

Collected Steps per Second: 13286.60126
Overall Steps per Second: 10667.25849

Timestep Collection Time: 3.76545
Timestep Consumption Time: 0.92460
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 4.69005

Cumulative Model Updates: 1248
Cumulative Timesteps: 20859678

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01671
Policy Entropy: 1.16752
Value Function Loss: 0.07778

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.15226
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.08167

Collected Steps per Second: 13093.17933
Overall Steps per Second: 10618.75324

Timestep Collection Time: 3.82275
Timestep Consumption Time: 0.89079
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 4.71355

Cumulative Model Updates: 1251
Cumulative Timesteps: 20909730

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 20909730...
Checkpoint 20909730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00035
Policy Entropy: 1.13742
Value Function Loss: 0.07797

Mean KL Divergence: 0.05644
SB3 Clip Fraction: 0.31463
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.09015

Collected Steps per Second: 13293.09173
Overall Steps per Second: 10582.92531

Timestep Collection Time: 3.76556
Timestep Consumption Time: 0.96432
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 4.72988

Cumulative Model Updates: 1254
Cumulative Timesteps: 20959786

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02479
Policy Entropy: 1.16339
Value Function Loss: 0.04758

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.17411
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.07915

Collected Steps per Second: 13398.25719
Overall Steps per Second: 10790.52496

Timestep Collection Time: 3.73571
Timestep Consumption Time: 0.90280
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 4.63851

Cumulative Model Updates: 1257
Cumulative Timesteps: 21009838

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 21009838...
Checkpoint 21009838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00237
Policy Entropy: 1.17193
Value Function Loss: 0.05485

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.17814
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.07756

Collected Steps per Second: 13428.80280
Overall Steps per Second: 10815.33568

Timestep Collection Time: 3.72528
Timestep Consumption Time: 0.90019
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 4.62547

Cumulative Model Updates: 1260
Cumulative Timesteps: 21059864

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08537
Policy Entropy: 1.15005
Value Function Loss: 0.05064

Mean KL Divergence: 0.02521
SB3 Clip Fraction: 0.20053
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.06461

Collected Steps per Second: 13030.68587
Overall Steps per Second: 10523.45319

Timestep Collection Time: 3.83817
Timestep Consumption Time: 0.91445
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 4.75262

Cumulative Model Updates: 1263
Cumulative Timesteps: 21109878

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 21109878...
Checkpoint 21109878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01574
Policy Entropy: 1.14807
Value Function Loss: 0.05522

Mean KL Divergence: 0.03478
SB3 Clip Fraction: 0.25717
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.06251

Collected Steps per Second: 13189.18876
Overall Steps per Second: 10766.54516

Timestep Collection Time: 3.79159
Timestep Consumption Time: 0.85317
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 4.64476

Cumulative Model Updates: 1266
Cumulative Timesteps: 21159886

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04205
Policy Entropy: 1.15715
Value Function Loss: 0.06639

Mean KL Divergence: 0.02820
SB3 Clip Fraction: 0.20703
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.05907

Collected Steps per Second: 12942.91393
Overall Steps per Second: 10475.56759

Timestep Collection Time: 3.86667
Timestep Consumption Time: 0.91073
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 4.77740

Cumulative Model Updates: 1269
Cumulative Timesteps: 21209932

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 21209932...
Checkpoint 21209932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03717
Policy Entropy: 1.19623
Value Function Loss: 0.06042

Mean KL Divergence: 0.04139
SB3 Clip Fraction: 0.29107
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.07209

Collected Steps per Second: 13080.13096
Overall Steps per Second: 10620.65952

Timestep Collection Time: 3.82397
Timestep Consumption Time: 0.88553
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 4.70950

Cumulative Model Updates: 1272
Cumulative Timesteps: 21259950

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01440
Policy Entropy: 1.13235
Value Function Loss: 0.05415

Mean KL Divergence: 0.07682
SB3 Clip Fraction: 0.34797
Policy Update Magnitude: 0.04671
Value Function Update Magnitude: 0.07239

Collected Steps per Second: 13557.91865
Overall Steps per Second: 10862.69278

Timestep Collection Time: 3.68877
Timestep Consumption Time: 0.91525
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 4.60401

Cumulative Model Updates: 1275
Cumulative Timesteps: 21309962

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 21309962...
Checkpoint 21309962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01615
Policy Entropy: 1.15974
Value Function Loss: 0.04257

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.04011
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 11460.96428
Overall Steps per Second: 9168.28565

Timestep Collection Time: 4.36438
Timestep Consumption Time: 1.09138
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 5.45576

Cumulative Model Updates: 1278
Cumulative Timesteps: 21359982

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00264
Policy Entropy: 1.14619
Value Function Loss: 0.06072

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.05405

Collected Steps per Second: 13251.03546
Overall Steps per Second: 10877.03450

Timestep Collection Time: 3.77661
Timestep Consumption Time: 0.82428
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 4.60089

Cumulative Model Updates: 1281
Cumulative Timesteps: 21410026

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 21410026...
Checkpoint 21410026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03345
Policy Entropy: 1.14395
Value Function Loss: 0.07353

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.06976

Collected Steps per Second: 13285.94904
Overall Steps per Second: 10715.66708

Timestep Collection Time: 3.76503
Timestep Consumption Time: 0.90309
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 4.66812

Cumulative Model Updates: 1284
Cumulative Timesteps: 21460048

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01410
Policy Entropy: 1.13544
Value Function Loss: 0.08557

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.17422
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.07810

Collected Steps per Second: 13260.63871
Overall Steps per Second: 10722.12001

Timestep Collection Time: 3.77388
Timestep Consumption Time: 0.89349
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 4.66736

Cumulative Model Updates: 1287
Cumulative Timesteps: 21510092

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 21510092...
Checkpoint 21510092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11164
Policy Entropy: 1.15101
Value Function Loss: 0.07622

Mean KL Divergence: 0.04501
SB3 Clip Fraction: 0.25816
Policy Update Magnitude: 0.05480
Value Function Update Magnitude: 0.08620

Collected Steps per Second: 13346.71999
Overall Steps per Second: 10747.90662

Timestep Collection Time: 3.74699
Timestep Consumption Time: 0.90601
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 4.65300

Cumulative Model Updates: 1290
Cumulative Timesteps: 21560102

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00136
Policy Entropy: 1.14152
Value Function Loss: 0.06272

Mean KL Divergence: 0.05930
SB3 Clip Fraction: 0.30300
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.07917

Collected Steps per Second: 12988.09710
Overall Steps per Second: 10460.29837

Timestep Collection Time: 3.84968
Timestep Consumption Time: 0.93030
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 4.77998

Cumulative Model Updates: 1293
Cumulative Timesteps: 21610102

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 21610102...
Checkpoint 21610102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01718
Policy Entropy: 1.13032
Value Function Loss: 0.05210

Mean KL Divergence: 0.04701
SB3 Clip Fraction: 0.28553
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.07073

Collected Steps per Second: 13125.65762
Overall Steps per Second: 10588.02559

Timestep Collection Time: 3.81162
Timestep Consumption Time: 0.91353
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 4.72515

Cumulative Model Updates: 1296
Cumulative Timesteps: 21660132

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06835
Policy Entropy: 1.14498
Value Function Loss: 0.05762

Mean KL Divergence: 0.04715
SB3 Clip Fraction: 0.26856
Policy Update Magnitude: 0.05016
Value Function Update Magnitude: 0.06512

Collected Steps per Second: 13594.78743
Overall Steps per Second: 10889.18301

Timestep Collection Time: 3.68112
Timestep Consumption Time: 0.91464
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 4.59575

Cumulative Model Updates: 1299
Cumulative Timesteps: 21710176

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 21710176...
Checkpoint 21710176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02588
Policy Entropy: 1.13802
Value Function Loss: 0.07386

Mean KL Divergence: 0.03845
SB3 Clip Fraction: 0.27096
Policy Update Magnitude: 0.04867
Value Function Update Magnitude: 0.07442

Collected Steps per Second: 12637.84581
Overall Steps per Second: 10288.15641

Timestep Collection Time: 3.95827
Timestep Consumption Time: 0.90402
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 4.86229

Cumulative Model Updates: 1302
Cumulative Timesteps: 21760200

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06471
Policy Entropy: 1.11321
Value Function Loss: 0.08350

Mean KL Divergence: 0.05775
SB3 Clip Fraction: 0.29355
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.07008

Collected Steps per Second: 13371.16932
Overall Steps per Second: 10978.26277

Timestep Collection Time: 3.74148
Timestep Consumption Time: 0.81552
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 4.55701

Cumulative Model Updates: 1305
Cumulative Timesteps: 21810228

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 21810228...
Checkpoint 21810228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01856
Policy Entropy: 1.15503
Value Function Loss: 0.10178

Mean KL Divergence: 0.02783
SB3 Clip Fraction: 0.22865
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.07831

Collected Steps per Second: 13011.97447
Overall Steps per Second: 10483.22258

Timestep Collection Time: 3.84538
Timestep Consumption Time: 0.92758
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 4.77296

Cumulative Model Updates: 1308
Cumulative Timesteps: 21860264

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02569
Policy Entropy: 1.16056
Value Function Loss: 0.08979

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.24319
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.07875

Collected Steps per Second: 13240.03747
Overall Steps per Second: 10957.57864

Timestep Collection Time: 3.77854
Timestep Consumption Time: 0.78707
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 4.56561

Cumulative Model Updates: 1311
Cumulative Timesteps: 21910292

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 21910292...
Checkpoint 21910292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05001
Policy Entropy: 1.11453
Value Function Loss: 0.07989

Mean KL Divergence: 0.04300
SB3 Clip Fraction: 0.26067
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.08207

Collected Steps per Second: 13564.12895
Overall Steps per Second: 11161.36630

Timestep Collection Time: 3.68767
Timestep Consumption Time: 0.79386
PPO Batch Consumption Time: 0.02945
Total Iteration Time: 4.48153

Cumulative Model Updates: 1314
Cumulative Timesteps: 21960312

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01441
Policy Entropy: 1.15765
Value Function Loss: 0.05169

Mean KL Divergence: 0.03682
SB3 Clip Fraction: 0.25855
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.08183

Collected Steps per Second: 13315.78422
Overall Steps per Second: 11026.74351

Timestep Collection Time: 3.75584
Timestep Consumption Time: 0.77968
PPO Batch Consumption Time: 0.02581
Total Iteration Time: 4.53552

Cumulative Model Updates: 1317
Cumulative Timesteps: 22010324

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 22010324...
Checkpoint 22010324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00003
Policy Entropy: 1.11047
Value Function Loss: 0.04404

Mean KL Divergence: 0.07633
SB3 Clip Fraction: 0.31555
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.07490

Collected Steps per Second: 13082.33680
Overall Steps per Second: 11053.29263

Timestep Collection Time: 3.82516
Timestep Consumption Time: 0.70218
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 4.52734

Cumulative Model Updates: 1320
Cumulative Timesteps: 22060366

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00947
Policy Entropy: 1.15872
Value Function Loss: 0.05224

Mean KL Divergence: 0.06713
SB3 Clip Fraction: 0.31365
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.06127

Collected Steps per Second: 13112.08956
Overall Steps per Second: 10783.71906

Timestep Collection Time: 3.81404
Timestep Consumption Time: 0.82351
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 4.63755

Cumulative Model Updates: 1323
Cumulative Timesteps: 22110376

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 22110376...
Checkpoint 22110376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02321
Policy Entropy: 1.13815
Value Function Loss: 0.05066

Mean KL Divergence: 0.05680
SB3 Clip Fraction: 0.31482
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.06246

Collected Steps per Second: 13256.36576
Overall Steps per Second: 10990.20426

Timestep Collection Time: 3.77238
Timestep Consumption Time: 0.77786
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 4.55023

Cumulative Model Updates: 1326
Cumulative Timesteps: 22160384

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03455
Policy Entropy: 1.15013
Value Function Loss: 0.04781

Mean KL Divergence: 0.02554
SB3 Clip Fraction: 0.17515
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.05985

Collected Steps per Second: 13431.43571
Overall Steps per Second: 11071.51098

Timestep Collection Time: 3.72410
Timestep Consumption Time: 0.79380
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 4.51790

Cumulative Model Updates: 1329
Cumulative Timesteps: 22210404

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 22210404...
Checkpoint 22210404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01287
Policy Entropy: 1.14073
Value Function Loss: 0.04508

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.06629

Collected Steps per Second: 13308.80589
Overall Steps per Second: 10934.59333

Timestep Collection Time: 3.75811
Timestep Consumption Time: 0.81599
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 4.57411

Cumulative Model Updates: 1332
Cumulative Timesteps: 22260420

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01168
Policy Entropy: 1.14162
Value Function Loss: 0.05514

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.06171

Collected Steps per Second: 12141.61444
Overall Steps per Second: 10233.63764

Timestep Collection Time: 4.12054
Timestep Consumption Time: 0.76824
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 4.88878

Cumulative Model Updates: 1335
Cumulative Timesteps: 22310450

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 22310450...
Checkpoint 22310450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01070
Policy Entropy: 1.11233
Value Function Loss: 0.06998

Mean KL Divergence: 0.03425
SB3 Clip Fraction: 0.26377
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.08510

Collected Steps per Second: 13041.52654
Overall Steps per Second: 10828.54626

Timestep Collection Time: 3.83575
Timestep Consumption Time: 0.78389
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 4.61964

Cumulative Model Updates: 1338
Cumulative Timesteps: 22360474

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00929
Policy Entropy: 1.14263
Value Function Loss: 0.06126

Mean KL Divergence: 0.02228
SB3 Clip Fraction: 0.19645
Policy Update Magnitude: 0.04849
Value Function Update Magnitude: 0.06639

Collected Steps per Second: 13262.51401
Overall Steps per Second: 11011.50008

Timestep Collection Time: 3.77229
Timestep Consumption Time: 0.77115
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 4.54343

Cumulative Model Updates: 1341
Cumulative Timesteps: 22410504

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 22410504...
Checkpoint 22410504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00985
Policy Entropy: 1.13865
Value Function Loss: 0.05645

Mean KL Divergence: 0.02326
SB3 Clip Fraction: 0.20993
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.08547

Collected Steps per Second: 13534.69147
Overall Steps per Second: 11173.81385

Timestep Collection Time: 3.69436
Timestep Consumption Time: 0.78057
PPO Batch Consumption Time: 0.02571
Total Iteration Time: 4.47493

Cumulative Model Updates: 1344
Cumulative Timesteps: 22460506

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02716
Policy Entropy: 1.12282
Value Function Loss: 0.05536

Mean KL Divergence: 0.03334
SB3 Clip Fraction: 0.21369
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.07730

Collected Steps per Second: 13454.06741
Overall Steps per Second: 11088.42365

Timestep Collection Time: 3.71709
Timestep Consumption Time: 0.79302
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 4.51011

Cumulative Model Updates: 1347
Cumulative Timesteps: 22510516

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 22510516...
Checkpoint 22510516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02756
Policy Entropy: 1.13201
Value Function Loss: 0.06554

Mean KL Divergence: 0.03866
SB3 Clip Fraction: 0.26839
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.08868

Collected Steps per Second: 12823.49691
Overall Steps per Second: 10711.42862

Timestep Collection Time: 3.90112
Timestep Consumption Time: 0.76922
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 4.67034

Cumulative Model Updates: 1350
Cumulative Timesteps: 22560542

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00765
Policy Entropy: 1.12533
Value Function Loss: 0.07963

Mean KL Divergence: 0.02560
SB3 Clip Fraction: 0.20920
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.07823

Collected Steps per Second: 13370.10502
Overall Steps per Second: 10990.85203

Timestep Collection Time: 3.74298
Timestep Consumption Time: 0.81026
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 4.55324

Cumulative Model Updates: 1353
Cumulative Timesteps: 22610586

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 22610586...
Checkpoint 22610586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02895
Policy Entropy: 1.11386
Value Function Loss: 0.09216

Mean KL Divergence: 0.03600
SB3 Clip Fraction: 0.24058
Policy Update Magnitude: 0.05154
Value Function Update Magnitude: 0.09103

Collected Steps per Second: 13455.62061
Overall Steps per Second: 11062.98000

Timestep Collection Time: 3.71637
Timestep Consumption Time: 0.80376
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 4.52012

Cumulative Model Updates: 1356
Cumulative Timesteps: 22660592

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02245
Policy Entropy: 1.05495
Value Function Loss: 0.09456

Mean KL Divergence: 0.08676
SB3 Clip Fraction: 0.38087
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.09227

Collected Steps per Second: 11594.40475
Overall Steps per Second: 9970.63226

Timestep Collection Time: 4.31398
Timestep Consumption Time: 0.70256
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 5.01653

Cumulative Model Updates: 1359
Cumulative Timesteps: 22710610

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 22710610...
Checkpoint 22710610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07333
Policy Entropy: 1.08813
Value Function Loss: 0.09711

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.15533
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.10145

Collected Steps per Second: 13200.13327
Overall Steps per Second: 10890.52949

Timestep Collection Time: 3.78951
Timestep Consumption Time: 0.80366
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 4.59317

Cumulative Model Updates: 1362
Cumulative Timesteps: 22760632

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07920
Policy Entropy: 1.05825
Value Function Loss: 0.08019

Mean KL Divergence: 0.05537
SB3 Clip Fraction: 0.30262
Policy Update Magnitude: 0.05246
Value Function Update Magnitude: 0.08637

Collected Steps per Second: 13300.55797
Overall Steps per Second: 11144.05873

Timestep Collection Time: 3.76315
Timestep Consumption Time: 0.72821
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 4.49136

Cumulative Model Updates: 1365
Cumulative Timesteps: 22810684

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 22810684...
Checkpoint 22810684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02742
Policy Entropy: 1.06949
Value Function Loss: 0.07900

Mean KL Divergence: 0.03956
SB3 Clip Fraction: 0.28197
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.08638

Collected Steps per Second: 13247.13757
Overall Steps per Second: 10943.73423

Timestep Collection Time: 3.77666
Timestep Consumption Time: 0.79490
PPO Batch Consumption Time: 0.03049
Total Iteration Time: 4.57157

Cumulative Model Updates: 1368
Cumulative Timesteps: 22860714

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04176
Policy Entropy: 1.09791
Value Function Loss: 0.07925

Mean KL Divergence: 0.04583
SB3 Clip Fraction: 0.26031
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.08582

Collected Steps per Second: 12995.62613
Overall Steps per Second: 10800.28607

Timestep Collection Time: 3.84930
Timestep Consumption Time: 0.78243
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 4.63173

Cumulative Model Updates: 1371
Cumulative Timesteps: 22910738

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 22910738...
Checkpoint 22910738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02114
Policy Entropy: 1.09616
Value Function Loss: 0.08687

Mean KL Divergence: 0.02947
SB3 Clip Fraction: 0.23855
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.09404

Collected Steps per Second: 13719.74074
Overall Steps per Second: 11258.90534

Timestep Collection Time: 3.64847
Timestep Consumption Time: 0.79744
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 4.44590

Cumulative Model Updates: 1374
Cumulative Timesteps: 22960794

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01003
Policy Entropy: 1.07200
Value Function Loss: 0.06951

Mean KL Divergence: 0.03168
SB3 Clip Fraction: 0.20257
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.08195

Collected Steps per Second: 13320.04478
Overall Steps per Second: 10977.24838

Timestep Collection Time: 3.75419
Timestep Consumption Time: 0.80123
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 4.55542

Cumulative Model Updates: 1377
Cumulative Timesteps: 23010800

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 23010800...
Checkpoint 23010800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09285
Policy Entropy: 1.07635
Value Function Loss: 0.06042

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.18114
Policy Update Magnitude: 0.05636
Value Function Update Magnitude: 0.08748

Collected Steps per Second: 13185.41447
Overall Steps per Second: 11118.83619

Timestep Collection Time: 3.79556
Timestep Consumption Time: 0.70545
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 4.50101

Cumulative Model Updates: 1380
Cumulative Timesteps: 23060846

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01070
Policy Entropy: 1.08944
Value Function Loss: 0.05492

Mean KL Divergence: 0.01882
SB3 Clip Fraction: 0.16405
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.07312

Collected Steps per Second: 13175.94671
Overall Steps per Second: 10916.60492

Timestep Collection Time: 3.79813
Timestep Consumption Time: 0.78608
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 4.58421

Cumulative Model Updates: 1383
Cumulative Timesteps: 23110890

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 23110890...
Checkpoint 23110890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00025
Policy Entropy: 1.08506
Value Function Loss: 0.05702

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.06980

Collected Steps per Second: 12939.98151
Overall Steps per Second: 10767.90018

Timestep Collection Time: 3.86708
Timestep Consumption Time: 0.78006
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 4.64715

Cumulative Model Updates: 1386
Cumulative Timesteps: 23160930

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02345
Policy Entropy: 1.08274
Value Function Loss: 0.04531

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.15100
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.06844

Collected Steps per Second: 13389.13476
Overall Steps per Second: 11208.47156

Timestep Collection Time: 3.73497
Timestep Consumption Time: 0.72666
PPO Batch Consumption Time: 0.02554
Total Iteration Time: 4.46163

Cumulative Model Updates: 1389
Cumulative Timesteps: 23210938

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 23210938...
Checkpoint 23210938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03004
Policy Entropy: 1.09170
Value Function Loss: 0.03556

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.06158

Collected Steps per Second: 13035.19635
Overall Steps per Second: 10808.03707

Timestep Collection Time: 3.83577
Timestep Consumption Time: 0.79042
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 4.62619

Cumulative Model Updates: 1392
Cumulative Timesteps: 23260938

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01814
Policy Entropy: 1.09184
Value Function Loss: 0.03807

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.05170
Value Function Update Magnitude: 0.04985

Collected Steps per Second: 13222.77212
Overall Steps per Second: 11121.40512

Timestep Collection Time: 3.78226
Timestep Consumption Time: 0.71465
PPO Batch Consumption Time: 0.02569
Total Iteration Time: 4.49691

Cumulative Model Updates: 1395
Cumulative Timesteps: 23310950

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 23310950...
Checkpoint 23310950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02122
Policy Entropy: 1.07961
Value Function Loss: 0.04108

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.05361

Collected Steps per Second: 13365.63991
Overall Steps per Second: 11035.17869

Timestep Collection Time: 3.74288
Timestep Consumption Time: 0.79044
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 4.53332

Cumulative Model Updates: 1398
Cumulative Timesteps: 23360976

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00811
Policy Entropy: 1.07514
Value Function Loss: 0.06259

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.05713

Collected Steps per Second: 13308.89292
Overall Steps per Second: 10957.82102

Timestep Collection Time: 3.75854
Timestep Consumption Time: 0.80642
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 4.56496

Cumulative Model Updates: 1401
Cumulative Timesteps: 23410998

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 23410998...
Checkpoint 23410998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02998
Policy Entropy: 1.08374
Value Function Loss: 0.06863

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.05109
Value Function Update Magnitude: 0.06368

Collected Steps per Second: 13474.86526
Overall Steps per Second: 11143.05007

Timestep Collection Time: 3.71135
Timestep Consumption Time: 0.77664
PPO Batch Consumption Time: 0.02547
Total Iteration Time: 4.48800

Cumulative Model Updates: 1404
Cumulative Timesteps: 23461008

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00494
Policy Entropy: 1.09082
Value Function Loss: 0.09756

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.05565
Value Function Update Magnitude: 0.07331

Collected Steps per Second: 13217.07868
Overall Steps per Second: 10893.12778

Timestep Collection Time: 3.78480
Timestep Consumption Time: 0.80745
PPO Batch Consumption Time: 0.02960
Total Iteration Time: 4.59225

Cumulative Model Updates: 1407
Cumulative Timesteps: 23511032

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 23511032...
Checkpoint 23511032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02551
Policy Entropy: 1.07951
Value Function Loss: 0.10634

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.15969
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.08130

Collected Steps per Second: 13476.94060
Overall Steps per Second: 11336.55903

Timestep Collection Time: 3.71078
Timestep Consumption Time: 0.70061
PPO Batch Consumption Time: 0.02794
Total Iteration Time: 4.41139

Cumulative Model Updates: 1410
Cumulative Timesteps: 23561042

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01158
Policy Entropy: 1.07928
Value Function Loss: 0.11482

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.08173

Collected Steps per Second: 13262.90633
Overall Steps per Second: 10940.79318

Timestep Collection Time: 3.77353
Timestep Consumption Time: 0.80091
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 4.57444

Cumulative Model Updates: 1413
Cumulative Timesteps: 23611090

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 23611090...
Checkpoint 23611090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09023
Policy Entropy: 1.09091
Value Function Loss: 0.08339

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.15425
Policy Update Magnitude: 0.06002
Value Function Update Magnitude: 0.08787

Collected Steps per Second: 13148.47372
Overall Steps per Second: 10926.65147

Timestep Collection Time: 3.80440
Timestep Consumption Time: 0.77358
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 4.57798

Cumulative Model Updates: 1416
Cumulative Timesteps: 23661112

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02906
Policy Entropy: 1.08895
Value Function Loss: 0.05944

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.06034
Value Function Update Magnitude: 0.08328

Collected Steps per Second: 13154.93811
Overall Steps per Second: 11068.42030

Timestep Collection Time: 3.80420
Timestep Consumption Time: 0.71713
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 4.52133

Cumulative Model Updates: 1419
Cumulative Timesteps: 23711156

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 23711156...
Checkpoint 23711156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07127
Policy Entropy: 1.04357
Value Function Loss: 0.05553

Mean KL Divergence: 0.07510
SB3 Clip Fraction: 0.34831
Policy Update Magnitude: 0.05916
Value Function Update Magnitude: 0.08049

Collected Steps per Second: 13372.72834
Overall Steps per Second: 10924.41209

Timestep Collection Time: 3.74015
Timestep Consumption Time: 0.83822
PPO Batch Consumption Time: 0.03115
Total Iteration Time: 4.57837

Cumulative Model Updates: 1422
Cumulative Timesteps: 23761172

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02162
Policy Entropy: 1.09847
Value Function Loss: 0.07603

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.17301
Policy Update Magnitude: 0.05549
Value Function Update Magnitude: 0.07979

Collected Steps per Second: 13208.12661
Overall Steps per Second: 10950.59005

Timestep Collection Time: 3.78600
Timestep Consumption Time: 0.78051
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 4.56651

Cumulative Model Updates: 1425
Cumulative Timesteps: 23811178

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 23811178...
Checkpoint 23811178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02266
Policy Entropy: 1.07002
Value Function Loss: 0.06945

Mean KL Divergence: 0.04812
SB3 Clip Fraction: 0.27421
Policy Update Magnitude: 0.05951
Value Function Update Magnitude: 0.09974

Collected Steps per Second: 13461.99503
Overall Steps per Second: 11048.54044

Timestep Collection Time: 3.71639
Timestep Consumption Time: 0.81181
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 4.52820

Cumulative Model Updates: 1428
Cumulative Timesteps: 23861208

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02956
Policy Entropy: 1.09858
Value Function Loss: 0.06782

Mean KL Divergence: 0.04372
SB3 Clip Fraction: 0.28367
Policy Update Magnitude: 0.05874
Value Function Update Magnitude: 0.08637

Collected Steps per Second: 13000.43040
Overall Steps per Second: 10798.12706

Timestep Collection Time: 3.84649
Timestep Consumption Time: 0.78450
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 4.63099

Cumulative Model Updates: 1431
Cumulative Timesteps: 23911214

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 23911214...
Checkpoint 23911214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00606
Policy Entropy: 1.10792
Value Function Loss: 0.03713

Mean KL Divergence: 0.04877
SB3 Clip Fraction: 0.23505
Policy Update Magnitude: 0.06767
Value Function Update Magnitude: 0.06840

Collected Steps per Second: 12977.84160
Overall Steps per Second: 10941.50384

Timestep Collection Time: 3.85457
Timestep Consumption Time: 0.71738
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 4.57195

Cumulative Model Updates: 1434
Cumulative Timesteps: 23961238

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04381
Policy Entropy: 1.09962
Value Function Loss: 0.06993

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.08483

Collected Steps per Second: 13213.86867
Overall Steps per Second: 10917.50387

Timestep Collection Time: 3.78511
Timestep Consumption Time: 0.79615
PPO Batch Consumption Time: 0.02826
Total Iteration Time: 4.58127

Cumulative Model Updates: 1437
Cumulative Timesteps: 24011254

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 24011254...
Checkpoint 24011254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02587
Policy Entropy: 1.08545
Value Function Loss: 0.06399

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.09154

Collected Steps per Second: 11099.01932
Overall Steps per Second: 9426.16129

Timestep Collection Time: 4.50652
Timestep Consumption Time: 0.79977
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 5.30630

Cumulative Model Updates: 1440
Cumulative Timesteps: 24061272

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05781
Policy Entropy: 1.09617
Value Function Loss: 0.07121

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.10949

Collected Steps per Second: 13491.97783
Overall Steps per Second: 11086.53305

Timestep Collection Time: 3.70709
Timestep Consumption Time: 0.80433
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 4.51142

Cumulative Model Updates: 1443
Cumulative Timesteps: 24111288

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 24111288...
Checkpoint 24111288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01124
Policy Entropy: 1.08505
Value Function Loss: 0.07103

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.16035
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.09900

Collected Steps per Second: 12668.93067
Overall Steps per Second: 10526.41676

Timestep Collection Time: 3.94793
Timestep Consumption Time: 0.80355
PPO Batch Consumption Time: 0.02920
Total Iteration Time: 4.75147

Cumulative Model Updates: 1446
Cumulative Timesteps: 24161304

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03307
Policy Entropy: 1.10837
Value Function Loss: 0.09511

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12410
Policy Update Magnitude: 0.05228
Value Function Update Magnitude: 0.09501

Collected Steps per Second: 13040.37497
Overall Steps per Second: 11012.49753

Timestep Collection Time: 3.83670
Timestep Consumption Time: 0.70650
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 4.54320

Cumulative Model Updates: 1449
Cumulative Timesteps: 24211336

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 24211336...
Checkpoint 24211336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00285
Policy Entropy: 1.10385
Value Function Loss: 0.09392

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.18333
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.07252

Collected Steps per Second: 13405.37341
Overall Steps per Second: 11067.19858

Timestep Collection Time: 3.73074
Timestep Consumption Time: 0.78820
PPO Batch Consumption Time: 0.02835
Total Iteration Time: 4.51894

Cumulative Model Updates: 1452
Cumulative Timesteps: 24261348

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01886
Policy Entropy: 1.10028
Value Function Loss: 0.09477

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.16103
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.07381

Collected Steps per Second: 13049.90732
Overall Steps per Second: 10854.51423

Timestep Collection Time: 3.83436
Timestep Consumption Time: 0.77552
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 4.60988

Cumulative Model Updates: 1455
Cumulative Timesteps: 24311386

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 24311386...
Checkpoint 24311386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00011
Policy Entropy: 1.10250
Value Function Loss: 0.09731

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.06631
Value Function Update Magnitude: 0.06133

Collected Steps per Second: 13216.11407
Overall Steps per Second: 10900.78694

Timestep Collection Time: 3.78432
Timestep Consumption Time: 0.80379
PPO Batch Consumption Time: 0.02576
Total Iteration Time: 4.58811

Cumulative Model Updates: 1458
Cumulative Timesteps: 24361400

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04531
Policy Entropy: 1.10054
Value Function Loss: 0.08381

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.06575
Value Function Update Magnitude: 0.05047

Collected Steps per Second: 13129.27997
Overall Steps per Second: 10839.28052

Timestep Collection Time: 3.80843
Timestep Consumption Time: 0.80460
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 4.61304

Cumulative Model Updates: 1461
Cumulative Timesteps: 24411402

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 24411402...
Checkpoint 24411402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02136
Policy Entropy: 1.11164
Value Function Loss: 0.06160

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.16116
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.04744

Collected Steps per Second: 13149.90714
Overall Steps per Second: 11031.14254

Timestep Collection Time: 3.80398
Timestep Consumption Time: 0.73064
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 4.53462

Cumulative Model Updates: 1464
Cumulative Timesteps: 24461424

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14482
Policy Entropy: 1.05789
Value Function Loss: 0.04569

Mean KL Divergence: 0.10349
SB3 Clip Fraction: 0.34749
Policy Update Magnitude: 0.05830
Value Function Update Magnitude: 0.03821

Collected Steps per Second: 13238.51472
Overall Steps per Second: 10880.21331

Timestep Collection Time: 3.77792
Timestep Consumption Time: 0.81887
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 4.59678

Cumulative Model Updates: 1467
Cumulative Timesteps: 24511438

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 24511438...
Checkpoint 24511438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04076
Policy Entropy: 1.14252
Value Function Loss: 0.07750

Mean KL Divergence: 0.12354
SB3 Clip Fraction: 0.38511
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.04382

Collected Steps per Second: 13190.47636
Overall Steps per Second: 10961.95962

Timestep Collection Time: 3.79061
Timestep Consumption Time: 0.77061
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 4.56123

Cumulative Model Updates: 1470
Cumulative Timesteps: 24561438

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01128
Policy Entropy: 1.10024
Value Function Loss: 0.09316

Mean KL Divergence: 0.11501
SB3 Clip Fraction: 0.35345
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.04702

Collected Steps per Second: 13412.58577
Overall Steps per Second: 10929.36166

Timestep Collection Time: 3.72889
Timestep Consumption Time: 0.84723
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 4.57611

Cumulative Model Updates: 1473
Cumulative Timesteps: 24611452

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 24611452...
Checkpoint 24611452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03327
Policy Entropy: 1.13564
Value Function Loss: 0.10850

Mean KL Divergence: 0.08063
SB3 Clip Fraction: 0.31207
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.05116

Collected Steps per Second: 12863.36322
Overall Steps per Second: 10621.00582

Timestep Collection Time: 3.88950
Timestep Consumption Time: 0.82117
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 4.71066

Cumulative Model Updates: 1476
Cumulative Timesteps: 24661484

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02263
Policy Entropy: 1.06820
Value Function Loss: 0.08802

Mean KL Divergence: 0.16809
SB3 Clip Fraction: 0.39204
Policy Update Magnitude: 0.04547
Value Function Update Magnitude: 0.03822

Collected Steps per Second: 13348.37884
Overall Steps per Second: 11195.49669

Timestep Collection Time: 3.74802
Timestep Consumption Time: 0.72074
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 4.46876

Cumulative Model Updates: 1479
Cumulative Timesteps: 24711514

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 24711514...
Checkpoint 24711514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03466
Policy Entropy: 1.09828
Value Function Loss: 0.07568

Mean KL Divergence: 0.02854
SB3 Clip Fraction: 0.18303
Policy Update Magnitude: 0.04412
Value Function Update Magnitude: 0.04555

Collected Steps per Second: 13439.81036
Overall Steps per Second: 11108.90294

Timestep Collection Time: 3.72342
Timestep Consumption Time: 0.78126
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 4.50468

Cumulative Model Updates: 1482
Cumulative Timesteps: 24761556

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00373
Policy Entropy: 1.08165
Value Function Loss: 0.09058

Mean KL Divergence: 0.02617
SB3 Clip Fraction: 0.18911
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.03537

Collected Steps per Second: 13469.63697
Overall Steps per Second: 11097.98550

Timestep Collection Time: 3.71383
Timestep Consumption Time: 0.79365
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.50748

Cumulative Model Updates: 1485
Cumulative Timesteps: 24811580

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 24811580...
Checkpoint 24811580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01011
Policy Entropy: 1.07999
Value Function Loss: 0.09394

Mean KL Divergence: 0.02292
SB3 Clip Fraction: 0.16061
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.03876

Collected Steps per Second: 13587.82001
Overall Steps per Second: 11140.46599

Timestep Collection Time: 3.68212
Timestep Consumption Time: 0.80889
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 4.49102

Cumulative Model Updates: 1488
Cumulative Timesteps: 24861612

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02781
Policy Entropy: 1.03733
Value Function Loss: 0.10667

Mean KL Divergence: 0.07838
SB3 Clip Fraction: 0.33383
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.04013

Collected Steps per Second: 13337.02116
Overall Steps per Second: 11069.46639

Timestep Collection Time: 3.74956
Timestep Consumption Time: 0.76809
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 4.51765

Cumulative Model Updates: 1491
Cumulative Timesteps: 24911620

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 24911620...
Checkpoint 24911620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02963
Policy Entropy: 1.08512
Value Function Loss: 0.09867

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.04407

Collected Steps per Second: 12899.83843
Overall Steps per Second: 10891.21660

Timestep Collection Time: 3.87834
Timestep Consumption Time: 0.71527
PPO Batch Consumption Time: 0.02793
Total Iteration Time: 4.59361

Cumulative Model Updates: 1494
Cumulative Timesteps: 24961650

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00884
Policy Entropy: 1.06644
Value Function Loss: 0.09453

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.17306
Policy Update Magnitude: 0.04883
Value Function Update Magnitude: 0.04264

Collected Steps per Second: 13360.90195
Overall Steps per Second: 10924.03010

Timestep Collection Time: 3.74286
Timestep Consumption Time: 0.83494
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 4.57780

Cumulative Model Updates: 1497
Cumulative Timesteps: 25011658

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 25011658...
Checkpoint 25011658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03474
Policy Entropy: 1.07355
Value Function Loss: 0.07956

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.04068

Collected Steps per Second: 13077.94006
Overall Steps per Second: 10896.96106

Timestep Collection Time: 3.82384
Timestep Consumption Time: 0.76533
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 4.58917

Cumulative Model Updates: 1500
Cumulative Timesteps: 25061666

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13089
Policy Entropy: 1.07239
Value Function Loss: 0.06959

Mean KL Divergence: 0.03168
SB3 Clip Fraction: 0.21888
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.03920

Collected Steps per Second: 13697.39904
Overall Steps per Second: 11211.77589

Timestep Collection Time: 3.65339
Timestep Consumption Time: 0.80995
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 4.46334

Cumulative Model Updates: 1503
Cumulative Timesteps: 25111708

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 25111708...
Checkpoint 25111708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04985
Policy Entropy: 1.08533
Value Function Loss: 0.07612

Mean KL Divergence: 0.04678
SB3 Clip Fraction: 0.28734
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.04251

Collected Steps per Second: 12972.52812
Overall Steps per Second: 10740.44672

Timestep Collection Time: 3.85754
Timestep Consumption Time: 0.80167
PPO Batch Consumption Time: 0.02545
Total Iteration Time: 4.65921

Cumulative Model Updates: 1506
Cumulative Timesteps: 25161750

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03886
Policy Entropy: 1.00250
Value Function Loss: 0.08108

Mean KL Divergence: 0.15538
SB3 Clip Fraction: 0.41420
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.04304

Collected Steps per Second: 13190.29522
Overall Steps per Second: 10990.85920

Timestep Collection Time: 3.79385
Timestep Consumption Time: 0.75921
PPO Batch Consumption Time: 0.02873
Total Iteration Time: 4.55306

Cumulative Model Updates: 1509
Cumulative Timesteps: 25211792

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 25211792...
Checkpoint 25211792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00879
Policy Entropy: 1.08772
Value Function Loss: 0.06800

Mean KL Divergence: 0.10486
SB3 Clip Fraction: 0.39957
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.03868

Collected Steps per Second: 13391.91644
Overall Steps per Second: 11017.33607

Timestep Collection Time: 3.73569
Timestep Consumption Time: 0.80516
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 4.54084

Cumulative Model Updates: 1512
Cumulative Timesteps: 25261820

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01868
Policy Entropy: 1.04728
Value Function Loss: 0.06308

Mean KL Divergence: 0.10317
SB3 Clip Fraction: 0.35750
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.04742

Collected Steps per Second: 13039.06170
Overall Steps per Second: 10825.06294

Timestep Collection Time: 3.83525
Timestep Consumption Time: 0.78440
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 4.61965

Cumulative Model Updates: 1515
Cumulative Timesteps: 25311828

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 25311828...
Checkpoint 25311828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02477
Policy Entropy: 1.11637
Value Function Loss: 0.05321

Mean KL Divergence: 0.11917
SB3 Clip Fraction: 0.38494
Policy Update Magnitude: 0.04411
Value Function Update Magnitude: 0.03572

Collected Steps per Second: 13556.34173
Overall Steps per Second: 11144.78559

Timestep Collection Time: 3.68861
Timestep Consumption Time: 0.79816
PPO Batch Consumption Time: 0.02870
Total Iteration Time: 4.48676

Cumulative Model Updates: 1518
Cumulative Timesteps: 25361832

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01208
Policy Entropy: 1.04770
Value Function Loss: 0.06911

Mean KL Divergence: 0.13297
SB3 Clip Fraction: 0.38227
Policy Update Magnitude: 0.04480
Value Function Update Magnitude: 0.03681

Collected Steps per Second: 13061.07813
Overall Steps per Second: 10695.47205

Timestep Collection Time: 3.83046
Timestep Consumption Time: 0.84722
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 4.67768

Cumulative Model Updates: 1521
Cumulative Timesteps: 25411862

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 25411862...
Checkpoint 25411862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02470
Policy Entropy: 1.09626
Value Function Loss: 0.05867

Mean KL Divergence: 0.09039
SB3 Clip Fraction: 0.33631
Policy Update Magnitude: 0.04395
Value Function Update Magnitude: 0.04160

Collected Steps per Second: 12987.98994
Overall Steps per Second: 10986.77888

Timestep Collection Time: 3.85264
Timestep Consumption Time: 0.70175
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 4.55438

Cumulative Model Updates: 1524
Cumulative Timesteps: 25461900

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00517
Policy Entropy: 1.04490
Value Function Loss: 0.05994

Mean KL Divergence: 0.11762
SB3 Clip Fraction: 0.36209
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.04265

Collected Steps per Second: 12979.26093
Overall Steps per Second: 10716.68026

Timestep Collection Time: 3.85569
Timestep Consumption Time: 0.81404
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 4.66973

Cumulative Model Updates: 1527
Cumulative Timesteps: 25511944

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 25511944...
Checkpoint 25511944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01663
Policy Entropy: 1.11781
Value Function Loss: 0.04391

Mean KL Divergence: 0.09866
SB3 Clip Fraction: 0.36217
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.03516

Collected Steps per Second: 13210.86727
Overall Steps per Second: 10940.50336

Timestep Collection Time: 3.78552
Timestep Consumption Time: 0.78557
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 4.57109

Cumulative Model Updates: 1530
Cumulative Timesteps: 25561954

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00246
Policy Entropy: 1.08833
Value Function Loss: 0.03721

Mean KL Divergence: 0.07920
SB3 Clip Fraction: 0.30781
Policy Update Magnitude: 0.03710
Value Function Update Magnitude: 0.03257

Collected Steps per Second: 13340.18895
Overall Steps per Second: 10985.32625

Timestep Collection Time: 3.74987
Timestep Consumption Time: 0.80384
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 4.55371

Cumulative Model Updates: 1533
Cumulative Timesteps: 25611978

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 25611978...
Checkpoint 25611978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00048
Policy Entropy: 1.12868
Value Function Loss: 0.04121

Mean KL Divergence: 0.05834
SB3 Clip Fraction: 0.29600
Policy Update Magnitude: 0.04080
Value Function Update Magnitude: 0.03706

Collected Steps per Second: 13403.77911
Overall Steps per Second: 11006.40146

Timestep Collection Time: 3.73223
Timestep Consumption Time: 0.81294
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 4.54517

Cumulative Model Updates: 1536
Cumulative Timesteps: 25662004

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08568
Policy Entropy: 1.06967
Value Function Loss: 0.05642

Mean KL Divergence: 0.06927
SB3 Clip Fraction: 0.31070
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.03935

Collected Steps per Second: 10829.41482
Overall Steps per Second: 9227.05967

Timestep Collection Time: 4.61705
Timestep Consumption Time: 0.80179
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 5.41884

Cumulative Model Updates: 1539
Cumulative Timesteps: 25712004

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 25712004...
Checkpoint 25712004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03708
Policy Entropy: 1.10295
Value Function Loss: 0.08537

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.05340
Value Function Update Magnitude: 0.04086

Collected Steps per Second: 12017.23646
Overall Steps per Second: 10050.03680

Timestep Collection Time: 4.16385
Timestep Consumption Time: 0.81503
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 4.97889

Cumulative Model Updates: 1542
Cumulative Timesteps: 25762042

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01960
Policy Entropy: 1.08066
Value Function Loss: 0.09477

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.05795
Value Function Update Magnitude: 0.04371

Collected Steps per Second: 13134.44146
Overall Steps per Second: 10928.02865

Timestep Collection Time: 3.80831
Timestep Consumption Time: 0.76891
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 4.57722

Cumulative Model Updates: 1545
Cumulative Timesteps: 25812062

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 25812062...
Checkpoint 25812062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07449
Policy Entropy: 1.08220
Value Function Loss: 0.09687

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.05313

Collected Steps per Second: 12823.77606
Overall Steps per Second: 10827.01453

Timestep Collection Time: 3.90166
Timestep Consumption Time: 0.71956
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 4.62122

Cumulative Model Updates: 1548
Cumulative Timesteps: 25862096

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00763
Policy Entropy: 1.05966
Value Function Loss: 0.07987

Mean KL Divergence: 0.04314
SB3 Clip Fraction: 0.28011
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.05224

Collected Steps per Second: 13069.11414
Overall Steps per Second: 10682.86349

Timestep Collection Time: 3.82734
Timestep Consumption Time: 0.85492
PPO Batch Consumption Time: 0.02995
Total Iteration Time: 4.68227

Cumulative Model Updates: 1551
Cumulative Timesteps: 25912116

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 25912116...
Checkpoint 25912116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02866
Policy Entropy: 1.09760
Value Function Loss: 0.07937

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.05671
Value Function Update Magnitude: 0.04802

Collected Steps per Second: 11971.10382
Overall Steps per Second: 10026.66756

Timestep Collection Time: 4.17756
Timestep Consumption Time: 0.81014
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 4.98770

Cumulative Model Updates: 1554
Cumulative Timesteps: 25962126

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01866
Policy Entropy: 1.08576
Value Function Loss: 0.07646

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.04549

Collected Steps per Second: 12523.09181
Overall Steps per Second: 10442.71510

Timestep Collection Time: 3.99598
Timestep Consumption Time: 0.79607
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 4.79205

Cumulative Model Updates: 1557
Cumulative Timesteps: 26012168

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 26012168...
Checkpoint 26012168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06079
Policy Entropy: 1.08197
Value Function Loss: 0.08109

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.04338

Collected Steps per Second: 13096.68331
Overall Steps per Second: 10859.20910

Timestep Collection Time: 3.82066
Timestep Consumption Time: 0.78722
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 4.60789

Cumulative Model Updates: 1560
Cumulative Timesteps: 26062206

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00080
Policy Entropy: 1.04977
Value Function Loss: 0.07382

Mean KL Divergence: 0.06522
SB3 Clip Fraction: 0.31185
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.04415

Collected Steps per Second: 13012.58260
Overall Steps per Second: 10943.04714

Timestep Collection Time: 3.84351
Timestep Consumption Time: 0.72688
PPO Batch Consumption Time: 0.02894
Total Iteration Time: 4.57039

Cumulative Model Updates: 1563
Cumulative Timesteps: 26112220

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 26112220...
Checkpoint 26112220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02623
Policy Entropy: 1.11407
Value Function Loss: 0.05555

Mean KL Divergence: 0.06277
SB3 Clip Fraction: 0.32484
Policy Update Magnitude: 0.04591
Value Function Update Magnitude: 0.04593

Collected Steps per Second: 13062.68066
Overall Steps per Second: 10794.20980

Timestep Collection Time: 3.82877
Timestep Consumption Time: 0.80464
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 4.63341

Cumulative Model Updates: 1566
Cumulative Timesteps: 26162234

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06672
Policy Entropy: 1.03381
Value Function Loss: 0.06708

Mean KL Divergence: 0.13556
SB3 Clip Fraction: 0.41543
Policy Update Magnitude: 0.04517
Value Function Update Magnitude: 0.04383

Collected Steps per Second: 13164.54108
Overall Steps per Second: 10926.83548

Timestep Collection Time: 3.80203
Timestep Consumption Time: 0.77862
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 4.58065

Cumulative Model Updates: 1569
Cumulative Timesteps: 26212286

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 26212286...
Checkpoint 26212286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03024
Policy Entropy: 1.07635
Value Function Loss: 0.07608

Mean KL Divergence: 0.08104
SB3 Clip Fraction: 0.32602
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.04735

Collected Steps per Second: 13343.14490
Overall Steps per Second: 10987.59028

Timestep Collection Time: 3.74814
Timestep Consumption Time: 0.80354
PPO Batch Consumption Time: 0.02959
Total Iteration Time: 4.55168

Cumulative Model Updates: 1572
Cumulative Timesteps: 26262298

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03734
Policy Entropy: 1.05340
Value Function Loss: 0.07465

Mean KL Divergence: 0.09272
SB3 Clip Fraction: 0.31857
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.04848

Collected Steps per Second: 13410.71892
Overall Steps per Second: 11001.34563

Timestep Collection Time: 3.72896
Timestep Consumption Time: 0.81667
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 4.54563

Cumulative Model Updates: 1575
Cumulative Timesteps: 26312306

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 26312306...
Checkpoint 26312306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03961
Policy Entropy: 1.10662
Value Function Loss: 0.05886

Mean KL Divergence: 0.06401
SB3 Clip Fraction: 0.30587
Policy Update Magnitude: 0.04237
Value Function Update Magnitude: 0.05430

Collected Steps per Second: 13043.03603
Overall Steps per Second: 10958.01743

Timestep Collection Time: 3.83377
Timestep Consumption Time: 0.72946
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 4.56323

Cumulative Model Updates: 1578
Cumulative Timesteps: 26362310

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06592
Policy Entropy: 1.04110
Value Function Loss: 0.05965

Mean KL Divergence: 0.06039
SB3 Clip Fraction: 0.30377
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.05353

Collected Steps per Second: 13372.65709
Overall Steps per Second: 11027.51329

Timestep Collection Time: 3.74196
Timestep Consumption Time: 0.79578
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 4.53774

Cumulative Model Updates: 1581
Cumulative Timesteps: 26412350

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 26412350...
Checkpoint 26412350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04449
Policy Entropy: 1.09684
Value Function Loss: 0.05726

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.20028
Policy Update Magnitude: 0.04542
Value Function Update Magnitude: 0.05118

Collected Steps per Second: 13331.81645
Overall Steps per Second: 11001.72206

Timestep Collection Time: 3.75343
Timestep Consumption Time: 0.79495
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 4.54838

Cumulative Model Updates: 1584
Cumulative Timesteps: 26462390

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04963
Policy Entropy: 1.05260
Value Function Loss: 0.06910

Mean KL Divergence: 0.02375
SB3 Clip Fraction: 0.17385
Policy Update Magnitude: 0.05712
Value Function Update Magnitude: 0.04316

Collected Steps per Second: 13491.55164
Overall Steps per Second: 11068.21007

Timestep Collection Time: 3.70647
Timestep Consumption Time: 0.81152
PPO Batch Consumption Time: 0.03032
Total Iteration Time: 4.51798

Cumulative Model Updates: 1587
Cumulative Timesteps: 26512396

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 26512396...
Checkpoint 26512396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02677
Policy Entropy: 1.06997
Value Function Loss: 0.06426

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.18227
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.04799

Collected Steps per Second: 13286.50425
Overall Steps per Second: 10881.27894

Timestep Collection Time: 3.76427
Timestep Consumption Time: 0.83206
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 4.59633

Cumulative Model Updates: 1590
Cumulative Timesteps: 26562410

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03483
Policy Entropy: 1.03026
Value Function Loss: 0.07445

Mean KL Divergence: 0.03739
SB3 Clip Fraction: 0.23802
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.04460

Collected Steps per Second: 10994.48317
Overall Steps per Second: 9043.64799

Timestep Collection Time: 4.54919
Timestep Consumption Time: 0.98132
PPO Batch Consumption Time: 0.03175
Total Iteration Time: 5.53051

Cumulative Model Updates: 1593
Cumulative Timesteps: 26612426

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 26612426...
Checkpoint 26612426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09304
Policy Entropy: 1.08048
Value Function Loss: 0.07125

Mean KL Divergence: 0.02790
SB3 Clip Fraction: 0.21047
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.05041

Collected Steps per Second: 12264.59582
Overall Steps per Second: 10215.22999

Timestep Collection Time: 4.07890
Timestep Consumption Time: 0.81830
PPO Batch Consumption Time: 0.02930
Total Iteration Time: 4.89720

Cumulative Model Updates: 1596
Cumulative Timesteps: 26662452

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05077
Policy Entropy: 1.05205
Value Function Loss: 0.07267

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.16839
Policy Update Magnitude: 0.05423
Value Function Update Magnitude: 0.04118

Collected Steps per Second: 13156.72430
Overall Steps per Second: 10939.83470

Timestep Collection Time: 3.80079
Timestep Consumption Time: 0.77021
PPO Batch Consumption Time: 0.02909
Total Iteration Time: 4.57100

Cumulative Model Updates: 1599
Cumulative Timesteps: 26712458

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 26712458...
Checkpoint 26712458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02800
Policy Entropy: 1.04889
Value Function Loss: 0.07139

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.21304
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.04997

Collected Steps per Second: 13149.59930
Overall Steps per Second: 10885.42328

Timestep Collection Time: 3.80331
Timestep Consumption Time: 0.79109
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.59440

Cumulative Model Updates: 1602
Cumulative Timesteps: 26762470

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01505
Policy Entropy: 1.00653
Value Function Loss: 0.07293

Mean KL Divergence: 0.04151
SB3 Clip Fraction: 0.26448
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.04427

Collected Steps per Second: 12959.14445
Overall Steps per Second: 10716.05121

Timestep Collection Time: 3.85998
Timestep Consumption Time: 0.80797
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 4.66795

Cumulative Model Updates: 1605
Cumulative Timesteps: 26812492

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 26812492...
Checkpoint 26812492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00442
Policy Entropy: 1.04804
Value Function Loss: 0.07268

Mean KL Divergence: 0.02801
SB3 Clip Fraction: 0.21467
Policy Update Magnitude: 0.04435
Value Function Update Magnitude: 0.04883

Collected Steps per Second: 11825.39687
Overall Steps per Second: 10091.86533

Timestep Collection Time: 4.22988
Timestep Consumption Time: 0.72659
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 4.95647

Cumulative Model Updates: 1608
Cumulative Timesteps: 26862512

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01881
Policy Entropy: 1.03101
Value Function Loss: 0.07296

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.04602
Value Function Update Magnitude: 0.05505

Collected Steps per Second: 12738.58035
Overall Steps per Second: 10544.62125

Timestep Collection Time: 3.92760
Timestep Consumption Time: 0.81719
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 4.74479

Cumulative Model Updates: 1611
Cumulative Timesteps: 26912544

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 26912544...
Checkpoint 26912544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02483
Policy Entropy: 1.04082
Value Function Loss: 0.05872

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.21100
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.04262

Collected Steps per Second: 12970.52718
Overall Steps per Second: 10742.20527

Timestep Collection Time: 3.85844
Timestep Consumption Time: 0.80038
PPO Batch Consumption Time: 0.02950
Total Iteration Time: 4.65882

Cumulative Model Updates: 1614
Cumulative Timesteps: 26962590

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04189
Policy Entropy: 1.01555
Value Function Loss: 0.04410

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.04439

Collected Steps per Second: 12862.35293
Overall Steps per Second: 10672.34580

Timestep Collection Time: 3.89058
Timestep Consumption Time: 0.79836
PPO Batch Consumption Time: 0.02855
Total Iteration Time: 4.68894

Cumulative Model Updates: 1617
Cumulative Timesteps: 27012632

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 27012632...
Checkpoint 27012632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05632
Policy Entropy: 1.04254
Value Function Loss: 0.03293

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.03587

Collected Steps per Second: 12050.70802
Overall Steps per Second: 10045.94288

Timestep Collection Time: 4.15113
Timestep Consumption Time: 0.82840
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 4.97952

Cumulative Model Updates: 1620
Cumulative Timesteps: 27062656

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03155
Policy Entropy: 1.03970
Value Function Loss: 0.05482

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.04857
Value Function Update Magnitude: 0.03521

Collected Steps per Second: 13175.09776
Overall Steps per Second: 11082.07819

Timestep Collection Time: 3.79716
Timestep Consumption Time: 0.71715
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 4.51432

Cumulative Model Updates: 1623
Cumulative Timesteps: 27112684

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 27112684...
Checkpoint 27112684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01050
Policy Entropy: 1.06135
Value Function Loss: 0.07712

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.15646
Policy Update Magnitude: 0.05183
Value Function Update Magnitude: 0.04067

Collected Steps per Second: 12248.69127
Overall Steps per Second: 10264.35314

Timestep Collection Time: 4.08370
Timestep Consumption Time: 0.78947
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 4.87318

Cumulative Model Updates: 1626
Cumulative Timesteps: 27162704

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06481
Policy Entropy: 1.04047
Value Function Loss: 0.08606

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.04993

Collected Steps per Second: 13104.08031
Overall Steps per Second: 10900.37010

Timestep Collection Time: 3.81698
Timestep Consumption Time: 0.77167
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 4.58865

Cumulative Model Updates: 1629
Cumulative Timesteps: 27212722

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 27212722...
Checkpoint 27212722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11408
Policy Entropy: 1.04310
Value Function Loss: 0.07935

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.04749

Collected Steps per Second: 13023.11536
Overall Steps per Second: 10794.28880

Timestep Collection Time: 3.84132
Timestep Consumption Time: 0.79316
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 4.63449

Cumulative Model Updates: 1632
Cumulative Timesteps: 27262748

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02458
Policy Entropy: 1.04122
Value Function Loss: 0.06221

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.04935

Collected Steps per Second: 13001.79101
Overall Steps per Second: 10721.17654

Timestep Collection Time: 3.84670
Timestep Consumption Time: 0.81827
PPO Batch Consumption Time: 0.02711
Total Iteration Time: 4.66497

Cumulative Model Updates: 1635
Cumulative Timesteps: 27312762

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 27312762...
Checkpoint 27312762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01558
Policy Entropy: 1.04603
Value Function Loss: 0.04815

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.05405
Value Function Update Magnitude: 0.04345

Collected Steps per Second: 13291.67654
Overall Steps per Second: 10982.04753

Timestep Collection Time: 3.76597
Timestep Consumption Time: 0.79202
PPO Batch Consumption Time: 0.02988
Total Iteration Time: 4.55798

Cumulative Model Updates: 1638
Cumulative Timesteps: 27362818

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01071
Policy Entropy: 1.03468
Value Function Loss: 0.04915

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.04126

Collected Steps per Second: 13538.49767
Overall Steps per Second: 11144.05500

Timestep Collection Time: 3.69568
Timestep Consumption Time: 0.79406
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 4.48975

Cumulative Model Updates: 1641
Cumulative Timesteps: 27412852

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 27412852...
Checkpoint 27412852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00070
Policy Entropy: 1.02589
Value Function Loss: 0.06570

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.03747

Collected Steps per Second: 12896.95350
Overall Steps per Second: 10713.11135

Timestep Collection Time: 3.87921
Timestep Consumption Time: 0.79077
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 4.66998

Cumulative Model Updates: 1644
Cumulative Timesteps: 27462882

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01082
Policy Entropy: 1.01958
Value Function Loss: 0.08871

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14858
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.03923

Collected Steps per Second: 13102.69941
Overall Steps per Second: 11030.55771

Timestep Collection Time: 3.81860
Timestep Consumption Time: 0.71734
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 4.53594

Cumulative Model Updates: 1647
Cumulative Timesteps: 27512916

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 27512916...
Checkpoint 27512916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05687
Policy Entropy: 1.02794
Value Function Loss: 0.07370

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.04906

Collected Steps per Second: 13123.52302
Overall Steps per Second: 10840.41832

Timestep Collection Time: 3.81102
Timestep Consumption Time: 0.80264
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 4.61366

Cumulative Model Updates: 1650
Cumulative Timesteps: 27562930

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00784
Policy Entropy: 1.03610
Value Function Loss: 0.05084

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.04174

Collected Steps per Second: 13277.85886
Overall Steps per Second: 11019.43655

Timestep Collection Time: 3.76582
Timestep Consumption Time: 0.77180
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 4.53762

Cumulative Model Updates: 1653
Cumulative Timesteps: 27612932

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 27612932...
Checkpoint 27612932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07823
Policy Entropy: 1.03961
Value Function Loss: 0.05008

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.04351

Collected Steps per Second: 13653.06839
Overall Steps per Second: 11201.02474

Timestep Collection Time: 3.66394
Timestep Consumption Time: 0.80208
PPO Batch Consumption Time: 0.02852
Total Iteration Time: 4.46602

Cumulative Model Updates: 1656
Cumulative Timesteps: 27662956

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00324
Policy Entropy: 1.01369
Value Function Loss: 0.06188

Mean KL Divergence: 0.02767
SB3 Clip Fraction: 0.18653
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.04715

Collected Steps per Second: 13188.79188
Overall Steps per Second: 10899.05206

Timestep Collection Time: 3.79307
Timestep Consumption Time: 0.79687
PPO Batch Consumption Time: 0.02869
Total Iteration Time: 4.58994

Cumulative Model Updates: 1659
Cumulative Timesteps: 27712982

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 27712982...
Checkpoint 27712982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00980
Policy Entropy: 1.02462
Value Function Loss: 0.07539

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.18107
Policy Update Magnitude: 0.04189
Value Function Update Magnitude: 0.05806

Collected Steps per Second: 13118.32692
Overall Steps per Second: 11010.92992

Timestep Collection Time: 3.81253
Timestep Consumption Time: 0.72969
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 4.54221

Cumulative Model Updates: 1662
Cumulative Timesteps: 27762996

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01215
Policy Entropy: 1.02693
Value Function Loss: 0.05770

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.04074
Value Function Update Magnitude: 0.04420

Collected Steps per Second: 13242.52966
Overall Steps per Second: 10902.17972

Timestep Collection Time: 3.77677
Timestep Consumption Time: 0.81075
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 4.58752

Cumulative Model Updates: 1665
Cumulative Timesteps: 27813010

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 27813010...
Checkpoint 27813010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02572
Policy Entropy: 1.03233
Value Function Loss: 0.06088

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.06468

Collected Steps per Second: 12727.50630
Overall Steps per Second: 10522.91069

Timestep Collection Time: 3.93039
Timestep Consumption Time: 0.82343
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 4.75382

Cumulative Model Updates: 1668
Cumulative Timesteps: 27863034

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00627
Policy Entropy: 1.01953
Value Function Loss: 0.05671

Mean KL Divergence: 0.03033
SB3 Clip Fraction: 0.22301
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.06151

Collected Steps per Second: 11725.24011
Overall Steps per Second: 9606.71034

Timestep Collection Time: 4.26738
Timestep Consumption Time: 0.94107
PPO Batch Consumption Time: 0.03055
Total Iteration Time: 5.20844

Cumulative Model Updates: 1671
Cumulative Timesteps: 27913070

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 27913070...
Checkpoint 27913070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02148
Policy Entropy: 1.08651
Value Function Loss: 0.06547

Mean KL Divergence: 0.03744
SB3 Clip Fraction: 0.24017
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.04977

Collected Steps per Second: 11390.89898
Overall Steps per Second: 9473.46906

Timestep Collection Time: 4.39193
Timestep Consumption Time: 0.88893
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 5.28085

Cumulative Model Updates: 1674
Cumulative Timesteps: 27963098

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01908
Policy Entropy: 1.03819
Value Function Loss: 0.06168

Mean KL Divergence: 0.04571
SB3 Clip Fraction: 0.24120
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.05477

Collected Steps per Second: 10931.99903
Overall Steps per Second: 9426.29065

Timestep Collection Time: 4.57574
Timestep Consumption Time: 0.73091
PPO Batch Consumption Time: 0.02504
Total Iteration Time: 5.30665

Cumulative Model Updates: 1677
Cumulative Timesteps: 28013120

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 28013120...
Checkpoint 28013120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12081
Policy Entropy: 1.05317
Value Function Loss: 0.06960

Mean KL Divergence: 0.03303
SB3 Clip Fraction: 0.21207
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.04854

Collected Steps per Second: 11564.10463
Overall Steps per Second: 9804.07151

Timestep Collection Time: 4.32684
Timestep Consumption Time: 0.77676
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 5.10359

Cumulative Model Updates: 1680
Cumulative Timesteps: 28063156

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03580
Policy Entropy: 1.02604
Value Function Loss: 0.07957

Mean KL Divergence: 0.04499
SB3 Clip Fraction: 0.27320
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.05166

Collected Steps per Second: 11065.71035
Overall Steps per Second: 9408.00258

Timestep Collection Time: 4.52117
Timestep Consumption Time: 0.79664
PPO Batch Consumption Time: 0.02511
Total Iteration Time: 5.31781

Cumulative Model Updates: 1683
Cumulative Timesteps: 28113186

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 28113186...
Checkpoint 28113186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10586
Policy Entropy: 1.05596
Value Function Loss: 0.07695

Mean KL Divergence: 0.02781
SB3 Clip Fraction: 0.18381
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.06097

Collected Steps per Second: 11527.23774
Overall Steps per Second: 9655.38457

Timestep Collection Time: 4.33773
Timestep Consumption Time: 0.84094
PPO Batch Consumption Time: 0.03219
Total Iteration Time: 5.17866

Cumulative Model Updates: 1686
Cumulative Timesteps: 28163188

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01486
Policy Entropy: 1.05170
Value Function Loss: 0.07580

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.18385
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.05849

Collected Steps per Second: 10596.16326
Overall Steps per Second: 8765.30679

Timestep Collection Time: 4.72152
Timestep Consumption Time: 0.98621
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 5.70773

Cumulative Model Updates: 1689
Cumulative Timesteps: 28213218

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 28213218...
Checkpoint 28213218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02859
Policy Entropy: 1.01847
Value Function Loss: 0.06769

Mean KL Divergence: 0.05977
SB3 Clip Fraction: 0.26600
Policy Update Magnitude: 0.04582
Value Function Update Magnitude: 0.06206

Collected Steps per Second: 13042.39099
Overall Steps per Second: 10908.51625

Timestep Collection Time: 3.83672
Timestep Consumption Time: 0.75052
PPO Batch Consumption Time: 0.02747
Total Iteration Time: 4.58724

Cumulative Model Updates: 1692
Cumulative Timesteps: 28263258

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00176
Policy Entropy: 1.01385
Value Function Loss: 0.07862

Mean KL Divergence: 0.04688
SB3 Clip Fraction: 0.26483
Policy Update Magnitude: 0.04500
Value Function Update Magnitude: 0.05160

Collected Steps per Second: 12860.31878
Overall Steps per Second: 10610.54433

Timestep Collection Time: 3.88902
Timestep Consumption Time: 0.82460
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 4.71361

Cumulative Model Updates: 1695
Cumulative Timesteps: 28313272

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 28313272...
Checkpoint 28313272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01355
Policy Entropy: 1.03563
Value Function Loss: 0.06442

Mean KL Divergence: 0.03575
SB3 Clip Fraction: 0.20621
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.04894

Collected Steps per Second: 12143.53425
Overall Steps per Second: 10061.80293

Timestep Collection Time: 4.11758
Timestep Consumption Time: 0.85190
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 4.96949

Cumulative Model Updates: 1698
Cumulative Timesteps: 28363274

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03012
Policy Entropy: 1.03844
Value Function Loss: 0.06683

Mean KL Divergence: 0.02425
SB3 Clip Fraction: 0.19496
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.04829

Collected Steps per Second: 12618.18030
Overall Steps per Second: 10534.83190

Timestep Collection Time: 3.96555
Timestep Consumption Time: 0.78422
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 4.74977

Cumulative Model Updates: 1701
Cumulative Timesteps: 28413312

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 28413312...
Checkpoint 28413312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02827
Policy Entropy: 1.02626
Value Function Loss: 0.07220

Mean KL Divergence: 0.03792
SB3 Clip Fraction: 0.22693
Policy Update Magnitude: 0.04882
Value Function Update Magnitude: 0.04591

Collected Steps per Second: 13399.24463
Overall Steps per Second: 11093.65636

Timestep Collection Time: 3.73260
Timestep Consumption Time: 0.77574
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 4.50834

Cumulative Model Updates: 1704
Cumulative Timesteps: 28463326

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01639
Policy Entropy: 1.00728
Value Function Loss: 0.08014

Mean KL Divergence: 0.04294
SB3 Clip Fraction: 0.25453
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.05145

Collected Steps per Second: 13698.16596
Overall Steps per Second: 11206.32915

Timestep Collection Time: 3.65202
Timestep Consumption Time: 0.81206
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 4.46408

Cumulative Model Updates: 1707
Cumulative Timesteps: 28513352

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 28513352...
Checkpoint 28513352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07322
Policy Entropy: 1.02991
Value Function Loss: 0.07334

Mean KL Divergence: 0.02725
SB3 Clip Fraction: 0.19457
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.05877

Collected Steps per Second: 13606.30591
Overall Steps per Second: 11222.01634

Timestep Collection Time: 3.67697
Timestep Consumption Time: 0.78123
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 4.45820

Cumulative Model Updates: 1710
Cumulative Timesteps: 28563382

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05468
Policy Entropy: 1.03291
Value Function Loss: 0.05552

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.16861
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.05908

Collected Steps per Second: 13202.78080
Overall Steps per Second: 10905.14774

Timestep Collection Time: 3.78935
Timestep Consumption Time: 0.79839
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 4.58774

Cumulative Model Updates: 1713
Cumulative Timesteps: 28613412

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 28613412...
Checkpoint 28613412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03487
Policy Entropy: 1.01741
Value Function Loss: 0.06477

Mean KL Divergence: 0.04572
SB3 Clip Fraction: 0.25955
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.05607

Collected Steps per Second: 13174.27451
Overall Steps per Second: 11129.10364

Timestep Collection Time: 3.79679
Timestep Consumption Time: 0.69773
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 4.49452

Cumulative Model Updates: 1716
Cumulative Timesteps: 28663432

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01492
Policy Entropy: 1.02325
Value Function Loss: 0.06098

Mean KL Divergence: 0.05795
SB3 Clip Fraction: 0.28957
Policy Update Magnitude: 0.04709
Value Function Update Magnitude: 0.04815

Collected Steps per Second: 13400.31686
Overall Steps per Second: 11067.84981

Timestep Collection Time: 3.73364
Timestep Consumption Time: 0.78684
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 4.52048

Cumulative Model Updates: 1719
Cumulative Timesteps: 28713464

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 28713464...
Checkpoint 28713464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03147
Policy Entropy: 1.04983
Value Function Loss: 0.07087

Mean KL Divergence: 0.04350
SB3 Clip Fraction: 0.25586
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.04820

Collected Steps per Second: 13622.22073
Overall Steps per Second: 11281.80024

Timestep Collection Time: 3.67326
Timestep Consumption Time: 0.76202
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 4.43529

Cumulative Model Updates: 1722
Cumulative Timesteps: 28763502

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01538
Policy Entropy: 1.00623
Value Function Loss: 0.05922

Mean KL Divergence: 0.07036
SB3 Clip Fraction: 0.27824
Policy Update Magnitude: 0.05072
Value Function Update Magnitude: 0.04481

Collected Steps per Second: 13324.37249
Overall Steps per Second: 11001.59436

Timestep Collection Time: 3.75552
Timestep Consumption Time: 0.79291
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 4.54843

Cumulative Model Updates: 1725
Cumulative Timesteps: 28813542

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 28813542...
Checkpoint 28813542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01111
Policy Entropy: 1.01181
Value Function Loss: 0.05976

Mean KL Divergence: 0.04101
SB3 Clip Fraction: 0.25138
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.05128

Collected Steps per Second: 12468.06481
Overall Steps per Second: 10281.64903

Timestep Collection Time: 4.01329
Timestep Consumption Time: 0.85344
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 4.86673

Cumulative Model Updates: 1728
Cumulative Timesteps: 28863580

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00090
Policy Entropy: 1.03214
Value Function Loss: 0.06350

Mean KL Divergence: 0.04502
SB3 Clip Fraction: 0.23424
Policy Update Magnitude: 0.04920
Value Function Update Magnitude: 0.05672

Collected Steps per Second: 13742.18040
Overall Steps per Second: 11542.76038

Timestep Collection Time: 3.64047
Timestep Consumption Time: 0.69367
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 4.33415

Cumulative Model Updates: 1731
Cumulative Timesteps: 28913608

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 28913608...
Checkpoint 28913608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00337
Policy Entropy: 1.01923
Value Function Loss: 0.09621

Mean KL Divergence: 0.03604
SB3 Clip Fraction: 0.23969
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.05273

Collected Steps per Second: 14136.01798
Overall Steps per Second: 11614.17147

Timestep Collection Time: 3.53961
Timestep Consumption Time: 0.76857
PPO Batch Consumption Time: 0.02664
Total Iteration Time: 4.30819

Cumulative Model Updates: 1734
Cumulative Timesteps: 28963644

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01153
Policy Entropy: 0.99282
Value Function Loss: 0.09983

Mean KL Divergence: 0.04289
SB3 Clip Fraction: 0.20724
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.05675

Collected Steps per Second: 13558.59934
Overall Steps per Second: 11173.07170

Timestep Collection Time: 3.68932
Timestep Consumption Time: 0.78770
PPO Batch Consumption Time: 0.02529
Total Iteration Time: 4.47701

Cumulative Model Updates: 1737
Cumulative Timesteps: 29013666

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 29013666...
Checkpoint 29013666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02902
Policy Entropy: 0.94706
Value Function Loss: 0.08341

Mean KL Divergence: 0.08717
SB3 Clip Fraction: 0.34609
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.06241

Collected Steps per Second: 12541.73484
Overall Steps per Second: 10187.08333

Timestep Collection Time: 3.98828
Timestep Consumption Time: 0.92186
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 4.91014

Cumulative Model Updates: 1740
Cumulative Timesteps: 29063686

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02322
Policy Entropy: 0.98044
Value Function Loss: 0.05292

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.17204
Policy Update Magnitude: 0.04258
Value Function Update Magnitude: 0.05734

Collected Steps per Second: 9763.08764
Overall Steps per Second: 8301.94836

Timestep Collection Time: 5.12256
Timestep Consumption Time: 0.90157
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 6.02413

Cumulative Model Updates: 1743
Cumulative Timesteps: 29113698

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 29113698...
Checkpoint 29113698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07041
Policy Entropy: 0.97979
Value Function Loss: 0.07604

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.05646

Collected Steps per Second: 12146.23976
Overall Steps per Second: 10076.85283

Timestep Collection Time: 4.11946
Timestep Consumption Time: 0.84597
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 4.96544

Cumulative Model Updates: 1746
Cumulative Timesteps: 29163734

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01123
Policy Entropy: 0.98679
Value Function Loss: 0.06683

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.06408

Collected Steps per Second: 12541.76742
Overall Steps per Second: 10259.62992

Timestep Collection Time: 3.98700
Timestep Consumption Time: 0.88686
PPO Batch Consumption Time: 0.03064
Total Iteration Time: 4.87386

Cumulative Model Updates: 1749
Cumulative Timesteps: 29213738

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 29213738...
Checkpoint 29213738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02516
Policy Entropy: 0.98746
Value Function Loss: 0.05686

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.05277

Collected Steps per Second: 12016.80205
Overall Steps per Second: 10019.72075

Timestep Collection Time: 4.16450
Timestep Consumption Time: 0.83005
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 4.99455

Cumulative Model Updates: 1752
Cumulative Timesteps: 29263782

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02015
Policy Entropy: 0.95974
Value Function Loss: 0.02714

Mean KL Divergence: 0.03235
SB3 Clip Fraction: 0.24039
Policy Update Magnitude: 0.04474
Value Function Update Magnitude: 0.06722

Collected Steps per Second: 12437.17971
Overall Steps per Second: 10403.44984

Timestep Collection Time: 4.02069
Timestep Consumption Time: 0.78599
PPO Batch Consumption Time: 0.02993
Total Iteration Time: 4.80667

Cumulative Model Updates: 1755
Cumulative Timesteps: 29313788

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 29313788...
Checkpoint 29313788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00834
Policy Entropy: 1.02319
Value Function Loss: 0.04420

Mean KL Divergence: 0.03332
SB3 Clip Fraction: 0.22875
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.03931

Collected Steps per Second: 10757.10919
Overall Steps per Second: 9032.00688

Timestep Collection Time: 4.65144
Timestep Consumption Time: 0.88842
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 5.53985

Cumulative Model Updates: 1758
Cumulative Timesteps: 29363824

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07750
Policy Entropy: 0.99188
Value Function Loss: 0.06065

Mean KL Divergence: 0.02481
SB3 Clip Fraction: 0.20589
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.04979

Collected Steps per Second: 10447.31716
Overall Steps per Second: 8860.43741

Timestep Collection Time: 4.78764
Timestep Consumption Time: 0.85745
PPO Batch Consumption Time: 0.03225
Total Iteration Time: 5.64509

Cumulative Model Updates: 1761
Cumulative Timesteps: 29413842

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 29413842...
Checkpoint 29413842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00245
Policy Entropy: 0.99748
Value Function Loss: 0.06270

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.17001
Policy Update Magnitude: 0.05206
Value Function Update Magnitude: 0.06557

Collected Steps per Second: 11165.71156
Overall Steps per Second: 8869.84271

Timestep Collection Time: 4.48086
Timestep Consumption Time: 1.15983
PPO Batch Consumption Time: 0.03204
Total Iteration Time: 5.64069

Cumulative Model Updates: 1764
Cumulative Timesteps: 29463874

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01390
Policy Entropy: 0.96048
Value Function Loss: 0.05694

Mean KL Divergence: 0.04959
SB3 Clip Fraction: 0.28849
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.05239

Collected Steps per Second: 9464.72295
Overall Steps per Second: 8003.29985

Timestep Collection Time: 5.28637
Timestep Consumption Time: 0.96530
PPO Batch Consumption Time: 0.03273
Total Iteration Time: 6.25167

Cumulative Model Updates: 1767
Cumulative Timesteps: 29513908

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 29513908...
Checkpoint 29513908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04185
Policy Entropy: 1.00255
Value Function Loss: 0.05657

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.04225
Value Function Update Magnitude: 0.04860

Collected Steps per Second: 9737.51453
Overall Steps per Second: 8170.85811

Timestep Collection Time: 5.13601
Timestep Consumption Time: 0.98476
PPO Batch Consumption Time: 0.03093
Total Iteration Time: 6.12078

Cumulative Model Updates: 1770
Cumulative Timesteps: 29563920

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00116
Policy Entropy: 0.97221
Value Function Loss: 0.06486

Mean KL Divergence: 0.04259
SB3 Clip Fraction: 0.25804
Policy Update Magnitude: 0.04658
Value Function Update Magnitude: 0.05277

Collected Steps per Second: 10345.37578
Overall Steps per Second: 8715.99286

Timestep Collection Time: 4.83308
Timestep Consumption Time: 0.90350
PPO Batch Consumption Time: 0.03234
Total Iteration Time: 5.73658

Cumulative Model Updates: 1773
Cumulative Timesteps: 29613920

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 29613920...
Checkpoint 29613920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01793
Policy Entropy: 0.98837
Value Function Loss: 0.05698

Mean KL Divergence: 0.04282
SB3 Clip Fraction: 0.27029
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.04834

Collected Steps per Second: 9331.60646
Overall Steps per Second: 7727.67801

Timestep Collection Time: 5.35942
Timestep Consumption Time: 1.11238
PPO Batch Consumption Time: 0.04014
Total Iteration Time: 6.47180

Cumulative Model Updates: 1776
Cumulative Timesteps: 29663932

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02257
Policy Entropy: 0.99222
Value Function Loss: 0.04414

Mean KL Divergence: 0.05177
SB3 Clip Fraction: 0.23870
Policy Update Magnitude: 0.04564
Value Function Update Magnitude: 0.05240

Collected Steps per Second: 8107.46516
Overall Steps per Second: 7063.54730

Timestep Collection Time: 6.17209
Timestep Consumption Time: 0.91217
PPO Batch Consumption Time: 0.03022
Total Iteration Time: 7.08426

Cumulative Model Updates: 1779
Cumulative Timesteps: 29713972

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 29713972...
Checkpoint 29713972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03286
Policy Entropy: 1.00329
Value Function Loss: 0.05716

Mean KL Divergence: 0.04504
SB3 Clip Fraction: 0.25027
Policy Update Magnitude: 0.04209
Value Function Update Magnitude: 0.04672

Collected Steps per Second: 8998.22847
Overall Steps per Second: 7469.27853

Timestep Collection Time: 5.55909
Timestep Consumption Time: 1.13794
PPO Batch Consumption Time: 0.04109
Total Iteration Time: 6.69703

Cumulative Model Updates: 1782
Cumulative Timesteps: 29763994

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04410
Policy Entropy: 0.94226
Value Function Loss: 0.05872

Mean KL Divergence: 0.10442
SB3 Clip Fraction: 0.36290
Policy Update Magnitude: 0.03977
Value Function Update Magnitude: 0.04715

Collected Steps per Second: 9300.02468
Overall Steps per Second: 8119.85781

Timestep Collection Time: 5.37719
Timestep Consumption Time: 0.78154
PPO Batch Consumption Time: 0.02947
Total Iteration Time: 6.15873

Cumulative Model Updates: 1785
Cumulative Timesteps: 29814002

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 29814002...
Checkpoint 29814002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03413
Policy Entropy: 1.00628
Value Function Loss: 0.06359

Mean KL Divergence: 0.03203
SB3 Clip Fraction: 0.23597
Policy Update Magnitude: 0.03738
Value Function Update Magnitude: 0.06360

Collected Steps per Second: 11589.86918
Overall Steps per Second: 9298.54069

Timestep Collection Time: 4.31601
Timestep Consumption Time: 1.06354
PPO Batch Consumption Time: 0.02888
Total Iteration Time: 5.37955

Cumulative Model Updates: 1788
Cumulative Timesteps: 29864024

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05003
Policy Entropy: 0.94285
Value Function Loss: 0.05056

Mean KL Divergence: 0.05478
SB3 Clip Fraction: 0.25897
Policy Update Magnitude: 0.03780
Value Function Update Magnitude: 0.05356

Collected Steps per Second: 11087.05933
Overall Steps per Second: 9296.08684

Timestep Collection Time: 4.51193
Timestep Consumption Time: 0.86926
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 5.38119

Cumulative Model Updates: 1791
Cumulative Timesteps: 29914048

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 29914048...
Checkpoint 29914048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01820
Policy Entropy: 0.97265
Value Function Loss: 0.05571

Mean KL Divergence: 0.02195
SB3 Clip Fraction: 0.19345
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.06267

Collected Steps per Second: 11112.11136
Overall Steps per Second: 9445.03202

Timestep Collection Time: 4.50301
Timestep Consumption Time: 0.79480
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 5.29781

Cumulative Model Updates: 1794
Cumulative Timesteps: 29964086

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04014
Policy Entropy: 0.96191
Value Function Loss: 0.05340

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.18580
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.05396

Collected Steps per Second: 11484.18692
Overall Steps per Second: 9549.85725

Timestep Collection Time: 4.35660
Timestep Consumption Time: 0.88243
PPO Batch Consumption Time: 0.02723
Total Iteration Time: 5.23903

Cumulative Model Updates: 1797
Cumulative Timesteps: 30014118

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 30014118...
Checkpoint 30014118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01770
Policy Entropy: 0.97212
Value Function Loss: 0.04093

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.15901
Policy Update Magnitude: 0.04592
Value Function Update Magnitude: 0.05388

Collected Steps per Second: 11130.17116
Overall Steps per Second: 9513.71231

Timestep Collection Time: 4.49337
Timestep Consumption Time: 0.76346
PPO Batch Consumption Time: 0.03130
Total Iteration Time: 5.25683

Cumulative Model Updates: 1800
Cumulative Timesteps: 30064130

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06889
Policy Entropy: 0.93704
Value Function Loss: 0.04363

Mean KL Divergence: 0.04341
SB3 Clip Fraction: 0.25765
Policy Update Magnitude: 0.04509
Value Function Update Magnitude: 0.05194

Collected Steps per Second: 11732.46334
Overall Steps per Second: 9899.01366

Timestep Collection Time: 4.26253
Timestep Consumption Time: 0.78949
PPO Batch Consumption Time: 0.02853
Total Iteration Time: 5.05202

Cumulative Model Updates: 1803
Cumulative Timesteps: 30114140

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 30114140...
Checkpoint 30114140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05902
Policy Entropy: 0.99219
Value Function Loss: 0.04886

Mean KL Divergence: 0.02937
SB3 Clip Fraction: 0.22237
Policy Update Magnitude: 0.04232
Value Function Update Magnitude: 0.04873

Collected Steps per Second: 13035.89733
Overall Steps per Second: 10801.02201

Timestep Collection Time: 3.83786
Timestep Consumption Time: 0.79411
PPO Batch Consumption Time: 0.02827
Total Iteration Time: 4.63197

Cumulative Model Updates: 1806
Cumulative Timesteps: 30164170

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06909
Policy Entropy: 0.95056
Value Function Loss: 0.07023

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.19809
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.04915

Collected Steps per Second: 13106.20651
Overall Steps per Second: 11039.76911

Timestep Collection Time: 3.81529
Timestep Consumption Time: 0.71415
PPO Batch Consumption Time: 0.02865
Total Iteration Time: 4.52944

Cumulative Model Updates: 1809
Cumulative Timesteps: 30214174

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 30214174...
Checkpoint 30214174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06157
Policy Entropy: 0.95599
Value Function Loss: 0.07638

Mean KL Divergence: 0.02409
SB3 Clip Fraction: 0.17897
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.05315

Collected Steps per Second: 11812.94319
Overall Steps per Second: 9815.17761

Timestep Collection Time: 4.23332
Timestep Consumption Time: 0.86164
PPO Batch Consumption Time: 0.03411
Total Iteration Time: 5.09497

Cumulative Model Updates: 1812
Cumulative Timesteps: 30264182

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08327
Policy Entropy: 0.90784
Value Function Loss: 0.09932

Mean KL Divergence: 0.06111
SB3 Clip Fraction: 0.30741
Policy Update Magnitude: 0.05955
Value Function Update Magnitude: 0.05452

Collected Steps per Second: 11207.39885
Overall Steps per Second: 9499.96710

Timestep Collection Time: 4.46330
Timestep Consumption Time: 0.80219
PPO Batch Consumption Time: 0.03086
Total Iteration Time: 5.26549

Cumulative Model Updates: 1815
Cumulative Timesteps: 30314204

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 30314204...
Checkpoint 30314204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03595
Policy Entropy: 0.98098
Value Function Loss: 0.09266

Mean KL Divergence: 0.04047
SB3 Clip Fraction: 0.27873
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.06040

Collected Steps per Second: 10031.84730
Overall Steps per Second: 8549.85311

Timestep Collection Time: 4.98552
Timestep Consumption Time: 0.86417
PPO Batch Consumption Time: 0.02950
Total Iteration Time: 5.84969

Cumulative Model Updates: 1818
Cumulative Timesteps: 30364218

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06866
Policy Entropy: 0.92755
Value Function Loss: 0.09309

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.18322
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.06432

Collected Steps per Second: 12479.37646
Overall Steps per Second: 10424.23500

Timestep Collection Time: 4.00917
Timestep Consumption Time: 0.79041
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 4.79958

Cumulative Model Updates: 1821
Cumulative Timesteps: 30414250

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 30414250...
Checkpoint 30414250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00072
Policy Entropy: 0.93756
Value Function Loss: 0.07187

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.06099
Value Function Update Magnitude: 0.07174

Collected Steps per Second: 12852.23981
Overall Steps per Second: 10858.31220

Timestep Collection Time: 3.89193
Timestep Consumption Time: 0.71468
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 4.60661

Cumulative Model Updates: 1824
Cumulative Timesteps: 30464270

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01936
Policy Entropy: 0.93821
Value Function Loss: 0.06190

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.18897
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.06796

Collected Steps per Second: 13001.52050
Overall Steps per Second: 10635.61657

Timestep Collection Time: 3.84601
Timestep Consumption Time: 0.85555
PPO Batch Consumption Time: 0.02667
Total Iteration Time: 4.70156

Cumulative Model Updates: 1827
Cumulative Timesteps: 30514274

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 30514274...
Checkpoint 30514274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03329
Policy Entropy: 0.95510
Value Function Loss: 0.05435

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.16648
Policy Update Magnitude: 0.06065
Value Function Update Magnitude: 0.06635

Collected Steps per Second: 12835.96987
Overall Steps per Second: 10827.94545

Timestep Collection Time: 3.89702
Timestep Consumption Time: 0.72270
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 4.61971

Cumulative Model Updates: 1830
Cumulative Timesteps: 30564296

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00654
Policy Entropy: 0.97084
Value Function Loss: 0.05648

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.06158
Value Function Update Magnitude: 0.06009

Collected Steps per Second: 12599.58374
Overall Steps per Second: 10244.01433

Timestep Collection Time: 3.96965
Timestep Consumption Time: 0.91281
PPO Batch Consumption Time: 0.03472
Total Iteration Time: 4.88246

Cumulative Model Updates: 1833
Cumulative Timesteps: 30614312

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 30614312...
Checkpoint 30614312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05678
Policy Entropy: 0.96017
Value Function Loss: 0.06307

Mean KL Divergence: 0.02374
SB3 Clip Fraction: 0.17483
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.05961

Collected Steps per Second: 9981.44373
Overall Steps per Second: 8430.76822

Timestep Collection Time: 5.01110
Timestep Consumption Time: 0.92169
PPO Batch Consumption Time: 0.03299
Total Iteration Time: 5.93279

Cumulative Model Updates: 1836
Cumulative Timesteps: 30664330

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05012
Policy Entropy: 0.95063
Value Function Loss: 0.05558

Mean KL Divergence: 0.03226
SB3 Clip Fraction: 0.21971
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.05624

Collected Steps per Second: 9696.04735
Overall Steps per Second: 8392.71038

Timestep Collection Time: 5.15736
Timestep Consumption Time: 0.80091
PPO Batch Consumption Time: 0.02998
Total Iteration Time: 5.95827

Cumulative Model Updates: 1839
Cumulative Timesteps: 30714336

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 30714336...
Checkpoint 30714336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02735
Policy Entropy: 0.99549
Value Function Loss: 0.05591

Mean KL Divergence: 0.03388
SB3 Clip Fraction: 0.22198
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.06379

Collected Steps per Second: 10733.86758
Overall Steps per Second: 9064.83804

Timestep Collection Time: 4.65908
Timestep Consumption Time: 0.85784
PPO Batch Consumption Time: 0.03108
Total Iteration Time: 5.51692

Cumulative Model Updates: 1842
Cumulative Timesteps: 30764346

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02798
Policy Entropy: 0.95514
Value Function Loss: 0.05407

Mean KL Divergence: 0.03120
SB3 Clip Fraction: 0.19909
Policy Update Magnitude: 0.04366
Value Function Update Magnitude: 0.05582

Collected Steps per Second: 11588.81199
Overall Steps per Second: 9833.13202

Timestep Collection Time: 4.31830
Timestep Consumption Time: 0.77102
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 5.08932

Cumulative Model Updates: 1845
Cumulative Timesteps: 30814390

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 30814390...
Checkpoint 30814390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01983
Policy Entropy: 0.96098
Value Function Loss: 0.06375

Mean KL Divergence: 0.03152
SB3 Clip Fraction: 0.16621
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.05639

Collected Steps per Second: 11298.89322
Overall Steps per Second: 9483.55528

Timestep Collection Time: 4.42981
Timestep Consumption Time: 0.84795
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 5.27777

Cumulative Model Updates: 1848
Cumulative Timesteps: 30864442

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04611
Policy Entropy: 0.92044
Value Function Loss: 0.06004

Mean KL Divergence: 0.06316
SB3 Clip Fraction: 0.31351
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.06026

Collected Steps per Second: 11537.21278
Overall Steps per Second: 9699.05042

Timestep Collection Time: 4.33692
Timestep Consumption Time: 0.82193
PPO Batch Consumption Time: 0.02910
Total Iteration Time: 5.15886

Cumulative Model Updates: 1851
Cumulative Timesteps: 30914478

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 30914478...
Checkpoint 30914478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01373
Policy Entropy: 0.95703
Value Function Loss: 0.05820

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.15977
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.05826

Collected Steps per Second: 10398.45182
Overall Steps per Second: 8823.95659

Timestep Collection Time: 4.81091
Timestep Consumption Time: 0.85843
PPO Batch Consumption Time: 0.03135
Total Iteration Time: 5.66934

Cumulative Model Updates: 1854
Cumulative Timesteps: 30964504

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00073
Policy Entropy: 0.94980
Value Function Loss: 0.05066

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.05378

Collected Steps per Second: 10106.81023
Overall Steps per Second: 8449.12381

Timestep Collection Time: 4.95072
Timestep Consumption Time: 0.97131
PPO Batch Consumption Time: 0.03064
Total Iteration Time: 5.92203

Cumulative Model Updates: 1857
Cumulative Timesteps: 31014540

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 31014540...
Checkpoint 31014540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00653
Policy Entropy: 0.93903
Value Function Loss: 0.06987

Mean KL Divergence: 0.02786
SB3 Clip Fraction: 0.20447
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.04721

Collected Steps per Second: 9597.36456
Overall Steps per Second: 8262.08304

Timestep Collection Time: 5.21122
Timestep Consumption Time: 0.84221
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 6.05344

Cumulative Model Updates: 1860
Cumulative Timesteps: 31064554

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00427
Policy Entropy: 0.90086
Value Function Loss: 0.07140

Mean KL Divergence: 0.03822
SB3 Clip Fraction: 0.24275
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.04928

Collected Steps per Second: 11903.54283
Overall Steps per Second: 10001.49941

Timestep Collection Time: 4.20060
Timestep Consumption Time: 0.79885
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 4.99945

Cumulative Model Updates: 1863
Cumulative Timesteps: 31114556

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 31114556...
Checkpoint 31114556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01052
Policy Entropy: 0.96119
Value Function Loss: 0.08834

Mean KL Divergence: 0.04813
SB3 Clip Fraction: 0.27085
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.06031

Collected Steps per Second: 11428.59445
Overall Steps per Second: 9280.74219

Timestep Collection Time: 4.37534
Timestep Consumption Time: 1.01259
PPO Batch Consumption Time: 0.03124
Total Iteration Time: 5.38793

Cumulative Model Updates: 1866
Cumulative Timesteps: 31164560

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07556
Policy Entropy: 0.95208
Value Function Loss: 0.06994

Mean KL Divergence: 0.03503
SB3 Clip Fraction: 0.22882
Policy Update Magnitude: 0.05778
Value Function Update Magnitude: 0.05798

Collected Steps per Second: 11812.22529
Overall Steps per Second: 10040.53633

Timestep Collection Time: 4.23527
Timestep Consumption Time: 0.74733
PPO Batch Consumption Time: 0.03133
Total Iteration Time: 4.98260

Cumulative Model Updates: 1869
Cumulative Timesteps: 31214588

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 31214588...
Checkpoint 31214588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04020
Policy Entropy: 0.94426
Value Function Loss: 0.07897

Mean KL Divergence: 0.05527
SB3 Clip Fraction: 0.26647
Policy Update Magnitude: 0.06548
Value Function Update Magnitude: 0.05255

Collected Steps per Second: 11360.83350
Overall Steps per Second: 9460.83187

Timestep Collection Time: 4.40513
Timestep Consumption Time: 0.88468
PPO Batch Consumption Time: 0.03244
Total Iteration Time: 5.28981

Cumulative Model Updates: 1872
Cumulative Timesteps: 31264634

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12132
Policy Entropy: 0.95714
Value Function Loss: 0.07344

Mean KL Divergence: 0.08278
SB3 Clip Fraction: 0.33397
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.05277

Collected Steps per Second: 10186.46357
Overall Steps per Second: 8772.21487

Timestep Collection Time: 4.91221
Timestep Consumption Time: 0.79194
PPO Batch Consumption Time: 0.02612
Total Iteration Time: 5.70415

Cumulative Model Updates: 1875
Cumulative Timesteps: 31314672

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 31314672...
Checkpoint 31314672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01542
Policy Entropy: 0.96706
Value Function Loss: 0.07506

Mean KL Divergence: 0.08576
SB3 Clip Fraction: 0.32528
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.05569

Collected Steps per Second: 11643.65490
Overall Steps per Second: 9814.92634

Timestep Collection Time: 4.29676
Timestep Consumption Time: 0.80058
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 5.09734

Cumulative Model Updates: 1878
Cumulative Timesteps: 31364702

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01160
Policy Entropy: 0.93911
Value Function Loss: 0.06167

Mean KL Divergence: 0.04249
SB3 Clip Fraction: 0.23571
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.05620

Collected Steps per Second: 11516.35272
Overall Steps per Second: 9691.82805

Timestep Collection Time: 4.34443
Timestep Consumption Time: 0.81786
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 5.16229

Cumulative Model Updates: 1881
Cumulative Timesteps: 31414734

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 31414734...
Checkpoint 31414734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01260
Policy Entropy: 0.96255
Value Function Loss: 0.07959

Mean KL Divergence: 0.02999
SB3 Clip Fraction: 0.20501
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.05561

Collected Steps per Second: 12082.11909
Overall Steps per Second: 10180.08542

Timestep Collection Time: 4.13984
Timestep Consumption Time: 0.77348
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 4.91332

Cumulative Model Updates: 1884
Cumulative Timesteps: 31464752

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15710
Policy Entropy: 0.96205
Value Function Loss: 0.09736

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.05156

Collected Steps per Second: 11975.55307
Overall Steps per Second: 9970.31628

Timestep Collection Time: 4.17634
Timestep Consumption Time: 0.83995
PPO Batch Consumption Time: 0.03068
Total Iteration Time: 5.01629

Cumulative Model Updates: 1887
Cumulative Timesteps: 31514766

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 31514766...
Checkpoint 31514766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03160
Policy Entropy: 0.98802
Value Function Loss: 0.09714

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.06064
Value Function Update Magnitude: 0.05089

Collected Steps per Second: 12076.55584
Overall Steps per Second: 10081.16018

Timestep Collection Time: 4.14274
Timestep Consumption Time: 0.81999
PPO Batch Consumption Time: 0.03049
Total Iteration Time: 4.96272

Cumulative Model Updates: 1890
Cumulative Timesteps: 31564796

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03781
Policy Entropy: 0.98122
Value Function Loss: 0.07599

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.06596
Value Function Update Magnitude: 0.05159

Collected Steps per Second: 12737.64120
Overall Steps per Second: 10567.64275

Timestep Collection Time: 3.92537
Timestep Consumption Time: 0.80605
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 4.73142

Cumulative Model Updates: 1893
Cumulative Timesteps: 31614796

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 31614796...
Checkpoint 31614796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01928
Policy Entropy: 0.98539
Value Function Loss: 0.06960

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.06494
Value Function Update Magnitude: 0.05320

Collected Steps per Second: 12937.85973
Overall Steps per Second: 10713.57225

Timestep Collection Time: 3.86494
Timestep Consumption Time: 0.80241
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 4.66735

Cumulative Model Updates: 1896
Cumulative Timesteps: 31664800

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11440
Policy Entropy: 0.94463
Value Function Loss: 0.06838

Mean KL Divergence: 0.06364
SB3 Clip Fraction: 0.31830
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.04862

Collected Steps per Second: 12746.10405
Overall Steps per Second: 10716.41407

Timestep Collection Time: 3.92371
Timestep Consumption Time: 0.74315
PPO Batch Consumption Time: 0.02873
Total Iteration Time: 4.66686

Cumulative Model Updates: 1899
Cumulative Timesteps: 31714812

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 31714812...
Checkpoint 31714812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01463
Policy Entropy: 1.01096
Value Function Loss: 0.06851

Mean KL Divergence: 0.05620
SB3 Clip Fraction: 0.28833
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.05799

Collected Steps per Second: 12319.83784
Overall Steps per Second: 10281.87742

Timestep Collection Time: 4.05898
Timestep Consumption Time: 0.80453
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 4.86351

Cumulative Model Updates: 1902
Cumulative Timesteps: 31764818

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03001
Policy Entropy: 0.92232
Value Function Loss: 0.04896

Mean KL Divergence: 0.16689
SB3 Clip Fraction: 0.38976
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.05724

Collected Steps per Second: 12736.69462
Overall Steps per Second: 10585.78222

Timestep Collection Time: 3.92896
Timestep Consumption Time: 0.79832
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 4.72728

Cumulative Model Updates: 1905
Cumulative Timesteps: 31814860

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 31814860...
Checkpoint 31814860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00514
Policy Entropy: 1.00535
Value Function Loss: 0.04632

Mean KL Divergence: 0.10664
SB3 Clip Fraction: 0.38169
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.04774

Collected Steps per Second: 12899.39495
Overall Steps per Second: 10603.92161

Timestep Collection Time: 3.87677
Timestep Consumption Time: 0.83922
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 4.71599

Cumulative Model Updates: 1908
Cumulative Timesteps: 31864868

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00276
Policy Entropy: 0.96174
Value Function Loss: 0.04105

Mean KL Divergence: 0.11531
SB3 Clip Fraction: 0.33529
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.05524

Collected Steps per Second: 12698.58585
Overall Steps per Second: 10568.03787

Timestep Collection Time: 3.93745
Timestep Consumption Time: 0.79380
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 4.73125

Cumulative Model Updates: 1911
Cumulative Timesteps: 31914868

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 31914868...
Checkpoint 31914868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03992
Policy Entropy: 0.99727
Value Function Loss: 0.06724

Mean KL Divergence: 0.07803
SB3 Clip Fraction: 0.30653
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.05470

Collected Steps per Second: 11961.60357
Overall Steps per Second: 10161.10167

Timestep Collection Time: 4.18121
Timestep Consumption Time: 0.74089
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 4.92210

Cumulative Model Updates: 1914
Cumulative Timesteps: 31964882

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03941
Policy Entropy: 0.94942
Value Function Loss: 0.08759

Mean KL Divergence: 0.06769
SB3 Clip Fraction: 0.24537
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.05084

Collected Steps per Second: 12939.70887
Overall Steps per Second: 10712.41502

Timestep Collection Time: 3.86670
Timestep Consumption Time: 0.80395
PPO Batch Consumption Time: 0.02870
Total Iteration Time: 4.67066

Cumulative Model Updates: 1917
Cumulative Timesteps: 32014916

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 32014916...
Checkpoint 32014916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01152
Policy Entropy: 1.01967
Value Function Loss: 0.11198

Mean KL Divergence: 0.06597
SB3 Clip Fraction: 0.30319
Policy Update Magnitude: 0.05378
Value Function Update Magnitude: 0.05877

Collected Steps per Second: 12346.66436
Overall Steps per Second: 10207.11736

Timestep Collection Time: 4.05194
Timestep Consumption Time: 0.84934
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 4.90129

Cumulative Model Updates: 1920
Cumulative Timesteps: 32064944

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03393
Policy Entropy: 0.98661
Value Function Loss: 0.08642

Mean KL Divergence: 0.07374
SB3 Clip Fraction: 0.28636
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.05647

Collected Steps per Second: 12198.69659
Overall Steps per Second: 10150.46753

Timestep Collection Time: 4.10060
Timestep Consumption Time: 0.82745
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 4.92805

Cumulative Model Updates: 1923
Cumulative Timesteps: 32114966

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 32114966...
Checkpoint 32114966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03858
Policy Entropy: 1.02674
Value Function Loss: 0.08288

Mean KL Divergence: 0.05056
SB3 Clip Fraction: 0.25361
Policy Update Magnitude: 0.05080
Value Function Update Magnitude: 0.06288

Collected Steps per Second: 10365.78249
Overall Steps per Second: 8567.27767

Timestep Collection Time: 4.82819
Timestep Consumption Time: 1.01357
PPO Batch Consumption Time: 0.03030
Total Iteration Time: 5.84176

Cumulative Model Updates: 1926
Cumulative Timesteps: 32165014

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01812
Policy Entropy: 1.01705
Value Function Loss: 0.06902

Mean KL Divergence: 0.05343
SB3 Clip Fraction: 0.27209
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.05457

Collected Steps per Second: 9389.28362
Overall Steps per Second: 8062.20218

Timestep Collection Time: 5.32735
Timestep Consumption Time: 0.87691
PPO Batch Consumption Time: 0.02918
Total Iteration Time: 6.20426

Cumulative Model Updates: 1929
Cumulative Timesteps: 32215034

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 32215034...
Checkpoint 32215034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02064
Policy Entropy: 1.02897
Value Function Loss: 0.08266

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.06480

Collected Steps per Second: 10891.48701
Overall Steps per Second: 9221.66298

Timestep Collection Time: 4.59221
Timestep Consumption Time: 0.83154
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 5.42375

Cumulative Model Updates: 1932
Cumulative Timesteps: 32265050

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02867
Policy Entropy: 1.02493
Value Function Loss: 0.06599

Mean KL Divergence: 0.02711
SB3 Clip Fraction: 0.18517
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.07166

Collected Steps per Second: 11607.55692
Overall Steps per Second: 9742.30671

Timestep Collection Time: 4.30823
Timestep Consumption Time: 0.82485
PPO Batch Consumption Time: 0.03052
Total Iteration Time: 5.13308

Cumulative Model Updates: 1935
Cumulative Timesteps: 32315058

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 32315058...
Checkpoint 32315058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02975
Policy Entropy: 1.05838
Value Function Loss: 0.05057

Mean KL Divergence: 0.02949
SB3 Clip Fraction: 0.21149
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.05635

Collected Steps per Second: 12247.17367
Overall Steps per Second: 10075.81063

Timestep Collection Time: 4.08568
Timestep Consumption Time: 0.88047
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 4.96615

Cumulative Model Updates: 1938
Cumulative Timesteps: 32365096

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02690
Policy Entropy: 1.03766
Value Function Loss: 0.03125

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.16866
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.04502

Collected Steps per Second: 10397.20190
Overall Steps per Second: 8582.79694

Timestep Collection Time: 4.81322
Timestep Consumption Time: 1.01752
PPO Batch Consumption Time: 0.02989
Total Iteration Time: 5.83073

Cumulative Model Updates: 1941
Cumulative Timesteps: 32415140

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 32415140...
Checkpoint 32415140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00117
Policy Entropy: 1.02501
Value Function Loss: 0.03922

Mean KL Divergence: 0.03386
SB3 Clip Fraction: 0.17255
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 9839.20613
Overall Steps per Second: 8449.48695

Timestep Collection Time: 5.08435
Timestep Consumption Time: 0.83624
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 5.92060

Cumulative Model Updates: 1944
Cumulative Timesteps: 32465166

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02109
Policy Entropy: 0.99417
Value Function Loss: 0.05619

Mean KL Divergence: 0.05562
SB3 Clip Fraction: 0.27119
Policy Update Magnitude: 0.04607
Value Function Update Magnitude: 0.04402

Collected Steps per Second: 10597.14751
Overall Steps per Second: 8960.60345

Timestep Collection Time: 4.71901
Timestep Consumption Time: 0.86187
PPO Batch Consumption Time: 0.03029
Total Iteration Time: 5.58087

Cumulative Model Updates: 1947
Cumulative Timesteps: 32515174

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 32515174...
Checkpoint 32515174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03675
Policy Entropy: 1.00991
Value Function Loss: 0.07047

Mean KL Divergence: 0.02895
SB3 Clip Fraction: 0.17957
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.05416

Collected Steps per Second: 11804.03989
Overall Steps per Second: 9880.61342

Timestep Collection Time: 4.23618
Timestep Consumption Time: 0.82464
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 5.06082

Cumulative Model Updates: 1950
Cumulative Timesteps: 32565178

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01232
Policy Entropy: 1.02769
Value Function Loss: 0.07564

Mean KL Divergence: 0.03047
SB3 Clip Fraction: 0.21905
Policy Update Magnitude: 0.04291
Value Function Update Magnitude: 0.04967

Collected Steps per Second: 11745.77900
Overall Steps per Second: 9808.53453

Timestep Collection Time: 4.25923
Timestep Consumption Time: 0.84122
PPO Batch Consumption Time: 0.03003
Total Iteration Time: 5.10046

Cumulative Model Updates: 1953
Cumulative Timesteps: 32615206

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 32615206...
Checkpoint 32615206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00155
Policy Entropy: 0.98487
Value Function Loss: 0.07178

Mean KL Divergence: 0.03125
SB3 Clip Fraction: 0.17965
Policy Update Magnitude: 0.04293
Value Function Update Magnitude: 0.04627

Collected Steps per Second: 12126.36029
Overall Steps per Second: 10079.09963

Timestep Collection Time: 4.12737
Timestep Consumption Time: 0.83835
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 4.96572

Cumulative Model Updates: 1956
Cumulative Timesteps: 32665256

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06637
Policy Entropy: 0.99336
Value Function Loss: 0.05418

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.19381
Policy Update Magnitude: 0.04195
Value Function Update Magnitude: 0.04634

Collected Steps per Second: 11970.42789
Overall Steps per Second: 10111.06787

Timestep Collection Time: 4.17830
Timestep Consumption Time: 0.76836
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 4.94666

Cumulative Model Updates: 1959
Cumulative Timesteps: 32715272

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 32715272...
Checkpoint 32715272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01400
Policy Entropy: 1.00636
Value Function Loss: 0.04796

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.05137

Collected Steps per Second: 11852.95529
Overall Steps per Second: 9723.57515

Timestep Collection Time: 4.21920
Timestep Consumption Time: 0.92397
PPO Batch Consumption Time: 0.02996
Total Iteration Time: 5.14317

Cumulative Model Updates: 1962
Cumulative Timesteps: 32765282

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04274
Policy Entropy: 1.01133
Value Function Loss: 0.05654

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.05267

Collected Steps per Second: 11835.50865
Overall Steps per Second: 9975.03035

Timestep Collection Time: 4.22610
Timestep Consumption Time: 0.78822
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 5.01432

Cumulative Model Updates: 1965
Cumulative Timesteps: 32815300

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 32815300...
Checkpoint 32815300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00873
Policy Entropy: 1.02385
Value Function Loss: 0.06101

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.05207
Value Function Update Magnitude: 0.05245

Collected Steps per Second: 12786.29096
Overall Steps per Second: 10609.49179

Timestep Collection Time: 3.91138
Timestep Consumption Time: 0.80252
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 4.71389

Cumulative Model Updates: 1968
Cumulative Timesteps: 32865312

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02716
Policy Entropy: 1.00851
Value Function Loss: 0.06471

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.07318

Collected Steps per Second: 13221.75282
Overall Steps per Second: 10915.62848

Timestep Collection Time: 3.78180
Timestep Consumption Time: 0.79897
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 4.58077

Cumulative Model Updates: 1971
Cumulative Timesteps: 32915314

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 32915314...
Checkpoint 32915314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02294
Policy Entropy: 1.01553
Value Function Loss: 0.04955

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.05863
Value Function Update Magnitude: 0.07400

Collected Steps per Second: 12977.61918
Overall Steps per Second: 10897.86653

Timestep Collection Time: 3.85541
Timestep Consumption Time: 0.73577
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 4.59117

Cumulative Model Updates: 1974
Cumulative Timesteps: 32965348

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04113
Policy Entropy: 0.99755
Value Function Loss: 0.06615

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.17049
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.06884

Collected Steps per Second: 12647.08470
Overall Steps per Second: 10451.51610

Timestep Collection Time: 3.95522
Timestep Consumption Time: 0.83088
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 4.78610

Cumulative Model Updates: 1977
Cumulative Timesteps: 33015370

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 33015370...
Checkpoint 33015370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00196
Policy Entropy: 1.04461
Value Function Loss: 0.06761

Mean KL Divergence: 0.04229
SB3 Clip Fraction: 0.24435
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.06847

Collected Steps per Second: 12624.35324
Overall Steps per Second: 10505.85244

Timestep Collection Time: 3.96060
Timestep Consumption Time: 0.79865
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 4.75925

Cumulative Model Updates: 1980
Cumulative Timesteps: 33065370

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03375
Policy Entropy: 1.01344
Value Function Loss: 0.05774

Mean KL Divergence: 0.03185
SB3 Clip Fraction: 0.22747
Policy Update Magnitude: 0.04660
Value Function Update Magnitude: 0.08863

Collected Steps per Second: 12949.27381
Overall Steps per Second: 10672.04346

Timestep Collection Time: 3.86199
Timestep Consumption Time: 0.82408
PPO Batch Consumption Time: 0.02872
Total Iteration Time: 4.68608

Cumulative Model Updates: 1983
Cumulative Timesteps: 33115380

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 33115380...
Checkpoint 33115380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02173
Policy Entropy: 0.99886
Value Function Loss: 0.03933

Mean KL Divergence: 0.03086
SB3 Clip Fraction: 0.16529
Policy Update Magnitude: 0.04303
Value Function Update Magnitude: 0.08907

Collected Steps per Second: 13133.28150
Overall Steps per Second: 10744.55723

Timestep Collection Time: 3.80971
Timestep Consumption Time: 0.84697
PPO Batch Consumption Time: 0.02907
Total Iteration Time: 4.65668

Cumulative Model Updates: 1986
Cumulative Timesteps: 33165414

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00516
Policy Entropy: 1.00587
Value Function Loss: 0.02744

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15270
Policy Update Magnitude: 0.03933
Value Function Update Magnitude: 0.07727

Collected Steps per Second: 13056.17357
Overall Steps per Second: 11027.00269

Timestep Collection Time: 3.83221
Timestep Consumption Time: 0.70520
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 4.53741

Cumulative Model Updates: 1989
Cumulative Timesteps: 33215448

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 33215448...
Checkpoint 33215448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03019
Policy Entropy: 1.01595
Value Function Loss: 0.02424

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.03945
Value Function Update Magnitude: 0.07012

Collected Steps per Second: 13580.15551
Overall Steps per Second: 11217.62978

Timestep Collection Time: 3.68390
Timestep Consumption Time: 0.77586
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 4.45977

Cumulative Model Updates: 1992
Cumulative Timesteps: 33265476

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01536
Policy Entropy: 1.01706
Value Function Loss: 0.03098

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.03973
Value Function Update Magnitude: 0.06400

Collected Steps per Second: 13796.63632
Overall Steps per Second: 11349.00751

Timestep Collection Time: 3.62755
Timestep Consumption Time: 0.78235
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 4.40990

Cumulative Model Updates: 1995
Cumulative Timesteps: 33315524

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 33315524...
Checkpoint 33315524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00377
Policy Entropy: 1.02830
Value Function Loss: 0.04847

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.04445
Value Function Update Magnitude: 0.08109

Collected Steps per Second: 13382.43645
Overall Steps per Second: 11033.24637

Timestep Collection Time: 3.73923
Timestep Consumption Time: 0.79615
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 4.53538

Cumulative Model Updates: 1998
Cumulative Timesteps: 33365564

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02360
Policy Entropy: 1.02668
Value Function Loss: 0.07771

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.04771
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 13975.91835
Overall Steps per Second: 11436.39373

Timestep Collection Time: 3.57873
Timestep Consumption Time: 0.79468
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 4.37341

Cumulative Model Updates: 2001
Cumulative Timesteps: 33415580

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 33415580...
Checkpoint 33415580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02923
Policy Entropy: 1.02400
Value Function Loss: 0.08241

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.08163

Collected Steps per Second: 13465.24877
Overall Steps per Second: 11297.43028

Timestep Collection Time: 3.71564
Timestep Consumption Time: 0.71298
PPO Batch Consumption Time: 0.02610
Total Iteration Time: 4.42862

Cumulative Model Updates: 2004
Cumulative Timesteps: 33465612

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00255
Policy Entropy: 1.02812
Value Function Loss: 0.06985

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.09126

Collected Steps per Second: 13942.86906
Overall Steps per Second: 11447.54951

Timestep Collection Time: 3.58821
Timestep Consumption Time: 0.78215
PPO Batch Consumption Time: 0.02883
Total Iteration Time: 4.37037

Cumulative Model Updates: 2007
Cumulative Timesteps: 33515642

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 33515642...
Checkpoint 33515642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05280
Policy Entropy: 1.02695
Value Function Loss: 0.05364

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.08984

Collected Steps per Second: 12369.20244
Overall Steps per Second: 10397.70967

Timestep Collection Time: 4.04262
Timestep Consumption Time: 0.76651
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 4.80914

Cumulative Model Updates: 2010
Cumulative Timesteps: 33565646

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00099
Policy Entropy: 1.00813
Value Function Loss: 0.04059

Mean KL Divergence: 0.02840
SB3 Clip Fraction: 0.19569
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.08478

Collected Steps per Second: 13646.73289
Overall Steps per Second: 11294.84512

Timestep Collection Time: 3.66637
Timestep Consumption Time: 0.76344
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 4.42981

Cumulative Model Updates: 2013
Cumulative Timesteps: 33615680

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 33615680...
Checkpoint 33615680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02068
Policy Entropy: 1.05400
Value Function Loss: 0.02303

Mean KL Divergence: 0.03901
SB3 Clip Fraction: 0.22527
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.07906

Collected Steps per Second: 13829.21388
Overall Steps per Second: 11369.53252

Timestep Collection Time: 3.61857
Timestep Consumption Time: 0.78284
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 4.40141

Cumulative Model Updates: 2016
Cumulative Timesteps: 33665722

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02933
Policy Entropy: 1.02432
Value Function Loss: 0.02881

Mean KL Divergence: 0.05311
SB3 Clip Fraction: 0.25303
Policy Update Magnitude: 0.04243
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 13558.30670
Overall Steps per Second: 11263.07638

Timestep Collection Time: 3.69014
Timestep Consumption Time: 0.75199
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 4.44213

Cumulative Model Updates: 2019
Cumulative Timesteps: 33715754

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 33715754...
Checkpoint 33715754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03443
Policy Entropy: 1.02333
Value Function Loss: 0.04631

Mean KL Divergence: 0.07092
SB3 Clip Fraction: 0.28169
Policy Update Magnitude: 0.04180
Value Function Update Magnitude: 0.05957

Collected Steps per Second: 13551.86300
Overall Steps per Second: 11169.58685

Timestep Collection Time: 3.69012
Timestep Consumption Time: 0.78704
PPO Batch Consumption Time: 0.02862
Total Iteration Time: 4.47716

Cumulative Model Updates: 2022
Cumulative Timesteps: 33765762

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03892
Policy Entropy: 1.03512
Value Function Loss: 0.05239

Mean KL Divergence: 0.04812
SB3 Clip Fraction: 0.21425
Policy Update Magnitude: 0.04679
Value Function Update Magnitude: 0.06663

Collected Steps per Second: 13572.70368
Overall Steps per Second: 11284.09985

Timestep Collection Time: 3.68607
Timestep Consumption Time: 0.74760
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 4.43367

Cumulative Model Updates: 2025
Cumulative Timesteps: 33815792

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 33815792...
Checkpoint 33815792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03427
Policy Entropy: 1.04451
Value Function Loss: 0.05676

Mean KL Divergence: 0.04544
SB3 Clip Fraction: 0.23769
Policy Update Magnitude: 0.04398
Value Function Update Magnitude: 0.07717

Collected Steps per Second: 12574.08105
Overall Steps per Second: 10515.89594

Timestep Collection Time: 3.97802
Timestep Consumption Time: 0.77858
PPO Batch Consumption Time: 0.02827
Total Iteration Time: 4.75661

Cumulative Model Updates: 2028
Cumulative Timesteps: 33865812

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02630
Policy Entropy: 1.00536
Value Function Loss: 0.06403

Mean KL Divergence: 0.05667
SB3 Clip Fraction: 0.21275
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.08582

Collected Steps per Second: 12083.98507
Overall Steps per Second: 9587.67757

Timestep Collection Time: 4.13986
Timestep Consumption Time: 1.07788
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 5.21774

Cumulative Model Updates: 2031
Cumulative Timesteps: 33915838

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 33915838...
Checkpoint 33915838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03815
Policy Entropy: 1.05220
Value Function Loss: 0.05455

Mean KL Divergence: 0.04697
SB3 Clip Fraction: 0.24303
Policy Update Magnitude: 0.04442
Value Function Update Magnitude: 0.09341

Collected Steps per Second: 12380.25850
Overall Steps per Second: 10305.93562

Timestep Collection Time: 4.04111
Timestep Consumption Time: 0.81337
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 4.85448

Cumulative Model Updates: 2034
Cumulative Timesteps: 33965868

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02087
Policy Entropy: 1.03115
Value Function Loss: 0.04108

Mean KL Divergence: 0.03703
SB3 Clip Fraction: 0.22661
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.08640

Collected Steps per Second: 12473.35721
Overall Steps per Second: 10342.61398

Timestep Collection Time: 4.00854
Timestep Consumption Time: 0.82582
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 4.83437

Cumulative Model Updates: 2037
Cumulative Timesteps: 34015868

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 34015868...
Checkpoint 34015868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04693
Policy Entropy: 1.02045
Value Function Loss: 0.02526

Mean KL Divergence: 0.03950
SB3 Clip Fraction: 0.18911
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.07247

Collected Steps per Second: 12130.42697
Overall Steps per Second: 10005.73840

Timestep Collection Time: 4.12450
Timestep Consumption Time: 0.87583
PPO Batch Consumption Time: 0.03055
Total Iteration Time: 5.00033

Cumulative Model Updates: 2040
Cumulative Timesteps: 34065900

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01106
Policy Entropy: 0.99174
Value Function Loss: 0.02561

Mean KL Divergence: 0.05259
SB3 Clip Fraction: 0.26017
Policy Update Magnitude: 0.04417
Value Function Update Magnitude: 0.05747

Collected Steps per Second: 11038.19548
Overall Steps per Second: 9318.45543

Timestep Collection Time: 4.53317
Timestep Consumption Time: 0.83661
PPO Batch Consumption Time: 0.02989
Total Iteration Time: 5.36977

Cumulative Model Updates: 2043
Cumulative Timesteps: 34115938

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 34115938...
Checkpoint 34115938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05987
Policy Entropy: 1.02229
Value Function Loss: 0.02655

Mean KL Divergence: 0.02657
SB3 Clip Fraction: 0.17304
Policy Update Magnitude: 0.04008
Value Function Update Magnitude: 0.04872

Collected Steps per Second: 10576.03909
Overall Steps per Second: 8903.23443

Timestep Collection Time: 4.72861
Timestep Consumption Time: 0.88845
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 5.61706

Cumulative Model Updates: 2046
Cumulative Timesteps: 34165948

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05942
Policy Entropy: 1.00839
Value Function Loss: 0.04385

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.06013

Collected Steps per Second: 10893.72516
Overall Steps per Second: 9195.15731

Timestep Collection Time: 4.59108
Timestep Consumption Time: 0.84808
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 5.43917

Cumulative Model Updates: 2049
Cumulative Timesteps: 34215962

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 34215962...
Checkpoint 34215962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01693
Policy Entropy: 1.00334
Value Function Loss: 0.06651

Mean KL Divergence: 0.02263
SB3 Clip Fraction: 0.15968
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.06756

Collected Steps per Second: 11749.12681
Overall Steps per Second: 9671.97576

Timestep Collection Time: 4.25768
Timestep Consumption Time: 0.91438
PPO Batch Consumption Time: 0.02875
Total Iteration Time: 5.17206

Cumulative Model Updates: 2052
Cumulative Timesteps: 34265986

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01069
Policy Entropy: 1.03289
Value Function Loss: 0.07340

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.16284
Policy Update Magnitude: 0.04014
Value Function Update Magnitude: 0.07524

Collected Steps per Second: 11347.24078
Overall Steps per Second: 9452.07636

Timestep Collection Time: 4.40794
Timestep Consumption Time: 0.88380
PPO Batch Consumption Time: 0.02659
Total Iteration Time: 5.29175

Cumulative Model Updates: 2055
Cumulative Timesteps: 34316004

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 34316004...
Checkpoint 34316004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02434
Policy Entropy: 1.02244
Value Function Loss: 0.07121

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.11679
Policy Update Magnitude: 0.04118
Value Function Update Magnitude: 0.08213

Collected Steps per Second: 11475.63134
Overall Steps per Second: 9454.51469

Timestep Collection Time: 4.35863
Timestep Consumption Time: 0.93176
PPO Batch Consumption Time: 0.03328
Total Iteration Time: 5.29038

Cumulative Model Updates: 2058
Cumulative Timesteps: 34366022

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04531
Policy Entropy: 1.03200
Value Function Loss: 0.07197

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.04039
Value Function Update Magnitude: 0.07434

Collected Steps per Second: 11586.87213
Overall Steps per Second: 9623.50741

Timestep Collection Time: 4.31782
Timestep Consumption Time: 0.88091
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 5.19873

Cumulative Model Updates: 2061
Cumulative Timesteps: 34416052

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 34416052...
Checkpoint 34416052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00981
Policy Entropy: 1.02748
Value Function Loss: 0.06574

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.04196
Value Function Update Magnitude: 0.06427

Collected Steps per Second: 11155.60482
Overall Steps per Second: 9297.78299

Timestep Collection Time: 4.48384
Timestep Consumption Time: 0.89593
PPO Batch Consumption Time: 0.03140
Total Iteration Time: 5.37978

Cumulative Model Updates: 2064
Cumulative Timesteps: 34466072

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00430
Policy Entropy: 1.01536
Value Function Loss: 0.07407

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.15194
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.06901

Collected Steps per Second: 11587.78814
Overall Steps per Second: 9842.46433

Timestep Collection Time: 4.31661
Timestep Consumption Time: 0.76545
PPO Batch Consumption Time: 0.03255
Total Iteration Time: 5.08206

Cumulative Model Updates: 2067
Cumulative Timesteps: 34516092

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 34516092...
Checkpoint 34516092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01003
Policy Entropy: 1.02109
Value Function Loss: 0.05424

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.04719
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 11866.74494
Overall Steps per Second: 9741.28207

Timestep Collection Time: 4.21396
Timestep Consumption Time: 0.91945
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 5.13341

Cumulative Model Updates: 2070
Cumulative Timesteps: 34566098

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01688
Policy Entropy: 1.00845
Value Function Loss: 0.06481

Mean KL Divergence: 0.02654
SB3 Clip Fraction: 0.19977
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 11878.76214
Overall Steps per Second: 9886.54146

Timestep Collection Time: 4.21138
Timestep Consumption Time: 0.84863
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 5.06001

Cumulative Model Updates: 2073
Cumulative Timesteps: 34616124

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 34616124...
Checkpoint 34616124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05463
Policy Entropy: 1.05490
Value Function Loss: 0.04170

Mean KL Divergence: 0.02816
SB3 Clip Fraction: 0.20067
Policy Update Magnitude: 0.04262
Value Function Update Magnitude: 0.06631

Collected Steps per Second: 11993.98794
Overall Steps per Second: 9933.32079

Timestep Collection Time: 4.17242
Timestep Consumption Time: 0.86557
PPO Batch Consumption Time: 0.02894
Total Iteration Time: 5.03799

Cumulative Model Updates: 2076
Cumulative Timesteps: 34666168

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00870
Policy Entropy: 1.03378
Value Function Loss: 0.06760

Mean KL Divergence: 0.03194
SB3 Clip Fraction: 0.21546
Policy Update Magnitude: 0.04092
Value Function Update Magnitude: 0.06130

Collected Steps per Second: 11609.58588
Overall Steps per Second: 9568.89666

Timestep Collection Time: 4.30989
Timestep Consumption Time: 0.91914
PPO Batch Consumption Time: 0.02921
Total Iteration Time: 5.22903

Cumulative Model Updates: 2079
Cumulative Timesteps: 34716204

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 34716204...
Checkpoint 34716204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00821
Policy Entropy: 1.03843
Value Function Loss: 0.05755

Mean KL Divergence: 0.02967
SB3 Clip Fraction: 0.19445
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.06836

Collected Steps per Second: 11276.93023
Overall Steps per Second: 9501.20641

Timestep Collection Time: 4.43507
Timestep Consumption Time: 0.82889
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 5.26396

Cumulative Model Updates: 2082
Cumulative Timesteps: 34766218

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00984
Policy Entropy: 1.03679
Value Function Loss: 0.05445

Mean KL Divergence: 0.02701
SB3 Clip Fraction: 0.20313
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.06939

Collected Steps per Second: 11932.77654
Overall Steps per Second: 9892.29152

Timestep Collection Time: 4.19232
Timestep Consumption Time: 0.86475
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 5.05707

Cumulative Model Updates: 2085
Cumulative Timesteps: 34816244

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 34816244...
Checkpoint 34816244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00300
Policy Entropy: 1.05285
Value Function Loss: 0.04197

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 11605.82728
Overall Steps per Second: 9801.72444

Timestep Collection Time: 4.31059
Timestep Consumption Time: 0.79341
PPO Batch Consumption Time: 0.02765
Total Iteration Time: 5.10400

Cumulative Model Updates: 2088
Cumulative Timesteps: 34866272

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01199
Policy Entropy: 1.05628
Value Function Loss: 0.03030

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.06640

Collected Steps per Second: 13565.77346
Overall Steps per Second: 11295.28345

Timestep Collection Time: 3.68619
Timestep Consumption Time: 0.74097
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 4.42716

Cumulative Model Updates: 2091
Cumulative Timesteps: 34916278

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 34916278...
Checkpoint 34916278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00431
Policy Entropy: 1.05025
Value Function Loss: 0.04913

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.04261
Value Function Update Magnitude: 0.06803

Collected Steps per Second: 13009.08152
Overall Steps per Second: 10776.87288

Timestep Collection Time: 3.84378
Timestep Consumption Time: 0.79616
PPO Batch Consumption Time: 0.02860
Total Iteration Time: 4.63994

Cumulative Model Updates: 2094
Cumulative Timesteps: 34966282

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02584
Policy Entropy: 1.04805
Value Function Loss: 0.04644

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.04247
Value Function Update Magnitude: 0.06615

Collected Steps per Second: 13357.97747
Overall Steps per Second: 11056.73592

Timestep Collection Time: 3.74653
Timestep Consumption Time: 0.77977
PPO Batch Consumption Time: 0.02852
Total Iteration Time: 4.52629

Cumulative Model Updates: 2097
Cumulative Timesteps: 35016328

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 35016328...
Checkpoint 35016328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00823
Policy Entropy: 1.03924
Value Function Loss: 0.06108

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.17591
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.07326

Collected Steps per Second: 14104.62563
Overall Steps per Second: 11597.85514

Timestep Collection Time: 3.54508
Timestep Consumption Time: 0.76624
PPO Batch Consumption Time: 0.02660
Total Iteration Time: 4.31131

Cumulative Model Updates: 2100
Cumulative Timesteps: 35066330

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01357
Policy Entropy: 1.08695
Value Function Loss: 0.04114

Mean KL Divergence: 0.03602
SB3 Clip Fraction: 0.22303
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.07518

Collected Steps per Second: 13724.13365
Overall Steps per Second: 11292.47883

Timestep Collection Time: 3.64526
Timestep Consumption Time: 0.78495
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 4.43021

Cumulative Model Updates: 2103
Cumulative Timesteps: 35116358

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 35116358...
Checkpoint 35116358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01179
Policy Entropy: 1.04961
Value Function Loss: 0.04382

Mean KL Divergence: 0.05012
SB3 Clip Fraction: 0.23603
Policy Update Magnitude: 0.04079
Value Function Update Magnitude: 0.07520

Collected Steps per Second: 13875.91713
Overall Steps per Second: 11634.08938

Timestep Collection Time: 3.60610
Timestep Consumption Time: 0.69488
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 4.30098

Cumulative Model Updates: 2106
Cumulative Timesteps: 35166396

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02504
Policy Entropy: 1.06070
Value Function Loss: 0.03952

Mean KL Divergence: 0.03719
SB3 Clip Fraction: 0.22193
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.08074

Collected Steps per Second: 13279.08623
Overall Steps per Second: 10960.10679

Timestep Collection Time: 3.76547
Timestep Consumption Time: 0.79671
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 4.56218

Cumulative Model Updates: 2109
Cumulative Timesteps: 35216398

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 35216398...
Checkpoint 35216398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00915
Policy Entropy: 1.05544
Value Function Loss: 0.04228

Mean KL Divergence: 0.03166
SB3 Clip Fraction: 0.20691
Policy Update Magnitude: 0.04680
Value Function Update Magnitude: 0.09122

Collected Steps per Second: 13258.67896
Overall Steps per Second: 11035.70594

Timestep Collection Time: 3.77172
Timestep Consumption Time: 0.75975
PPO Batch Consumption Time: 0.02506
Total Iteration Time: 4.53147

Cumulative Model Updates: 2112
Cumulative Timesteps: 35266406

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03253
Policy Entropy: 1.06756
Value Function Loss: 0.05192

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.10028

Collected Steps per Second: 13483.01040
Overall Steps per Second: 11138.84166

Timestep Collection Time: 3.71000
Timestep Consumption Time: 0.78077
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 4.49077

Cumulative Model Updates: 2115
Cumulative Timesteps: 35316428

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 35316428...
Checkpoint 35316428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02423
Policy Entropy: 1.07261
Value Function Loss: 0.05263

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.04237
Value Function Update Magnitude: 0.10296

Collected Steps per Second: 13755.23663
Overall Steps per Second: 11382.31547

Timestep Collection Time: 3.63687
Timestep Consumption Time: 0.75819
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 4.39506

Cumulative Model Updates: 2118
Cumulative Timesteps: 35366454

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02814
Policy Entropy: 1.06352
Value Function Loss: 0.05210

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.04145
Value Function Update Magnitude: 0.10637

Collected Steps per Second: 13713.67522
Overall Steps per Second: 11493.04756

Timestep Collection Time: 3.64716
Timestep Consumption Time: 0.70469
PPO Batch Consumption Time: 0.02483
Total Iteration Time: 4.35185

Cumulative Model Updates: 2121
Cumulative Timesteps: 35416470

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 35416470...
Checkpoint 35416470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01977
Policy Entropy: 1.03612
Value Function Loss: 0.04872

Mean KL Divergence: 0.03307
SB3 Clip Fraction: 0.18330
Policy Update Magnitude: 0.04052
Value Function Update Magnitude: 0.10661

Collected Steps per Second: 13478.17174
Overall Steps per Second: 11175.48903

Timestep Collection Time: 3.70985
Timestep Consumption Time: 0.76441
PPO Batch Consumption Time: 0.02491
Total Iteration Time: 4.47426

Cumulative Model Updates: 2124
Cumulative Timesteps: 35466472

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01335
Policy Entropy: 1.05540
Value Function Loss: 0.03481

Mean KL Divergence: 0.03750
SB3 Clip Fraction: 0.21820
Policy Update Magnitude: 0.03979
Value Function Update Magnitude: 0.10520

Collected Steps per Second: 13016.22816
Overall Steps per Second: 10793.17790

Timestep Collection Time: 3.84290
Timestep Consumption Time: 0.79151
PPO Batch Consumption Time: 0.02546
Total Iteration Time: 4.63441

Cumulative Model Updates: 2127
Cumulative Timesteps: 35516492

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 35516492...
Checkpoint 35516492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02966
Policy Entropy: 1.05617
Value Function Loss: 0.03294

Mean KL Divergence: 0.04413
SB3 Clip Fraction: 0.23408
Policy Update Magnitude: 0.03612
Value Function Update Magnitude: 0.09844

Collected Steps per Second: 13787.98950
Overall Steps per Second: 11272.59837

Timestep Collection Time: 3.62692
Timestep Consumption Time: 0.80932
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 4.43624

Cumulative Model Updates: 2130
Cumulative Timesteps: 35566500

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03085
Policy Entropy: 1.04531
Value Function Loss: 0.01831

Mean KL Divergence: 0.03153
SB3 Clip Fraction: 0.18714
Policy Update Magnitude: 0.03491
Value Function Update Magnitude: 0.08145

Collected Steps per Second: 13726.24607
Overall Steps per Second: 11323.77979

Timestep Collection Time: 3.64557
Timestep Consumption Time: 0.77345
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 4.41902

Cumulative Model Updates: 2133
Cumulative Timesteps: 35616540

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 35616540...
Checkpoint 35616540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04426
Policy Entropy: 1.05730
Value Function Loss: 0.02424

Mean KL Divergence: 0.02860
SB3 Clip Fraction: 0.19273
Policy Update Magnitude: 0.03327
Value Function Update Magnitude: 0.07413

Collected Steps per Second: 13473.93870
Overall Steps per Second: 11274.30925

Timestep Collection Time: 3.71265
Timestep Consumption Time: 0.72434
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 4.43699

Cumulative Model Updates: 2136
Cumulative Timesteps: 35666564

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00678
Policy Entropy: 1.07498
Value Function Loss: 0.02183

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.03153
Value Function Update Magnitude: 0.07159

Collected Steps per Second: 13902.24113
Overall Steps per Second: 11362.71035

Timestep Collection Time: 3.59870
Timestep Consumption Time: 0.80430
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 4.40300

Cumulative Model Updates: 2139
Cumulative Timesteps: 35716594

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 35716594...
Checkpoint 35716594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00011
Policy Entropy: 1.07460
Value Function Loss: 0.02905

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.03353
Value Function Update Magnitude: 0.07254

Collected Steps per Second: 13175.80482
Overall Steps per Second: 10925.88022

Timestep Collection Time: 3.79635
Timestep Consumption Time: 0.78177
PPO Batch Consumption Time: 0.02599
Total Iteration Time: 4.57812

Cumulative Model Updates: 2142
Cumulative Timesteps: 35766614

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00581
Policy Entropy: 1.06822
Value Function Loss: 0.04342

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.03741
Value Function Update Magnitude: 0.07334

Collected Steps per Second: 13252.81832
Overall Steps per Second: 10958.41540

Timestep Collection Time: 3.77399
Timestep Consumption Time: 0.79017
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 4.56416

Cumulative Model Updates: 2145
Cumulative Timesteps: 35816630

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 35816630...
Checkpoint 35816630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00148
Policy Entropy: 1.04353
Value Function Loss: 0.04995

Mean KL Divergence: 0.03657
SB3 Clip Fraction: 0.22506
Policy Update Magnitude: 0.04032
Value Function Update Magnitude: 0.07159

Collected Steps per Second: 13624.83293
Overall Steps per Second: 11211.72882

Timestep Collection Time: 3.67212
Timestep Consumption Time: 0.79035
PPO Batch Consumption Time: 0.02563
Total Iteration Time: 4.46247

Cumulative Model Updates: 2148
Cumulative Timesteps: 35866662

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01448
Policy Entropy: 1.06652
Value Function Loss: 0.05681

Mean KL Divergence: 0.02646
SB3 Clip Fraction: 0.16694
Policy Update Magnitude: 0.03997
Value Function Update Magnitude: 0.06951

Collected Steps per Second: 13861.75942
Overall Steps per Second: 11554.68861

Timestep Collection Time: 3.61036
Timestep Consumption Time: 0.72086
PPO Batch Consumption Time: 0.02904
Total Iteration Time: 4.33123

Cumulative Model Updates: 2151
Cumulative Timesteps: 35916708

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 35916708...
Checkpoint 35916708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03855
Policy Entropy: 1.08650
Value Function Loss: 0.05585

Mean KL Divergence: 0.03772
SB3 Clip Fraction: 0.22285
Policy Update Magnitude: 0.03918
Value Function Update Magnitude: 0.06096

Collected Steps per Second: 12690.95340
Overall Steps per Second: 10558.11834

Timestep Collection Time: 3.94092
Timestep Consumption Time: 0.79610
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 4.73702

Cumulative Model Updates: 2154
Cumulative Timesteps: 35966722

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01953
Policy Entropy: 1.01550
Value Function Loss: 0.05725

Mean KL Divergence: 0.14063
SB3 Clip Fraction: 0.33338
Policy Update Magnitude: 0.04055
Value Function Update Magnitude: 0.05431

Collected Steps per Second: 13239.55567
Overall Steps per Second: 10699.38074

Timestep Collection Time: 3.77732
Timestep Consumption Time: 0.89679
PPO Batch Consumption Time: 0.03220
Total Iteration Time: 4.67410

Cumulative Model Updates: 2157
Cumulative Timesteps: 36016732

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 36016732...
Checkpoint 36016732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01853
Policy Entropy: 1.08103
Value Function Loss: 0.07893

Mean KL Divergence: 0.06920
SB3 Clip Fraction: 0.29402
Policy Update Magnitude: 0.03903
Value Function Update Magnitude: 0.05196

Collected Steps per Second: 13182.67843
Overall Steps per Second: 10901.35102

Timestep Collection Time: 3.79452
Timestep Consumption Time: 0.79408
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 4.58861

Cumulative Model Updates: 2160
Cumulative Timesteps: 36066754

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00826
Policy Entropy: 1.00758
Value Function Loss: 0.06614

Mean KL Divergence: 0.14671
SB3 Clip Fraction: 0.35367
Policy Update Magnitude: 0.03982
Value Function Update Magnitude: 0.06351

Collected Steps per Second: 13368.80459
Overall Steps per Second: 11010.80467

Timestep Collection Time: 3.74259
Timestep Consumption Time: 0.80149
PPO Batch Consumption Time: 0.02537
Total Iteration Time: 4.54408

Cumulative Model Updates: 2163
Cumulative Timesteps: 36116788

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 36116788...
Checkpoint 36116788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00060
Policy Entropy: 1.03581
Value Function Loss: 0.07704

Mean KL Divergence: 0.07430
SB3 Clip Fraction: 0.27147
Policy Update Magnitude: 0.04156
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 13246.10818
Overall Steps per Second: 11167.72292

Timestep Collection Time: 3.77771
Timestep Consumption Time: 0.70306
PPO Batch Consumption Time: 0.02523
Total Iteration Time: 4.48077

Cumulative Model Updates: 2166
Cumulative Timesteps: 36166828

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01497
Policy Entropy: 0.98958
Value Function Loss: 0.05867

Mean KL Divergence: 0.11363
SB3 Clip Fraction: 0.32148
Policy Update Magnitude: 0.03829
Value Function Update Magnitude: 0.06511

Collected Steps per Second: 13599.98681
Overall Steps per Second: 11221.11102

Timestep Collection Time: 3.68000
Timestep Consumption Time: 0.78016
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 4.46016

Cumulative Model Updates: 2169
Cumulative Timesteps: 36216876

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 36216876...
Checkpoint 36216876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01802
Policy Entropy: 1.02283
Value Function Loss: 0.06892

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.17066
Policy Update Magnitude: 0.03852
Value Function Update Magnitude: 0.06888

Collected Steps per Second: 12387.37563
Overall Steps per Second: 10285.28018

Timestep Collection Time: 4.03944
Timestep Consumption Time: 0.82558
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 4.86501

Cumulative Model Updates: 2172
Cumulative Timesteps: 36266914

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00463
Policy Entropy: 1.00761
Value Function Loss: 0.04858

Mean KL Divergence: 0.05014
SB3 Clip Fraction: 0.24763
Policy Update Magnitude: 0.04139
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 12936.39165
Overall Steps per Second: 10659.47005

Timestep Collection Time: 3.86738
Timestep Consumption Time: 0.82609
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 4.69348

Cumulative Model Updates: 2175
Cumulative Timesteps: 36316944

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 36316944...
Checkpoint 36316944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00207
Policy Entropy: 1.01565
Value Function Loss: 0.04718

Mean KL Divergence: 0.05083
SB3 Clip Fraction: 0.25109
Policy Update Magnitude: 0.03862
Value Function Update Magnitude: 0.05777

Collected Steps per Second: 13050.91033
Overall Steps per Second: 10758.89133

Timestep Collection Time: 3.83146
Timestep Consumption Time: 0.81623
PPO Batch Consumption Time: 0.02866
Total Iteration Time: 4.64769

Cumulative Model Updates: 2178
Cumulative Timesteps: 36366948

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00030
Policy Entropy: 1.03897
Value Function Loss: 0.07238

Mean KL Divergence: 0.03411
SB3 Clip Fraction: 0.19949
Policy Update Magnitude: 0.04322
Value Function Update Magnitude: 0.05821

Collected Steps per Second: 13343.67777
Overall Steps per Second: 11119.06351

Timestep Collection Time: 3.74859
Timestep Consumption Time: 0.74999
PPO Batch Consumption Time: 0.03274
Total Iteration Time: 4.49858

Cumulative Model Updates: 2181
Cumulative Timesteps: 36416968

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 36416968...
Checkpoint 36416968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02501
Policy Entropy: 1.03572
Value Function Loss: 0.06648

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.04720
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 13115.66744
Overall Steps per Second: 10690.05929

Timestep Collection Time: 3.81345
Timestep Consumption Time: 0.86528
PPO Batch Consumption Time: 0.02910
Total Iteration Time: 4.67874

Cumulative Model Updates: 2184
Cumulative Timesteps: 36466984

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04594
Policy Entropy: 1.01928
Value Function Loss: 0.07911

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.15344
Policy Update Magnitude: 0.05028
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 12809.61834
Overall Steps per Second: 10658.50640

Timestep Collection Time: 3.90613
Timestep Consumption Time: 0.78834
PPO Batch Consumption Time: 0.02670
Total Iteration Time: 4.69447

Cumulative Model Updates: 2187
Cumulative Timesteps: 36517020

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 36517020...
Checkpoint 36517020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05394
Policy Entropy: 0.97592
Value Function Loss: 0.05662

Mean KL Divergence: 0.09277
SB3 Clip Fraction: 0.32390
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.06960

Collected Steps per Second: 13064.60870
Overall Steps per Second: 10783.91356

Timestep Collection Time: 3.82759
Timestep Consumption Time: 0.80950
PPO Batch Consumption Time: 0.02651
Total Iteration Time: 4.63709

Cumulative Model Updates: 2190
Cumulative Timesteps: 36567026

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01965
Policy Entropy: 1.05281
Value Function Loss: 0.06164

Mean KL Divergence: 0.09298
SB3 Clip Fraction: 0.33531
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 13019.88989
Overall Steps per Second: 10836.00973

Timestep Collection Time: 3.84120
Timestep Consumption Time: 0.77415
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 4.61535

Cumulative Model Updates: 2193
Cumulative Timesteps: 36617038

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 36617038...
Checkpoint 36617038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03137
Policy Entropy: 1.00417
Value Function Loss: 0.03524

Mean KL Divergence: 0.08838
SB3 Clip Fraction: 0.29947
Policy Update Magnitude: 0.04083
Value Function Update Magnitude: 0.06038

Collected Steps per Second: 13307.49034
Overall Steps per Second: 11153.38853

Timestep Collection Time: 3.75743
Timestep Consumption Time: 0.72569
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 4.48312

Cumulative Model Updates: 2196
Cumulative Timesteps: 36667040

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05000
Policy Entropy: 1.01034
Value Function Loss: 0.03429

Mean KL Divergence: 0.03871
SB3 Clip Fraction: 0.21338
Policy Update Magnitude: 0.03732
Value Function Update Magnitude: 0.06057

Collected Steps per Second: 11909.39066
Overall Steps per Second: 9991.38993

Timestep Collection Time: 4.20122
Timestep Consumption Time: 0.80649
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 5.00771

Cumulative Model Updates: 2199
Cumulative Timesteps: 36717074

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 36717074...
Checkpoint 36717074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01017
Policy Entropy: 1.00635
Value Function Loss: 0.03599

Mean KL Divergence: 0.05905
SB3 Clip Fraction: 0.23195
Policy Update Magnitude: 0.03787
Value Function Update Magnitude: 0.05487

Collected Steps per Second: 13301.02807
Overall Steps per Second: 10979.86620

Timestep Collection Time: 3.76121
Timestep Consumption Time: 0.79513
PPO Batch Consumption Time: 0.03032
Total Iteration Time: 4.55634

Cumulative Model Updates: 2202
Cumulative Timesteps: 36767102

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02495
Policy Entropy: 0.96895
Value Function Loss: 0.07164

Mean KL Divergence: 0.04880
SB3 Clip Fraction: 0.25656
Policy Update Magnitude: 0.04132
Value Function Update Magnitude: 0.06202

Collected Steps per Second: 13235.90485
Overall Steps per Second: 10885.62072

Timestep Collection Time: 3.77760
Timestep Consumption Time: 0.81561
PPO Batch Consumption Time: 0.02961
Total Iteration Time: 4.59322

Cumulative Model Updates: 2205
Cumulative Timesteps: 36817102

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 36817102...
Checkpoint 36817102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01438
Policy Entropy: 0.99976
Value Function Loss: 0.06770

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.04351
Value Function Update Magnitude: 0.07645

Collected Steps per Second: 12590.54681
Overall Steps per Second: 10480.60831

Timestep Collection Time: 3.97123
Timestep Consumption Time: 0.79948
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 4.77072

Cumulative Model Updates: 2208
Cumulative Timesteps: 36867102

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00120
Policy Entropy: 0.98679
Value Function Loss: 0.08303

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.08052

Collected Steps per Second: 12700.38045
Overall Steps per Second: 10576.97261

Timestep Collection Time: 3.93799
Timestep Consumption Time: 0.79058
PPO Batch Consumption Time: 0.02557
Total Iteration Time: 4.72857

Cumulative Model Updates: 2211
Cumulative Timesteps: 36917116

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 36917116...
Checkpoint 36917116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07108
Policy Entropy: 0.98421
Value Function Loss: 0.06158

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12031
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.06926

Collected Steps per Second: 13580.76611
Overall Steps per Second: 11160.24423

Timestep Collection Time: 3.68448
Timestep Consumption Time: 0.79912
PPO Batch Consumption Time: 0.02695
Total Iteration Time: 4.48359

Cumulative Model Updates: 2214
Cumulative Timesteps: 36967154

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05743
Policy Entropy: 0.98110
Value Function Loss: 0.07442

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.06874

Collected Steps per Second: 13065.03986
Overall Steps per Second: 10683.25386

Timestep Collection Time: 3.82838
Timestep Consumption Time: 0.85352
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 4.68191

Cumulative Model Updates: 2217
Cumulative Timesteps: 37017172

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 37017172...
Checkpoint 37017172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03881
Policy Entropy: 0.99119
Value Function Loss: 0.05485

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.04208
Value Function Update Magnitude: 0.06696

Collected Steps per Second: 13204.81946
Overall Steps per Second: 11038.43381

Timestep Collection Time: 3.79059
Timestep Consumption Time: 0.74393
PPO Batch Consumption Time: 0.02933
Total Iteration Time: 4.53452

Cumulative Model Updates: 2220
Cumulative Timesteps: 37067226

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02731
Policy Entropy: 0.95880
Value Function Loss: 0.07006

Mean KL Divergence: 0.04349
SB3 Clip Fraction: 0.24918
Policy Update Magnitude: 0.04246
Value Function Update Magnitude: 0.07625

Collected Steps per Second: 12985.51723
Overall Steps per Second: 10740.11250

Timestep Collection Time: 3.85291
Timestep Consumption Time: 0.80552
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 4.65842

Cumulative Model Updates: 2223
Cumulative Timesteps: 37117258

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 37117258...
Checkpoint 37117258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02902
Policy Entropy: 1.00229
Value Function Loss: 0.05488

Mean KL Divergence: 0.02428
SB3 Clip Fraction: 0.17779
Policy Update Magnitude: 0.03710
Value Function Update Magnitude: 0.07630

Collected Steps per Second: 12879.15752
Overall Steps per Second: 10675.66096

Timestep Collection Time: 3.88442
Timestep Consumption Time: 0.80176
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 4.68617

Cumulative Model Updates: 2226
Cumulative Timesteps: 37167286

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05112
Policy Entropy: 1.00256
Value Function Loss: 0.04561

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.04305
Value Function Update Magnitude: 0.06656

Collected Steps per Second: 12383.00916
Overall Steps per Second: 10324.60121

Timestep Collection Time: 4.03973
Timestep Consumption Time: 0.80540
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 4.84513

Cumulative Model Updates: 2229
Cumulative Timesteps: 37217310

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 37217310...
Checkpoint 37217310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00862
Policy Entropy: 1.00816
Value Function Loss: 0.04471

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.06843

Collected Steps per Second: 12179.81434
Overall Steps per Second: 10107.41807

Timestep Collection Time: 4.10844
Timestep Consumption Time: 0.84238
PPO Batch Consumption Time: 0.03094
Total Iteration Time: 4.95082

Cumulative Model Updates: 2232
Cumulative Timesteps: 37267350

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02681
Policy Entropy: 0.98722
Value Function Loss: 0.03908

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.15644
Policy Update Magnitude: 0.04171
Value Function Update Magnitude: 0.06227

Collected Steps per Second: 12275.55259
Overall Steps per Second: 10319.12273

Timestep Collection Time: 4.07428
Timestep Consumption Time: 0.77245
PPO Batch Consumption Time: 0.02959
Total Iteration Time: 4.84673

Cumulative Model Updates: 2235
Cumulative Timesteps: 37317364

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 37317364...
Checkpoint 37317364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00136
Policy Entropy: 0.99105
Value Function Loss: 0.05649

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.17107
Policy Update Magnitude: 0.03939
Value Function Update Magnitude: 0.06786

Collected Steps per Second: 12768.56089
Overall Steps per Second: 10571.73857

Timestep Collection Time: 3.91884
Timestep Consumption Time: 0.81434
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 4.73319

Cumulative Model Updates: 2238
Cumulative Timesteps: 37367402

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01913
Policy Entropy: 1.02597
Value Function Loss: 0.06429

Mean KL Divergence: 0.03826
SB3 Clip Fraction: 0.22486
Policy Update Magnitude: 0.04001
Value Function Update Magnitude: 0.05222

Collected Steps per Second: 12890.55850
Overall Steps per Second: 10701.09040

Timestep Collection Time: 3.88207
Timestep Consumption Time: 0.79428
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 4.67635

Cumulative Model Updates: 2241
Cumulative Timesteps: 37417444

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 37417444...
Checkpoint 37417444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12876
Policy Entropy: 1.02318
Value Function Loss: 0.07611

Mean KL Divergence: 0.04008
SB3 Clip Fraction: 0.23357
Policy Update Magnitude: 0.04010
Value Function Update Magnitude: 0.06984

Collected Steps per Second: 12998.82049
Overall Steps per Second: 10781.27737

Timestep Collection Time: 3.84866
Timestep Consumption Time: 0.79161
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 4.64027

Cumulative Model Updates: 2244
Cumulative Timesteps: 37467472

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01996
Policy Entropy: 1.00580
Value Function Loss: 0.08258

Mean KL Divergence: 0.04045
SB3 Clip Fraction: 0.19488
Policy Update Magnitude: 0.04768
Value Function Update Magnitude: 0.08112

Collected Steps per Second: 13187.35322
Overall Steps per Second: 10862.38257

Timestep Collection Time: 3.79242
Timestep Consumption Time: 0.81173
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 4.60415

Cumulative Model Updates: 2247
Cumulative Timesteps: 37517484

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 37517484...
Checkpoint 37517484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02306
Policy Entropy: 0.99619
Value Function Loss: 0.06130

Mean KL Divergence: 0.03951
SB3 Clip Fraction: 0.22933
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.08000

Collected Steps per Second: 12905.36619
Overall Steps per Second: 10660.82674

Timestep Collection Time: 3.87730
Timestep Consumption Time: 0.81633
PPO Batch Consumption Time: 0.02996
Total Iteration Time: 4.69363

Cumulative Model Updates: 2250
Cumulative Timesteps: 37567522

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01098
Policy Entropy: 1.02735
Value Function Loss: 0.04972

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.16205
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.07259

Collected Steps per Second: 13303.42301
Overall Steps per Second: 10934.86491

Timestep Collection Time: 3.76114
Timestep Consumption Time: 0.81469
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 4.57582

Cumulative Model Updates: 2253
Cumulative Timesteps: 37617558

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 37617558...
Checkpoint 37617558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04766
Policy Entropy: 1.03338
Value Function Loss: 0.04180

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.16517
Policy Update Magnitude: 0.04315
Value Function Update Magnitude: 0.06708

Collected Steps per Second: 12997.69773
Overall Steps per Second: 10814.55475

Timestep Collection Time: 3.84914
Timestep Consumption Time: 0.77703
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 4.62617

Cumulative Model Updates: 2256
Cumulative Timesteps: 37667588

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00387
Policy Entropy: 1.00393
Value Function Loss: 0.04582

Mean KL Divergence: 0.03451
SB3 Clip Fraction: 0.19441
Policy Update Magnitude: 0.04567
Value Function Update Magnitude: 0.06366

Collected Steps per Second: 13036.33198
Overall Steps per Second: 10947.96149

Timestep Collection Time: 3.83881
Timestep Consumption Time: 0.73227
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 4.57108

Cumulative Model Updates: 2259
Cumulative Timesteps: 37717632

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 37717632...
Checkpoint 37717632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08460
Policy Entropy: 1.05199
Value Function Loss: 0.06661

Mean KL Divergence: 0.04618
SB3 Clip Fraction: 0.22891
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.06796

Collected Steps per Second: 13070.53690
Overall Steps per Second: 10776.46353

Timestep Collection Time: 3.82815
Timestep Consumption Time: 0.81493
PPO Batch Consumption Time: 0.02685
Total Iteration Time: 4.64308

Cumulative Model Updates: 2262
Cumulative Timesteps: 37767668

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01349
Policy Entropy: 1.01213
Value Function Loss: 0.05155

Mean KL Divergence: 0.06747
SB3 Clip Fraction: 0.25100
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 12610.55064
Overall Steps per Second: 10522.98637

Timestep Collection Time: 3.96604
Timestep Consumption Time: 0.78679
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 4.75283

Cumulative Model Updates: 2265
Cumulative Timesteps: 37817682

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 37817682...
Checkpoint 37817682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00862
Policy Entropy: 1.05517
Value Function Loss: 0.05525

Mean KL Divergence: 0.05216
SB3 Clip Fraction: 0.25199
Policy Update Magnitude: 0.04302
Value Function Update Magnitude: 0.08291

Collected Steps per Second: 12894.99793
Overall Steps per Second: 10660.31384

Timestep Collection Time: 3.88042
Timestep Consumption Time: 0.81344
PPO Batch Consumption Time: 0.02728
Total Iteration Time: 4.69386

Cumulative Model Updates: 2268
Cumulative Timesteps: 37867720

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00246
Policy Entropy: 1.05310
Value Function Loss: 0.04119

Mean KL Divergence: 0.05213
SB3 Clip Fraction: 0.22425
Policy Update Magnitude: 0.04229
Value Function Update Magnitude: 0.09024

Collected Steps per Second: 13152.54588
Overall Steps per Second: 10834.09479

Timestep Collection Time: 3.80170
Timestep Consumption Time: 0.81355
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 4.61524

Cumulative Model Updates: 2271
Cumulative Timesteps: 37917722

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 37917722...
Checkpoint 37917722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01732
Policy Entropy: 1.04136
Value Function Loss: 0.05230

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.04538
Value Function Update Magnitude: 0.09974

Collected Steps per Second: 12680.46186
Overall Steps per Second: 10696.83371

Timestep Collection Time: 3.94434
Timestep Consumption Time: 0.73144
PPO Batch Consumption Time: 0.02815
Total Iteration Time: 4.67578

Cumulative Model Updates: 2274
Cumulative Timesteps: 37967738

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06198
Policy Entropy: 1.04222
Value Function Loss: 0.05475

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.09798

Collected Steps per Second: 13116.68028
Overall Steps per Second: 10832.52180

Timestep Collection Time: 3.81316
Timestep Consumption Time: 0.80405
PPO Batch Consumption Time: 0.02942
Total Iteration Time: 4.61721

Cumulative Model Updates: 2277
Cumulative Timesteps: 38017754

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 38017754...
Checkpoint 38017754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05819
Policy Entropy: 1.04441
Value Function Loss: 0.04454

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.04558
Value Function Update Magnitude: 0.09699

Collected Steps per Second: 12948.65081
Overall Steps per Second: 10730.10866

Timestep Collection Time: 3.86419
Timestep Consumption Time: 0.79895
PPO Batch Consumption Time: 0.02878
Total Iteration Time: 4.66314

Cumulative Model Updates: 2280
Cumulative Timesteps: 38067790

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05105
Policy Entropy: 1.04587
Value Function Loss: 0.02795

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.04233
Value Function Update Magnitude: 0.10041

Collected Steps per Second: 12853.33754
Overall Steps per Second: 10640.47459

Timestep Collection Time: 3.89222
Timestep Consumption Time: 0.80945
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.70167

Cumulative Model Updates: 2283
Cumulative Timesteps: 38117818

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 38117818...
Checkpoint 38117818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05362
Policy Entropy: 1.03746
Value Function Loss: 0.03831

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.04443
Value Function Update Magnitude: 0.09954

Collected Steps per Second: 13040.42153
Overall Steps per Second: 10752.27031

Timestep Collection Time: 3.83638
Timestep Consumption Time: 0.81641
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 4.65278

Cumulative Model Updates: 2286
Cumulative Timesteps: 38167846

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06162
Policy Entropy: 1.03545
Value Function Loss: 0.04037

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.04397
Value Function Update Magnitude: 0.10782

Collected Steps per Second: 12920.05311
Overall Steps per Second: 10624.45601

Timestep Collection Time: 3.86995
Timestep Consumption Time: 0.83617
PPO Batch Consumption Time: 0.02866
Total Iteration Time: 4.70612

Cumulative Model Updates: 2289
Cumulative Timesteps: 38217846

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 38217846...
Checkpoint 38217846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09595
Policy Entropy: 1.02023
Value Function Loss: 0.06034

Mean KL Divergence: 0.02820
SB3 Clip Fraction: 0.18720
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.10166

Collected Steps per Second: 12773.74901
Overall Steps per Second: 10563.51041

Timestep Collection Time: 3.91506
Timestep Consumption Time: 0.81916
PPO Batch Consumption Time: 0.02832
Total Iteration Time: 4.73422

Cumulative Model Updates: 2292
Cumulative Timesteps: 38267856

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01118
Policy Entropy: 1.07361
Value Function Loss: 0.08188

Mean KL Divergence: 0.04309
SB3 Clip Fraction: 0.22022
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.08897

Collected Steps per Second: 12830.10234
Overall Steps per Second: 10701.48088

Timestep Collection Time: 3.89880
Timestep Consumption Time: 0.77551
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 4.67431

Cumulative Model Updates: 2295
Cumulative Timesteps: 38317878

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 38317878...
Checkpoint 38317878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14494
Policy Entropy: 1.05140
Value Function Loss: 0.09368

Mean KL Divergence: 0.03019
SB3 Clip Fraction: 0.16755
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.09035

Collected Steps per Second: 12549.51382
Overall Steps per Second: 10614.75293

Timestep Collection Time: 3.98693
Timestep Consumption Time: 0.72670
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 4.71363

Cumulative Model Updates: 2298
Cumulative Timesteps: 38367912

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02480
Policy Entropy: 1.05892
Value Function Loss: 0.06698

Mean KL Divergence: 0.03276
SB3 Clip Fraction: 0.16706
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.09003

Collected Steps per Second: 12942.92118
Overall Steps per Second: 10667.61299

Timestep Collection Time: 3.86512
Timestep Consumption Time: 0.82440
PPO Batch Consumption Time: 0.02753
Total Iteration Time: 4.68952

Cumulative Model Updates: 2301
Cumulative Timesteps: 38417938

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 38417938...
Checkpoint 38417938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01255
Policy Entropy: 1.02312
Value Function Loss: 0.03625

Mean KL Divergence: 0.09124
SB3 Clip Fraction: 0.29003
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.07639

Collected Steps per Second: 13060.86017
Overall Steps per Second: 10838.47797

Timestep Collection Time: 3.83022
Timestep Consumption Time: 0.78537
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 4.61559

Cumulative Model Updates: 2304
Cumulative Timesteps: 38467964

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02050
Policy Entropy: 1.05648
Value Function Loss: 0.02906

Mean KL Divergence: 0.02420
SB3 Clip Fraction: 0.17878
Policy Update Magnitude: 0.04044
Value Function Update Magnitude: 0.06957

Collected Steps per Second: 13313.96988
Overall Steps per Second: 10991.76571

Timestep Collection Time: 3.75771
Timestep Consumption Time: 0.79388
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 4.55159

Cumulative Model Updates: 2307
Cumulative Timesteps: 38517994

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 38517994...
Checkpoint 38517994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02208
Policy Entropy: 1.00088
Value Function Loss: 0.05300

Mean KL Divergence: 0.07415
SB3 Clip Fraction: 0.24333
Policy Update Magnitude: 0.03590
Value Function Update Magnitude: 0.07837

Collected Steps per Second: 12830.22690
Overall Steps per Second: 10578.41229

Timestep Collection Time: 3.89876
Timestep Consumption Time: 0.82993
PPO Batch Consumption Time: 0.03000
Total Iteration Time: 4.72869

Cumulative Model Updates: 2310
Cumulative Timesteps: 38568016

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03605
Policy Entropy: 1.00095
Value Function Loss: 0.04937

Mean KL Divergence: 0.02922
SB3 Clip Fraction: 0.19007
Policy Update Magnitude: 0.03253
Value Function Update Magnitude: 0.08538

Collected Steps per Second: 11784.92569
Overall Steps per Second: 10029.02665

Timestep Collection Time: 4.24525
Timestep Consumption Time: 0.74327
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 4.98852

Cumulative Model Updates: 2313
Cumulative Timesteps: 38618046

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 38618046...
Checkpoint 38618046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02019
Policy Entropy: 0.99832
Value Function Loss: 0.05606

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.16027
Policy Update Magnitude: 0.03817
Value Function Update Magnitude: 0.08194

Collected Steps per Second: 12301.64981
Overall Steps per Second: 10254.16737

Timestep Collection Time: 4.06563
Timestep Consumption Time: 0.81180
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 4.87743

Cumulative Model Updates: 2316
Cumulative Timesteps: 38668060

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00668
Policy Entropy: 0.98610
Value Function Loss: 0.05167

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.17650
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.08154

Collected Steps per Second: 12850.97438
Overall Steps per Second: 10691.21083

Timestep Collection Time: 3.89293
Timestep Consumption Time: 0.78642
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 4.67936

Cumulative Model Updates: 2319
Cumulative Timesteps: 38718088

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 38718088...
Checkpoint 38718088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03856
Policy Entropy: 0.99342
Value Function Loss: 0.05417

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.07929

Collected Steps per Second: 12565.36712
Overall Steps per Second: 10611.16448

Timestep Collection Time: 3.98062
Timestep Consumption Time: 0.73309
PPO Batch Consumption Time: 0.02688
Total Iteration Time: 4.71371

Cumulative Model Updates: 2322
Cumulative Timesteps: 38768106

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01095
Policy Entropy: 0.98349
Value Function Loss: 0.05489

Mean KL Divergence: 0.03057
SB3 Clip Fraction: 0.20074
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.09857

Collected Steps per Second: 12640.22113
Overall Steps per Second: 10492.33265

Timestep Collection Time: 3.95800
Timestep Consumption Time: 0.81024
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 4.76824

Cumulative Model Updates: 2325
Cumulative Timesteps: 38818136

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 38818136...
Checkpoint 38818136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06622
Policy Entropy: 1.00446
Value Function Loss: 0.05210

Mean KL Divergence: 0.03630
SB3 Clip Fraction: 0.20675
Policy Update Magnitude: 0.04374
Value Function Update Magnitude: 0.10477

Collected Steps per Second: 12664.39649
Overall Steps per Second: 10585.39374

Timestep Collection Time: 3.95218
Timestep Consumption Time: 0.77622
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 4.72840

Cumulative Model Updates: 2328
Cumulative Timesteps: 38868188

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03013
Policy Entropy: 1.01171
Value Function Loss: 0.05480

Mean KL Divergence: 0.03365
SB3 Clip Fraction: 0.22940
Policy Update Magnitude: 0.04123
Value Function Update Magnitude: 0.09713

Collected Steps per Second: 13049.66722
Overall Steps per Second: 10790.63287

Timestep Collection Time: 3.83443
Timestep Consumption Time: 0.80274
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 4.63717

Cumulative Model Updates: 2331
Cumulative Timesteps: 38918226

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 38918226...
Checkpoint 38918226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00960
Policy Entropy: 0.97576
Value Function Loss: 0.03570

Mean KL Divergence: 0.04073
SB3 Clip Fraction: 0.20730
Policy Update Magnitude: 0.03964
Value Function Update Magnitude: 0.07646

Collected Steps per Second: 13108.57015
Overall Steps per Second: 10901.64697

Timestep Collection Time: 3.81659
Timestep Consumption Time: 0.77263
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 4.58921

Cumulative Model Updates: 2334
Cumulative Timesteps: 38968256

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02132
Policy Entropy: 0.98351
Value Function Loss: 0.02809

Mean KL Divergence: 0.02536
SB3 Clip Fraction: 0.21071
Policy Update Magnitude: 0.03863
Value Function Update Magnitude: 0.06137

Collected Steps per Second: 12588.69693
Overall Steps per Second: 10617.92653

Timestep Collection Time: 3.97277
Timestep Consumption Time: 0.73738
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 4.71015

Cumulative Model Updates: 2337
Cumulative Timesteps: 39018268

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 39018268...
Checkpoint 39018268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04032
Policy Entropy: 0.99527
Value Function Loss: 0.04725

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.04035
Value Function Update Magnitude: 0.06851

Collected Steps per Second: 13210.94586
Overall Steps per Second: 10903.87171

Timestep Collection Time: 3.78519
Timestep Consumption Time: 0.80088
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 4.58608

Cumulative Model Updates: 2340
Cumulative Timesteps: 39068274

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02763
Policy Entropy: 0.98938
Value Function Loss: 0.06809

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.07887

Collected Steps per Second: 12641.52420
Overall Steps per Second: 10538.65881

Timestep Collection Time: 3.95743
Timestep Consumption Time: 0.78966
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 4.74709

Cumulative Model Updates: 2343
Cumulative Timesteps: 39118302

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 39118302...
Checkpoint 39118302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08361
Policy Entropy: 0.98103
Value Function Loss: 0.07117

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.08582

Collected Steps per Second: 13061.24005
Overall Steps per Second: 10773.11910

Timestep Collection Time: 3.83134
Timestep Consumption Time: 0.81374
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 4.64508

Cumulative Model Updates: 2346
Cumulative Timesteps: 39168344

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08901
Policy Entropy: 0.96379
Value Function Loss: 0.06239

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.19249
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.08154

Collected Steps per Second: 12932.38783
Overall Steps per Second: 10754.15142

Timestep Collection Time: 3.86688
Timestep Consumption Time: 0.78323
PPO Batch Consumption Time: 0.02696
Total Iteration Time: 4.65011

Cumulative Model Updates: 2349
Cumulative Timesteps: 39218352

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 39218352...
Checkpoint 39218352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01629
Policy Entropy: 0.99788
Value Function Loss: 0.05108

Mean KL Divergence: 0.02641
SB3 Clip Fraction: 0.20501
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.06920

Collected Steps per Second: 12608.65709
Overall Steps per Second: 10669.08477

Timestep Collection Time: 3.96569
Timestep Consumption Time: 0.72094
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 4.68663

Cumulative Model Updates: 2352
Cumulative Timesteps: 39268354

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01867
Policy Entropy: 1.01408
Value Function Loss: 0.03673

Mean KL Divergence: 0.03164
SB3 Clip Fraction: 0.22003
Policy Update Magnitude: 0.04111
Value Function Update Magnitude: 0.06811

Collected Steps per Second: 12935.94672
Overall Steps per Second: 10748.10644

Timestep Collection Time: 3.86721
Timestep Consumption Time: 0.78719
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 4.65440

Cumulative Model Updates: 2355
Cumulative Timesteps: 39318380

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 39318380...
Checkpoint 39318380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01456
Policy Entropy: 0.98517
Value Function Loss: 0.02604

Mean KL Divergence: 0.03171
SB3 Clip Fraction: 0.18472
Policy Update Magnitude: 0.03945
Value Function Update Magnitude: 0.06250

Collected Steps per Second: 13060.13891
Overall Steps per Second: 10846.28171

Timestep Collection Time: 3.82952
Timestep Consumption Time: 0.78165
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 4.61117

Cumulative Model Updates: 2358
Cumulative Timesteps: 39368394

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03621
Policy Entropy: 1.00091
Value Function Loss: 0.02198

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.17809
Policy Update Magnitude: 0.04134
Value Function Update Magnitude: 0.05933

Collected Steps per Second: 13311.72205
Overall Steps per Second: 10957.97730

Timestep Collection Time: 3.75909
Timestep Consumption Time: 0.80744
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 4.56654

Cumulative Model Updates: 2361
Cumulative Timesteps: 39418434

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 39418434...
Checkpoint 39418434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02631
Policy Entropy: 1.01990
Value Function Loss: 0.03302

Mean KL Divergence: 0.02682
SB3 Clip Fraction: 0.17806
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.06229

Collected Steps per Second: 12854.68342
Overall Steps per Second: 10668.27470

Timestep Collection Time: 3.89010
Timestep Consumption Time: 0.79726
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 4.68736

Cumulative Model Updates: 2364
Cumulative Timesteps: 39468440

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00643
Policy Entropy: 1.03213
Value Function Loss: 0.04303

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.04179
Value Function Update Magnitude: 0.05894

Collected Steps per Second: 12735.77505
Overall Steps per Second: 10733.62468

Timestep Collection Time: 3.92626
Timestep Consumption Time: 0.73237
PPO Batch Consumption Time: 0.02822
Total Iteration Time: 4.65863

Cumulative Model Updates: 2367
Cumulative Timesteps: 39518444

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 39518444...
Checkpoint 39518444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00063
Policy Entropy: 1.01152
Value Function Loss: 0.05627

Mean KL Divergence: 0.02619
SB3 Clip Fraction: 0.17648
Policy Update Magnitude: 0.04291
Value Function Update Magnitude: 0.06098

Collected Steps per Second: 12694.39437
Overall Steps per Second: 10452.21672

Timestep Collection Time: 3.93890
Timestep Consumption Time: 0.84496
PPO Batch Consumption Time: 0.02751
Total Iteration Time: 4.78387

Cumulative Model Updates: 2370
Cumulative Timesteps: 39568446

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03914
Policy Entropy: 0.98164
Value Function Loss: 0.06343

Mean KL Divergence: 0.03246
SB3 Clip Fraction: 0.20387
Policy Update Magnitude: 0.04447
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 12833.69287
Overall Steps per Second: 10675.24665

Timestep Collection Time: 3.89662
Timestep Consumption Time: 0.78786
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 4.68448

Cumulative Model Updates: 2373
Cumulative Timesteps: 39618454

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 39618454...
Checkpoint 39618454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01225
Policy Entropy: 1.02145
Value Function Loss: 0.05736

Mean KL Divergence: 0.03233
SB3 Clip Fraction: 0.21517
Policy Update Magnitude: 0.04072
Value Function Update Magnitude: 0.06623

Collected Steps per Second: 12947.36624
Overall Steps per Second: 10665.88358

Timestep Collection Time: 3.86194
Timestep Consumption Time: 0.82609
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 4.68803

Cumulative Model Updates: 2376
Cumulative Timesteps: 39668456

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01134
Policy Entropy: 0.99812
Value Function Loss: 0.04780

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.14923
Policy Update Magnitude: 0.04289
Value Function Update Magnitude: 0.05659

Collected Steps per Second: 12797.99431
Overall Steps per Second: 10591.33741

Timestep Collection Time: 3.90952
Timestep Consumption Time: 0.81453
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 4.72405

Cumulative Model Updates: 2379
Cumulative Timesteps: 39718490

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 39718490...
Checkpoint 39718490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04089
Policy Entropy: 0.98874
Value Function Loss: 0.03947

Mean KL Divergence: 0.02639
SB3 Clip Fraction: 0.17078
Policy Update Magnitude: 0.04123
Value Function Update Magnitude: 0.05110

Collected Steps per Second: 12787.20945
Overall Steps per Second: 10800.35325

Timestep Collection Time: 3.91063
Timestep Consumption Time: 0.71941
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.63003

Cumulative Model Updates: 2382
Cumulative Timesteps: 39768496

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02561
Policy Entropy: 0.96990
Value Function Loss: 0.03382

Mean KL Divergence: 0.03064
SB3 Clip Fraction: 0.20041
Policy Update Magnitude: 0.03843
Value Function Update Magnitude: 0.05183

Collected Steps per Second: 13155.99508
Overall Steps per Second: 10847.78428

Timestep Collection Time: 3.80329
Timestep Consumption Time: 0.80927
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 4.61255

Cumulative Model Updates: 2385
Cumulative Timesteps: 39818532

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 39818532...
Checkpoint 39818532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01075
Policy Entropy: 1.01110
Value Function Loss: 0.03474

Mean KL Divergence: 0.03206
SB3 Clip Fraction: 0.20636
Policy Update Magnitude: 0.03614
Value Function Update Magnitude: 0.04869

Collected Steps per Second: 13019.47447
Overall Steps per Second: 10807.80334

Timestep Collection Time: 3.84194
Timestep Consumption Time: 0.78620
PPO Batch Consumption Time: 0.02665
Total Iteration Time: 4.62814

Cumulative Model Updates: 2388
Cumulative Timesteps: 39868552

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01985
Policy Entropy: 1.00956
Value Function Loss: 0.02572

Mean KL Divergence: 0.01724
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.03415
Value Function Update Magnitude: 0.04917

Collected Steps per Second: 12803.66333
Overall Steps per Second: 10575.81555

Timestep Collection Time: 3.90935
Timestep Consumption Time: 0.82352
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 4.73287

Cumulative Model Updates: 2391
Cumulative Timesteps: 39918606

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 39918606...
Checkpoint 39918606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01079
Policy Entropy: 1.01050
Value Function Loss: 0.03353

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.03677
Value Function Update Magnitude: 0.05644

Collected Steps per Second: 13130.48447
Overall Steps per Second: 10791.70774

Timestep Collection Time: 3.80930
Timestep Consumption Time: 0.82555
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 4.63485

Cumulative Model Updates: 2394
Cumulative Timesteps: 39968624

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02825
Policy Entropy: 1.01142
Value Function Loss: 0.02976

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.03954
Value Function Update Magnitude: 0.06329

Collected Steps per Second: 12399.93221
Overall Steps per Second: 10407.59912

Timestep Collection Time: 4.03631
Timestep Consumption Time: 0.77267
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 4.80899

Cumulative Model Updates: 2397
Cumulative Timesteps: 40018674

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 40018674...
Checkpoint 40018674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03674
Policy Entropy: 0.99533
Value Function Loss: 0.03884

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.04398
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 12248.40802
Overall Steps per Second: 10183.12921

Timestep Collection Time: 4.08478
Timestep Consumption Time: 0.82845
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 4.91322

Cumulative Model Updates: 2400
Cumulative Timesteps: 40068706

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03065
Policy Entropy: 1.00239
Value Function Loss: 0.02740

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.04134
Value Function Update Magnitude: 0.06969

Collected Steps per Second: 12775.25739
Overall Steps per Second: 10481.35328

Timestep Collection Time: 3.91679
Timestep Consumption Time: 0.85721
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 4.77400

Cumulative Model Updates: 2403
Cumulative Timesteps: 40118744

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 40118744...
Checkpoint 40118744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00560
Policy Entropy: 1.00316
Value Function Loss: 0.03100

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.05747

Collected Steps per Second: 13130.50763
Overall Steps per Second: 10836.48293

Timestep Collection Time: 3.80808
Timestep Consumption Time: 0.80615
PPO Batch Consumption Time: 0.02607
Total Iteration Time: 4.61423

Cumulative Model Updates: 2406
Cumulative Timesteps: 40168746

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04449
Policy Entropy: 1.01577
Value Function Loss: 0.05213

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.04690
Value Function Update Magnitude: 0.05977

Collected Steps per Second: 13172.40162
Overall Steps per Second: 10850.12689

Timestep Collection Time: 3.79885
Timestep Consumption Time: 0.81308
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 4.61193

Cumulative Model Updates: 2409
Cumulative Timesteps: 40218786

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 40218786...
Checkpoint 40218786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00017
Policy Entropy: 1.02344
Value Function Loss: 0.05037

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.04612
Value Function Update Magnitude: 0.06685

Collected Steps per Second: 12643.68964
Overall Steps per Second: 10480.46400

Timestep Collection Time: 3.95865
Timestep Consumption Time: 0.81709
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 4.77574

Cumulative Model Updates: 2412
Cumulative Timesteps: 40268838

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00093
Policy Entropy: 1.03050
Value Function Loss: 0.05619

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.07236

Collected Steps per Second: 13363.26581
Overall Steps per Second: 10914.16381

Timestep Collection Time: 3.74564
Timestep Consumption Time: 0.84051
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 4.58615

Cumulative Model Updates: 2415
Cumulative Timesteps: 40318892

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 40318892...
Checkpoint 40318892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01306
Policy Entropy: 1.02334
Value Function Loss: 0.02581

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.03832
Value Function Update Magnitude: 0.06292

Collected Steps per Second: 12827.34981
Overall Steps per Second: 10634.00657

Timestep Collection Time: 3.89964
Timestep Consumption Time: 0.80433
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 4.70397

Cumulative Model Updates: 2418
Cumulative Timesteps: 40368914

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04393
Policy Entropy: 1.00547
Value Function Loss: 0.04337

Mean KL Divergence: 0.03731
SB3 Clip Fraction: 0.23113
Policy Update Magnitude: 0.03666
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 12967.01885
Overall Steps per Second: 10882.60529

Timestep Collection Time: 3.85995
Timestep Consumption Time: 0.73932
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 4.59927

Cumulative Model Updates: 2421
Cumulative Timesteps: 40418966

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 40418966...
Checkpoint 40418966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00383
Policy Entropy: 1.03382
Value Function Loss: 0.04487

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.16895
Policy Update Magnitude: 0.03628
Value Function Update Magnitude: 0.06003

Collected Steps per Second: 12725.52931
Overall Steps per Second: 10515.10194

Timestep Collection Time: 3.92974
Timestep Consumption Time: 0.82609
PPO Batch Consumption Time: 0.02846
Total Iteration Time: 4.75583

Cumulative Model Updates: 2424
Cumulative Timesteps: 40468974

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03489
Policy Entropy: 1.03553
Value Function Loss: 0.05906

Mean KL Divergence: 0.02593
SB3 Clip Fraction: 0.19507
Policy Update Magnitude: 0.03645
Value Function Update Magnitude: 0.05143

Collected Steps per Second: 12660.47082
Overall Steps per Second: 10485.61547

Timestep Collection Time: 3.95246
Timestep Consumption Time: 0.81979
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 4.77225

Cumulative Model Updates: 2427
Cumulative Timesteps: 40519014

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 40519014...
Checkpoint 40519014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00021
Policy Entropy: 1.01121
Value Function Loss: 0.04937

Mean KL Divergence: 0.03561
SB3 Clip Fraction: 0.20018
Policy Update Magnitude: 0.03885
Value Function Update Magnitude: 0.05679

Collected Steps per Second: 13419.78633
Overall Steps per Second: 11035.41564

Timestep Collection Time: 3.72823
Timestep Consumption Time: 0.80554
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 4.53377

Cumulative Model Updates: 2430
Cumulative Timesteps: 40569046

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00007
Policy Entropy: 0.99204
Value Function Loss: 0.03763

Mean KL Divergence: 0.04012
SB3 Clip Fraction: 0.24117
Policy Update Magnitude: 0.03666
Value Function Update Magnitude: 0.06177

Collected Steps per Second: 12727.26421
Overall Steps per Second: 10542.51957

Timestep Collection Time: 3.93062
Timestep Consumption Time: 0.81455
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 4.74517

Cumulative Model Updates: 2433
Cumulative Timesteps: 40619072

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 40619072...
Checkpoint 40619072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01632
Policy Entropy: 1.00490
Value Function Loss: 0.04255

Mean KL Divergence: 0.03418
SB3 Clip Fraction: 0.18697
Policy Update Magnitude: 0.03847
Value Function Update Magnitude: 0.05637

Collected Steps per Second: 12845.41205
Overall Steps per Second: 10831.64633

Timestep Collection Time: 3.89384
Timestep Consumption Time: 0.72392
PPO Batch Consumption Time: 0.02819
Total Iteration Time: 4.61777

Cumulative Model Updates: 2436
Cumulative Timesteps: 40669090

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02053
Policy Entropy: 1.01046
Value Function Loss: 0.04892

Mean KL Divergence: 0.03898
SB3 Clip Fraction: 0.22534
Policy Update Magnitude: 0.03783
Value Function Update Magnitude: 0.05846

Collected Steps per Second: 12792.69793
Overall Steps per Second: 10578.31754

Timestep Collection Time: 3.91051
Timestep Consumption Time: 0.81860
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 4.72911

Cumulative Model Updates: 2439
Cumulative Timesteps: 40719116

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 40719116...
Checkpoint 40719116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03003
Policy Entropy: 0.96076
Value Function Loss: 0.05014

Mean KL Divergence: 0.06037
SB3 Clip Fraction: 0.24871
Policy Update Magnitude: 0.03898
Value Function Update Magnitude: 0.06028

Collected Steps per Second: 12937.05349
Overall Steps per Second: 10689.25142

Timestep Collection Time: 3.86765
Timestep Consumption Time: 0.81331
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 4.68096

Cumulative Model Updates: 2442
Cumulative Timesteps: 40769152

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02501
Policy Entropy: 1.00483
Value Function Loss: 0.04835

Mean KL Divergence: 0.02946
SB3 Clip Fraction: 0.20223
Policy Update Magnitude: 0.03796
Value Function Update Magnitude: 0.05726

Collected Steps per Second: 13231.67779
Overall Steps per Second: 10922.40048

Timestep Collection Time: 3.78108
Timestep Consumption Time: 0.79942
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 4.58049

Cumulative Model Updates: 2445
Cumulative Timesteps: 40819182

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 40819182...
Checkpoint 40819182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10487
Policy Entropy: 0.99103
Value Function Loss: 0.03567

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.17397
Policy Update Magnitude: 0.03871
Value Function Update Magnitude: 0.06255

Collected Steps per Second: 13097.17148
Overall Steps per Second: 10791.34189

Timestep Collection Time: 3.81777
Timestep Consumption Time: 0.81576
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 4.63353

Cumulative Model Updates: 2448
Cumulative Timesteps: 40869184

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12932
Policy Entropy: 0.98821
Value Function Loss: 0.05616

Mean KL Divergence: 0.02658
SB3 Clip Fraction: 0.16863
Policy Update Magnitude: 0.04242
Value Function Update Magnitude: 0.07277

Collected Steps per Second: 13043.21518
Overall Steps per Second: 10963.16283

Timestep Collection Time: 3.83433
Timestep Consumption Time: 0.72749
PPO Batch Consumption Time: 0.02666
Total Iteration Time: 4.56182

Cumulative Model Updates: 2451
Cumulative Timesteps: 40919196

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 40919196...
Checkpoint 40919196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00617
Policy Entropy: 0.95735
Value Function Loss: 0.06084

Mean KL Divergence: 0.06693
SB3 Clip Fraction: 0.30123
Policy Update Magnitude: 0.04219
Value Function Update Magnitude: 0.07482

Collected Steps per Second: 12895.76508
Overall Steps per Second: 10682.81982

Timestep Collection Time: 3.87879
Timestep Consumption Time: 0.80349
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 4.68228

Cumulative Model Updates: 2454
Cumulative Timesteps: 40969216

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02949
Policy Entropy: 1.01590
Value Function Loss: 0.08803

Mean KL Divergence: 0.03400
SB3 Clip Fraction: 0.23887
Policy Update Magnitude: 0.04066
Value Function Update Magnitude: 0.07831

Collected Steps per Second: 13000.67440
Overall Steps per Second: 10725.81376

Timestep Collection Time: 3.84765
Timestep Consumption Time: 0.81606
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 4.66370

Cumulative Model Updates: 2457
Cumulative Timesteps: 41019238

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 41019238...
Checkpoint 41019238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07185
Policy Entropy: 0.97321
Value Function Loss: 0.06836

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.15075
Policy Update Magnitude: 0.03998
Value Function Update Magnitude: 0.09211

Collected Steps per Second: 13035.88393
Overall Steps per Second: 10760.12518

Timestep Collection Time: 3.83741
Timestep Consumption Time: 0.81161
PPO Batch Consumption Time: 0.02866
Total Iteration Time: 4.64902

Cumulative Model Updates: 2460
Cumulative Timesteps: 41069262

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09402
Policy Entropy: 0.95532
Value Function Loss: 0.06875

Mean KL Divergence: 0.02568
SB3 Clip Fraction: 0.19722
Policy Update Magnitude: 0.04111
Value Function Update Magnitude: 0.08647

Collected Steps per Second: 13250.56647
Overall Steps per Second: 10874.85714

Timestep Collection Time: 3.77373
Timestep Consumption Time: 0.82440
PPO Batch Consumption Time: 0.03016
Total Iteration Time: 4.59813

Cumulative Model Updates: 2463
Cumulative Timesteps: 41119266

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 41119266...
Checkpoint 41119266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03928
Policy Entropy: 0.98777
Value Function Loss: 0.05252

Mean KL Divergence: 0.02831
SB3 Clip Fraction: 0.18597
Policy Update Magnitude: 0.04072
Value Function Update Magnitude: 0.07050

Collected Steps per Second: 13096.60005
Overall Steps per Second: 10842.67168

Timestep Collection Time: 3.81916
Timestep Consumption Time: 0.79391
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.61307

Cumulative Model Updates: 2466
Cumulative Timesteps: 41169284

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03976
Policy Entropy: 0.98592
Value Function Loss: 0.04132

Mean KL Divergence: 0.02638
SB3 Clip Fraction: 0.19195
Policy Update Magnitude: 0.04222
Value Function Update Magnitude: 0.07686

Collected Steps per Second: 13049.24983
Overall Steps per Second: 10792.83371

Timestep Collection Time: 3.83317
Timestep Consumption Time: 0.80139
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 4.63456

Cumulative Model Updates: 2469
Cumulative Timesteps: 41219304

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 41219304...
Checkpoint 41219304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03821
Policy Entropy: 0.97077
Value Function Loss: 0.04247

Mean KL Divergence: 0.03254
SB3 Clip Fraction: 0.17405
Policy Update Magnitude: 0.04363
Value Function Update Magnitude: 0.07706

Collected Steps per Second: 13005.93423
Overall Steps per Second: 10674.49127

Timestep Collection Time: 3.84732
Timestep Consumption Time: 0.84030
PPO Batch Consumption Time: 0.02782
Total Iteration Time: 4.68762

Cumulative Model Updates: 2472
Cumulative Timesteps: 41269342

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00993
Policy Entropy: 0.97811
Value Function Loss: 0.04929

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.16099
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.06535

Collected Steps per Second: 12555.96698
Overall Steps per Second: 10647.16971

Timestep Collection Time: 3.98536
Timestep Consumption Time: 0.71448
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 4.69984

Cumulative Model Updates: 2475
Cumulative Timesteps: 41319382

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 41319382...
Checkpoint 41319382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04722
Policy Entropy: 0.98990
Value Function Loss: 0.08035

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.06480
Value Function Update Magnitude: 0.07524

Collected Steps per Second: 13079.82929
Overall Steps per Second: 10747.09182

Timestep Collection Time: 3.82375
Timestep Consumption Time: 0.82997
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 4.65372

Cumulative Model Updates: 2478
Cumulative Timesteps: 41369396

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01028
Policy Entropy: 0.98716
Value Function Loss: 0.08226

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.06940

Collected Steps per Second: 12942.45551
Overall Steps per Second: 10638.00151

Timestep Collection Time: 3.86372
Timestep Consumption Time: 0.83698
PPO Batch Consumption Time: 0.02965
Total Iteration Time: 4.70069

Cumulative Model Updates: 2481
Cumulative Timesteps: 41419402

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 41419402...
Checkpoint 41419402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01760
Policy Entropy: 0.99532
Value Function Loss: 0.08666

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.05995
Value Function Update Magnitude: 0.07185

Collected Steps per Second: 12547.88976
Overall Steps per Second: 10392.67554

Timestep Collection Time: 3.98776
Timestep Consumption Time: 0.82697
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 4.81474

Cumulative Model Updates: 2484
Cumulative Timesteps: 41469440

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03160
Policy Entropy: 1.00144
Value Function Loss: 0.06959

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.05601
Value Function Update Magnitude: 0.07670

Collected Steps per Second: 12854.44032
Overall Steps per Second: 10612.92374

Timestep Collection Time: 3.89251
Timestep Consumption Time: 0.82212
PPO Batch Consumption Time: 0.03205
Total Iteration Time: 4.71463

Cumulative Model Updates: 2487
Cumulative Timesteps: 41519476

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 41519476...
Checkpoint 41519476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05273
Policy Entropy: 1.00226
Value Function Loss: 0.06799

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.08307

Collected Steps per Second: 12589.17514
Overall Steps per Second: 10604.25176

Timestep Collection Time: 3.97405
Timestep Consumption Time: 0.74387
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 4.71792

Cumulative Model Updates: 2490
Cumulative Timesteps: 41569506

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04709
Policy Entropy: 0.99605
Value Function Loss: 0.06168

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.08886

Collected Steps per Second: 12708.92336
Overall Steps per Second: 10548.30507

Timestep Collection Time: 3.93487
Timestep Consumption Time: 0.80598
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 4.74086

Cumulative Model Updates: 2493
Cumulative Timesteps: 41619514

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 41619514...
Checkpoint 41619514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02203
Policy Entropy: 0.98856
Value Function Loss: 0.06500

Mean KL Divergence: 0.01961
SB3 Clip Fraction: 0.15948
Policy Update Magnitude: 0.05561
Value Function Update Magnitude: 0.09408

Collected Steps per Second: 12991.60204
Overall Steps per Second: 10702.98263

Timestep Collection Time: 3.84926
Timestep Consumption Time: 0.82309
PPO Batch Consumption Time: 0.02983
Total Iteration Time: 4.67234

Cumulative Model Updates: 2496
Cumulative Timesteps: 41669522

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00678
Policy Entropy: 0.97210
Value Function Loss: 0.05753

Mean KL Divergence: 0.02377
SB3 Clip Fraction: 0.18312
Policy Update Magnitude: 0.05384
Value Function Update Magnitude: 0.08722

Collected Steps per Second: 13022.53768
Overall Steps per Second: 10650.97954

Timestep Collection Time: 3.84180
Timestep Consumption Time: 0.85542
PPO Batch Consumption Time: 0.02855
Total Iteration Time: 4.69722

Cumulative Model Updates: 2499
Cumulative Timesteps: 41719552

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 41719552...
Checkpoint 41719552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03573
Policy Entropy: 1.02694
Value Function Loss: 0.05067

Mean KL Divergence: 0.03906
SB3 Clip Fraction: 0.21456
Policy Update Magnitude: 0.05493
Value Function Update Magnitude: 0.07477

Collected Steps per Second: 11592.89038
Overall Steps per Second: 9718.65820

Timestep Collection Time: 4.31385
Timestep Consumption Time: 0.83192
PPO Batch Consumption Time: 0.02916
Total Iteration Time: 5.14577

Cumulative Model Updates: 2502
Cumulative Timesteps: 41769562

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11781
Policy Entropy: 1.01113
Value Function Loss: 0.07083

Mean KL Divergence: 0.03760
SB3 Clip Fraction: 0.22024
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.07543

Collected Steps per Second: 10351.16777
Overall Steps per Second: 8961.27640

Timestep Collection Time: 4.83269
Timestep Consumption Time: 0.74955
PPO Batch Consumption Time: 0.02856
Total Iteration Time: 5.58224

Cumulative Model Updates: 2505
Cumulative Timesteps: 41819586

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 41819586...
Checkpoint 41819586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09669
Policy Entropy: 0.99119
Value Function Loss: 0.08376

Mean KL Divergence: 0.06686
SB3 Clip Fraction: 0.25769
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.10060

Collected Steps per Second: 12589.94391
Overall Steps per Second: 10434.85413

Timestep Collection Time: 3.97349
Timestep Consumption Time: 0.82064
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 4.79413

Cumulative Model Updates: 2508
Cumulative Timesteps: 41869612

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07252
Policy Entropy: 1.02458
Value Function Loss: 0.07547

Mean KL Divergence: 0.05197
SB3 Clip Fraction: 0.22123
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.10767

Collected Steps per Second: 12715.03262
Overall Steps per Second: 10574.64421

Timestep Collection Time: 3.93629
Timestep Consumption Time: 0.79673
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 4.73302

Cumulative Model Updates: 2511
Cumulative Timesteps: 41919662

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 41919662...
Checkpoint 41919662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03829
Policy Entropy: 1.02004
Value Function Loss: 0.05366

Mean KL Divergence: 0.03270
SB3 Clip Fraction: 0.21039
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.08730

Collected Steps per Second: 13330.98547
Overall Steps per Second: 10954.69016

Timestep Collection Time: 3.75186
Timestep Consumption Time: 0.81385
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 4.56572

Cumulative Model Updates: 2514
Cumulative Timesteps: 41969678

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00126
Policy Entropy: 1.00230
Value Function Loss: 0.06780

Mean KL Divergence: 0.04697
SB3 Clip Fraction: 0.21159
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.07489

Collected Steps per Second: 12993.78057
Overall Steps per Second: 10715.86169

Timestep Collection Time: 3.85123
Timestep Consumption Time: 0.81867
PPO Batch Consumption Time: 0.02913
Total Iteration Time: 4.66990

Cumulative Model Updates: 2517
Cumulative Timesteps: 42019720

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 42019720...
Checkpoint 42019720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04236
Policy Entropy: 1.00916
Value Function Loss: 0.07670

Mean KL Divergence: 0.05525
SB3 Clip Fraction: 0.25823
Policy Update Magnitude: 0.04456
Value Function Update Magnitude: 0.07532

Collected Steps per Second: 12790.21970
Overall Steps per Second: 10694.15237

Timestep Collection Time: 3.91283
Timestep Consumption Time: 0.76692
PPO Batch Consumption Time: 0.02662
Total Iteration Time: 4.67975

Cumulative Model Updates: 2520
Cumulative Timesteps: 42069766

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01179
Policy Entropy: 1.03566
Value Function Loss: 0.06407

Mean KL Divergence: 0.04737
SB3 Clip Fraction: 0.19985
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.08068

Collected Steps per Second: 12752.61687
Overall Steps per Second: 10563.17176

Timestep Collection Time: 3.92139
Timestep Consumption Time: 0.81279
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 4.73418

Cumulative Model Updates: 2523
Cumulative Timesteps: 42119774

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 42119774...
Checkpoint 42119774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01319
Policy Entropy: 1.04307
Value Function Loss: 0.03126

Mean KL Divergence: 0.03500
SB3 Clip Fraction: 0.21439
Policy Update Magnitude: 0.04189
Value Function Update Magnitude: 0.08276

Collected Steps per Second: 12720.27585
Overall Steps per Second: 10557.32257

Timestep Collection Time: 3.93372
Timestep Consumption Time: 0.80593
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 4.73965

Cumulative Model Updates: 2526
Cumulative Timesteps: 42169812

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03303
Policy Entropy: 1.01045
Value Function Loss: 0.01849

Mean KL Divergence: 0.03499
SB3 Clip Fraction: 0.17897
Policy Update Magnitude: 0.03894
Value Function Update Magnitude: 0.07985

Collected Steps per Second: 12899.64648
Overall Steps per Second: 10687.89338

Timestep Collection Time: 3.87840
Timestep Consumption Time: 0.80260
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 4.68100

Cumulative Model Updates: 2529
Cumulative Timesteps: 42219842

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 42219842...
Checkpoint 42219842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01744
Policy Entropy: 0.98811
Value Function Loss: 0.03620

Mean KL Divergence: 0.05235
SB3 Clip Fraction: 0.25143
Policy Update Magnitude: 0.03786
Value Function Update Magnitude: 0.07274

Collected Steps per Second: 13023.98289
Overall Steps per Second: 10812.33114

Timestep Collection Time: 3.84199
Timestep Consumption Time: 0.78588
PPO Batch Consumption Time: 0.02593
Total Iteration Time: 4.62786

Cumulative Model Updates: 2532
Cumulative Timesteps: 42269880

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01527
Policy Entropy: 1.02063
Value Function Loss: 0.03427

Mean KL Divergence: 0.02430
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.04030
Value Function Update Magnitude: 0.07375

Collected Steps per Second: 10470.70806
Overall Steps per Second: 9032.44245

Timestep Collection Time: 4.77675
Timestep Consumption Time: 0.76062
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 5.53737

Cumulative Model Updates: 2535
Cumulative Timesteps: 42319896

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 42319896...
Checkpoint 42319896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00200
Policy Entropy: 1.01366
Value Function Loss: 0.05253

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.08292

Collected Steps per Second: 12894.86692
Overall Steps per Second: 10699.54120

Timestep Collection Time: 3.87860
Timestep Consumption Time: 0.79581
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.67441

Cumulative Model Updates: 2538
Cumulative Timesteps: 42369910

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01678
Policy Entropy: 1.02690
Value Function Loss: 0.04849

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.08181

Collected Steps per Second: 12677.74660
Overall Steps per Second: 10569.74223

Timestep Collection Time: 3.94613
Timestep Consumption Time: 0.78701
PPO Batch Consumption Time: 0.02967
Total Iteration Time: 4.73313

Cumulative Model Updates: 2541
Cumulative Timesteps: 42419938

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 42419938...
Checkpoint 42419938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04405
Policy Entropy: 1.02268
Value Function Loss: 0.05314

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.08654

Collected Steps per Second: 12773.12988
Overall Steps per Second: 10431.61993

Timestep Collection Time: 3.91541
Timestep Consumption Time: 0.87886
PPO Batch Consumption Time: 0.02883
Total Iteration Time: 4.79427

Cumulative Model Updates: 2544
Cumulative Timesteps: 42469950

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09743
Policy Entropy: 1.01979
Value Function Loss: 0.06745

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.08710

Collected Steps per Second: 13850.67931
Overall Steps per Second: 11386.98148

Timestep Collection Time: 3.61311
Timestep Consumption Time: 0.78174
PPO Batch Consumption Time: 0.02613
Total Iteration Time: 4.39484

Cumulative Model Updates: 2547
Cumulative Timesteps: 42519994

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 42519994...
Checkpoint 42519994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04594
Policy Entropy: 0.98326
Value Function Loss: 0.05744

Mean KL Divergence: 0.06444
SB3 Clip Fraction: 0.24807
Policy Update Magnitude: 0.04675
Value Function Update Magnitude: 0.08615

Collected Steps per Second: 13783.58075
Overall Steps per Second: 11506.39493

Timestep Collection Time: 3.63128
Timestep Consumption Time: 0.71865
PPO Batch Consumption Time: 0.02582
Total Iteration Time: 4.34993

Cumulative Model Updates: 2550
Cumulative Timesteps: 42570046

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00027
Policy Entropy: 1.00710
Value Function Loss: 0.07388

Mean KL Divergence: 0.03411
SB3 Clip Fraction: 0.17869
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.08240

Collected Steps per Second: 14149.14336
Overall Steps per Second: 11616.42422

Timestep Collection Time: 3.53491
Timestep Consumption Time: 0.77071
PPO Batch Consumption Time: 0.02425
Total Iteration Time: 4.30563

Cumulative Model Updates: 2553
Cumulative Timesteps: 42620062

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 42620062...
Checkpoint 42620062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06630
Policy Entropy: 1.01773
Value Function Loss: 0.06614

Mean KL Divergence: 0.04004
SB3 Clip Fraction: 0.22191
Policy Update Magnitude: 0.04389
Value Function Update Magnitude: 0.08165

Collected Steps per Second: 13989.65041
Overall Steps per Second: 11493.00184

Timestep Collection Time: 3.57421
Timestep Consumption Time: 0.77643
PPO Batch Consumption Time: 0.02857
Total Iteration Time: 4.35065

Cumulative Model Updates: 2556
Cumulative Timesteps: 42670064

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06967
Policy Entropy: 0.99353
Value Function Loss: 0.08274

Mean KL Divergence: 0.03850
SB3 Clip Fraction: 0.18431
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.08540

Collected Steps per Second: 14166.47914
Overall Steps per Second: 11595.55996

Timestep Collection Time: 3.53129
Timestep Consumption Time: 0.78294
PPO Batch Consumption Time: 0.02544
Total Iteration Time: 4.31424

Cumulative Model Updates: 2559
Cumulative Timesteps: 42720090

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 42720090...
Checkpoint 42720090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04062
Policy Entropy: 0.94693
Value Function Loss: 0.08168

Mean KL Divergence: 0.12632
SB3 Clip Fraction: 0.32317
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.08636

Collected Steps per Second: 13719.98568
Overall Steps per Second: 11297.47522

Timestep Collection Time: 3.64461
Timestep Consumption Time: 0.78151
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 4.42612

Cumulative Model Updates: 2562
Cumulative Timesteps: 42770094

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01721
Policy Entropy: 1.02429
Value Function Loss: 0.07904

Mean KL Divergence: 0.11006
SB3 Clip Fraction: 0.34129
Policy Update Magnitude: 0.05369
Value Function Update Magnitude: 0.09046

Collected Steps per Second: 13594.31793
Overall Steps per Second: 11465.40156

Timestep Collection Time: 3.67830
Timestep Consumption Time: 0.68299
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 4.36130

Cumulative Model Updates: 2565
Cumulative Timesteps: 42820098

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 42820098...
Checkpoint 42820098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04154
Policy Entropy: 0.99496
Value Function Loss: 0.07501

Mean KL Divergence: 0.10283
SB3 Clip Fraction: 0.30968
Policy Update Magnitude: 0.05950
Value Function Update Magnitude: 0.08810

Collected Steps per Second: 13878.46032
Overall Steps per Second: 11437.53720

Timestep Collection Time: 3.60357
Timestep Consumption Time: 0.76905
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 4.37262

Cumulative Model Updates: 2568
Cumulative Timesteps: 42870110

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04189
Policy Entropy: 1.03861
Value Function Loss: 0.05941

Mean KL Divergence: 0.08646
SB3 Clip Fraction: 0.29125
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.08828

Collected Steps per Second: 13993.82914
Overall Steps per Second: 11473.94515

Timestep Collection Time: 3.57358
Timestep Consumption Time: 0.78482
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 4.35840

Cumulative Model Updates: 2571
Cumulative Timesteps: 42920118

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 42920118...
Checkpoint 42920118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03323
Policy Entropy: 0.99757
Value Function Loss: 0.04120

Mean KL Divergence: 0.08654
SB3 Clip Fraction: 0.28085
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.08228

Collected Steps per Second: 14162.03960
Overall Steps per Second: 11649.80490

Timestep Collection Time: 3.53099
Timestep Consumption Time: 0.76144
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 4.29243

Cumulative Model Updates: 2574
Cumulative Timesteps: 42970124

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00608
Policy Entropy: 1.02797
Value Function Loss: 0.03822

Mean KL Divergence: 0.04046
SB3 Clip Fraction: 0.18923
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.07715

Collected Steps per Second: 13849.94317
Overall Steps per Second: 11421.27398

Timestep Collection Time: 3.61041
Timestep Consumption Time: 0.76773
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 4.37815

Cumulative Model Updates: 2577
Cumulative Timesteps: 43020128

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 43020128...
Checkpoint 43020128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00961
Policy Entropy: 1.04056
Value Function Loss: 0.03039

Mean KL Divergence: 0.04358
SB3 Clip Fraction: 0.23091
Policy Update Magnitude: 0.04466
Value Function Update Magnitude: 0.08723

Collected Steps per Second: 14054.83165
Overall Steps per Second: 11755.41402

Timestep Collection Time: 3.55821
Timestep Consumption Time: 0.69600
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 4.25421

Cumulative Model Updates: 2580
Cumulative Timesteps: 43070138

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01663
Policy Entropy: 0.98819
Value Function Loss: 0.04614

Mean KL Divergence: 0.05230
SB3 Clip Fraction: 0.20300
Policy Update Magnitude: 0.04530
Value Function Update Magnitude: 0.08888

Collected Steps per Second: 14040.38899
Overall Steps per Second: 11586.44074

Timestep Collection Time: 3.56472
Timestep Consumption Time: 0.75499
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 4.31970

Cumulative Model Updates: 2583
Cumulative Timesteps: 43120188

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 43120188...
Checkpoint 43120188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00950
Policy Entropy: 1.01412
Value Function Loss: 0.06097

Mean KL Divergence: 0.04150
SB3 Clip Fraction: 0.21751
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.08218

Collected Steps per Second: 13974.04560
Overall Steps per Second: 11573.33735

Timestep Collection Time: 3.57878
Timestep Consumption Time: 0.74236
PPO Batch Consumption Time: 0.02440
Total Iteration Time: 4.32114

Cumulative Model Updates: 2586
Cumulative Timesteps: 43170198

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02751
Policy Entropy: 1.01687
Value Function Loss: 0.07098

Mean KL Divergence: 0.03629
SB3 Clip Fraction: 0.20963
Policy Update Magnitude: 0.04226
Value Function Update Magnitude: 0.07528

Collected Steps per Second: 14284.18421
Overall Steps per Second: 11703.60612

Timestep Collection Time: 3.50065
Timestep Consumption Time: 0.77187
PPO Batch Consumption Time: 0.02611
Total Iteration Time: 4.27253

Cumulative Model Updates: 2589
Cumulative Timesteps: 43220202

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 43220202...
Checkpoint 43220202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05734
Policy Entropy: 1.00228
Value Function Loss: 0.06172

Mean KL Divergence: 0.03201
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.04521
Value Function Update Magnitude: 0.07641

Collected Steps per Second: 13640.94719
Overall Steps per Second: 11277.47677

Timestep Collection Time: 3.66631
Timestep Consumption Time: 0.76837
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 4.43468

Cumulative Model Updates: 2592
Cumulative Timesteps: 43270214

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00299
Policy Entropy: 0.94600
Value Function Loss: 0.05747

Mean KL Divergence: 0.13737
SB3 Clip Fraction: 0.34031
Policy Update Magnitude: 0.04012
Value Function Update Magnitude: 0.07482

Collected Steps per Second: 13970.32547
Overall Steps per Second: 11723.46539

Timestep Collection Time: 3.58131
Timestep Consumption Time: 0.68637
PPO Batch Consumption Time: 0.02629
Total Iteration Time: 4.26768

Cumulative Model Updates: 2595
Cumulative Timesteps: 43320246

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 43320246...
Checkpoint 43320246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00026
Policy Entropy: 1.00592
Value Function Loss: 0.06312

Mean KL Divergence: 0.09100
SB3 Clip Fraction: 0.32150
Policy Update Magnitude: 0.03778
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 14018.30146
Overall Steps per Second: 11428.16702

Timestep Collection Time: 3.56962
Timestep Consumption Time: 0.80904
PPO Batch Consumption Time: 0.02872
Total Iteration Time: 4.37865

Cumulative Model Updates: 2598
Cumulative Timesteps: 43370286

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00077
Policy Entropy: 0.96542
Value Function Loss: 0.07958

Mean KL Divergence: 0.10155
SB3 Clip Fraction: 0.30415
Policy Update Magnitude: 0.03599
Value Function Update Magnitude: 0.07461

Collected Steps per Second: 14021.96087
Overall Steps per Second: 11593.33747

Timestep Collection Time: 3.56626
Timestep Consumption Time: 0.74708
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 4.31334

Cumulative Model Updates: 2601
Cumulative Timesteps: 43420292

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 43420292...
Checkpoint 43420292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04682
Policy Entropy: 1.01975
Value Function Loss: 0.08866

Mean KL Divergence: 0.09762
SB3 Clip Fraction: 0.31644
Policy Update Magnitude: 0.03846
Value Function Update Magnitude: 0.07956

Collected Steps per Second: 14214.57300
Overall Steps per Second: 11672.65770

Timestep Collection Time: 3.52005
Timestep Consumption Time: 0.76655
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 4.28660

Cumulative Model Updates: 2604
Cumulative Timesteps: 43470328

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04492
Policy Entropy: 0.96748
Value Function Loss: 0.08040

Mean KL Divergence: 0.12527
SB3 Clip Fraction: 0.32428
Policy Update Magnitude: 0.04184
Value Function Update Magnitude: 0.07831

Collected Steps per Second: 12344.41177
Overall Steps per Second: 10125.54904

Timestep Collection Time: 4.05317
Timestep Consumption Time: 0.88819
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 4.94136

Cumulative Model Updates: 2607
Cumulative Timesteps: 43520362

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 43520362...
Checkpoint 43520362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15604
Policy Entropy: 1.01793
Value Function Loss: 0.05492

Mean KL Divergence: 0.09097
SB3 Clip Fraction: 0.31011
Policy Update Magnitude: 0.03836
Value Function Update Magnitude: 0.07702

Collected Steps per Second: 11234.56289
Overall Steps per Second: 9546.29166

Timestep Collection Time: 4.45180
Timestep Consumption Time: 0.78730
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 5.23910

Cumulative Model Updates: 2610
Cumulative Timesteps: 43570376

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01677
Policy Entropy: 0.97772
Value Function Loss: 0.03506

Mean KL Divergence: 0.08359
SB3 Clip Fraction: 0.28569
Policy Update Magnitude: 0.03666
Value Function Update Magnitude: 0.06697

Collected Steps per Second: 13516.96130
Overall Steps per Second: 11080.75737

Timestep Collection Time: 3.70113
Timestep Consumption Time: 0.81373
PPO Batch Consumption Time: 0.02970
Total Iteration Time: 4.51485

Cumulative Model Updates: 2613
Cumulative Timesteps: 43620404

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 43620404...
Checkpoint 43620404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00291
Policy Entropy: 1.01617
Value Function Loss: 0.03816

Mean KL Divergence: 0.03568
SB3 Clip Fraction: 0.20205
Policy Update Magnitude: 0.03500
Value Function Update Magnitude: 0.06316

Collected Steps per Second: 12822.48033
Overall Steps per Second: 10631.23515

Timestep Collection Time: 3.90237
Timestep Consumption Time: 0.80433
PPO Batch Consumption Time: 0.03091
Total Iteration Time: 4.70670

Cumulative Model Updates: 2616
Cumulative Timesteps: 43670442

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00825
Policy Entropy: 0.99195
Value Function Loss: 0.04513

Mean KL Divergence: 0.03934
SB3 Clip Fraction: 0.21803
Policy Update Magnitude: 0.03488
Value Function Update Magnitude: 0.07084

Collected Steps per Second: 12330.58639
Overall Steps per Second: 10439.60557

Timestep Collection Time: 4.05771
Timestep Consumption Time: 0.73500
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 4.79271

Cumulative Model Updates: 2619
Cumulative Timesteps: 43720476

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 43720476...
Checkpoint 43720476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04064
Policy Entropy: 0.99368
Value Function Loss: 0.04371

Mean KL Divergence: 0.03844
SB3 Clip Fraction: 0.22333
Policy Update Magnitude: 0.03766
Value Function Update Magnitude: 0.08001

Collected Steps per Second: 12909.06990
Overall Steps per Second: 10691.48321

Timestep Collection Time: 3.87526
Timestep Consumption Time: 0.80379
PPO Batch Consumption Time: 0.02634
Total Iteration Time: 4.67905

Cumulative Model Updates: 2622
Cumulative Timesteps: 43770502

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03689
Policy Entropy: 1.02103
Value Function Loss: 0.03152

Mean KL Divergence: 0.02986
SB3 Clip Fraction: 0.17143
Policy Update Magnitude: 0.04097
Value Function Update Magnitude: 0.07777

Collected Steps per Second: 12902.76960
Overall Steps per Second: 10730.91677

Timestep Collection Time: 3.87576
Timestep Consumption Time: 0.78442
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 4.66018

Cumulative Model Updates: 2625
Cumulative Timesteps: 43820510

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 43820510...
Checkpoint 43820510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02884
Policy Entropy: 1.02785
Value Function Loss: 0.02714

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.17457
Policy Update Magnitude: 0.04045
Value Function Update Magnitude: 0.07030

Collected Steps per Second: 13294.70306
Overall Steps per Second: 10897.94066

Timestep Collection Time: 3.76240
Timestep Consumption Time: 0.82746
PPO Batch Consumption Time: 0.02570
Total Iteration Time: 4.58986

Cumulative Model Updates: 2628
Cumulative Timesteps: 43870530

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01110
Policy Entropy: 0.99907
Value Function Loss: 0.04619

Mean KL Divergence: 0.03067
SB3 Clip Fraction: 0.18932
Policy Update Magnitude: 0.03661
Value Function Update Magnitude: 0.06926

Collected Steps per Second: 12715.96203
Overall Steps per Second: 10536.74252

Timestep Collection Time: 3.93458
Timestep Consumption Time: 0.81375
PPO Batch Consumption Time: 0.02908
Total Iteration Time: 4.74834

Cumulative Model Updates: 2631
Cumulative Timesteps: 43920562

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 43920562...
Checkpoint 43920562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01889
Policy Entropy: 0.96911
Value Function Loss: 0.04776

Mean KL Divergence: 0.05903
SB3 Clip Fraction: 0.27123
Policy Update Magnitude: 0.03574
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 12905.72120
Overall Steps per Second: 10862.38528

Timestep Collection Time: 3.87425
Timestep Consumption Time: 0.72879
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 4.60304

Cumulative Model Updates: 2634
Cumulative Timesteps: 43970562

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00399
Policy Entropy: 1.01599
Value Function Loss: 0.04784

Mean KL Divergence: 0.02989
SB3 Clip Fraction: 0.20047
Policy Update Magnitude: 0.03460
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 13034.93636
Overall Steps per Second: 10785.56873

Timestep Collection Time: 3.83861
Timestep Consumption Time: 0.80055
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 4.63916

Cumulative Model Updates: 2637
Cumulative Timesteps: 44020598

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 44020598...
Checkpoint 44020598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00937
Policy Entropy: 0.97133
Value Function Loss: 0.03041

Mean KL Divergence: 0.02734
SB3 Clip Fraction: 0.19737
Policy Update Magnitude: 0.03343
Value Function Update Magnitude: 0.07169

Collected Steps per Second: 12738.56152
Overall Steps per Second: 10624.28492

Timestep Collection Time: 3.92729
Timestep Consumption Time: 0.78155
PPO Batch Consumption Time: 0.02914
Total Iteration Time: 4.70883

Cumulative Model Updates: 2640
Cumulative Timesteps: 44070626

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01929
Policy Entropy: 0.97474
Value Function Loss: 0.04166

Mean KL Divergence: 0.02829
SB3 Clip Fraction: 0.19752
Policy Update Magnitude: 0.03555
Value Function Update Magnitude: 0.05752

Collected Steps per Second: 13229.33706
Overall Steps per Second: 10836.77582

Timestep Collection Time: 3.78069
Timestep Consumption Time: 0.83471
PPO Batch Consumption Time: 0.02741
Total Iteration Time: 4.61539

Cumulative Model Updates: 2643
Cumulative Timesteps: 44120642

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 44120642...
Checkpoint 44120642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06216
Policy Entropy: 1.00470
Value Function Loss: 0.04674

Mean KL Divergence: 0.04640
SB3 Clip Fraction: 0.21990
Policy Update Magnitude: 0.03922
Value Function Update Magnitude: 0.05923

Collected Steps per Second: 13209.48074
Overall Steps per Second: 10779.52359

Timestep Collection Time: 3.78546
Timestep Consumption Time: 0.85333
PPO Batch Consumption Time: 0.03466
Total Iteration Time: 4.63879

Cumulative Model Updates: 2646
Cumulative Timesteps: 44170646

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02230
Policy Entropy: 1.01793
Value Function Loss: 0.04559

Mean KL Divergence: 0.04218
SB3 Clip Fraction: 0.22920
Policy Update Magnitude: 0.03854
Value Function Update Magnitude: 0.06884

Collected Steps per Second: 12985.07217
Overall Steps per Second: 10741.17824

Timestep Collection Time: 3.85289
Timestep Consumption Time: 0.80489
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 4.65778

Cumulative Model Updates: 2649
Cumulative Timesteps: 44220676

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 44220676...
Checkpoint 44220676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00758
Policy Entropy: 0.99068
Value Function Loss: 0.04472

Mean KL Divergence: 0.03243
SB3 Clip Fraction: 0.16189
Policy Update Magnitude: 0.03727
Value Function Update Magnitude: 0.07267

Collected Steps per Second: 13274.14865
Overall Steps per Second: 10932.78204

Timestep Collection Time: 3.76943
Timestep Consumption Time: 0.80726
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 4.57669

Cumulative Model Updates: 2652
Cumulative Timesteps: 44270712

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05086
Policy Entropy: 1.01411
Value Function Loss: 0.05857

Mean KL Divergence: 0.03158
SB3 Clip Fraction: 0.19571
Policy Update Magnitude: 0.03807
Value Function Update Magnitude: 0.07157

Collected Steps per Second: 12874.92236
Overall Steps per Second: 10606.91582

Timestep Collection Time: 3.88492
Timestep Consumption Time: 0.83069
PPO Batch Consumption Time: 0.02869
Total Iteration Time: 4.71560

Cumulative Model Updates: 2655
Cumulative Timesteps: 44320730

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 44320730...
Checkpoint 44320730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05849
Policy Entropy: 1.03562
Value Function Loss: 0.05939

Mean KL Divergence: 0.04707
SB3 Clip Fraction: 0.24113
Policy Update Magnitude: 0.03875
Value Function Update Magnitude: 0.07576

Collected Steps per Second: 13066.29964
Overall Steps per Second: 10952.97404

Timestep Collection Time: 3.82955
Timestep Consumption Time: 0.73889
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 4.56844

Cumulative Model Updates: 2658
Cumulative Timesteps: 44370768

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01664
Policy Entropy: 0.99931
Value Function Loss: 0.04864

Mean KL Divergence: 0.04773
SB3 Clip Fraction: 0.21722
Policy Update Magnitude: 0.03562
Value Function Update Magnitude: 0.07669

Collected Steps per Second: 12961.32719
Overall Steps per Second: 10725.83407

Timestep Collection Time: 3.85994
Timestep Consumption Time: 0.80449
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 4.66444

Cumulative Model Updates: 2661
Cumulative Timesteps: 44420798

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 44420798...
Checkpoint 44420798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07238
Policy Entropy: 1.04062
Value Function Loss: 0.03938

Mean KL Divergence: 0.03038
SB3 Clip Fraction: 0.18273
Policy Update Magnitude: 0.03552
Value Function Update Magnitude: 0.06797

Collected Steps per Second: 13045.12425
Overall Steps per Second: 10797.91105

Timestep Collection Time: 3.83331
Timestep Consumption Time: 0.79777
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 4.63108

Cumulative Model Updates: 2664
Cumulative Timesteps: 44470804

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04363
Policy Entropy: 1.02936
Value Function Loss: 0.04288

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.14814
Policy Update Magnitude: 0.03941
Value Function Update Magnitude: 0.06574

Collected Steps per Second: 13228.29258
Overall Steps per Second: 10900.90322

Timestep Collection Time: 3.78205
Timestep Consumption Time: 0.80748
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 4.58953

Cumulative Model Updates: 2667
Cumulative Timesteps: 44520834

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 44520834...
Checkpoint 44520834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04272
Policy Entropy: 1.01306
Value Function Loss: 0.03604

Mean KL Divergence: 0.02535
SB3 Clip Fraction: 0.15077
Policy Update Magnitude: 0.04180
Value Function Update Magnitude: 0.06994

Collected Steps per Second: 12493.49893
Overall Steps per Second: 10329.41849

Timestep Collection Time: 4.00448
Timestep Consumption Time: 0.83897
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.84345

Cumulative Model Updates: 2670
Cumulative Timesteps: 44570864

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02035
Policy Entropy: 0.98510
Value Function Loss: 0.02667

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.15819
Policy Update Magnitude: 0.03954
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 12888.77088
Overall Steps per Second: 10823.35049

Timestep Collection Time: 3.87935
Timestep Consumption Time: 0.74030
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 4.61964

Cumulative Model Updates: 2673
Cumulative Timesteps: 44620864

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 44620864...
Checkpoint 44620864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04800
Policy Entropy: 0.98957
Value Function Loss: 0.02164

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.03767
Value Function Update Magnitude: 0.06509

Collected Steps per Second: 12787.83223
Overall Steps per Second: 10588.66402

Timestep Collection Time: 3.91200
Timestep Consumption Time: 0.81249
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.72449

Cumulative Model Updates: 2676
Cumulative Timesteps: 44670890

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00863
Policy Entropy: 0.99145
Value Function Loss: 0.03603

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12041
Policy Update Magnitude: 0.03806
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 13225.92997
Overall Steps per Second: 10932.91554

Timestep Collection Time: 3.78272
Timestep Consumption Time: 0.79337
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 4.57609

Cumulative Model Updates: 2679
Cumulative Timesteps: 44720920

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 44720920...
Checkpoint 44720920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01318
Policy Entropy: 0.99116
Value Function Loss: 0.03491

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.04102
Value Function Update Magnitude: 0.06950

Collected Steps per Second: 13500.13294
Overall Steps per Second: 11052.11817

Timestep Collection Time: 3.70470
Timestep Consumption Time: 0.82058
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 4.52529

Cumulative Model Updates: 2682
Cumulative Timesteps: 44770934

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07661
Policy Entropy: 0.99226
Value Function Loss: 0.06148

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.04155
Value Function Update Magnitude: 0.06836

Collected Steps per Second: 12864.70309
Overall Steps per Second: 10625.16924

Timestep Collection Time: 3.88723
Timestep Consumption Time: 0.81933
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 4.70656

Cumulative Model Updates: 2685
Cumulative Timesteps: 44820942

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 44820942...
Checkpoint 44820942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01208
Policy Entropy: 0.98520
Value Function Loss: 0.05093

Mean KL Divergence: 0.02902
SB3 Clip Fraction: 0.18397
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.06812

Collected Steps per Second: 12847.67027
Overall Steps per Second: 10589.09743

Timestep Collection Time: 3.89518
Timestep Consumption Time: 0.83081
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 4.72599

Cumulative Model Updates: 2688
Cumulative Timesteps: 44870986

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05910
Policy Entropy: 1.03109
Value Function Loss: 0.05049

Mean KL Divergence: 0.03528
SB3 Clip Fraction: 0.22013
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.06966

Collected Steps per Second: 13385.00941
Overall Steps per Second: 10999.73764

Timestep Collection Time: 3.73791
Timestep Consumption Time: 0.81056
PPO Batch Consumption Time: 0.02693
Total Iteration Time: 4.54847

Cumulative Model Updates: 2691
Cumulative Timesteps: 44921018

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 44921018...
Checkpoint 44921018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03463
Policy Entropy: 0.99337
Value Function Loss: 0.02799

Mean KL Divergence: 0.05871
SB3 Clip Fraction: 0.24833
Policy Update Magnitude: 0.04175
Value Function Update Magnitude: 0.06449

Collected Steps per Second: 12956.16843
Overall Steps per Second: 10790.09339

Timestep Collection Time: 3.86055
Timestep Consumption Time: 0.77499
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 4.63555

Cumulative Model Updates: 2694
Cumulative Timesteps: 44971036

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00980
Policy Entropy: 1.00208
Value Function Loss: 0.04102

Mean KL Divergence: 0.05389
SB3 Clip Fraction: 0.25271
Policy Update Magnitude: 0.04082
Value Function Update Magnitude: 0.06973

Collected Steps per Second: 12888.82671
Overall Steps per Second: 10820.25307

Timestep Collection Time: 3.88181
Timestep Consumption Time: 0.74211
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 4.62392

Cumulative Model Updates: 2697
Cumulative Timesteps: 45021068

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 45021068...
Checkpoint 45021068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03773
Policy Entropy: 1.02815
Value Function Loss: 0.04275

Mean KL Divergence: 0.05395
SB3 Clip Fraction: 0.22715
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.07557

Collected Steps per Second: 12842.61455
Overall Steps per Second: 10625.46896

Timestep Collection Time: 3.89500
Timestep Consumption Time: 0.81274
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 4.70775

Cumulative Model Updates: 2700
Cumulative Timesteps: 45071090

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07505
Policy Entropy: 1.01283
Value Function Loss: 0.03111

Mean KL Divergence: 0.04574
SB3 Clip Fraction: 0.23115
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.07343

Collected Steps per Second: 13071.02050
Overall Steps per Second: 10839.30858

Timestep Collection Time: 3.82862
Timestep Consumption Time: 0.78828
PPO Batch Consumption Time: 0.02679
Total Iteration Time: 4.61690

Cumulative Model Updates: 2703
Cumulative Timesteps: 45121134

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 45121134...
Checkpoint 45121134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00611
Policy Entropy: 0.98327
Value Function Loss: 0.02166

Mean KL Divergence: 0.09331
SB3 Clip Fraction: 0.28592
Policy Update Magnitude: 0.04130
Value Function Update Magnitude: 0.06063

Collected Steps per Second: 13425.08158
Overall Steps per Second: 11073.47258

Timestep Collection Time: 3.72527
Timestep Consumption Time: 0.79111
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 4.51638

Cumulative Model Updates: 2706
Cumulative Timesteps: 45171146

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03009
Policy Entropy: 1.00126
Value Function Loss: 0.01660

Mean KL Divergence: 0.04035
SB3 Clip Fraction: 0.18953
Policy Update Magnitude: 0.04143
Value Function Update Magnitude: 0.04921

Collected Steps per Second: 12389.49266
Overall Steps per Second: 10289.66015

Timestep Collection Time: 4.03939
Timestep Consumption Time: 0.82433
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 4.86372

Cumulative Model Updates: 2709
Cumulative Timesteps: 45221192

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 45221192...
Checkpoint 45221192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00494
Policy Entropy: 0.98996
Value Function Loss: 0.03536

Mean KL Divergence: 0.04199
SB3 Clip Fraction: 0.22887
Policy Update Magnitude: 0.05306
Value Function Update Magnitude: 0.05072

Collected Steps per Second: 13163.29390
Overall Steps per Second: 11063.72263

Timestep Collection Time: 3.80102
Timestep Consumption Time: 0.72132
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 4.52235

Cumulative Model Updates: 2712
Cumulative Timesteps: 45271226

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00386
Policy Entropy: 0.94710
Value Function Loss: 0.04644

Mean KL Divergence: 0.07250
SB3 Clip Fraction: 0.24483
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.05341

Collected Steps per Second: 12675.67288
Overall Steps per Second: 10503.29952

Timestep Collection Time: 3.94819
Timestep Consumption Time: 0.81660
PPO Batch Consumption Time: 0.02903
Total Iteration Time: 4.76479

Cumulative Model Updates: 2715
Cumulative Timesteps: 45321272

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 45321272...
Checkpoint 45321272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04869
Policy Entropy: 0.99097
Value Function Loss: 0.05878

Mean KL Divergence: 0.03476
SB3 Clip Fraction: 0.23143
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.06647

Collected Steps per Second: 12815.83469
Overall Steps per Second: 10630.33345

Timestep Collection Time: 3.90189
Timestep Consumption Time: 0.80219
PPO Batch Consumption Time: 0.02814
Total Iteration Time: 4.70409

Cumulative Model Updates: 2718
Cumulative Timesteps: 45371278

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02171
Policy Entropy: 0.95823
Value Function Loss: 0.04959

Mean KL Divergence: 0.04565
SB3 Clip Fraction: 0.25625
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.06445

Collected Steps per Second: 13360.32158
Overall Steps per Second: 11022.38082

Timestep Collection Time: 3.74392
Timestep Consumption Time: 0.79412
PPO Batch Consumption Time: 0.02589
Total Iteration Time: 4.53804

Cumulative Model Updates: 2721
Cumulative Timesteps: 45421298

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 45421298...
Checkpoint 45421298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03038
Policy Entropy: 0.96188
Value Function Loss: 0.07093

Mean KL Divergence: 0.03688
SB3 Clip Fraction: 0.21035
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.05837

Collected Steps per Second: 13034.04527
Overall Steps per Second: 10758.80390

Timestep Collection Time: 3.83856
Timestep Consumption Time: 0.81177
PPO Batch Consumption Time: 0.02568
Total Iteration Time: 4.65033

Cumulative Model Updates: 2724
Cumulative Timesteps: 45471330

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02861
Policy Entropy: 0.95176
Value Function Loss: 0.06683

Mean KL Divergence: 0.02718
SB3 Clip Fraction: 0.20696
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.06388

Collected Steps per Second: 13046.72560
Overall Steps per Second: 10850.85803

Timestep Collection Time: 3.83636
Timestep Consumption Time: 0.77636
PPO Batch Consumption Time: 0.02843
Total Iteration Time: 4.61272

Cumulative Model Updates: 2727
Cumulative Timesteps: 45521382

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 45521382...
Checkpoint 45521382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14473
Policy Entropy: 0.96635
Value Function Loss: 0.05764

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.16263
Policy Update Magnitude: 0.04762
Value Function Update Magnitude: 0.07168

Collected Steps per Second: 12919.85973
Overall Steps per Second: 10667.20720

Timestep Collection Time: 3.87079
Timestep Consumption Time: 0.81741
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 4.68820

Cumulative Model Updates: 2730
Cumulative Timesteps: 45571392

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00284
Policy Entropy: 0.97314
Value Function Loss: 0.03601

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 12819.77274
Overall Steps per Second: 10618.70993

Timestep Collection Time: 3.90179
Timestep Consumption Time: 0.80877
PPO Batch Consumption Time: 0.03113
Total Iteration Time: 4.71055

Cumulative Model Updates: 2733
Cumulative Timesteps: 45621412

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 45621412...
Checkpoint 45621412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00726
Policy Entropy: 0.96261
Value Function Loss: 0.02486

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.05812
Value Function Update Magnitude: 0.05730

Collected Steps per Second: 13479.50978
Overall Steps per Second: 11055.66431

Timestep Collection Time: 3.71260
Timestep Consumption Time: 0.81395
PPO Batch Consumption Time: 0.02914
Total Iteration Time: 4.52655

Cumulative Model Updates: 2736
Cumulative Timesteps: 45671456

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00106
Policy Entropy: 0.95582
Value Function Loss: 0.03046

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.05287

Collected Steps per Second: 12983.98832
Overall Steps per Second: 10716.21450

Timestep Collection Time: 3.85290
Timestep Consumption Time: 0.81535
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 4.66825

Cumulative Model Updates: 2739
Cumulative Timesteps: 45721482

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 45721482...
Checkpoint 45721482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02211
Policy Entropy: 0.93269
Value Function Loss: 0.03163

Mean KL Divergence: 0.03276
SB3 Clip Fraction: 0.21733
Policy Update Magnitude: 0.04272
Value Function Update Magnitude: 0.05757

Collected Steps per Second: 13053.38440
Overall Steps per Second: 10954.00032

Timestep Collection Time: 3.83226
Timestep Consumption Time: 0.73447
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 4.56673

Cumulative Model Updates: 2742
Cumulative Timesteps: 45771506

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00612
Policy Entropy: 0.97804
Value Function Loss: 0.04179

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.19511
Policy Update Magnitude: 0.03644
Value Function Update Magnitude: 0.06641

Collected Steps per Second: 12677.15965
Overall Steps per Second: 10530.64107

Timestep Collection Time: 3.94710
Timestep Consumption Time: 0.80456
PPO Batch Consumption Time: 0.02548
Total Iteration Time: 4.75166

Cumulative Model Updates: 2745
Cumulative Timesteps: 45821544

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 45821544...
Checkpoint 45821544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04093
Policy Entropy: 0.97706
Value Function Loss: 0.03816

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.03709
Value Function Update Magnitude: 0.06151

Collected Steps per Second: 12466.87904
Overall Steps per Second: 10405.12601

Timestep Collection Time: 4.01111
Timestep Consumption Time: 0.79479
PPO Batch Consumption Time: 0.02991
Total Iteration Time: 4.80590

Cumulative Model Updates: 2748
Cumulative Timesteps: 45871550

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02686
Policy Entropy: 0.96738
Value Function Loss: 0.04899

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.04292
Value Function Update Magnitude: 0.07082

Collected Steps per Second: 13257.97838
Overall Steps per Second: 10890.19483

Timestep Collection Time: 3.77282
Timestep Consumption Time: 0.82030
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 4.59312

Cumulative Model Updates: 2751
Cumulative Timesteps: 45921570

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 45921570...
Checkpoint 45921570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04405
Policy Entropy: 0.93553
Value Function Loss: 0.07443

Mean KL Divergence: 0.04431
SB3 Clip Fraction: 0.25431
Policy Update Magnitude: 0.04489
Value Function Update Magnitude: 0.08094

Collected Steps per Second: 12877.61041
Overall Steps per Second: 10665.23466

Timestep Collection Time: 3.88504
Timestep Consumption Time: 0.80590
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 4.69094

Cumulative Model Updates: 2754
Cumulative Timesteps: 45971600

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00091
Policy Entropy: 0.96427
Value Function Loss: 0.08047

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.16202
Policy Update Magnitude: 0.03931
Value Function Update Magnitude: 0.08013

Collected Steps per Second: 13091.71405
Overall Steps per Second: 10848.59656

Timestep Collection Time: 3.81921
Timestep Consumption Time: 0.78968
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 4.60889

Cumulative Model Updates: 2757
Cumulative Timesteps: 46021600

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 46021600...
Checkpoint 46021600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01191
Policy Entropy: 0.97418
Value Function Loss: 0.06932

Mean KL Divergence: 0.03106
SB3 Clip Fraction: 0.23168
Policy Update Magnitude: 0.03671
Value Function Update Magnitude: 0.08240

Collected Steps per Second: 13287.09322
Overall Steps per Second: 10929.23040

Timestep Collection Time: 3.76395
Timestep Consumption Time: 0.81203
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 4.57599

Cumulative Model Updates: 2760
Cumulative Timesteps: 46071612

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00773
Policy Entropy: 0.94596
Value Function Loss: 0.05486

Mean KL Divergence: 0.02614
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.08507

Collected Steps per Second: 12994.78248
Overall Steps per Second: 10786.26159

Timestep Collection Time: 3.85001
Timestep Consumption Time: 0.78830
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 4.63831

Cumulative Model Updates: 2763
Cumulative Timesteps: 46121642

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 46121642...
Checkpoint 46121642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02627
Policy Entropy: 0.91111
Value Function Loss: 0.05506

Mean KL Divergence: 0.06020
SB3 Clip Fraction: 0.29069
Policy Update Magnitude: 0.03969
Value Function Update Magnitude: 0.08487

Collected Steps per Second: 12936.27052
Overall Steps per Second: 10947.35199

Timestep Collection Time: 3.86696
Timestep Consumption Time: 0.70255
PPO Batch Consumption Time: 0.02566
Total Iteration Time: 4.56951

Cumulative Model Updates: 2766
Cumulative Timesteps: 46171666

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03115
Policy Entropy: 0.95463
Value Function Loss: 0.05197

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11853
Policy Update Magnitude: 0.03885
Value Function Update Magnitude: 0.09041

Collected Steps per Second: 13009.73588
Overall Steps per Second: 10728.60618

Timestep Collection Time: 3.84358
Timestep Consumption Time: 0.81723
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 4.66081

Cumulative Model Updates: 2769
Cumulative Timesteps: 46221670

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 46221670...
Checkpoint 46221670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02377
Policy Entropy: 0.91501
Value Function Loss: 0.03692

Mean KL Divergence: 0.04544
SB3 Clip Fraction: 0.24589
Policy Update Magnitude: 0.03932
Value Function Update Magnitude: 0.08221

Collected Steps per Second: 13188.57445
Overall Steps per Second: 10954.15998

Timestep Collection Time: 3.79192
Timestep Consumption Time: 0.77347
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 4.56539

Cumulative Model Updates: 2772
Cumulative Timesteps: 46271680

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04240
Policy Entropy: 0.91585
Value Function Loss: 0.05207

Mean KL Divergence: 0.04354
SB3 Clip Fraction: 0.24486
Policy Update Magnitude: 0.03519
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 12940.59468
Overall Steps per Second: 10730.57126

Timestep Collection Time: 3.86613
Timestep Consumption Time: 0.79625
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 4.66238

Cumulative Model Updates: 2775
Cumulative Timesteps: 46321710

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 46321710...
Checkpoint 46321710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01717
Policy Entropy: 0.93372
Value Function Loss: 0.05173

Mean KL Divergence: 0.04200
SB3 Clip Fraction: 0.20959
Policy Update Magnitude: 0.03645
Value Function Update Magnitude: 0.06619

Collected Steps per Second: 13150.99331
Overall Steps per Second: 10882.40989

Timestep Collection Time: 3.80519
Timestep Consumption Time: 0.79324
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 4.59843

Cumulative Model Updates: 2778
Cumulative Timesteps: 46371752

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01877
Policy Entropy: 0.93218
Value Function Loss: 0.04969

Mean KL Divergence: 0.03876
SB3 Clip Fraction: 0.23162
Policy Update Magnitude: 0.03257
Value Function Update Magnitude: 0.07399

Collected Steps per Second: 13005.04343
Overall Steps per Second: 10970.59692

Timestep Collection Time: 3.84789
Timestep Consumption Time: 0.71357
PPO Batch Consumption Time: 0.02605
Total Iteration Time: 4.56147

Cumulative Model Updates: 2781
Cumulative Timesteps: 46421794

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 46421794...
Checkpoint 46421794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04835
Policy Entropy: 0.87599
Value Function Loss: 0.05088

Mean KL Divergence: 0.08923
SB3 Clip Fraction: 0.30251
Policy Update Magnitude: 0.03703
Value Function Update Magnitude: 0.07321

Collected Steps per Second: 13013.99622
Overall Steps per Second: 10781.46043

Timestep Collection Time: 3.84524
Timestep Consumption Time: 0.79624
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 4.64149

Cumulative Model Updates: 2784
Cumulative Timesteps: 46471836

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01138
Policy Entropy: 0.92639
Value Function Loss: 0.06111

Mean KL Divergence: 0.02579
SB3 Clip Fraction: 0.19386
Policy Update Magnitude: 0.03731
Value Function Update Magnitude: 0.07966

Collected Steps per Second: 12799.96196
Overall Steps per Second: 10637.06695

Timestep Collection Time: 3.90907
Timestep Consumption Time: 0.79485
PPO Batch Consumption Time: 0.03185
Total Iteration Time: 4.70393

Cumulative Model Updates: 2787
Cumulative Timesteps: 46521872

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 46521872...
Checkpoint 46521872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01463
Policy Entropy: 0.88884
Value Function Loss: 0.06663

Mean KL Divergence: 0.03550
SB3 Clip Fraction: 0.22296
Policy Update Magnitude: 0.03955
Value Function Update Magnitude: 0.10687

Collected Steps per Second: 12975.66352
Overall Steps per Second: 10744.45316

Timestep Collection Time: 3.85506
Timestep Consumption Time: 0.80055
PPO Batch Consumption Time: 0.02565
Total Iteration Time: 4.65561

Cumulative Model Updates: 2790
Cumulative Timesteps: 46571894

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00996
Policy Entropy: 0.87540
Value Function Loss: 0.05050

Mean KL Divergence: 0.04862
SB3 Clip Fraction: 0.21145
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.09482

Collected Steps per Second: 12798.70539
Overall Steps per Second: 10595.85765

Timestep Collection Time: 3.90680
Timestep Consumption Time: 0.81221
PPO Batch Consumption Time: 0.02892
Total Iteration Time: 4.71901

Cumulative Model Updates: 2793
Cumulative Timesteps: 46621896

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 46621896...
Checkpoint 46621896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06482
Policy Entropy: 0.83245
Value Function Loss: 0.06309

Mean KL Divergence: 0.07837
SB3 Clip Fraction: 0.31937
Policy Update Magnitude: 0.04178
Value Function Update Magnitude: 0.09311

Collected Steps per Second: 12668.19788
Overall Steps per Second: 10374.81394

Timestep Collection Time: 3.94958
Timestep Consumption Time: 0.87307
PPO Batch Consumption Time: 0.03046
Total Iteration Time: 4.82264

Cumulative Model Updates: 2796
Cumulative Timesteps: 46671930

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03687
Policy Entropy: 0.87988
Value Function Loss: 0.06481

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.17494
Policy Update Magnitude: 0.03786
Value Function Update Magnitude: 0.08925

Collected Steps per Second: 13063.55120
Overall Steps per Second: 10757.93851

Timestep Collection Time: 3.83081
Timestep Consumption Time: 0.82101
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 4.65182

Cumulative Model Updates: 2799
Cumulative Timesteps: 46721974

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 46721974...
Checkpoint 46721974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00186
Policy Entropy: 0.82654
Value Function Loss: 0.07299

Mean KL Divergence: 0.04930
SB3 Clip Fraction: 0.24503
Policy Update Magnitude: 0.03655
Value Function Update Magnitude: 0.08150

Collected Steps per Second: 12909.27333
Overall Steps per Second: 10749.01915

Timestep Collection Time: 3.87597
Timestep Consumption Time: 0.77896
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 4.65494

Cumulative Model Updates: 2802
Cumulative Timesteps: 46772010

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07232
Policy Entropy: 0.83357
Value Function Loss: 0.05436

Mean KL Divergence: 0.02673
SB3 Clip Fraction: 0.20035
Policy Update Magnitude: 0.03786
Value Function Update Magnitude: 0.08144

Collected Steps per Second: 12573.91983
Overall Steps per Second: 10618.94413

Timestep Collection Time: 3.97648
Timestep Consumption Time: 0.73208
PPO Batch Consumption Time: 0.03001
Total Iteration Time: 4.70857

Cumulative Model Updates: 2805
Cumulative Timesteps: 46822010

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 46822010...
Checkpoint 46822010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03306
Policy Entropy: 0.84936
Value Function Loss: 0.04603

Mean KL Divergence: 0.03777
SB3 Clip Fraction: 0.21865
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.08300

Collected Steps per Second: 12853.44886
Overall Steps per Second: 10542.60780

Timestep Collection Time: 3.89203
Timestep Consumption Time: 0.85310
PPO Batch Consumption Time: 0.02864
Total Iteration Time: 4.74513

Cumulative Model Updates: 2808
Cumulative Timesteps: 46872036

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00985
Policy Entropy: 0.86094
Value Function Loss: 0.05193

Mean KL Divergence: 0.03606
SB3 Clip Fraction: 0.23993
Policy Update Magnitude: 0.03946
Value Function Update Magnitude: 0.07125

Collected Steps per Second: 13214.05449
Overall Steps per Second: 10927.22141

Timestep Collection Time: 3.78733
Timestep Consumption Time: 0.79261
PPO Batch Consumption Time: 0.02918
Total Iteration Time: 4.57994

Cumulative Model Updates: 2811
Cumulative Timesteps: 46922082

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 46922082...
Checkpoint 46922082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07821
Policy Entropy: 0.83805
Value Function Loss: 0.05678

Mean KL Divergence: 0.04113
SB3 Clip Fraction: 0.21231
Policy Update Magnitude: 0.04288
Value Function Update Magnitude: 0.06451

Collected Steps per Second: 12128.41012
Overall Steps per Second: 10063.78597

Timestep Collection Time: 4.12486
Timestep Consumption Time: 0.84623
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 4.97109

Cumulative Model Updates: 2814
Cumulative Timesteps: 46972110

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06749
Policy Entropy: 0.82310
Value Function Loss: 0.06730

Mean KL Divergence: 0.04726
SB3 Clip Fraction: 0.26793
Policy Update Magnitude: 0.04713
Value Function Update Magnitude: 0.07798

Collected Steps per Second: 12985.75288
Overall Steps per Second: 10729.63320

Timestep Collection Time: 3.85084
Timestep Consumption Time: 0.80972
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 4.66055

Cumulative Model Updates: 2817
Cumulative Timesteps: 47022116

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 47022116...
Checkpoint 47022116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00398
Policy Entropy: 0.85243
Value Function Loss: 0.06984

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.16974
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.08249

Collected Steps per Second: 12767.67904
Overall Steps per Second: 10707.20261

Timestep Collection Time: 3.91724
Timestep Consumption Time: 0.75383
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 4.67106

Cumulative Model Updates: 2820
Cumulative Timesteps: 47072130

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01646
Policy Entropy: 0.86921
Value Function Loss: 0.06943

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.14864
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.08547

Collected Steps per Second: 12799.10633
Overall Steps per Second: 10639.95981

Timestep Collection Time: 3.90699
Timestep Consumption Time: 0.79284
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 4.69983

Cumulative Model Updates: 2823
Cumulative Timesteps: 47122136

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 47122136...
Checkpoint 47122136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00335
Policy Entropy: 0.85785
Value Function Loss: 0.07863

Mean KL Divergence: 0.02886
SB3 Clip Fraction: 0.20811
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.07738

Collected Steps per Second: 12921.87265
Overall Steps per Second: 10721.04786

Timestep Collection Time: 3.87096
Timestep Consumption Time: 0.79463
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 4.66559

Cumulative Model Updates: 2826
Cumulative Timesteps: 47172156

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06986
Policy Entropy: 0.84013
Value Function Loss: 0.06324

Mean KL Divergence: 0.04963
SB3 Clip Fraction: 0.26674
Policy Update Magnitude: 0.04717
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 13533.92731
Overall Steps per Second: 11138.89059

Timestep Collection Time: 3.69457
Timestep Consumption Time: 0.79439
PPO Batch Consumption Time: 0.02559
Total Iteration Time: 4.48896

Cumulative Model Updates: 2829
Cumulative Timesteps: 47222158

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 47222158...
Checkpoint 47222158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02652
Policy Entropy: 0.88739
Value Function Loss: 0.05693

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.17905
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.07130

Collected Steps per Second: 13008.08702
Overall Steps per Second: 10648.19508

Timestep Collection Time: 3.84576
Timestep Consumption Time: 0.85231
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 4.69807

Cumulative Model Updates: 2832
Cumulative Timesteps: 47272184

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02201
Policy Entropy: 0.84522
Value Function Loss: 0.03777

Mean KL Divergence: 0.05163
SB3 Clip Fraction: 0.25576
Policy Update Magnitude: 0.04587
Value Function Update Magnitude: 0.06090

Collected Steps per Second: 12615.59032
Overall Steps per Second: 10674.22736

Timestep Collection Time: 3.96367
Timestep Consumption Time: 0.72089
PPO Batch Consumption Time: 0.02675
Total Iteration Time: 4.68455

Cumulative Model Updates: 2835
Cumulative Timesteps: 47322188

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 47322188...
Checkpoint 47322188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02841
Policy Entropy: 0.87069
Value Function Loss: 0.06018

Mean KL Divergence: 0.04442
SB3 Clip Fraction: 0.25743
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.06150

Collected Steps per Second: 12883.97785
Overall Steps per Second: 10677.94036

Timestep Collection Time: 3.88172
Timestep Consumption Time: 0.80195
PPO Batch Consumption Time: 0.02824
Total Iteration Time: 4.68367

Cumulative Model Updates: 2838
Cumulative Timesteps: 47372200

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00566
Policy Entropy: 0.86578
Value Function Loss: 0.05681

Mean KL Divergence: 0.05053
SB3 Clip Fraction: 0.22899
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.06498

Collected Steps per Second: 13049.42199
Overall Steps per Second: 10829.75869

Timestep Collection Time: 3.83297
Timestep Consumption Time: 0.78560
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 4.61857

Cumulative Model Updates: 2841
Cumulative Timesteps: 47422218

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 47422218...
Checkpoint 47422218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01347
Policy Entropy: 0.88380
Value Function Loss: 0.04526

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.14007
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.07290

Collected Steps per Second: 13193.41278
Overall Steps per Second: 10824.56067

Timestep Collection Time: 3.79083
Timestep Consumption Time: 0.82959
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 4.62042

Cumulative Model Updates: 2844
Cumulative Timesteps: 47472232

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01340
Policy Entropy: 0.89571
Value Function Loss: 0.03539

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.11566
Policy Update Magnitude: 0.04166
Value Function Update Magnitude: 0.06863

Collected Steps per Second: 13050.08524
Overall Steps per Second: 10705.17253

Timestep Collection Time: 3.83568
Timestep Consumption Time: 0.84019
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 4.67587

Cumulative Model Updates: 2847
Cumulative Timesteps: 47522288

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 47522288...
Checkpoint 47522288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04101
Policy Entropy: 0.89425
Value Function Loss: 0.04240

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.04280
Value Function Update Magnitude: 0.05794

Collected Steps per Second: 12905.37871
Overall Steps per Second: 10741.03764

Timestep Collection Time: 3.87544
Timestep Consumption Time: 0.78091
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 4.65635

Cumulative Model Updates: 2850
Cumulative Timesteps: 47572302

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00778
Policy Entropy: 0.89705
Value Function Loss: 0.06866

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.04215
Value Function Update Magnitude: 0.04967

Collected Steps per Second: 13395.70050
Overall Steps per Second: 11052.68628

Timestep Collection Time: 3.73538
Timestep Consumption Time: 0.79185
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 4.52723

Cumulative Model Updates: 2853
Cumulative Timesteps: 47622340

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 47622340...
Checkpoint 47622340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04621
Policy Entropy: 0.87597
Value Function Loss: 0.06465

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.15790
Policy Update Magnitude: 0.04175
Value Function Update Magnitude: 0.05012

Collected Steps per Second: 13140.10867
Overall Steps per Second: 10892.62858

Timestep Collection Time: 3.80712
Timestep Consumption Time: 0.78552
PPO Batch Consumption Time: 0.02623
Total Iteration Time: 4.59265

Cumulative Model Updates: 2856
Cumulative Timesteps: 47672366

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03070
Policy Entropy: 0.89755
Value Function Loss: 0.05902

Mean KL Divergence: 0.04158
SB3 Clip Fraction: 0.24285
Policy Update Magnitude: 0.03983
Value Function Update Magnitude: 0.06011

Collected Steps per Second: 13099.68667
Overall Steps per Second: 10990.08262

Timestep Collection Time: 3.82024
Timestep Consumption Time: 0.73332
PPO Batch Consumption Time: 0.02943
Total Iteration Time: 4.55356

Cumulative Model Updates: 2859
Cumulative Timesteps: 47722410

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 47722410...
Checkpoint 47722410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14493
Policy Entropy: 0.89024
Value Function Loss: 0.05414

Mean KL Divergence: 0.04409
SB3 Clip Fraction: 0.26007
Policy Update Magnitude: 0.03430
Value Function Update Magnitude: 0.06085

Collected Steps per Second: 12661.03162
Overall Steps per Second: 10469.95172

Timestep Collection Time: 3.95102
Timestep Consumption Time: 0.82684
PPO Batch Consumption Time: 0.02921
Total Iteration Time: 4.77786

Cumulative Model Updates: 2862
Cumulative Timesteps: 47772434

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04983
Policy Entropy: 0.88374
Value Function Loss: 0.05138

Mean KL Divergence: 0.03941
SB3 Clip Fraction: 0.22247
Policy Update Magnitude: 0.03610
Value Function Update Magnitude: 0.05940

Collected Steps per Second: 13093.39140
Overall Steps per Second: 10818.62907

Timestep Collection Time: 3.82162
Timestep Consumption Time: 0.80355
PPO Batch Consumption Time: 0.03441
Total Iteration Time: 4.62517

Cumulative Model Updates: 2865
Cumulative Timesteps: 47822472

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 47822472...
Checkpoint 47822472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00433
Policy Entropy: 0.83624
Value Function Loss: 0.07394

Mean KL Divergence: 0.06247
SB3 Clip Fraction: 0.31084
Policy Update Magnitude: 0.03974
Value Function Update Magnitude: 0.05529

Collected Steps per Second: 13346.06724
Overall Steps per Second: 10902.71544

Timestep Collection Time: 3.74852
Timestep Consumption Time: 0.84006
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 4.58858

Cumulative Model Updates: 2868
Cumulative Timesteps: 47872500

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12957
Policy Entropy: 0.92810
Value Function Loss: 0.08490

Mean KL Divergence: 0.12136
SB3 Clip Fraction: 0.36394
Policy Update Magnitude: 0.04295
Value Function Update Magnitude: 0.06379

Collected Steps per Second: 13270.64941
Overall Steps per Second: 10954.45418

Timestep Collection Time: 3.77118
Timestep Consumption Time: 0.79737
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 4.56855

Cumulative Model Updates: 2871
Cumulative Timesteps: 47922546

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 47922546...
Checkpoint 47922546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06424
Policy Entropy: 0.89646
Value Function Loss: 0.08428

Mean KL Divergence: 0.08379
SB3 Clip Fraction: 0.30178
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.06995

Collected Steps per Second: 12875.22440
Overall Steps per Second: 10839.02959

Timestep Collection Time: 3.88405
Timestep Consumption Time: 0.72965
PPO Batch Consumption Time: 0.03070
Total Iteration Time: 4.61370

Cumulative Model Updates: 2874
Cumulative Timesteps: 47972554

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05044
Policy Entropy: 0.93108
Value Function Loss: 0.06482

Mean KL Divergence: 0.06452
SB3 Clip Fraction: 0.28470
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.06539

Collected Steps per Second: 13220.06601
Overall Steps per Second: 10947.70253

Timestep Collection Time: 3.78485
Timestep Consumption Time: 0.78560
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 4.57046

Cumulative Model Updates: 2877
Cumulative Timesteps: 48022590

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 48022590...
Checkpoint 48022590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06635
Policy Entropy: 0.90997
Value Function Loss: 0.03681

Mean KL Divergence: 0.06577
SB3 Clip Fraction: 0.23185
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.05810

Collected Steps per Second: 13203.18324
Overall Steps per Second: 10915.63993

Timestep Collection Time: 3.78757
Timestep Consumption Time: 0.79374
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 4.58132

Cumulative Model Updates: 2880
Cumulative Timesteps: 48072598

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03060
Policy Entropy: 0.92366
Value Function Loss: 0.05726

Mean KL Divergence: 0.05382
SB3 Clip Fraction: 0.26558
Policy Update Magnitude: 0.04005
Value Function Update Magnitude: 0.05341

Collected Steps per Second: 13158.21696
Overall Steps per Second: 10842.89566

Timestep Collection Time: 3.80021
Timestep Consumption Time: 0.81147
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 4.61168

Cumulative Model Updates: 2883
Cumulative Timesteps: 48122602

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 48122602...
Checkpoint 48122602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00466
Policy Entropy: 0.93797
Value Function Loss: 0.04445

Mean KL Divergence: 0.03875
SB3 Clip Fraction: 0.19114
Policy Update Magnitude: 0.04137
Value Function Update Magnitude: 0.04511

Collected Steps per Second: 12964.58638
Overall Steps per Second: 10732.03216

Timestep Collection Time: 3.85959
Timestep Consumption Time: 0.80290
PPO Batch Consumption Time: 0.02868
Total Iteration Time: 4.66249

Cumulative Model Updates: 2886
Cumulative Timesteps: 48172640

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07715
Policy Entropy: 0.93183
Value Function Loss: 0.06625

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.04763
Value Function Update Magnitude: 0.05342

Collected Steps per Second: 13161.69384
Overall Steps per Second: 10826.56730

Timestep Collection Time: 3.80255
Timestep Consumption Time: 0.82015
PPO Batch Consumption Time: 0.02666
Total Iteration Time: 4.62270

Cumulative Model Updates: 2889
Cumulative Timesteps: 48222688

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 48222688...
Checkpoint 48222688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06734
Policy Entropy: 0.92714
Value Function Loss: 0.03932

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.14206
Policy Update Magnitude: 0.04483
Value Function Update Magnitude: 0.05416

Collected Steps per Second: 13032.04698
Overall Steps per Second: 10791.37853

Timestep Collection Time: 3.83808
Timestep Consumption Time: 0.79692
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 4.63500

Cumulative Model Updates: 2892
Cumulative Timesteps: 48272706

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00972
Policy Entropy: 0.91496
Value Function Loss: 0.04782

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.04096
Value Function Update Magnitude: 0.05884

Collected Steps per Second: 12942.66562
Overall Steps per Second: 10608.77446

Timestep Collection Time: 3.86721
Timestep Consumption Time: 0.85077
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 4.71798

Cumulative Model Updates: 2895
Cumulative Timesteps: 48322758

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 48322758...
Checkpoint 48322758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02813
Policy Entropy: 0.96943
Value Function Loss: 0.02737

Mean KL Divergence: 0.04338
SB3 Clip Fraction: 0.23786
Policy Update Magnitude: 0.03910
Value Function Update Magnitude: 0.05519

Collected Steps per Second: 13326.93322
Overall Steps per Second: 11174.85518

Timestep Collection Time: 3.75480
Timestep Consumption Time: 0.72311
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 4.47791

Cumulative Model Updates: 2898
Cumulative Timesteps: 48372798

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08783
Policy Entropy: 0.94765
Value Function Loss: 0.02400

Mean KL Divergence: 0.03038
SB3 Clip Fraction: 0.20458
Policy Update Magnitude: 0.03726
Value Function Update Magnitude: 0.05934

Collected Steps per Second: 13293.23893
Overall Steps per Second: 10929.33409

Timestep Collection Time: 3.76131
Timestep Consumption Time: 0.81353
PPO Batch Consumption Time: 0.02882
Total Iteration Time: 4.57484

Cumulative Model Updates: 2901
Cumulative Timesteps: 48422798

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 48422798...
Checkpoint 48422798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08386
Policy Entropy: 0.94087
Value Function Loss: 0.02647

Mean KL Divergence: 0.02485
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 0.03810
Value Function Update Magnitude: 0.05391

Collected Steps per Second: 13060.62754
Overall Steps per Second: 10812.12183

Timestep Collection Time: 3.83075
Timestep Consumption Time: 0.79665
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 4.62740

Cumulative Model Updates: 2904
Cumulative Timesteps: 48472830

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03386
Policy Entropy: 0.91796
Value Function Loss: 0.02277

Mean KL Divergence: 0.03950
SB3 Clip Fraction: 0.22755
Policy Update Magnitude: 0.03632
Value Function Update Magnitude: 0.05920

Collected Steps per Second: 13140.58813
Overall Steps per Second: 10807.33106

Timestep Collection Time: 3.80790
Timestep Consumption Time: 0.82211
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 4.63001

Cumulative Model Updates: 2907
Cumulative Timesteps: 48522868

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 48522868...
Checkpoint 48522868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05921
Policy Entropy: 0.94187
Value Function Loss: 0.03294

Mean KL Divergence: 0.02591
SB3 Clip Fraction: 0.16411
Policy Update Magnitude: 0.03691
Value Function Update Magnitude: 0.05766

Collected Steps per Second: 13272.68260
Overall Steps per Second: 10952.48762

Timestep Collection Time: 3.77090
Timestep Consumption Time: 0.79883
PPO Batch Consumption Time: 0.02642
Total Iteration Time: 4.56974

Cumulative Model Updates: 2910
Cumulative Timesteps: 48572918

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04404
Policy Entropy: 0.96046
Value Function Loss: 0.03662

Mean KL Divergence: 0.03559
SB3 Clip Fraction: 0.21865
Policy Update Magnitude: 0.03716
Value Function Update Magnitude: 0.05979

Collected Steps per Second: 12996.50624
Overall Steps per Second: 10960.61833

Timestep Collection Time: 3.84888
Timestep Consumption Time: 0.71491
PPO Batch Consumption Time: 0.02799
Total Iteration Time: 4.56379

Cumulative Model Updates: 2913
Cumulative Timesteps: 48622940

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 48622940...
Checkpoint 48622940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01363
Policy Entropy: 0.91136
Value Function Loss: 0.04992

Mean KL Divergence: 0.04072
SB3 Clip Fraction: 0.18961
Policy Update Magnitude: 0.03801
Value Function Update Magnitude: 0.06878

Collected Steps per Second: 13158.86269
Overall Steps per Second: 10833.84609

Timestep Collection Time: 3.80215
Timestep Consumption Time: 0.81597
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 4.61812

Cumulative Model Updates: 2916
Cumulative Timesteps: 48672972

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01387
Policy Entropy: 0.95040
Value Function Loss: 0.03991

Mean KL Divergence: 0.04139
SB3 Clip Fraction: 0.22959
Policy Update Magnitude: 0.03961
Value Function Update Magnitude: 0.06050

Collected Steps per Second: 12851.42243
Overall Steps per Second: 10675.80141

Timestep Collection Time: 3.89062
Timestep Consumption Time: 0.79287
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 4.68349

Cumulative Model Updates: 2919
Cumulative Timesteps: 48722972

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 48722972...
Checkpoint 48722972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01123
Policy Entropy: 0.94283
Value Function Loss: 0.03729

Mean KL Divergence: 0.04002
SB3 Clip Fraction: 0.23376
Policy Update Magnitude: 0.03727
Value Function Update Magnitude: 0.05490

Collected Steps per Second: 13693.51761
Overall Steps per Second: 11075.90175

Timestep Collection Time: 3.65414
Timestep Consumption Time: 0.86360
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 4.51774

Cumulative Model Updates: 2922
Cumulative Timesteps: 48773010

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03064
Policy Entropy: 0.91146
Value Function Loss: 0.04166

Mean KL Divergence: 0.05523
SB3 Clip Fraction: 0.22193
Policy Update Magnitude: 0.03999
Value Function Update Magnitude: 0.05188

Collected Steps per Second: 12909.90710
Overall Steps per Second: 10685.93960

Timestep Collection Time: 3.87470
Timestep Consumption Time: 0.80641
PPO Batch Consumption Time: 0.03144
Total Iteration Time: 4.68110

Cumulative Model Updates: 2925
Cumulative Timesteps: 48823032

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 48823032...
Checkpoint 48823032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00049
Policy Entropy: 0.89560
Value Function Loss: 0.06761

Mean KL Divergence: 0.04684
SB3 Clip Fraction: 0.26396
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.04718

Collected Steps per Second: 13257.08138
Overall Steps per Second: 11163.02832

Timestep Collection Time: 3.77308
Timestep Consumption Time: 0.70779
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 4.48086

Cumulative Model Updates: 2928
Cumulative Timesteps: 48873052

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02415
Policy Entropy: 0.92358
Value Function Loss: 0.06870

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.16730
Policy Update Magnitude: 0.04209
Value Function Update Magnitude: 0.05480

Collected Steps per Second: 12688.64895
Overall Steps per Second: 10294.24900

Timestep Collection Time: 3.94226
Timestep Consumption Time: 0.91695
PPO Batch Consumption Time: 0.02931
Total Iteration Time: 4.85922

Cumulative Model Updates: 2931
Cumulative Timesteps: 48923074

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 48923074...
Checkpoint 48923074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00862
Policy Entropy: 0.96450
Value Function Loss: 0.04501

Mean KL Divergence: 0.03952
SB3 Clip Fraction: 0.24282
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.05806

Collected Steps per Second: 8450.11496
Overall Steps per Second: 7312.66933

Timestep Collection Time: 5.91850
Timestep Consumption Time: 0.92059
PPO Batch Consumption Time: 0.02941
Total Iteration Time: 6.83909

Cumulative Model Updates: 2934
Cumulative Timesteps: 48973086

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02004
Policy Entropy: 0.91228
Value Function Loss: 0.03729

Mean KL Divergence: 0.03501
SB3 Clip Fraction: 0.23139
Policy Update Magnitude: 0.04098
Value Function Update Magnitude: 0.05136

Collected Steps per Second: 12731.24149
Overall Steps per Second: 10520.13733

Timestep Collection Time: 3.92876
Timestep Consumption Time: 0.82574
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 4.75450

Cumulative Model Updates: 2937
Cumulative Timesteps: 49023104

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 49023104...
Checkpoint 49023104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02487
Policy Entropy: 0.97324
Value Function Loss: 0.02435

Mean KL Divergence: 0.03957
SB3 Clip Fraction: 0.22188
Policy Update Magnitude: 0.04037
Value Function Update Magnitude: 0.04794

Collected Steps per Second: 12781.16549
Overall Steps per Second: 10588.97220

Timestep Collection Time: 3.91201
Timestep Consumption Time: 0.80989
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 4.72189

Cumulative Model Updates: 2940
Cumulative Timesteps: 49073104

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01883
Policy Entropy: 0.94771
Value Function Loss: 0.03112

Mean KL Divergence: 0.04048
SB3 Clip Fraction: 0.22753
Policy Update Magnitude: 0.03709
Value Function Update Magnitude: 0.04947

Collected Steps per Second: 13020.85022
Overall Steps per Second: 10732.45307

Timestep Collection Time: 3.84384
Timestep Consumption Time: 0.81959
PPO Batch Consumption Time: 0.02691
Total Iteration Time: 4.66343

Cumulative Model Updates: 2943
Cumulative Timesteps: 49123154

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 49123154...
Checkpoint 49123154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01830
Policy Entropy: 0.93230
Value Function Loss: 0.02065

Mean KL Divergence: 0.04344
SB3 Clip Fraction: 0.20451
Policy Update Magnitude: 0.03806
Value Function Update Magnitude: 0.05474

Collected Steps per Second: 13076.97038
Overall Steps per Second: 10710.35484

Timestep Collection Time: 3.82382
Timestep Consumption Time: 0.84493
PPO Batch Consumption Time: 0.03013
Total Iteration Time: 4.66875

Cumulative Model Updates: 2946
Cumulative Timesteps: 49173158

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04957
Policy Entropy: 0.97475
Value Function Loss: 0.02607

Mean KL Divergence: 0.04448
SB3 Clip Fraction: 0.22210
Policy Update Magnitude: 0.03731
Value Function Update Magnitude: 0.05308

Collected Steps per Second: 12796.89694
Overall Steps per Second: 10579.97574

Timestep Collection Time: 3.91017
Timestep Consumption Time: 0.81933
PPO Batch Consumption Time: 0.02893
Total Iteration Time: 4.72950

Cumulative Model Updates: 2949
Cumulative Timesteps: 49223196

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 49223196...
Checkpoint 49223196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01134
Policy Entropy: 0.95845
Value Function Loss: 0.01892

Mean KL Divergence: 0.04074
SB3 Clip Fraction: 0.22630
Policy Update Magnitude: 0.03533
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 12768.18461
Overall Steps per Second: 10767.97956

Timestep Collection Time: 3.91833
Timestep Consumption Time: 0.72785
PPO Batch Consumption Time: 0.02873
Total Iteration Time: 4.64618

Cumulative Model Updates: 2952
Cumulative Timesteps: 49273226

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06409
Policy Entropy: 0.95165
Value Function Loss: 0.01725

Mean KL Divergence: 0.03855
SB3 Clip Fraction: 0.19724
Policy Update Magnitude: 0.03503
Value Function Update Magnitude: 0.06041

Collected Steps per Second: 13188.75701
Overall Steps per Second: 10812.11052

Timestep Collection Time: 3.79399
Timestep Consumption Time: 0.83397
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 4.62796

Cumulative Model Updates: 2955
Cumulative Timesteps: 49323264

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 49323264...
Checkpoint 49323264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00674
Policy Entropy: 0.96596
Value Function Loss: 0.02220

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.17290
Policy Update Magnitude: 0.03546
Value Function Update Magnitude: 0.05544

Collected Steps per Second: 13267.10996
Overall Steps per Second: 11001.36864

Timestep Collection Time: 3.77143
Timestep Consumption Time: 0.77673
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 4.54816

Cumulative Model Updates: 2958
Cumulative Timesteps: 49373300

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01731
Policy Entropy: 0.98526
Value Function Loss: 0.03687

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.04010
Value Function Update Magnitude: 0.05659

Collected Steps per Second: 13193.77171
Overall Steps per Second: 10764.34309

Timestep Collection Time: 3.79042
Timestep Consumption Time: 0.85547
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 4.64589

Cumulative Model Updates: 2961
Cumulative Timesteps: 49423310

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 49423310...
Checkpoint 49423310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01396
Policy Entropy: 0.98475
Value Function Loss: 0.05282

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.06847

Collected Steps per Second: 13068.06850
Overall Steps per Second: 10809.01327

Timestep Collection Time: 3.83025
Timestep Consumption Time: 0.80051
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 4.63076

Cumulative Model Updates: 2964
Cumulative Timesteps: 49473364

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02547
Policy Entropy: 1.00341
Value Function Loss: 0.05915

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.17281
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.08410

Collected Steps per Second: 13300.77301
Overall Steps per Second: 11160.30391

Timestep Collection Time: 3.76189
Timestep Consumption Time: 0.72150
PPO Batch Consumption Time: 0.02866
Total Iteration Time: 4.48339

Cumulative Model Updates: 2967
Cumulative Timesteps: 49523400

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 49523400...
Checkpoint 49523400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02282
Policy Entropy: 0.95988
Value Function Loss: 0.05679

Mean KL Divergence: 0.03640
SB3 Clip Fraction: 0.21354
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.07938

Collected Steps per Second: 12937.38738
Overall Steps per Second: 10722.29265

Timestep Collection Time: 3.86570
Timestep Consumption Time: 0.79861
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 4.66430

Cumulative Model Updates: 2970
Cumulative Timesteps: 49573412

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00784
Policy Entropy: 0.97541
Value Function Loss: 0.04678

Mean KL Divergence: 0.01981
SB3 Clip Fraction: 0.17671
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 12596.93792
Overall Steps per Second: 10466.52428

Timestep Collection Time: 3.97033
Timestep Consumption Time: 0.80814
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 4.77847

Cumulative Model Updates: 2973
Cumulative Timesteps: 49623426

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 49623426...
Checkpoint 49623426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02201
Policy Entropy: 0.97003
Value Function Loss: 0.03815

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.16403
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.07293

Collected Steps per Second: 13572.59242
Overall Steps per Second: 11123.78466

Timestep Collection Time: 3.68640
Timestep Consumption Time: 0.81153
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.49793

Cumulative Model Updates: 2976
Cumulative Timesteps: 49673460

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02023
Policy Entropy: 0.96916
Value Function Loss: 0.03334

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 12427.64871
Overall Steps per Second: 10342.63527

Timestep Collection Time: 4.02586
Timestep Consumption Time: 0.81159
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 4.83745

Cumulative Model Updates: 2979
Cumulative Timesteps: 49723492

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 49723492...
Checkpoint 49723492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02875
Policy Entropy: 0.97965
Value Function Loss: 0.02249

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.12301
Policy Update Magnitude: 0.04415
Value Function Update Magnitude: 0.06126

Collected Steps per Second: 13228.50795
Overall Steps per Second: 10958.06686

Timestep Collection Time: 3.78229
Timestep Consumption Time: 0.78367
PPO Batch Consumption Time: 0.02740
Total Iteration Time: 4.56595

Cumulative Model Updates: 2982
Cumulative Timesteps: 49773526

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00284
Policy Entropy: 0.96702
Value Function Loss: 0.02908

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.05335

Collected Steps per Second: 12794.98075
Overall Steps per Second: 10627.11022

Timestep Collection Time: 3.90856
Timestep Consumption Time: 0.79732
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 4.70589

Cumulative Model Updates: 2985
Cumulative Timesteps: 49823536

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 49823536...
Checkpoint 49823536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09211
Policy Entropy: 0.98069
Value Function Loss: 0.03212

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.06568

Collected Steps per Second: 13030.29631
Overall Steps per Second: 10793.64244

Timestep Collection Time: 3.83921
Timestep Consumption Time: 0.79556
PPO Batch Consumption Time: 0.03024
Total Iteration Time: 4.63477

Cumulative Model Updates: 2988
Cumulative Timesteps: 49873562

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01766
Policy Entropy: 0.97950
Value Function Loss: 0.04169

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.07982

Collected Steps per Second: 12769.80924
Overall Steps per Second: 10795.18537

Timestep Collection Time: 3.91611
Timestep Consumption Time: 0.71632
PPO Batch Consumption Time: 0.02714
Total Iteration Time: 4.63244

Cumulative Model Updates: 2991
Cumulative Timesteps: 49923570

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 49923570...
Checkpoint 49923570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01640
Policy Entropy: 0.97187
Value Function Loss: 0.04273

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.11554
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.08042

Collected Steps per Second: 12983.22164
Overall Steps per Second: 10737.33396

Timestep Collection Time: 3.85513
Timestep Consumption Time: 0.80636
PPO Batch Consumption Time: 0.03021
Total Iteration Time: 4.66149

Cumulative Model Updates: 2994
Cumulative Timesteps: 49973622

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01385
Policy Entropy: 0.98498
Value Function Loss: 0.05807

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.04903
Value Function Update Magnitude: 0.07664

Collected Steps per Second: 11974.76037
Overall Steps per Second: 10074.19792

Timestep Collection Time: 4.17612
Timestep Consumption Time: 0.78785
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 4.96397

Cumulative Model Updates: 2997
Cumulative Timesteps: 50023630

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 50023630...
Checkpoint 50023630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01123
Policy Entropy: 0.98158
Value Function Loss: 0.06146

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07602

Collected Steps per Second: 12887.97203
Overall Steps per Second: 10579.96944

Timestep Collection Time: 3.88067
Timestep Consumption Time: 0.84656
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 4.72723

Cumulative Model Updates: 3000
Cumulative Timesteps: 50073644

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00370
Policy Entropy: 0.98218
Value Function Loss: 0.05736

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.10327
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.08290

Collected Steps per Second: 12706.22724
Overall Steps per Second: 10495.97230

Timestep Collection Time: 3.93649
Timestep Consumption Time: 0.82895
PPO Batch Consumption Time: 0.02763
Total Iteration Time: 4.76545

Cumulative Model Updates: 3003
Cumulative Timesteps: 50123662

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 50123662...
Checkpoint 50123662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06570
Policy Entropy: 0.99649
Value Function Loss: 0.04346

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.04982
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 13002.70091
Overall Steps per Second: 10914.49806

Timestep Collection Time: 3.84735
Timestep Consumption Time: 0.73609
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 4.58344

Cumulative Model Updates: 3006
Cumulative Timesteps: 50173688

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00777
Policy Entropy: 0.98851
Value Function Loss: 0.04047

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.07480

Collected Steps per Second: 13178.50330
Overall Steps per Second: 10867.46586

Timestep Collection Time: 3.79542
Timestep Consumption Time: 0.80712
PPO Batch Consumption Time: 0.02909
Total Iteration Time: 4.60254

Cumulative Model Updates: 3009
Cumulative Timesteps: 50223706

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 50223706...
Checkpoint 50223706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02092
Policy Entropy: 0.98129
Value Function Loss: 0.04387

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.06330

Collected Steps per Second: 13057.44312
Overall Steps per Second: 10832.36798

Timestep Collection Time: 3.83230
Timestep Consumption Time: 0.78719
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 4.61949

Cumulative Model Updates: 3012
Cumulative Timesteps: 50273746

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00527
Policy Entropy: 0.95760
Value Function Loss: 0.03424

Mean KL Divergence: 0.03508
SB3 Clip Fraction: 0.21314
Policy Update Magnitude: 0.04339
Value Function Update Magnitude: 0.05888

Collected Steps per Second: 12581.23136
Overall Steps per Second: 10418.07996

Timestep Collection Time: 3.97704
Timestep Consumption Time: 0.82577
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 4.80280

Cumulative Model Updates: 3015
Cumulative Timesteps: 50323782

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 50323782...
Checkpoint 50323782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00677
Policy Entropy: 0.98899
Value Function Loss: 0.03770

Mean KL Divergence: 0.03096
SB3 Clip Fraction: 0.18378
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.05725

Collected Steps per Second: 13353.81433
Overall Steps per Second: 11003.93457

Timestep Collection Time: 3.74635
Timestep Consumption Time: 0.80003
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 4.54637

Cumulative Model Updates: 3018
Cumulative Timesteps: 50373810

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03544
Policy Entropy: 1.01106
Value Function Loss: 0.04712

Mean KL Divergence: 0.04065
SB3 Clip Fraction: 0.23444
Policy Update Magnitude: 0.04140
Value Function Update Magnitude: 0.04695

Collected Steps per Second: 12732.96713
Overall Steps per Second: 10628.63881

Timestep Collection Time: 3.92729
Timestep Consumption Time: 0.77755
PPO Batch Consumption Time: 0.02937
Total Iteration Time: 4.70484

Cumulative Model Updates: 3021
Cumulative Timesteps: 50423816

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 50423816...
Checkpoint 50423816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04231
Policy Entropy: 0.99436
Value Function Loss: 0.04897

Mean KL Divergence: 0.02741
SB3 Clip Fraction: 0.17399
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.05534

Collected Steps per Second: 12782.23864
Overall Steps per Second: 10581.07353

Timestep Collection Time: 3.91199
Timestep Consumption Time: 0.81381
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 4.72580

Cumulative Model Updates: 3024
Cumulative Timesteps: 50473820

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06958
Policy Entropy: 0.97662
Value Function Loss: 0.04810

Mean KL Divergence: 0.03095
SB3 Clip Fraction: 0.21462
Policy Update Magnitude: 0.04162
Value Function Update Magnitude: 0.06538

Collected Steps per Second: 12931.11718
Overall Steps per Second: 10766.83840

Timestep Collection Time: 3.86772
Timestep Consumption Time: 0.77746
PPO Batch Consumption Time: 0.02604
Total Iteration Time: 4.64519

Cumulative Model Updates: 3027
Cumulative Timesteps: 50523834

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 50523834...
Checkpoint 50523834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02087
Policy Entropy: 1.00146
Value Function Loss: 0.03429

Mean KL Divergence: 0.02741
SB3 Clip Fraction: 0.17505
Policy Update Magnitude: 0.04010
Value Function Update Magnitude: 0.06989

Collected Steps per Second: 13346.27247
Overall Steps per Second: 11005.89253

Timestep Collection Time: 3.74756
Timestep Consumption Time: 0.79691
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 4.54447

Cumulative Model Updates: 3030
Cumulative Timesteps: 50573850

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01541
Policy Entropy: 1.00750
Value Function Loss: 0.04556

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.04265
Value Function Update Magnitude: 0.06009

Collected Steps per Second: 12998.36500
Overall Steps per Second: 10726.05410

Timestep Collection Time: 3.85002
Timestep Consumption Time: 0.81563
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 4.66565

Cumulative Model Updates: 3033
Cumulative Timesteps: 50623894

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 50623894...
Checkpoint 50623894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06299
Policy Entropy: 1.00575
Value Function Loss: 0.04444

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.15010
Policy Update Magnitude: 0.04334
Value Function Update Magnitude: 0.05869

Collected Steps per Second: 12086.93830
Overall Steps per Second: 10071.41162

Timestep Collection Time: 4.13752
Timestep Consumption Time: 0.82802
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 4.96554

Cumulative Model Updates: 3036
Cumulative Timesteps: 50673904

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06490
Policy Entropy: 0.99630
Value Function Loss: 0.05156

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.16325
Policy Update Magnitude: 0.03970
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 12367.79297
Overall Steps per Second: 10143.58910

Timestep Collection Time: 4.04373
Timestep Consumption Time: 0.88668
PPO Batch Consumption Time: 0.03113
Total Iteration Time: 4.93040

Cumulative Model Updates: 3039
Cumulative Timesteps: 50723916

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 50723916...
Checkpoint 50723916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03835
Policy Entropy: 1.02550
Value Function Loss: 0.06271

Mean KL Divergence: 0.04020
SB3 Clip Fraction: 0.20621
Policy Update Magnitude: 0.03973
Value Function Update Magnitude: 0.06728

Collected Steps per Second: 12328.15038
Overall Steps per Second: 10277.87051

Timestep Collection Time: 4.05657
Timestep Consumption Time: 0.80922
PPO Batch Consumption Time: 0.02945
Total Iteration Time: 4.86579

Cumulative Model Updates: 3042
Cumulative Timesteps: 50773926

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01817
Policy Entropy: 1.00863
Value Function Loss: 0.06630

Mean KL Divergence: 0.03852
SB3 Clip Fraction: 0.20762
Policy Update Magnitude: 0.03479
Value Function Update Magnitude: 0.06848

Collected Steps per Second: 12694.40048
Overall Steps per Second: 10657.63069

Timestep Collection Time: 3.94127
Timestep Consumption Time: 0.75321
PPO Batch Consumption Time: 0.03460
Total Iteration Time: 4.69448

Cumulative Model Updates: 3045
Cumulative Timesteps: 50823958

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 50823958...
Checkpoint 50823958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02194
Policy Entropy: 0.97383
Value Function Loss: 0.08364

Mean KL Divergence: 0.04751
SB3 Clip Fraction: 0.19219
Policy Update Magnitude: 0.03886
Value Function Update Magnitude: 0.07896

Collected Steps per Second: 12742.31561
Overall Steps per Second: 10583.83851

Timestep Collection Time: 3.92770
Timestep Consumption Time: 0.80102
PPO Batch Consumption Time: 0.02752
Total Iteration Time: 4.72872

Cumulative Model Updates: 3048
Cumulative Timesteps: 50874006

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02742
Policy Entropy: 0.98587
Value Function Loss: 0.05630

Mean KL Divergence: 0.04782
SB3 Clip Fraction: 0.21727
Policy Update Magnitude: 0.04172
Value Function Update Magnitude: 0.08336

Collected Steps per Second: 12984.38735
Overall Steps per Second: 10729.90713

Timestep Collection Time: 3.85494
Timestep Consumption Time: 0.80997
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 4.66491

Cumulative Model Updates: 3051
Cumulative Timesteps: 50924060

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 50924060...
Checkpoint 50924060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01547
Policy Entropy: 0.98427
Value Function Loss: 0.05395

Mean KL Divergence: 0.07105
SB3 Clip Fraction: 0.26118
Policy Update Magnitude: 0.04038
Value Function Update Magnitude: 0.07518

Collected Steps per Second: 13282.32330
Overall Steps per Second: 10972.52167

Timestep Collection Time: 3.76515
Timestep Consumption Time: 0.79259
PPO Batch Consumption Time: 0.02521
Total Iteration Time: 4.55775

Cumulative Model Updates: 3054
Cumulative Timesteps: 50974070

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08858
Policy Entropy: 0.98806
Value Function Loss: 0.02923

Mean KL Divergence: 0.07749
SB3 Clip Fraction: 0.26989
Policy Update Magnitude: 0.03605
Value Function Update Magnitude: 0.06878

Collected Steps per Second: 12875.19432
Overall Steps per Second: 10625.98721

Timestep Collection Time: 3.88483
Timestep Consumption Time: 0.82230
PPO Batch Consumption Time: 0.02760
Total Iteration Time: 4.70714

Cumulative Model Updates: 3057
Cumulative Timesteps: 51024088

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 51024088...
Checkpoint 51024088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01739
Policy Entropy: 1.00492
Value Function Loss: 0.02914

Mean KL Divergence: 0.06121
SB3 Clip Fraction: 0.20845
Policy Update Magnitude: 0.03802
Value Function Update Magnitude: 0.06369

Collected Steps per Second: 13100.24241
Overall Steps per Second: 11030.63566

Timestep Collection Time: 3.81856
Timestep Consumption Time: 0.71645
PPO Batch Consumption Time: 0.02600
Total Iteration Time: 4.53501

Cumulative Model Updates: 3060
Cumulative Timesteps: 51074112

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04050
Policy Entropy: 1.02787
Value Function Loss: 0.02164

Mean KL Divergence: 0.03162
SB3 Clip Fraction: 0.18380
Policy Update Magnitude: 0.03728
Value Function Update Magnitude: 0.05904

Collected Steps per Second: 12820.07911
Overall Steps per Second: 10618.20930

Timestep Collection Time: 3.90154
Timestep Consumption Time: 0.80905
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 4.71059

Cumulative Model Updates: 3063
Cumulative Timesteps: 51124130

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 51124130...
Checkpoint 51124130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00668
Policy Entropy: 1.00992
Value Function Loss: 0.02764

Mean KL Divergence: 0.02597
SB3 Clip Fraction: 0.15135
Policy Update Magnitude: 0.03792
Value Function Update Magnitude: 0.05846

Collected Steps per Second: 12826.76592
Overall Steps per Second: 10666.88818

Timestep Collection Time: 3.90091
Timestep Consumption Time: 0.78987
PPO Batch Consumption Time: 0.03066
Total Iteration Time: 4.69078

Cumulative Model Updates: 3066
Cumulative Timesteps: 51174166

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02455
Policy Entropy: 0.98434
Value Function Loss: 0.03262

Mean KL Divergence: 0.05634
SB3 Clip Fraction: 0.24673
Policy Update Magnitude: 0.03754
Value Function Update Magnitude: 0.05841

Collected Steps per Second: 13152.84263
Overall Steps per Second: 10854.88606

Timestep Collection Time: 3.80252
Timestep Consumption Time: 0.80499
PPO Batch Consumption Time: 0.02588
Total Iteration Time: 4.60751

Cumulative Model Updates: 3069
Cumulative Timesteps: 51224180

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 51224180...
Checkpoint 51224180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00785
Policy Entropy: 1.02159
Value Function Loss: 0.04167

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.03722
Value Function Update Magnitude: 0.06163

Collected Steps per Second: 13106.51119
Overall Steps per Second: 10772.99347

Timestep Collection Time: 3.81719
Timestep Consumption Time: 0.82683
PPO Batch Consumption Time: 0.03314
Total Iteration Time: 4.64402

Cumulative Model Updates: 3072
Cumulative Timesteps: 51274210

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00323
Policy Entropy: 1.00379
Value Function Loss: 0.03519

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.11044
Policy Update Magnitude: 0.03669
Value Function Update Magnitude: 0.05736

Collected Steps per Second: 12862.54017
Overall Steps per Second: 10677.63320

Timestep Collection Time: 3.88943
Timestep Consumption Time: 0.79587
PPO Batch Consumption Time: 0.03285
Total Iteration Time: 4.68531

Cumulative Model Updates: 3075
Cumulative Timesteps: 51324238

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 51324238...
Checkpoint 51324238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02501
Policy Entropy: 1.00477
Value Function Loss: 0.02142

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.03596
Value Function Update Magnitude: 0.05015

Collected Steps per Second: 13390.82235
Overall Steps per Second: 11050.97242

Timestep Collection Time: 3.73450
Timestep Consumption Time: 0.79071
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 4.52521

Cumulative Model Updates: 3078
Cumulative Timesteps: 51374246

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00311
Policy Entropy: 0.98733
Value Function Loss: 0.02762

Mean KL Divergence: 0.02619
SB3 Clip Fraction: 0.17125
Policy Update Magnitude: 0.03728
Value Function Update Magnitude: 0.04161

Collected Steps per Second: 12969.09419
Overall Steps per Second: 10734.42084

Timestep Collection Time: 3.85840
Timestep Consumption Time: 0.80324
PPO Batch Consumption Time: 0.02817
Total Iteration Time: 4.66164

Cumulative Model Updates: 3081
Cumulative Timesteps: 51424286

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 51424286...
Checkpoint 51424286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03472
Policy Entropy: 1.04016
Value Function Loss: 0.04481

Mean KL Divergence: 0.03625
SB3 Clip Fraction: 0.20139
Policy Update Magnitude: 0.03694
Value Function Update Magnitude: 0.04268

Collected Steps per Second: 12955.60117
Overall Steps per Second: 10900.63191

Timestep Collection Time: 3.86011
Timestep Consumption Time: 0.72770
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 4.58781

Cumulative Model Updates: 3084
Cumulative Timesteps: 51474296

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01797
Policy Entropy: 1.01735
Value Function Loss: 0.06922

Mean KL Divergence: 0.03068
SB3 Clip Fraction: 0.17621
Policy Update Magnitude: 0.04321
Value Function Update Magnitude: 0.05404

Collected Steps per Second: 12952.51732
Overall Steps per Second: 10687.94694

Timestep Collection Time: 3.86025
Timestep Consumption Time: 0.81791
PPO Batch Consumption Time: 0.02798
Total Iteration Time: 4.67817

Cumulative Model Updates: 3087
Cumulative Timesteps: 51524296

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 51524296...
Checkpoint 51524296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02955
Policy Entropy: 1.00786
Value Function Loss: 0.06496

Mean KL Divergence: 0.03822
SB3 Clip Fraction: 0.16752
Policy Update Magnitude: 0.04726
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 13096.27472
Overall Steps per Second: 10865.55409

Timestep Collection Time: 3.81849
Timestep Consumption Time: 0.78394
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 4.60243

Cumulative Model Updates: 3090
Cumulative Timesteps: 51574304

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00490
Policy Entropy: 0.99412
Value Function Loss: 0.05773

Mean KL Divergence: 0.04809
SB3 Clip Fraction: 0.23791
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.06475

Collected Steps per Second: 12988.16702
Overall Steps per Second: 10711.70815

Timestep Collection Time: 3.85181
Timestep Consumption Time: 0.81859
PPO Batch Consumption Time: 0.02937
Total Iteration Time: 4.67040

Cumulative Model Updates: 3093
Cumulative Timesteps: 51624332

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 51624332...
Checkpoint 51624332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01303
Policy Entropy: 1.02129
Value Function Loss: 0.05742

Mean KL Divergence: 0.02749
SB3 Clip Fraction: 0.15663
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.05906

Collected Steps per Second: 12653.28796
Overall Steps per Second: 10445.14828

Timestep Collection Time: 3.95265
Timestep Consumption Time: 0.83560
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.78825

Cumulative Model Updates: 3096
Cumulative Timesteps: 51674346

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01010
Policy Entropy: 1.03151
Value Function Loss: 0.05490

Mean KL Divergence: 0.03233
SB3 Clip Fraction: 0.21561
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.05670

Collected Steps per Second: 12992.61832
Overall Steps per Second: 10973.70450

Timestep Collection Time: 3.85019
Timestep Consumption Time: 0.70835
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 4.55853

Cumulative Model Updates: 3099
Cumulative Timesteps: 51724370

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 51724370...
Checkpoint 51724370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01962
Policy Entropy: 0.99601
Value Function Loss: 0.04980

Mean KL Divergence: 0.03188
SB3 Clip Fraction: 0.17080
Policy Update Magnitude: 0.04990
Value Function Update Magnitude: 0.08524

Collected Steps per Second: 13025.02055
Overall Steps per Second: 10816.39922

Timestep Collection Time: 3.84138
Timestep Consumption Time: 0.78438
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 4.62575

Cumulative Model Updates: 3102
Cumulative Timesteps: 51774404

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01384
Policy Entropy: 1.00814
Value Function Loss: 0.04701

Mean KL Divergence: 0.02607
SB3 Clip Fraction: 0.18591
Policy Update Magnitude: 0.04693
Value Function Update Magnitude: 0.07706

Collected Steps per Second: 12819.42568
Overall Steps per Second: 10667.41583

Timestep Collection Time: 3.90080
Timestep Consumption Time: 0.78693
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 4.68773

Cumulative Model Updates: 3105
Cumulative Timesteps: 51824410

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 51824410...
Checkpoint 51824410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04118
Policy Entropy: 1.01561
Value Function Loss: 0.03590

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.07455

Collected Steps per Second: 13316.18148
Overall Steps per Second: 10970.21672

Timestep Collection Time: 3.75618
Timestep Consumption Time: 0.80325
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.55944

Cumulative Model Updates: 3108
Cumulative Timesteps: 51874428

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02577
Policy Entropy: 1.01786
Value Function Loss: 0.04194

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 12882.05636
Overall Steps per Second: 10652.33385

Timestep Collection Time: 3.88370
Timestep Consumption Time: 0.81293
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 4.69662

Cumulative Model Updates: 3111
Cumulative Timesteps: 51924458

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 51924458...
Checkpoint 51924458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00922
Policy Entropy: 1.01950
Value Function Loss: 0.03126

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.04559
Value Function Update Magnitude: 0.06032

Collected Steps per Second: 12738.90121
Overall Steps per Second: 10745.11056

Timestep Collection Time: 3.92624
Timestep Consumption Time: 0.72853
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 4.65477

Cumulative Model Updates: 3114
Cumulative Timesteps: 51974474

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02408
Policy Entropy: 1.01151
Value Function Loss: 0.04918

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.06226

Collected Steps per Second: 13055.83836
Overall Steps per Second: 10671.33944

Timestep Collection Time: 3.83016
Timestep Consumption Time: 0.85585
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 4.68601

Cumulative Model Updates: 3117
Cumulative Timesteps: 52024480

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 52024480...
Checkpoint 52024480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07927
Policy Entropy: 1.03011
Value Function Loss: 0.06182

Mean KL Divergence: 0.02925
SB3 Clip Fraction: 0.19657
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.06169

Collected Steps per Second: 13113.04410
Overall Steps per Second: 10935.60549

Timestep Collection Time: 3.81467
Timestep Consumption Time: 0.75956
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 4.57423

Cumulative Model Updates: 3120
Cumulative Timesteps: 52074502

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00940
Policy Entropy: 1.05352
Value Function Loss: 0.06242

Mean KL Divergence: 0.05369
SB3 Clip Fraction: 0.25163
Policy Update Magnitude: 0.04340
Value Function Update Magnitude: 0.06441

Collected Steps per Second: 13264.35155
Overall Steps per Second: 10944.86089

Timestep Collection Time: 3.77071
Timestep Consumption Time: 0.79911
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 4.56982

Cumulative Model Updates: 3123
Cumulative Timesteps: 52124518

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 52124518...
Checkpoint 52124518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09317
Policy Entropy: 1.00534
Value Function Loss: 0.05590

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.04401
Value Function Update Magnitude: 0.06652

Collected Steps per Second: 12873.62160
Overall Steps per Second: 10660.62824

Timestep Collection Time: 3.88422
Timestep Consumption Time: 0.80631
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 4.69053

Cumulative Model Updates: 3126
Cumulative Timesteps: 52174522

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04758
Policy Entropy: 1.03953
Value Function Loss: 0.03682

Mean KL Divergence: 0.04492
SB3 Clip Fraction: 0.22317
Policy Update Magnitude: 0.04692
Value Function Update Magnitude: 0.07254

Collected Steps per Second: 12902.69117
Overall Steps per Second: 10850.51601

Timestep Collection Time: 3.87625
Timestep Consumption Time: 0.73312
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 4.60937

Cumulative Model Updates: 3129
Cumulative Timesteps: 52224536

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 52224536...
Checkpoint 52224536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05912
Policy Entropy: 1.05437
Value Function Loss: 0.03838

Mean KL Divergence: 0.04863
SB3 Clip Fraction: 0.23229
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.06326

Collected Steps per Second: 12933.06864
Overall Steps per Second: 10714.45305

Timestep Collection Time: 3.86621
Timestep Consumption Time: 0.80057
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 4.66678

Cumulative Model Updates: 3132
Cumulative Timesteps: 52274538

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02713
Policy Entropy: 1.04133
Value Function Loss: 0.03807

Mean KL Divergence: 0.04298
SB3 Clip Fraction: 0.18120
Policy Update Magnitude: 0.04636
Value Function Update Magnitude: 0.05976

Collected Steps per Second: 13006.63141
Overall Steps per Second: 10803.23598

Timestep Collection Time: 3.84804
Timestep Consumption Time: 0.78483
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 4.63287

Cumulative Model Updates: 3135
Cumulative Timesteps: 52324588

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 52324588...
Checkpoint 52324588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01169
Policy Entropy: 1.10373
Value Function Loss: 0.03531

Mean KL Divergence: 0.08162
SB3 Clip Fraction: 0.26636
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.05738

Collected Steps per Second: 13224.58271
Overall Steps per Second: 10953.24896

Timestep Collection Time: 3.78265
Timestep Consumption Time: 0.78439
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 4.56705

Cumulative Model Updates: 3138
Cumulative Timesteps: 52374612

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01219
Policy Entropy: 1.04667
Value Function Loss: 0.02434

Mean KL Divergence: 0.06510
SB3 Clip Fraction: 0.22418
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.05230

Collected Steps per Second: 12545.03661
Overall Steps per Second: 10382.42637

Timestep Collection Time: 3.98676
Timestep Consumption Time: 0.83042
PPO Batch Consumption Time: 0.03137
Total Iteration Time: 4.81718

Cumulative Model Updates: 3141
Cumulative Timesteps: 52424626

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 52424626...
Checkpoint 52424626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01666
Policy Entropy: 1.12801
Value Function Loss: 0.02731

Mean KL Divergence: 0.11204
SB3 Clip Fraction: 0.25920
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.04610

Collected Steps per Second: 12808.01177
Overall Steps per Second: 10660.99395

Timestep Collection Time: 3.90693
Timestep Consumption Time: 0.78682
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 4.69375

Cumulative Model Updates: 3144
Cumulative Timesteps: 52474666

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04539
Policy Entropy: 1.09537
Value Function Loss: 0.03333

Mean KL Divergence: 0.06060
SB3 Clip Fraction: 0.20889
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.05292

Collected Steps per Second: 13255.70473
Overall Steps per Second: 10880.10417

Timestep Collection Time: 3.77332
Timestep Consumption Time: 0.82388
PPO Batch Consumption Time: 0.02933
Total Iteration Time: 4.59720

Cumulative Model Updates: 3147
Cumulative Timesteps: 52524684

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 52524684...
Checkpoint 52524684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02786
Policy Entropy: 1.12182
Value Function Loss: 0.03435

Mean KL Divergence: 0.02218
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.05070
Value Function Update Magnitude: 0.06946

Collected Steps per Second: 12813.65348
Overall Steps per Second: 10632.11913

Timestep Collection Time: 3.90334
Timestep Consumption Time: 0.80090
PPO Batch Consumption Time: 0.02624
Total Iteration Time: 4.70424

Cumulative Model Updates: 3150
Cumulative Timesteps: 52574700

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04418
Policy Entropy: 1.09657
Value Function Loss: 0.02701

Mean KL Divergence: 0.02102
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.06866

Collected Steps per Second: 13464.46300
Overall Steps per Second: 10943.34438

Timestep Collection Time: 3.71571
Timestep Consumption Time: 0.85602
PPO Batch Consumption Time: 0.02863
Total Iteration Time: 4.57173

Cumulative Model Updates: 3153
Cumulative Timesteps: 52624730

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 52624730...
Checkpoint 52624730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00214
Policy Entropy: 1.09517
Value Function Loss: 0.02453

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.04536
Value Function Update Magnitude: 0.05584

Collected Steps per Second: 12867.51562
Overall Steps per Second: 10684.96833

Timestep Collection Time: 3.88715
Timestep Consumption Time: 0.79400
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 4.68116

Cumulative Model Updates: 3156
Cumulative Timesteps: 52674748

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01643
Policy Entropy: 1.09588
Value Function Loss: 0.03218

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.04133
Value Function Update Magnitude: 0.04842

Collected Steps per Second: 13050.46168
Overall Steps per Second: 10895.31840

Timestep Collection Time: 3.83465
Timestep Consumption Time: 0.75851
PPO Batch Consumption Time: 0.03221
Total Iteration Time: 4.59317

Cumulative Model Updates: 3159
Cumulative Timesteps: 52724792

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 52724792...
Checkpoint 52724792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00006
Policy Entropy: 1.11409
Value Function Loss: 0.02732

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.04030
Value Function Update Magnitude: 0.04851

Collected Steps per Second: 10904.98321
Overall Steps per Second: 9232.49805

Timestep Collection Time: 4.58579
Timestep Consumption Time: 0.83073
PPO Batch Consumption Time: 0.02718
Total Iteration Time: 5.41652

Cumulative Model Updates: 3162
Cumulative Timesteps: 52774800

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00395
Policy Entropy: 1.10797
Value Function Loss: 0.02775

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.05311

Collected Steps per Second: 13009.21318
Overall Steps per Second: 10719.76762

Timestep Collection Time: 3.84604
Timestep Consumption Time: 0.82141
PPO Batch Consumption Time: 0.03434
Total Iteration Time: 4.66745

Cumulative Model Updates: 3165
Cumulative Timesteps: 52824834

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 52824834...
Checkpoint 52824834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01295
Policy Entropy: 1.12408
Value Function Loss: 0.02708

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.04522
Value Function Update Magnitude: 0.05236

Collected Steps per Second: 11622.22711
Overall Steps per Second: 9767.69687

Timestep Collection Time: 4.30451
Timestep Consumption Time: 0.81727
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 5.12178

Cumulative Model Updates: 3168
Cumulative Timesteps: 52874862

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06019
Policy Entropy: 1.11152
Value Function Loss: 0.02893

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.04229

Collected Steps per Second: 12302.57917
Overall Steps per Second: 10257.16891

Timestep Collection Time: 4.06435
Timestep Consumption Time: 0.81048
PPO Batch Consumption Time: 0.03333
Total Iteration Time: 4.87483

Cumulative Model Updates: 3171
Cumulative Timesteps: 52924864

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 52924864...
Checkpoint 52924864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00731
Policy Entropy: 1.11460
Value Function Loss: 0.02510

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.04364
Value Function Update Magnitude: 0.03546

Collected Steps per Second: 13005.36126
Overall Steps per Second: 10672.42861

Timestep Collection Time: 3.84488
Timestep Consumption Time: 0.84047
PPO Batch Consumption Time: 0.03182
Total Iteration Time: 4.68534

Cumulative Model Updates: 3174
Cumulative Timesteps: 52974868

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03798
Policy Entropy: 1.13102
Value Function Loss: 0.01328

Mean KL Divergence: 0.02328
SB3 Clip Fraction: 0.12966
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.03067

Collected Steps per Second: 12077.47938
Overall Steps per Second: 10169.01803

Timestep Collection Time: 4.14308
Timestep Consumption Time: 0.77755
PPO Batch Consumption Time: 0.02518
Total Iteration Time: 4.92063

Cumulative Model Updates: 3177
Cumulative Timesteps: 53024906

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 53024906...
Checkpoint 53024906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05823
Policy Entropy: 1.12910
Value Function Loss: 0.01427

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.04358
Value Function Update Magnitude: 0.03236

Collected Steps per Second: 13580.61989
Overall Steps per Second: 11079.38999

Timestep Collection Time: 3.68216
Timestep Consumption Time: 0.83127
PPO Batch Consumption Time: 0.03197
Total Iteration Time: 4.51343

Cumulative Model Updates: 3180
Cumulative Timesteps: 53074912

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02177
Policy Entropy: 1.11973
Value Function Loss: 0.01156

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.04184
Value Function Update Magnitude: 0.03630

Collected Steps per Second: 10785.05537
Overall Steps per Second: 9078.08244

Timestep Collection Time: 4.63808
Timestep Consumption Time: 0.87211
PPO Batch Consumption Time: 0.02827
Total Iteration Time: 5.51019

Cumulative Model Updates: 3183
Cumulative Timesteps: 53124934

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 53124934...
Checkpoint 53124934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03006
Policy Entropy: 1.10652
Value Function Loss: 0.02115

Mean KL Divergence: 0.02956
SB3 Clip Fraction: 0.16471
Policy Update Magnitude: 0.03914
Value Function Update Magnitude: 0.03977

Collected Steps per Second: 12306.73489
Overall Steps per Second: 10285.01143

Timestep Collection Time: 4.06558
Timestep Consumption Time: 0.79917
PPO Batch Consumption Time: 0.02783
Total Iteration Time: 4.86475

Cumulative Model Updates: 3186
Cumulative Timesteps: 53174968

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00982
Policy Entropy: 1.11722
Value Function Loss: 0.02781

Mean KL Divergence: 0.02809
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.03767
Value Function Update Magnitude: 0.03599

Collected Steps per Second: 12948.45214
Overall Steps per Second: 10962.22442

Timestep Collection Time: 3.86486
Timestep Consumption Time: 0.70027
PPO Batch Consumption Time: 0.02551
Total Iteration Time: 4.56513

Cumulative Model Updates: 3189
Cumulative Timesteps: 53225012

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 53225012...
Checkpoint 53225012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04632
Policy Entropy: 1.11425
Value Function Loss: 0.04958

Mean KL Divergence: 0.03094
SB3 Clip Fraction: 0.17734
Policy Update Magnitude: 0.04624
Value Function Update Magnitude: 0.05491

Collected Steps per Second: 12688.97348
Overall Steps per Second: 10530.29545

Timestep Collection Time: 3.94279
Timestep Consumption Time: 0.80826
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 4.75105

Cumulative Model Updates: 3192
Cumulative Timesteps: 53275042

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03256
Policy Entropy: 1.08822
Value Function Loss: 0.04299

Mean KL Divergence: 0.04796
SB3 Clip Fraction: 0.18159
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.06724

Collected Steps per Second: 12683.48002
Overall Steps per Second: 10480.03927

Timestep Collection Time: 3.94419
Timestep Consumption Time: 0.82927
PPO Batch Consumption Time: 0.02792
Total Iteration Time: 4.77346

Cumulative Model Updates: 3195
Cumulative Timesteps: 53325068

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 53325068...
Checkpoint 53325068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04633
Policy Entropy: 1.10312
Value Function Loss: 0.04197

Mean KL Divergence: 0.03716
SB3 Clip Fraction: 0.18993
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 13205.51329
Overall Steps per Second: 10869.32969

Timestep Collection Time: 3.78736
Timestep Consumption Time: 0.81403
PPO Batch Consumption Time: 0.03002
Total Iteration Time: 4.60139

Cumulative Model Updates: 3198
Cumulative Timesteps: 53375082

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02737
Policy Entropy: 1.10846
Value Function Loss: 0.03107

Mean KL Divergence: 0.02687
SB3 Clip Fraction: 0.17651
Policy Update Magnitude: 0.03697
Value Function Update Magnitude: 0.05658

Collected Steps per Second: 13028.02610
Overall Steps per Second: 10753.00878

Timestep Collection Time: 3.83865
Timestep Consumption Time: 0.81214
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.65079

Cumulative Model Updates: 3201
Cumulative Timesteps: 53425092

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 53425092...
Checkpoint 53425092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10384
Policy Entropy: 1.09038
Value Function Loss: 0.04400

Mean KL Divergence: 0.03017
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.04306
Value Function Update Magnitude: 0.04952

Collected Steps per Second: 12813.92934
Overall Steps per Second: 10840.59795

Timestep Collection Time: 3.90341
Timestep Consumption Time: 0.71054
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 4.61395

Cumulative Model Updates: 3204
Cumulative Timesteps: 53475110

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03229
Policy Entropy: 1.10340
Value Function Loss: 0.04813

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.05396

Collected Steps per Second: 12573.56632
Overall Steps per Second: 10345.04041

Timestep Collection Time: 3.97946
Timestep Consumption Time: 0.85725
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 4.83671

Cumulative Model Updates: 3207
Cumulative Timesteps: 53525146

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 53525146...
Checkpoint 53525146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01660
Policy Entropy: 1.10906
Value Function Loss: 0.04707

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.05856

Collected Steps per Second: 13094.12853
Overall Steps per Second: 10706.03170

Timestep Collection Time: 3.81912
Timestep Consumption Time: 0.85190
PPO Batch Consumption Time: 0.03155
Total Iteration Time: 4.67101

Cumulative Model Updates: 3210
Cumulative Timesteps: 53575154

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01292
Policy Entropy: 1.11364
Value Function Loss: 0.05878

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.05848

Collected Steps per Second: 13431.38618
Overall Steps per Second: 10998.32933

Timestep Collection Time: 3.72352
Timestep Consumption Time: 0.82372
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 4.54724

Cumulative Model Updates: 3213
Cumulative Timesteps: 53625166

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 53625166...
Checkpoint 53625166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04912
Policy Entropy: 1.10784
Value Function Loss: 0.05280

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06433
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 11873.27708
Overall Steps per Second: 9760.50846

Timestep Collection Time: 4.21366
Timestep Consumption Time: 0.91209
PPO Batch Consumption Time: 0.02946
Total Iteration Time: 5.12576

Cumulative Model Updates: 3216
Cumulative Timesteps: 53675196

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01049
Policy Entropy: 1.09823
Value Function Loss: 0.04999

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.05232
Value Function Update Magnitude: 0.06318

Collected Steps per Second: 10038.26321
Overall Steps per Second: 8614.90358

Timestep Collection Time: 4.98373
Timestep Consumption Time: 0.82342
PPO Batch Consumption Time: 0.02977
Total Iteration Time: 5.80715

Cumulative Model Updates: 3219
Cumulative Timesteps: 53725224

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 53725224...
Checkpoint 53725224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04231
Policy Entropy: 1.08534
Value Function Loss: 0.02762

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.04966
Value Function Update Magnitude: 0.05470

Collected Steps per Second: 10052.88452
Overall Steps per Second: 8487.87363

Timestep Collection Time: 4.97370
Timestep Consumption Time: 0.91706
PPO Batch Consumption Time: 0.03019
Total Iteration Time: 5.89076

Cumulative Model Updates: 3222
Cumulative Timesteps: 53775224

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01039
Policy Entropy: 1.11151
Value Function Loss: 0.02917

Mean KL Divergence: 0.03396
SB3 Clip Fraction: 0.18237
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.05440

Collected Steps per Second: 9904.37308
Overall Steps per Second: 8423.70380

Timestep Collection Time: 5.04969
Timestep Consumption Time: 0.88760
PPO Batch Consumption Time: 0.02962
Total Iteration Time: 5.93729

Cumulative Model Updates: 3225
Cumulative Timesteps: 53825238

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 53825238...
Checkpoint 53825238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00198
Policy Entropy: 1.10325
Value Function Loss: 0.02764

Mean KL Divergence: 0.02924
SB3 Clip Fraction: 0.17662
Policy Update Magnitude: 0.03972
Value Function Update Magnitude: 0.05520

Collected Steps per Second: 10468.99889
Overall Steps per Second: 8553.26108

Timestep Collection Time: 4.78002
Timestep Consumption Time: 1.07062
PPO Batch Consumption Time: 0.03051
Total Iteration Time: 5.85063

Cumulative Model Updates: 3228
Cumulative Timesteps: 53875280

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01049
Policy Entropy: 1.09133
Value Function Loss: 0.04401

Mean KL Divergence: 0.03850
SB3 Clip Fraction: 0.16683
Policy Update Magnitude: 0.03900
Value Function Update Magnitude: 0.04948

Collected Steps per Second: 10672.49748
Overall Steps per Second: 9024.15360

Timestep Collection Time: 4.68719
Timestep Consumption Time: 0.85616
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 5.54335

Cumulative Model Updates: 3231
Cumulative Timesteps: 53925304

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 53925304...
Checkpoint 53925304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01155
Policy Entropy: 1.10047
Value Function Loss: 0.04757

Mean KL Divergence: 0.03064
SB3 Clip Fraction: 0.17065
Policy Update Magnitude: 0.04091
Value Function Update Magnitude: 0.05353

Collected Steps per Second: 13071.09429
Overall Steps per Second: 10839.87607

Timestep Collection Time: 3.82829
Timestep Consumption Time: 0.78799
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 4.61629

Cumulative Model Updates: 3234
Cumulative Timesteps: 53975344

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07647
Policy Entropy: 1.10408
Value Function Loss: 0.05466

Mean KL Divergence: 0.03135
SB3 Clip Fraction: 0.18415
Policy Update Magnitude: 0.04173
Value Function Update Magnitude: 0.07111

Collected Steps per Second: 13345.95133
Overall Steps per Second: 11005.93897

Timestep Collection Time: 3.74900
Timestep Consumption Time: 0.79709
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 4.54609

Cumulative Model Updates: 3237
Cumulative Timesteps: 54025378

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 54025378...
Checkpoint 54025378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01159
Policy Entropy: 1.06406
Value Function Loss: 0.03011

Mean KL Divergence: 0.06445
SB3 Clip Fraction: 0.20756
Policy Update Magnitude: 0.04474
Value Function Update Magnitude: 0.06989

Collected Steps per Second: 13063.02103
Overall Steps per Second: 10734.06603

Timestep Collection Time: 3.83143
Timestep Consumption Time: 0.83130
PPO Batch Consumption Time: 0.02846
Total Iteration Time: 4.66273

Cumulative Model Updates: 3240
Cumulative Timesteps: 54075428

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06533
Policy Entropy: 1.12371
Value Function Loss: 0.04167

Mean KL Divergence: 0.04314
SB3 Clip Fraction: 0.21825
Policy Update Magnitude: 0.04208
Value Function Update Magnitude: 0.05948

Collected Steps per Second: 12980.06140
Overall Steps per Second: 10932.24465

Timestep Collection Time: 3.85283
Timestep Consumption Time: 0.72171
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 4.57454

Cumulative Model Updates: 3243
Cumulative Timesteps: 54125438

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 54125438...
Checkpoint 54125438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03137
Policy Entropy: 1.06740
Value Function Loss: 0.03829

Mean KL Divergence: 0.06288
SB3 Clip Fraction: 0.22057
Policy Update Magnitude: 0.03934
Value Function Update Magnitude: 0.04667

Collected Steps per Second: 12401.22737
Overall Steps per Second: 10313.58160

Timestep Collection Time: 4.03428
Timestep Consumption Time: 0.81661
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 4.85089

Cumulative Model Updates: 3246
Cumulative Timesteps: 54175468

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07033
Policy Entropy: 1.09620
Value Function Loss: 0.04511

Mean KL Divergence: 0.03593
SB3 Clip Fraction: 0.18602
Policy Update Magnitude: 0.03860
Value Function Update Magnitude: 0.04604

Collected Steps per Second: 13030.48795
Overall Steps per Second: 10690.36222

Timestep Collection Time: 3.83838
Timestep Consumption Time: 0.84022
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 4.67861

Cumulative Model Updates: 3249
Cumulative Timesteps: 54225484

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 54225484...
Checkpoint 54225484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02346
Policy Entropy: 1.08725
Value Function Loss: 0.03034

Mean KL Divergence: 0.02492
SB3 Clip Fraction: 0.15923
Policy Update Magnitude: 0.04182
Value Function Update Magnitude: 0.04248

Collected Steps per Second: 12815.30956
Overall Steps per Second: 10578.26027

Timestep Collection Time: 3.90158
Timestep Consumption Time: 0.82509
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 4.72668

Cumulative Model Updates: 3252
Cumulative Timesteps: 54275484

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01436
Policy Entropy: 1.09041
Value Function Loss: 0.03229

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.11486
Policy Update Magnitude: 0.04042
Value Function Update Magnitude: 0.04301

Collected Steps per Second: 13193.95080
Overall Steps per Second: 10783.88273

Timestep Collection Time: 3.79052
Timestep Consumption Time: 0.84714
PPO Batch Consumption Time: 0.02908
Total Iteration Time: 4.63766

Cumulative Model Updates: 3255
Cumulative Timesteps: 54325496

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 54325496...
Checkpoint 54325496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00936
Policy Entropy: 1.08853
Value Function Loss: 0.03308

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.04043
Value Function Update Magnitude: 0.04687

Collected Steps per Second: 13011.37584
Overall Steps per Second: 10779.69603

Timestep Collection Time: 3.84371
Timestep Consumption Time: 0.79575
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 4.63946

Cumulative Model Updates: 3258
Cumulative Timesteps: 54375508

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09895
Policy Entropy: 1.06697
Value Function Loss: 0.04480

Mean KL Divergence: 0.02240
SB3 Clip Fraction: 0.15481
Policy Update Magnitude: 0.03984
Value Function Update Magnitude: 0.05035

Collected Steps per Second: 13016.76448
Overall Steps per Second: 10791.17673

Timestep Collection Time: 3.84135
Timestep Consumption Time: 0.79225
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 4.63360

Cumulative Model Updates: 3261
Cumulative Timesteps: 54425510

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 54425510...
Checkpoint 54425510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03238
Policy Entropy: 1.06576
Value Function Loss: 0.02985

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.03729
Value Function Update Magnitude: 0.05029

Collected Steps per Second: 12665.09288
Overall Steps per Second: 10512.76218

Timestep Collection Time: 3.94896
Timestep Consumption Time: 0.80849
PPO Batch Consumption Time: 0.03020
Total Iteration Time: 4.75746

Cumulative Model Updates: 3264
Cumulative Timesteps: 54475524

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01229
Policy Entropy: 1.06656
Value Function Loss: 0.03213

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.03880
Value Function Update Magnitude: 0.05298

Collected Steps per Second: 13106.55504
Overall Steps per Second: 11023.28573

Timestep Collection Time: 3.81763
Timestep Consumption Time: 0.72149
PPO Batch Consumption Time: 0.02949
Total Iteration Time: 4.53912

Cumulative Model Updates: 3267
Cumulative Timesteps: 54525560

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 54525560...
Checkpoint 54525560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05518
Policy Entropy: 1.08812
Value Function Loss: 0.01775

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.03732
Value Function Update Magnitude: 0.05598

Collected Steps per Second: 13143.58638
Overall Steps per Second: 10787.98618

Timestep Collection Time: 3.80718
Timestep Consumption Time: 0.83131
PPO Batch Consumption Time: 0.02974
Total Iteration Time: 4.63849

Cumulative Model Updates: 3270
Cumulative Timesteps: 54575600

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02371
Policy Entropy: 1.09181
Value Function Loss: 0.03299

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.03779
Value Function Update Magnitude: 0.05251

Collected Steps per Second: 13090.29542
Overall Steps per Second: 10862.63795

Timestep Collection Time: 3.82253
Timestep Consumption Time: 0.78391
PPO Batch Consumption Time: 0.02853
Total Iteration Time: 4.60643

Cumulative Model Updates: 3273
Cumulative Timesteps: 54625638

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 54625638...
Checkpoint 54625638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01394
Policy Entropy: 1.09774
Value Function Loss: 0.05221

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.11377
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.04603

Collected Steps per Second: 13230.69278
Overall Steps per Second: 10912.08127

Timestep Collection Time: 3.78181
Timestep Consumption Time: 0.80356
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 4.58538

Cumulative Model Updates: 3276
Cumulative Timesteps: 54675674

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04052
Policy Entropy: 1.07856
Value Function Loss: 0.06956

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.07066

Collected Steps per Second: 12749.81157
Overall Steps per Second: 10550.10794

Timestep Collection Time: 3.92414
Timestep Consumption Time: 0.81818
PPO Batch Consumption Time: 0.02855
Total Iteration Time: 4.74232

Cumulative Model Updates: 3279
Cumulative Timesteps: 54725706

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 54725706...
Checkpoint 54725706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01920
Policy Entropy: 1.08762
Value Function Loss: 0.05249

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 12829.74562
Overall Steps per Second: 10754.93344

Timestep Collection Time: 3.90078
Timestep Consumption Time: 0.75253
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 4.65331

Cumulative Model Updates: 3282
Cumulative Timesteps: 54775752

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01150
Policy Entropy: 1.09147
Value Function Loss: 0.03495

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.06607
Value Function Update Magnitude: 0.09437

Collected Steps per Second: 12970.34110
Overall Steps per Second: 10736.68590

Timestep Collection Time: 3.85726
Timestep Consumption Time: 0.80246
PPO Batch Consumption Time: 0.02831
Total Iteration Time: 4.65972

Cumulative Model Updates: 3285
Cumulative Timesteps: 54825782

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 54825782...
Checkpoint 54825782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00370
Policy Entropy: 1.10350
Value Function Loss: 0.04739

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.08112

Collected Steps per Second: 12884.65032
Overall Steps per Second: 10704.14511

Timestep Collection Time: 3.88198
Timestep Consumption Time: 0.79079
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 4.67277

Cumulative Model Updates: 3288
Cumulative Timesteps: 54875800

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01118
Policy Entropy: 1.11512
Value Function Loss: 0.04173

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.06755
Value Function Update Magnitude: 0.06556

Collected Steps per Second: 13101.62041
Overall Steps per Second: 10857.94198

Timestep Collection Time: 3.81647
Timestep Consumption Time: 0.78863
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 4.60511

Cumulative Model Updates: 3291
Cumulative Timesteps: 54925802

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 54925802...
Checkpoint 54925802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00860
Policy Entropy: 1.11053
Value Function Loss: 0.03994

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.05622

Collected Steps per Second: 12731.66026
Overall Steps per Second: 10553.82453

Timestep Collection Time: 3.92769
Timestep Consumption Time: 0.81050
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 4.73819

Cumulative Model Updates: 3294
Cumulative Timesteps: 54975808

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02661
Policy Entropy: 1.09326
Value Function Loss: 0.02565

Mean KL Divergence: 0.02849
SB3 Clip Fraction: 0.17486
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.05444

Collected Steps per Second: 13080.44676
Overall Steps per Second: 11024.00249

Timestep Collection Time: 3.82586
Timestep Consumption Time: 0.71369
PPO Batch Consumption Time: 0.02654
Total Iteration Time: 4.53955

Cumulative Model Updates: 3297
Cumulative Timesteps: 55025852

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 55025852...
Checkpoint 55025852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00541
Policy Entropy: 1.12314
Value Function Loss: 0.03361

Mean KL Divergence: 0.02803
SB3 Clip Fraction: 0.16907
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.04983

Collected Steps per Second: 12778.44585
Overall Steps per Second: 10611.84259

Timestep Collection Time: 3.91456
Timestep Consumption Time: 0.79923
PPO Batch Consumption Time: 0.02800
Total Iteration Time: 4.71379

Cumulative Model Updates: 3300
Cumulative Timesteps: 55075874

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02380
Policy Entropy: 1.11159
Value Function Loss: 0.02928

Mean KL Divergence: 0.02864
SB3 Clip Fraction: 0.17870
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.05621

Collected Steps per Second: 13073.02028
Overall Steps per Second: 10858.24076

Timestep Collection Time: 3.82773
Timestep Consumption Time: 0.78075
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 4.60848

Cumulative Model Updates: 3303
Cumulative Timesteps: 55125914

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 55125914...
Checkpoint 55125914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03658
Policy Entropy: 1.10536
Value Function Loss: 0.03277

Mean KL Divergence: 0.02830
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.05796

Collected Steps per Second: 13691.74868
Overall Steps per Second: 11196.25294

Timestep Collection Time: 3.65446
Timestep Consumption Time: 0.81453
PPO Batch Consumption Time: 0.02638
Total Iteration Time: 4.46900

Cumulative Model Updates: 3306
Cumulative Timesteps: 55175950

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00949
Policy Entropy: 1.10571
Value Function Loss: 0.04360

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.04888

Collected Steps per Second: 12727.28712
Overall Steps per Second: 10544.28584

Timestep Collection Time: 3.93187
Timestep Consumption Time: 0.81402
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 4.74589

Cumulative Model Updates: 3309
Cumulative Timesteps: 55225992

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 55225992...
Checkpoint 55225992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03569
Policy Entropy: 1.11160
Value Function Loss: 0.06480

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.05088

Collected Steps per Second: 12916.07701
Overall Steps per Second: 10738.78067

Timestep Collection Time: 3.87207
Timestep Consumption Time: 0.78507
PPO Batch Consumption Time: 0.02726
Total Iteration Time: 4.65714

Cumulative Model Updates: 3312
Cumulative Timesteps: 55276004

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00564
Policy Entropy: 1.11532
Value Function Loss: 0.05991

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.05536

Collected Steps per Second: 13081.10454
Overall Steps per Second: 10776.60273

Timestep Collection Time: 3.82628
Timestep Consumption Time: 0.81822
PPO Batch Consumption Time: 0.02802
Total Iteration Time: 4.64451

Cumulative Model Updates: 3315
Cumulative Timesteps: 55326056

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 55326056...
Checkpoint 55326056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04530
Policy Entropy: 1.11308
Value Function Loss: 0.05071

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.05311

Collected Steps per Second: 12731.72751
Overall Steps per Second: 10523.04262

Timestep Collection Time: 3.93018
Timestep Consumption Time: 0.82491
PPO Batch Consumption Time: 0.03052
Total Iteration Time: 4.75509

Cumulative Model Updates: 3318
Cumulative Timesteps: 55376094

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00861
Policy Entropy: 1.11618
Value Function Loss: 0.03163

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.05222

Collected Steps per Second: 13114.00484
Overall Steps per Second: 11012.41175

Timestep Collection Time: 3.81379
Timestep Consumption Time: 0.72782
PPO Batch Consumption Time: 0.02750
Total Iteration Time: 4.54160

Cumulative Model Updates: 3321
Cumulative Timesteps: 55426108

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 55426108...
Checkpoint 55426108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00330
Policy Entropy: 1.12012
Value Function Loss: 0.02322

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.05020

Collected Steps per Second: 12775.19750
Overall Steps per Second: 10572.22276

Timestep Collection Time: 3.91665
Timestep Consumption Time: 0.81613
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 4.73278

Cumulative Model Updates: 3324
Cumulative Timesteps: 55476144

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05148
Policy Entropy: 1.12205
Value Function Loss: 0.00974

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.04615
Value Function Update Magnitude: 0.04315

Collected Steps per Second: 13217.16717
Overall Steps per Second: 10929.06713

Timestep Collection Time: 3.78493
Timestep Consumption Time: 0.79241
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 4.57733

Cumulative Model Updates: 3327
Cumulative Timesteps: 55526170

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 55526170...
Checkpoint 55526170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09241
Policy Entropy: 1.12043
Value Function Loss: 0.01977

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.04543
Value Function Update Magnitude: 0.03950

Collected Steps per Second: 13243.17788
Overall Steps per Second: 10924.17450

Timestep Collection Time: 3.77810
Timestep Consumption Time: 0.80202
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 4.58012

Cumulative Model Updates: 3330
Cumulative Timesteps: 55576204

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08408
Policy Entropy: 1.10324
Value Function Loss: 0.03668

Mean KL Divergence: 0.02191
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.06727

Collected Steps per Second: 13107.48972
Overall Steps per Second: 10796.26495

Timestep Collection Time: 3.81538
Timestep Consumption Time: 0.81678
PPO Batch Consumption Time: 0.02845
Total Iteration Time: 4.63216

Cumulative Model Updates: 3333
Cumulative Timesteps: 55626214

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 55626214...
Checkpoint 55626214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04879
Policy Entropy: 1.09872
Value Function Loss: 0.04653

Mean KL Divergence: 0.03096
SB3 Clip Fraction: 0.20465
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.06551

Collected Steps per Second: 13016.83955
Overall Steps per Second: 10839.80369

Timestep Collection Time: 3.84410
Timestep Consumption Time: 0.77204
PPO Batch Consumption Time: 0.02880
Total Iteration Time: 4.61614

Cumulative Model Updates: 3336
Cumulative Timesteps: 55676252

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04683
Policy Entropy: 1.12923
Value Function Loss: 0.04650

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.15171
Policy Update Magnitude: 0.05399
Value Function Update Magnitude: 0.06543

Collected Steps per Second: 13026.67803
Overall Steps per Second: 10757.78753

Timestep Collection Time: 3.84119
Timestep Consumption Time: 0.81013
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 4.65133

Cumulative Model Updates: 3339
Cumulative Timesteps: 55726290

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 55726290...
Checkpoint 55726290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05061
Policy Entropy: 1.11852
Value Function Loss: 0.03819

Mean KL Divergence: 0.01936
SB3 Clip Fraction: 0.15259
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.06425

Collected Steps per Second: 13236.66730
Overall Steps per Second: 10794.63379

Timestep Collection Time: 3.77844
Timestep Consumption Time: 0.85478
PPO Batch Consumption Time: 0.02820
Total Iteration Time: 4.63323

Cumulative Model Updates: 3342
Cumulative Timesteps: 55776304

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03285
Policy Entropy: 1.10455
Value Function Loss: 0.03541

Mean KL Divergence: 0.02540
SB3 Clip Fraction: 0.15023
Policy Update Magnitude: 0.04507
Value Function Update Magnitude: 0.05996

Collected Steps per Second: 13309.59639
Overall Steps per Second: 10924.18877

Timestep Collection Time: 3.75879
Timestep Consumption Time: 0.82077
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 4.57956

Cumulative Model Updates: 3345
Cumulative Timesteps: 55826332

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 55826332...
Checkpoint 55826332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00827
Policy Entropy: 1.11445
Value Function Loss: 0.02376

Mean KL Divergence: 0.02178
SB3 Clip Fraction: 0.16023
Policy Update Magnitude: 0.04372
Value Function Update Magnitude: 0.05489

Collected Steps per Second: 12665.34830
Overall Steps per Second: 10518.37791

Timestep Collection Time: 3.94967
Timestep Consumption Time: 0.80619
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 4.75587

Cumulative Model Updates: 3348
Cumulative Timesteps: 55876356

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02136
Policy Entropy: 1.12673
Value Function Loss: 0.03230

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.04185
Value Function Update Magnitude: 0.05676

Collected Steps per Second: 13004.52259
Overall Steps per Second: 10765.87958

Timestep Collection Time: 3.84789
Timestep Consumption Time: 0.80013
PPO Batch Consumption Time: 0.02773
Total Iteration Time: 4.64802

Cumulative Model Updates: 3351
Cumulative Timesteps: 55926396

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 55926396...
Checkpoint 55926396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02841
Policy Entropy: 1.11882
Value Function Loss: 0.03272

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.03809
Value Function Update Magnitude: 0.04877

Collected Steps per Second: 13296.47482
Overall Steps per Second: 10906.88655

Timestep Collection Time: 3.76130
Timestep Consumption Time: 0.82406
PPO Batch Consumption Time: 0.02734
Total Iteration Time: 4.58536

Cumulative Model Updates: 3354
Cumulative Timesteps: 55976408

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06075
Policy Entropy: 1.11266
Value Function Loss: 0.03676

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.04481

Collected Steps per Second: 13075.66519
Overall Steps per Second: 10782.51749

Timestep Collection Time: 3.82803
Timestep Consumption Time: 0.81412
PPO Batch Consumption Time: 0.02985
Total Iteration Time: 4.64214

Cumulative Model Updates: 3357
Cumulative Timesteps: 56026462

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 56026462...
Checkpoint 56026462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02727
Policy Entropy: 1.09674
Value Function Loss: 0.03943

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.04160
Value Function Update Magnitude: 0.04242

Collected Steps per Second: 12934.85476
Overall Steps per Second: 10893.45387

Timestep Collection Time: 3.86939
Timestep Consumption Time: 0.72511
PPO Batch Consumption Time: 0.02829
Total Iteration Time: 4.59450

Cumulative Model Updates: 3360
Cumulative Timesteps: 56076512

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08428
Policy Entropy: 1.10854
Value Function Loss: 0.05484

Mean KL Divergence: 0.02997
SB3 Clip Fraction: 0.17075
Policy Update Magnitude: 0.04257
Value Function Update Magnitude: 0.05306

Collected Steps per Second: 13252.95758
Overall Steps per Second: 10858.77185

Timestep Collection Time: 3.77486
Timestep Consumption Time: 0.83230
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 4.60715

Cumulative Model Updates: 3363
Cumulative Timesteps: 56126540

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 56126540...
Checkpoint 56126540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01812
Policy Entropy: 1.09912
Value Function Loss: 0.05662

Mean KL Divergence: 0.03458
SB3 Clip Fraction: 0.20030
Policy Update Magnitude: 0.04065
Value Function Update Magnitude: 0.06222

Collected Steps per Second: 12449.79913
Overall Steps per Second: 10425.03499

Timestep Collection Time: 4.01757
Timestep Consumption Time: 0.78030
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 4.79787

Cumulative Model Updates: 3366
Cumulative Timesteps: 56176558

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05002
Policy Entropy: 1.06432
Value Function Loss: 0.06805

Mean KL Divergence: 0.07701
SB3 Clip Fraction: 0.25473
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.06447

Collected Steps per Second: 13317.01593
Overall Steps per Second: 10992.18351

Timestep Collection Time: 3.75625
Timestep Consumption Time: 0.79444
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 4.55069

Cumulative Model Updates: 3369
Cumulative Timesteps: 56226580

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 56226580...
Checkpoint 56226580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06368
Policy Entropy: 1.09445
Value Function Loss: 0.05533

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.04309
Value Function Update Magnitude: 0.06540

Collected Steps per Second: 12788.67583
Overall Steps per Second: 10604.76248

Timestep Collection Time: 3.91221
Timestep Consumption Time: 0.80567
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 4.71788

Cumulative Model Updates: 3372
Cumulative Timesteps: 56276612

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01073
Policy Entropy: 1.10465
Value Function Loss: 0.04817

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.18146
Policy Update Magnitude: 0.04098
Value Function Update Magnitude: 0.06592

Collected Steps per Second: 12709.52342
Overall Steps per Second: 10706.72456

Timestep Collection Time: 3.93547
Timestep Consumption Time: 0.73617
PPO Batch Consumption Time: 0.03058
Total Iteration Time: 4.67164

Cumulative Model Updates: 3375
Cumulative Timesteps: 56326630

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 56326630...
Checkpoint 56326630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00671
Policy Entropy: 1.05813
Value Function Loss: 0.04205

Mean KL Divergence: 0.04396
SB3 Clip Fraction: 0.20930
Policy Update Magnitude: 0.04007
Value Function Update Magnitude: 0.06675

Collected Steps per Second: 13040.67020
Overall Steps per Second: 10777.30777

Timestep Collection Time: 3.83416
Timestep Consumption Time: 0.80522
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 4.63938

Cumulative Model Updates: 3378
Cumulative Timesteps: 56376630

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01396
Policy Entropy: 1.10537
Value Function Loss: 0.04818

Mean KL Divergence: 0.02927
SB3 Clip Fraction: 0.19533
Policy Update Magnitude: 0.04545
Value Function Update Magnitude: 0.07851

Collected Steps per Second: 12691.58426
Overall Steps per Second: 10556.95704

Timestep Collection Time: 3.94041
Timestep Consumption Time: 0.79675
PPO Batch Consumption Time: 0.02739
Total Iteration Time: 4.73716

Cumulative Model Updates: 3381
Cumulative Timesteps: 56426640

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 56426640...
Checkpoint 56426640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00115
Policy Entropy: 1.05196
Value Function Loss: 0.04519

Mean KL Divergence: 0.06012
SB3 Clip Fraction: 0.23918
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.08774

Collected Steps per Second: 13357.58255
Overall Steps per Second: 10968.82916

Timestep Collection Time: 3.74499
Timestep Consumption Time: 0.81557
PPO Batch Consumption Time: 0.02912
Total Iteration Time: 4.56056

Cumulative Model Updates: 3384
Cumulative Timesteps: 56476664

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04010
Policy Entropy: 1.11622
Value Function Loss: 0.03664

Mean KL Divergence: 0.05767
SB3 Clip Fraction: 0.20193
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.07583

Collected Steps per Second: 13279.15412
Overall Steps per Second: 10922.93396

Timestep Collection Time: 3.76741
Timestep Consumption Time: 0.81268
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 4.58009

Cumulative Model Updates: 3387
Cumulative Timesteps: 56526692

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 56526692...
Checkpoint 56526692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14209
Policy Entropy: 1.06233
Value Function Loss: 0.03665

Mean KL Divergence: 0.04745
SB3 Clip Fraction: 0.23633
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.06457

Collected Steps per Second: 12953.50670
Overall Steps per Second: 10914.79001

Timestep Collection Time: 3.86366
Timestep Consumption Time: 0.72167
PPO Batch Consumption Time: 0.02939
Total Iteration Time: 4.58534

Cumulative Model Updates: 3390
Cumulative Timesteps: 56576740

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01504
Policy Entropy: 1.11187
Value Function Loss: 0.03256

Mean KL Divergence: 0.02506
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.06236

Collected Steps per Second: 12974.05566
Overall Steps per Second: 10600.38582

Timestep Collection Time: 3.85785
Timestep Consumption Time: 0.86386
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 4.72171

Cumulative Model Updates: 3393
Cumulative Timesteps: 56626792

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 56626792...
Checkpoint 56626792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06830
Policy Entropy: 1.08113
Value Function Loss: 0.03591

Mean KL Divergence: 0.02565
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.05403
Value Function Update Magnitude: 0.07026

Collected Steps per Second: 12949.22519
Overall Steps per Second: 10751.66920

Timestep Collection Time: 3.86525
Timestep Consumption Time: 0.79003
PPO Batch Consumption Time: 0.02618
Total Iteration Time: 4.65528

Cumulative Model Updates: 3396
Cumulative Timesteps: 56676844

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04006
Policy Entropy: 1.09864
Value Function Loss: 0.03958

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07070

Collected Steps per Second: 13252.16618
Overall Steps per Second: 10786.18327

Timestep Collection Time: 3.77629
Timestep Consumption Time: 0.86335
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 4.63964

Cumulative Model Updates: 3399
Cumulative Timesteps: 56726888

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 56726888...
Checkpoint 56726888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00360
Policy Entropy: 1.10878
Value Function Loss: 0.04148

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.07150

Collected Steps per Second: 13282.74289
Overall Steps per Second: 10969.04529

Timestep Collection Time: 3.76639
Timestep Consumption Time: 0.79444
PPO Batch Consumption Time: 0.02590
Total Iteration Time: 4.56083

Cumulative Model Updates: 3402
Cumulative Timesteps: 56776916

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01624
Policy Entropy: 1.11382
Value Function Loss: 0.04085

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.04876
Value Function Update Magnitude: 0.06022

Collected Steps per Second: 13292.99742
Overall Steps per Second: 10979.58571

Timestep Collection Time: 3.76213
Timestep Consumption Time: 0.79269
PPO Batch Consumption Time: 0.02666
Total Iteration Time: 4.55482

Cumulative Model Updates: 3405
Cumulative Timesteps: 56826926

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 56826926...
Checkpoint 56826926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01679
Policy Entropy: 1.12094
Value Function Loss: 0.02855

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.04691
Value Function Update Magnitude: 0.05498

Collected Steps per Second: 12841.93005
Overall Steps per Second: 10620.55506

Timestep Collection Time: 3.89459
Timestep Consumption Time: 0.81458
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 4.70917

Cumulative Model Updates: 3408
Cumulative Timesteps: 56876940

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01214
Policy Entropy: 1.11236
Value Function Loss: 0.02173

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.04155
Value Function Update Magnitude: 0.05299

Collected Steps per Second: 12645.33403
Overall Steps per Second: 10447.71565

Timestep Collection Time: 3.95545
Timestep Consumption Time: 0.83201
PPO Batch Consumption Time: 0.02995
Total Iteration Time: 4.78746

Cumulative Model Updates: 3411
Cumulative Timesteps: 56926958

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 56926958...
Checkpoint 56926958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01083
Policy Entropy: 1.10130
Value Function Loss: 0.02719

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.03860
Value Function Update Magnitude: 0.05489

Collected Steps per Second: 12744.71664
Overall Steps per Second: 10775.03533

Timestep Collection Time: 3.92461
Timestep Consumption Time: 0.71742
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 4.64203

Cumulative Model Updates: 3414
Cumulative Timesteps: 56976976

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02447
Policy Entropy: 1.08123
Value Function Loss: 0.03338

Mean KL Divergence: 0.02516
SB3 Clip Fraction: 0.17493
Policy Update Magnitude: 0.03908
Value Function Update Magnitude: 0.05442

Collected Steps per Second: 13148.78714
Overall Steps per Second: 10867.81352

Timestep Collection Time: 3.80400
Timestep Consumption Time: 0.79840
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 4.60240

Cumulative Model Updates: 3417
Cumulative Timesteps: 57026994

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 57026994...
Checkpoint 57026994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01233
Policy Entropy: 1.11110
Value Function Loss: 0.03854

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.03870
Value Function Update Magnitude: 0.05253

Collected Steps per Second: 13048.59502
Overall Steps per Second: 10881.89719

Timestep Collection Time: 3.83551
Timestep Consumption Time: 0.76369
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 4.59920

Cumulative Model Updates: 3420
Cumulative Timesteps: 57077042

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06380
Policy Entropy: 1.08965
Value Function Loss: 0.03970

Mean KL Divergence: 0.03732
SB3 Clip Fraction: 0.19437
Policy Update Magnitude: 0.04167
Value Function Update Magnitude: 0.04619

Collected Steps per Second: 13046.11037
Overall Steps per Second: 10790.45859

Timestep Collection Time: 3.83609
Timestep Consumption Time: 0.80190
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 4.63799

Cumulative Model Updates: 3423
Cumulative Timesteps: 57127088

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 57127088...
Checkpoint 57127088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04474
Policy Entropy: 1.10422
Value Function Loss: 0.04665

Mean KL Divergence: 0.03369
SB3 Clip Fraction: 0.19853
Policy Update Magnitude: 0.04060
Value Function Update Magnitude: 0.05228

Collected Steps per Second: 13010.25130
Overall Steps per Second: 10817.43023

Timestep Collection Time: 3.84405
Timestep Consumption Time: 0.77923
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 4.62328

Cumulative Model Updates: 3426
Cumulative Timesteps: 57177100

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04355
Policy Entropy: 1.09625
Value Function Loss: 0.05153

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.04585
Value Function Update Magnitude: 0.06693

Collected Steps per Second: 12989.58100
Overall Steps per Second: 10987.20532

Timestep Collection Time: 3.84985
Timestep Consumption Time: 0.70162
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 4.55148

Cumulative Model Updates: 3429
Cumulative Timesteps: 57227108

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 57227108...
Checkpoint 57227108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00369
Policy Entropy: 1.08640
Value Function Loss: 0.04445

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.04711
Value Function Update Magnitude: 0.06725

Collected Steps per Second: 13220.97781
Overall Steps per Second: 10888.28691

Timestep Collection Time: 3.78444
Timestep Consumption Time: 0.81077
PPO Batch Consumption Time: 0.03026
Total Iteration Time: 4.59521

Cumulative Model Updates: 3432
Cumulative Timesteps: 57277142

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06940
Policy Entropy: 1.07832
Value Function Loss: 0.03274

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.05972

Collected Steps per Second: 12771.74740
Overall Steps per Second: 10671.35183

Timestep Collection Time: 3.91520
Timestep Consumption Time: 0.77061
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 4.68582

Cumulative Model Updates: 3435
Cumulative Timesteps: 57327146

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 57327146...
Checkpoint 57327146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02844
Policy Entropy: 1.08530
Value Function Loss: 0.03230

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.05682

Collected Steps per Second: 12755.96783
Overall Steps per Second: 10471.96326

Timestep Collection Time: 3.91989
Timestep Consumption Time: 0.85495
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 4.77484

Cumulative Model Updates: 3438
Cumulative Timesteps: 57377148

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08108
Policy Entropy: 1.09254
Value Function Loss: 0.03389

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.04327
Value Function Update Magnitude: 0.08115

Collected Steps per Second: 12617.68752
Overall Steps per Second: 10353.22087

Timestep Collection Time: 3.96507
Timestep Consumption Time: 0.86724
PPO Batch Consumption Time: 0.02927
Total Iteration Time: 4.83231

Cumulative Model Updates: 3441
Cumulative Timesteps: 57427178

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 57427178...
Checkpoint 57427178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00737
Policy Entropy: 1.09161
Value Function Loss: 0.04296

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07331
Policy Update Magnitude: 0.04444
Value Function Update Magnitude: 0.07048

Collected Steps per Second: 13196.08712
Overall Steps per Second: 10906.55055

Timestep Collection Time: 3.79112
Timestep Consumption Time: 0.79584
PPO Batch Consumption Time: 0.03290
Total Iteration Time: 4.58697

Cumulative Model Updates: 3444
Cumulative Timesteps: 57477206

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00393
Policy Entropy: 1.07006
Value Function Loss: 0.05076

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 11343.46379
Overall Steps per Second: 9435.17143

Timestep Collection Time: 4.41170
Timestep Consumption Time: 0.89228
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 5.30398

Cumulative Model Updates: 3447
Cumulative Timesteps: 57527250

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 57527250...
Checkpoint 57527250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00125
Policy Entropy: 1.10056
Value Function Loss: 0.04243

Mean KL Divergence: 0.02570
SB3 Clip Fraction: 0.18653
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.06137

Collected Steps per Second: 13073.98220
Overall Steps per Second: 10872.06930

Timestep Collection Time: 3.82500
Timestep Consumption Time: 0.77467
PPO Batch Consumption Time: 0.02578
Total Iteration Time: 4.59968

Cumulative Model Updates: 3450
Cumulative Timesteps: 57577258

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04382
Policy Entropy: 1.09372
Value Function Loss: 0.04620

Mean KL Divergence: 0.02392
SB3 Clip Fraction: 0.18210
Policy Update Magnitude: 0.04539
Value Function Update Magnitude: 0.05392

Collected Steps per Second: 12637.69096
Overall Steps per Second: 10460.05197

Timestep Collection Time: 3.95816
Timestep Consumption Time: 0.82403
PPO Batch Consumption Time: 0.02602
Total Iteration Time: 4.78219

Cumulative Model Updates: 3453
Cumulative Timesteps: 57627280

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 57627280...
Checkpoint 57627280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00488
Policy Entropy: 1.08600
Value Function Loss: 0.04270

Mean KL Divergence: 0.02314
SB3 Clip Fraction: 0.14521
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.05686

Collected Steps per Second: 12300.33498
Overall Steps per Second: 10252.70618

Timestep Collection Time: 4.06526
Timestep Consumption Time: 0.81190
PPO Batch Consumption Time: 0.03056
Total Iteration Time: 4.87715

Cumulative Model Updates: 3456
Cumulative Timesteps: 57677284

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03221
Policy Entropy: 1.09148
Value Function Loss: 0.04636

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.15867
Policy Update Magnitude: 0.05498
Value Function Update Magnitude: 0.07113

Collected Steps per Second: 12700.52113
Overall Steps per Second: 10713.00209

Timestep Collection Time: 3.93842
Timestep Consumption Time: 0.73067
PPO Batch Consumption Time: 0.03055
Total Iteration Time: 4.66909

Cumulative Model Updates: 3459
Cumulative Timesteps: 57727304

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 57727304...
Checkpoint 57727304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01978
Policy Entropy: 1.10689
Value Function Loss: 0.04405

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 13053.51092
Overall Steps per Second: 10702.23760

Timestep Collection Time: 3.83054
Timestep Consumption Time: 0.84157
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 4.67211

Cumulative Model Updates: 3462
Cumulative Timesteps: 57777306

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00547
Policy Entropy: 1.12213
Value Function Loss: 0.04439

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.06195

Collected Steps per Second: 12891.55297
Overall Steps per Second: 10722.86446

Timestep Collection Time: 3.88053
Timestep Consumption Time: 0.78483
PPO Batch Consumption Time: 0.02886
Total Iteration Time: 4.66536

Cumulative Model Updates: 3465
Cumulative Timesteps: 57827332

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 57827332...
Checkpoint 57827332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02672
Policy Entropy: 1.11023
Value Function Loss: 0.05827

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 12905.38725
Overall Steps per Second: 10688.75717

Timestep Collection Time: 3.87528
Timestep Consumption Time: 0.80365
PPO Batch Consumption Time: 0.02809
Total Iteration Time: 4.67893

Cumulative Model Updates: 3468
Cumulative Timesteps: 57877344

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02652
Policy Entropy: 1.10010
Value Function Loss: 0.04364

Mean KL Divergence: 0.03857
SB3 Clip Fraction: 0.21437
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 13122.11749
Overall Steps per Second: 10820.74718

Timestep Collection Time: 3.81143
Timestep Consumption Time: 0.81062
PPO Batch Consumption Time: 0.02648
Total Iteration Time: 4.62205

Cumulative Model Updates: 3471
Cumulative Timesteps: 57927358

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 57927358...
Checkpoint 57927358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01687
Policy Entropy: 1.12750
Value Function Loss: 0.04355

Mean KL Divergence: 0.02293
SB3 Clip Fraction: 0.15117
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.05636

Collected Steps per Second: 12897.54361
Overall Steps per Second: 10801.98975

Timestep Collection Time: 3.87903
Timestep Consumption Time: 0.75252
PPO Batch Consumption Time: 0.03435
Total Iteration Time: 4.63155

Cumulative Model Updates: 3474
Cumulative Timesteps: 57977388

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06428
Policy Entropy: 1.11241
Value Function Loss: 0.04029

Mean KL Divergence: 0.02910
SB3 Clip Fraction: 0.17357
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.05617

Collected Steps per Second: 12675.87658
Overall Steps per Second: 10489.48292

Timestep Collection Time: 3.94545
Timestep Consumption Time: 0.82238
PPO Batch Consumption Time: 0.02918
Total Iteration Time: 4.76782

Cumulative Model Updates: 3477
Cumulative Timesteps: 58027400

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 58027400...
Checkpoint 58027400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13738
Policy Entropy: 1.07589
Value Function Loss: 0.06264

Mean KL Divergence: 0.06495
SB3 Clip Fraction: 0.22463
Policy Update Magnitude: 0.04859
Value Function Update Magnitude: 0.06251

Collected Steps per Second: 13297.38993
Overall Steps per Second: 10985.37000

Timestep Collection Time: 3.76224
Timestep Consumption Time: 0.79181
PPO Batch Consumption Time: 0.02872
Total Iteration Time: 4.55406

Cumulative Model Updates: 3480
Cumulative Timesteps: 58077428

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01618
Policy Entropy: 1.12184
Value Function Loss: 0.04922

Mean KL Divergence: 0.03811
SB3 Clip Fraction: 0.21930
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.06196

Collected Steps per Second: 13334.30434
Overall Steps per Second: 10915.33427

Timestep Collection Time: 3.75198
Timestep Consumption Time: 0.83148
PPO Batch Consumption Time: 0.02885
Total Iteration Time: 4.58346

Cumulative Model Updates: 3483
Cumulative Timesteps: 58127458

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 58127458...
Checkpoint 58127458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00906
Policy Entropy: 1.05755
Value Function Loss: 0.04921

Mean KL Divergence: 0.07838
SB3 Clip Fraction: 0.24783
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.05886

Collected Steps per Second: 13006.81887
Overall Steps per Second: 10761.21536

Timestep Collection Time: 3.84660
Timestep Consumption Time: 0.80269
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 4.64929

Cumulative Model Updates: 3486
Cumulative Timesteps: 58177490

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02650
Policy Entropy: 1.12643
Value Function Loss: 0.04125

Mean KL Divergence: 0.04818
SB3 Clip Fraction: 0.19841
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.05641

Collected Steps per Second: 13120.44544
Overall Steps per Second: 11062.29680

Timestep Collection Time: 3.81283
Timestep Consumption Time: 0.70938
PPO Batch Consumption Time: 0.02580
Total Iteration Time: 4.52221

Cumulative Model Updates: 3489
Cumulative Timesteps: 58227516

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 58227516...
Checkpoint 58227516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04176
Policy Entropy: 1.07251
Value Function Loss: 0.04874

Mean KL Divergence: 0.05164
SB3 Clip Fraction: 0.22686
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.06081

Collected Steps per Second: 12769.44700
Overall Steps per Second: 10592.17471

Timestep Collection Time: 3.91967
Timestep Consumption Time: 0.80571
PPO Batch Consumption Time: 0.02926
Total Iteration Time: 4.72538

Cumulative Model Updates: 3492
Cumulative Timesteps: 58277568

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02279
Policy Entropy: 1.13454
Value Function Loss: 0.05223

Mean KL Divergence: 0.03645
SB3 Clip Fraction: 0.20115
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.06933

Collected Steps per Second: 13148.97876
Overall Steps per Second: 10832.55127

Timestep Collection Time: 3.80258
Timestep Consumption Time: 0.81314
PPO Batch Consumption Time: 0.03078
Total Iteration Time: 4.61572

Cumulative Model Updates: 3495
Cumulative Timesteps: 58327568

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 58327568...
Checkpoint 58327568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01712
Policy Entropy: 1.09241
Value Function Loss: 0.04994

Mean KL Divergence: 0.03313
SB3 Clip Fraction: 0.19419
Policy Update Magnitude: 0.06168
Value Function Update Magnitude: 0.07432

Collected Steps per Second: 13533.03363
Overall Steps per Second: 11091.08635

Timestep Collection Time: 3.69718
Timestep Consumption Time: 0.81401
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 4.51119

Cumulative Model Updates: 3498
Cumulative Timesteps: 58377602

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04777
Policy Entropy: 1.11558
Value Function Loss: 0.04136

Mean KL Divergence: 0.02884
SB3 Clip Fraction: 0.18489
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.07322

Collected Steps per Second: 13079.86503
Overall Steps per Second: 10800.24648

Timestep Collection Time: 3.82313
Timestep Consumption Time: 0.80695
PPO Batch Consumption Time: 0.02731
Total Iteration Time: 4.63008

Cumulative Model Updates: 3501
Cumulative Timesteps: 58427608

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 58427608...
Checkpoint 58427608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09041
Policy Entropy: 1.11048
Value Function Loss: 0.04358

Mean KL Divergence: 0.02445
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.06589

Collected Steps per Second: 12942.20043
Overall Steps per Second: 10932.58143

Timestep Collection Time: 3.86565
Timestep Consumption Time: 0.71058
PPO Batch Consumption Time: 0.02658
Total Iteration Time: 4.57623

Cumulative Model Updates: 3504
Cumulative Timesteps: 58477638

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06332
Policy Entropy: 1.10278
Value Function Loss: 0.05011

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 13075.81759
Overall Steps per Second: 10815.23150

Timestep Collection Time: 3.82523
Timestep Consumption Time: 0.79954
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 4.62477

Cumulative Model Updates: 3507
Cumulative Timesteps: 58527656

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 58527656...
Checkpoint 58527656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02162
Policy Entropy: 1.10603
Value Function Loss: 0.06325

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.05809

Collected Steps per Second: 12839.38372
Overall Steps per Second: 10680.26132

Timestep Collection Time: 3.89879
Timestep Consumption Time: 0.78818
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 4.68696

Cumulative Model Updates: 3510
Cumulative Timesteps: 58577714

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01718
Policy Entropy: 1.09553
Value Function Loss: 0.05223

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 13050.15451
Overall Steps per Second: 10807.76533

Timestep Collection Time: 3.83183
Timestep Consumption Time: 0.79503
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 4.62686

Cumulative Model Updates: 3513
Cumulative Timesteps: 58627720

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 58627720...
Checkpoint 58627720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03783
Policy Entropy: 1.10087
Value Function Loss: 0.04204

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.05704
Value Function Update Magnitude: 0.06409

Collected Steps per Second: 12917.55538
Overall Steps per Second: 10672.14831

Timestep Collection Time: 3.87117
Timestep Consumption Time: 0.81449
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 4.68565

Cumulative Model Updates: 3516
Cumulative Timesteps: 58677726

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06703
Policy Entropy: 1.09703
Value Function Loss: 0.03447

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.05392

Collected Steps per Second: 13098.35546
Overall Steps per Second: 10890.84386

Timestep Collection Time: 3.81941
Timestep Consumption Time: 0.77417
PPO Batch Consumption Time: 0.02704
Total Iteration Time: 4.59358

Cumulative Model Updates: 3519
Cumulative Timesteps: 58727754

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 58727754...
Checkpoint 58727754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00301
Policy Entropy: 1.10266
Value Function Loss: 0.03228

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11058
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.05056

Collected Steps per Second: 13168.88204
Overall Steps per Second: 10789.44602

Timestep Collection Time: 3.79926
Timestep Consumption Time: 0.83786
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 4.63712

Cumulative Model Updates: 3522
Cumulative Timesteps: 58777786

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03800
Policy Entropy: 1.11365
Value Function Loss: 0.02979

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.04890
Value Function Update Magnitude: 0.04798

Collected Steps per Second: 13037.72970
Overall Steps per Second: 10833.58134

Timestep Collection Time: 3.83686
Timestep Consumption Time: 0.78063
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 4.61749

Cumulative Model Updates: 3525
Cumulative Timesteps: 58827810

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 58827810...
Checkpoint 58827810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04250
Policy Entropy: 1.11851
Value Function Loss: 0.02444

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.04413
Value Function Update Magnitude: 0.04127

Collected Steps per Second: 13029.66433
Overall Steps per Second: 10777.38814

Timestep Collection Time: 3.83893
Timestep Consumption Time: 0.80227
PPO Batch Consumption Time: 0.02587
Total Iteration Time: 4.64120

Cumulative Model Updates: 3528
Cumulative Timesteps: 58877830

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00757
Policy Entropy: 1.12331
Value Function Loss: 0.02801

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.03703

Collected Steps per Second: 12922.77021
Overall Steps per Second: 10660.71413

Timestep Collection Time: 3.87316
Timestep Consumption Time: 0.82183
PPO Batch Consumption Time: 0.02916
Total Iteration Time: 4.69500

Cumulative Model Updates: 3531
Cumulative Timesteps: 58927882

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 58927882...
Checkpoint 58927882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01912
Policy Entropy: 1.11405
Value Function Loss: 0.03344

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.04468

Collected Steps per Second: 13102.31841
Overall Steps per Second: 11005.52403

Timestep Collection Time: 3.81749
Timestep Consumption Time: 0.72732
PPO Batch Consumption Time: 0.02715
Total Iteration Time: 4.54481

Cumulative Model Updates: 3534
Cumulative Timesteps: 58977900

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10881
Policy Entropy: 1.09796
Value Function Loss: 0.03257

Mean KL Divergence: 0.03465
SB3 Clip Fraction: 0.20985
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.04207

Collected Steps per Second: 13070.18466
Overall Steps per Second: 10772.24651

Timestep Collection Time: 3.82764
Timestep Consumption Time: 0.81651
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 4.64416

Cumulative Model Updates: 3537
Cumulative Timesteps: 59027928

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 59027928...
Checkpoint 59027928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02948
Policy Entropy: 1.12226
Value Function Loss: 0.05019

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.04392

Collected Steps per Second: 12708.13349
Overall Steps per Second: 10592.39033

Timestep Collection Time: 3.93858
Timestep Consumption Time: 0.78670
PPO Batch Consumption Time: 0.02944
Total Iteration Time: 4.72528

Cumulative Model Updates: 3540
Cumulative Timesteps: 59077980

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06085
Policy Entropy: 1.13354
Value Function Loss: 0.06460

Mean KL Divergence: 0.02749
SB3 Clip Fraction: 0.18559
Policy Update Magnitude: 0.05488
Value Function Update Magnitude: 0.05762

Collected Steps per Second: 13339.94500
Overall Steps per Second: 11024.91181

Timestep Collection Time: 3.74964
Timestep Consumption Time: 0.78736
PPO Batch Consumption Time: 0.02790
Total Iteration Time: 4.53700

Cumulative Model Updates: 3543
Cumulative Timesteps: 59128000

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 59128000...
Checkpoint 59128000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06768
Policy Entropy: 1.09518
Value Function Loss: 0.07050

Mean KL Divergence: 0.03879
SB3 Clip Fraction: 0.18707
Policy Update Magnitude: 0.06246
Value Function Update Magnitude: 0.05173

Collected Steps per Second: 13252.59453
Overall Steps per Second: 10914.61679

Timestep Collection Time: 3.77436
Timestep Consumption Time: 0.80849
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 4.58285

Cumulative Model Updates: 3546
Cumulative Timesteps: 59178020

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01496
Policy Entropy: 1.14374
Value Function Loss: 0.07025

Mean KL Divergence: 0.03540
SB3 Clip Fraction: 0.20993
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.05536

Collected Steps per Second: 12873.66304
Overall Steps per Second: 10902.50786

Timestep Collection Time: 3.88405
Timestep Consumption Time: 0.70223
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 4.58628

Cumulative Model Updates: 3549
Cumulative Timesteps: 59228022

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 59228022...
Checkpoint 59228022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01896
Policy Entropy: 1.12020
Value Function Loss: 0.04797

Mean KL Divergence: 0.03637
SB3 Clip Fraction: 0.19081
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.06288

Collected Steps per Second: 12206.27659
Overall Steps per Second: 10040.79897

Timestep Collection Time: 4.09756
Timestep Consumption Time: 0.88371
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 4.98128

Cumulative Model Updates: 3552
Cumulative Timesteps: 59278038

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10047
Policy Entropy: 1.13413
Value Function Loss: 0.05338

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.16645
Policy Update Magnitude: 0.05290
Value Function Update Magnitude: 0.06423

Collected Steps per Second: 10971.23968
Overall Steps per Second: 9170.76674

Timestep Collection Time: 4.55919
Timestep Consumption Time: 0.89509
PPO Batch Consumption Time: 0.03170
Total Iteration Time: 5.45429

Cumulative Model Updates: 3555
Cumulative Timesteps: 59328058

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 59328058...
Checkpoint 59328058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03938
Policy Entropy: 1.13195
Value Function Loss: 0.05186

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.17283
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.06247

Collected Steps per Second: 10631.32571
Overall Steps per Second: 8939.69503

Timestep Collection Time: 4.70572
Timestep Consumption Time: 0.89045
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 5.59616

Cumulative Model Updates: 3558
Cumulative Timesteps: 59378086

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00900
Policy Entropy: 1.13499
Value Function Loss: 0.06204

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.11061
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.05588

Collected Steps per Second: 9663.99515
Overall Steps per Second: 8194.46822

Timestep Collection Time: 5.17633
Timestep Consumption Time: 0.92828
PPO Batch Consumption Time: 0.03148
Total Iteration Time: 6.10461

Cumulative Model Updates: 3561
Cumulative Timesteps: 59428110

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 59428110...
Checkpoint 59428110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00866
Policy Entropy: 1.13922
Value Function Loss: 0.06063

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10541
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.05006

Collected Steps per Second: 12071.04890
Overall Steps per Second: 10189.32312

Timestep Collection Time: 4.14628
Timestep Consumption Time: 0.76572
PPO Batch Consumption Time: 0.03126
Total Iteration Time: 4.91200

Cumulative Model Updates: 3564
Cumulative Timesteps: 59478160

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11888
Policy Entropy: 1.13216
Value Function Loss: 0.05435

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.04753

Collected Steps per Second: 12806.63230
Overall Steps per Second: 10607.60171

Timestep Collection Time: 3.90516
Timestep Consumption Time: 0.80957
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 4.71473

Cumulative Model Updates: 3567
Cumulative Timesteps: 59528172

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 59528172...
Checkpoint 59528172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00677
Policy Entropy: 1.11337
Value Function Loss: 0.06442

Mean KL Divergence: 0.03320
SB3 Clip Fraction: 0.20522
Policy Update Magnitude: 0.04405
Value Function Update Magnitude: 0.04774

Collected Steps per Second: 13068.82986
Overall Steps per Second: 10854.84058

Timestep Collection Time: 3.82988
Timestep Consumption Time: 0.78115
PPO Batch Consumption Time: 0.02856
Total Iteration Time: 4.61103

Cumulative Model Updates: 3570
Cumulative Timesteps: 59578224

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00475
Policy Entropy: 1.11926
Value Function Loss: 0.05291

Mean KL Divergence: 0.02408
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.04271
Value Function Update Magnitude: 0.04900

Collected Steps per Second: 13104.98463
Overall Steps per Second: 10794.64672

Timestep Collection Time: 3.81702
Timestep Consumption Time: 0.81694
PPO Batch Consumption Time: 0.02927
Total Iteration Time: 4.63396

Cumulative Model Updates: 3573
Cumulative Timesteps: 59628246

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 59628246...
Checkpoint 59628246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01275
Policy Entropy: 1.12457
Value Function Loss: 0.06344

Mean KL Divergence: 0.02895
SB3 Clip Fraction: 0.18721
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.04774

Collected Steps per Second: 12509.07302
Overall Steps per Second: 10401.28209

Timestep Collection Time: 3.99886
Timestep Consumption Time: 0.81036
PPO Batch Consumption Time: 0.02926
Total Iteration Time: 4.80921

Cumulative Model Updates: 3576
Cumulative Timesteps: 59678268

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04601
Policy Entropy: 1.10224
Value Function Loss: 0.04980

Mean KL Divergence: 0.02700
SB3 Clip Fraction: 0.15250
Policy Update Magnitude: 0.04284
Value Function Update Magnitude: 0.05022

Collected Steps per Second: 13225.54155
Overall Steps per Second: 10931.14456

Timestep Collection Time: 3.78268
Timestep Consumption Time: 0.79397
PPO Batch Consumption Time: 0.02603
Total Iteration Time: 4.57665

Cumulative Model Updates: 3579
Cumulative Timesteps: 59728296

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 59728296...
Checkpoint 59728296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01688
Policy Entropy: 1.10018
Value Function Loss: 0.06137

Mean KL Divergence: 0.02133
SB3 Clip Fraction: 0.17339
Policy Update Magnitude: 0.04223
Value Function Update Magnitude: 0.05250

Collected Steps per Second: 13212.30249
Overall Steps per Second: 10853.87893

Timestep Collection Time: 3.78465
Timestep Consumption Time: 0.82236
PPO Batch Consumption Time: 0.02617
Total Iteration Time: 4.60702

Cumulative Model Updates: 3582
Cumulative Timesteps: 59778300

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00402
Policy Entropy: 1.12677
Value Function Loss: 0.04426

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.04104
Value Function Update Magnitude: 0.05055

Collected Steps per Second: 13027.43727
Overall Steps per Second: 10748.35227

Timestep Collection Time: 3.83990
Timestep Consumption Time: 0.81421
PPO Batch Consumption Time: 0.02756
Total Iteration Time: 4.65411

Cumulative Model Updates: 3585
Cumulative Timesteps: 59828324

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 59828324...
Checkpoint 59828324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04465
Policy Entropy: 1.13678
Value Function Loss: 0.03736

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.19075
Policy Update Magnitude: 0.03799
Value Function Update Magnitude: 0.04794

Collected Steps per Second: 12883.34164
Overall Steps per Second: 10916.32545

Timestep Collection Time: 3.88440
Timestep Consumption Time: 0.69993
PPO Batch Consumption Time: 0.02668
Total Iteration Time: 4.58433

Cumulative Model Updates: 3588
Cumulative Timesteps: 59878368

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04651
Policy Entropy: 1.09584
Value Function Loss: 0.02933

Mean KL Divergence: 0.03457
SB3 Clip Fraction: 0.19500
Policy Update Magnitude: 0.03611
Value Function Update Magnitude: 0.04245

Collected Steps per Second: 13046.50029
Overall Steps per Second: 10644.25405

Timestep Collection Time: 3.83428
Timestep Consumption Time: 0.86534
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 4.69962

Cumulative Model Updates: 3591
Cumulative Timesteps: 59928392

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 59928392...
Checkpoint 59928392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10207
Policy Entropy: 1.15694
Value Function Loss: 0.02770

Mean KL Divergence: 0.04995
SB3 Clip Fraction: 0.24566
Policy Update Magnitude: 0.03456
Value Function Update Magnitude: 0.03241

Collected Steps per Second: 13029.37037
Overall Steps per Second: 10690.60430

Timestep Collection Time: 3.83963
Timestep Consumption Time: 0.83999
PPO Batch Consumption Time: 0.02858
Total Iteration Time: 4.67962

Cumulative Model Updates: 3594
Cumulative Timesteps: 59978420

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01736
Policy Entropy: 1.10292
Value Function Loss: 0.03120

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.15658
Policy Update Magnitude: 0.03539
Value Function Update Magnitude: 0.02947

Collected Steps per Second: 13575.56408
Overall Steps per Second: 11131.68825

Timestep Collection Time: 3.68662
Timestep Consumption Time: 0.80937
PPO Batch Consumption Time: 0.02905
Total Iteration Time: 4.49599

Cumulative Model Updates: 3597
Cumulative Timesteps: 60028468

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 60028468...
Checkpoint 60028468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01209
Policy Entropy: 1.14883
Value Function Loss: 0.03949

Mean KL Divergence: 0.02474
SB3 Clip Fraction: 0.15435
Policy Update Magnitude: 0.04038
Value Function Update Magnitude: 0.03770

Collected Steps per Second: 13034.54399
Overall Steps per Second: 10778.06083

Timestep Collection Time: 3.83703
Timestep Consumption Time: 0.80332
PPO Batch Consumption Time: 0.02549
Total Iteration Time: 4.64035

Cumulative Model Updates: 3600
Cumulative Timesteps: 60078482

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00158
Policy Entropy: 1.13391
Value Function Loss: 0.05669

Mean KL Divergence: 0.02486
SB3 Clip Fraction: 0.15031
Policy Update Magnitude: 0.04341
Value Function Update Magnitude: 0.04280

Collected Steps per Second: 12885.23686
Overall Steps per Second: 10893.99482

Timestep Collection Time: 3.88150
Timestep Consumption Time: 0.70947
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 4.59097

Cumulative Model Updates: 3603
Cumulative Timesteps: 60128496

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 60128496...
Checkpoint 60128496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03407
Policy Entropy: 1.14482
Value Function Loss: 0.06808

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.05044

Collected Steps per Second: 13096.67115
Overall Steps per Second: 10823.31138

Timestep Collection Time: 3.81944
Timestep Consumption Time: 0.80225
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 4.62169

Cumulative Model Updates: 3606
Cumulative Timesteps: 60178518

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00760
Policy Entropy: 1.14357
Value Function Loss: 0.06703

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.04298
Value Function Update Magnitude: 0.05060

Collected Steps per Second: 13171.19673
Overall Steps per Second: 10922.62968

Timestep Collection Time: 3.79723
Timestep Consumption Time: 0.78171
PPO Batch Consumption Time: 0.02879
Total Iteration Time: 4.57893

Cumulative Model Updates: 3609
Cumulative Timesteps: 60228532

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 60228532...
Checkpoint 60228532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02489
Policy Entropy: 1.14421
Value Function Loss: 0.04831

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.04898

Collected Steps per Second: 13051.94527
Overall Steps per Second: 10731.57741

Timestep Collection Time: 3.83376
Timestep Consumption Time: 0.82893
PPO Batch Consumption Time: 0.02777
Total Iteration Time: 4.66269

Cumulative Model Updates: 3612
Cumulative Timesteps: 60278570

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01031
Policy Entropy: 1.14542
Value Function Loss: 0.03527

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08663
Policy Update Magnitude: 0.04211
Value Function Update Magnitude: 0.04950

Collected Steps per Second: 13270.25209
Overall Steps per Second: 10872.01914

Timestep Collection Time: 3.76798
Timestep Consumption Time: 0.83117
PPO Batch Consumption Time: 0.02771
Total Iteration Time: 4.59915

Cumulative Model Updates: 3615
Cumulative Timesteps: 60328572

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 60328572...
Checkpoint 60328572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04305
Policy Entropy: 1.14483
Value Function Loss: 0.03268

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.03977
Value Function Update Magnitude: 0.05747

Collected Steps per Second: 12791.75076
Overall Steps per Second: 10805.13284

Timestep Collection Time: 3.90955
Timestep Consumption Time: 0.71881
PPO Batch Consumption Time: 0.02786
Total Iteration Time: 4.62836

Cumulative Model Updates: 3618
Cumulative Timesteps: 60378582

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01180
Policy Entropy: 1.14834
Value Function Loss: 0.02781

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06846
Policy Update Magnitude: 0.04241
Value Function Update Magnitude: 0.05370

Collected Steps per Second: 12996.25842
Overall Steps per Second: 10768.52330

Timestep Collection Time: 3.84957
Timestep Consumption Time: 0.79638
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 4.64595

Cumulative Model Updates: 3621
Cumulative Timesteps: 60428612

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 60428612...
Checkpoint 60428612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00788
Policy Entropy: 1.14368
Value Function Loss: 0.02825

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.04030
Value Function Update Magnitude: 0.04596

Collected Steps per Second: 13187.83982
Overall Steps per Second: 10946.19845

Timestep Collection Time: 3.79349
Timestep Consumption Time: 0.77686
PPO Batch Consumption Time: 0.02655
Total Iteration Time: 4.57035

Cumulative Model Updates: 3624
Cumulative Timesteps: 60478640

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00383
Policy Entropy: 1.14096
Value Function Loss: 0.03193

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.03903
Value Function Update Magnitude: 0.04782

Collected Steps per Second: 13441.24175
Overall Steps per Second: 10972.09802

Timestep Collection Time: 3.72302
Timestep Consumption Time: 0.83782
PPO Batch Consumption Time: 0.03551
Total Iteration Time: 4.56084

Cumulative Model Updates: 3627
Cumulative Timesteps: 60528682

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 60528682...
Checkpoint 60528682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01385
Policy Entropy: 1.13801
Value Function Loss: 0.03064

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.14183
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.03988

Collected Steps per Second: 12338.15302
Overall Steps per Second: 10271.19724

Timestep Collection Time: 4.05377
Timestep Consumption Time: 0.81577
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 4.86954

Cumulative Model Updates: 3630
Cumulative Timesteps: 60578698

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02860
Policy Entropy: 1.13534
Value Function Loss: 0.05637

Mean KL Divergence: 0.02146
SB3 Clip Fraction: 0.15914
Policy Update Magnitude: 0.04032
Value Function Update Magnitude: 0.05501

Collected Steps per Second: 12943.13896
Overall Steps per Second: 10703.38073

Timestep Collection Time: 3.86321
Timestep Consumption Time: 0.80840
PPO Batch Consumption Time: 0.03039
Total Iteration Time: 4.67161

Cumulative Model Updates: 3633
Cumulative Timesteps: 60628700

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 60628700...
Checkpoint 60628700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00224
Policy Entropy: 1.14033
Value Function Loss: 0.05535

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.04285
Value Function Update Magnitude: 0.05821

Collected Steps per Second: 13103.67986
Overall Steps per Second: 10828.32409

Timestep Collection Time: 3.81755
Timestep Consumption Time: 0.80218
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 4.61974

Cumulative Model Updates: 3636
Cumulative Timesteps: 60678724

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03798
Policy Entropy: 1.14995
Value Function Loss: 0.05659

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.04263
Value Function Update Magnitude: 0.05642

Collected Steps per Second: 13056.22509
Overall Steps per Second: 10729.79007

Timestep Collection Time: 3.83005
Timestep Consumption Time: 0.83043
PPO Batch Consumption Time: 0.03054
Total Iteration Time: 4.66048

Cumulative Model Updates: 3639
Cumulative Timesteps: 60728730

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 60728730...
Checkpoint 60728730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00100
Policy Entropy: 1.13290
Value Function Loss: 0.03616

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.04324
Value Function Update Magnitude: 0.05587

Collected Steps per Second: 12849.28514
Overall Steps per Second: 10854.36993

Timestep Collection Time: 3.89298
Timestep Consumption Time: 0.71549
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 4.60847

Cumulative Model Updates: 3642
Cumulative Timesteps: 60778752

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01873
Policy Entropy: 1.12986
Value Function Loss: 0.03829

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.04433
Value Function Update Magnitude: 0.05042

Collected Steps per Second: 13046.19949
Overall Steps per Second: 10779.18435

Timestep Collection Time: 3.83269
Timestep Consumption Time: 0.80607
PPO Batch Consumption Time: 0.02572
Total Iteration Time: 4.63876

Cumulative Model Updates: 3645
Cumulative Timesteps: 60828754

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 60828754...
Checkpoint 60828754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07184
Policy Entropy: 1.12497
Value Function Loss: 0.03470

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.04643
Value Function Update Magnitude: 0.06131

Collected Steps per Second: 13235.02437
Overall Steps per Second: 10955.97207

Timestep Collection Time: 3.77982
Timestep Consumption Time: 0.78627
PPO Batch Consumption Time: 0.02804
Total Iteration Time: 4.56609

Cumulative Model Updates: 3648
Cumulative Timesteps: 60878780

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01318
Policy Entropy: 1.12945
Value Function Loss: 0.03550

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.06827

Collected Steps per Second: 13408.66250
Overall Steps per Second: 11050.67790

Timestep Collection Time: 3.73102
Timestep Consumption Time: 0.79612
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 4.52714

Cumulative Model Updates: 3651
Cumulative Timesteps: 60928808

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 60928808...
Checkpoint 60928808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00648
Policy Entropy: 1.12462
Value Function Loss: 0.05721

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.06853

Collected Steps per Second: 13219.51300
Overall Steps per Second: 10857.45520

Timestep Collection Time: 3.78410
Timestep Consumption Time: 0.82324
PPO Batch Consumption Time: 0.02818
Total Iteration Time: 4.60734

Cumulative Model Updates: 3654
Cumulative Timesteps: 60978832

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00526
Policy Entropy: 1.11923
Value Function Loss: 0.05983

Mean KL Divergence: 0.02531
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.07421

Collected Steps per Second: 12406.26604
Overall Steps per Second: 10534.47049

Timestep Collection Time: 4.03071
Timestep Consumption Time: 0.71619
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 4.74689

Cumulative Model Updates: 3657
Cumulative Timesteps: 61028838

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 61028838...
Checkpoint 61028838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00805
Policy Entropy: 1.12382
Value Function Loss: 0.05959

Mean KL Divergence: 0.02232
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.07848

Collected Steps per Second: 13090.18678
Overall Steps per Second: 10815.26964

Timestep Collection Time: 3.82088
Timestep Consumption Time: 0.80370
PPO Batch Consumption Time: 0.02630
Total Iteration Time: 4.62457

Cumulative Model Updates: 3660
Cumulative Timesteps: 61078854

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00047
Policy Entropy: 1.14386
Value Function Loss: 0.03060

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.15352
Policy Update Magnitude: 0.04600
Value Function Update Magnitude: 0.06331

Collected Steps per Second: 12995.11287
Overall Steps per Second: 10795.18171

Timestep Collection Time: 3.84899
Timestep Consumption Time: 0.78438
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 4.63336

Cumulative Model Updates: 3663
Cumulative Timesteps: 61128872

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 61128872...
Checkpoint 61128872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00158
Policy Entropy: 1.14114
Value Function Loss: 0.03404

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.04316
Value Function Update Magnitude: 0.06003

Collected Steps per Second: 13031.68535
Overall Steps per Second: 10812.83821

Timestep Collection Time: 3.83880
Timestep Consumption Time: 0.78774
PPO Batch Consumption Time: 0.02925
Total Iteration Time: 4.62654

Cumulative Model Updates: 3666
Cumulative Timesteps: 61178898

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01726
Policy Entropy: 1.12557
Value Function Loss: 0.03674

Mean KL Divergence: 0.02512
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.04055
Value Function Update Magnitude: 0.05803

Collected Steps per Second: 12433.85907
Overall Steps per Second: 10302.43462

Timestep Collection Time: 4.02160
Timestep Consumption Time: 0.83201
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 4.85361

Cumulative Model Updates: 3669
Cumulative Timesteps: 61228902

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 61228902...
Checkpoint 61228902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01060
Policy Entropy: 1.11845
Value Function Loss: 0.05061

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.03985
Value Function Update Magnitude: 0.05631

Collected Steps per Second: 13110.31097
Overall Steps per Second: 10854.00214

Timestep Collection Time: 3.81547
Timestep Consumption Time: 0.79315
PPO Batch Consumption Time: 0.02833
Total Iteration Time: 4.60862

Cumulative Model Updates: 3672
Cumulative Timesteps: 61278924

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02962
Policy Entropy: 1.12920
Value Function Loss: 0.07026

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.06451

Collected Steps per Second: 13113.14027
Overall Steps per Second: 10828.00066

Timestep Collection Time: 3.81571
Timestep Consumption Time: 0.80527
PPO Batch Consumption Time: 0.02736
Total Iteration Time: 4.62098

Cumulative Model Updates: 3675
Cumulative Timesteps: 61328960

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 61328960...
Checkpoint 61328960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10302
Policy Entropy: 1.13840
Value Function Loss: 0.07780

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.08813

Collected Steps per Second: 13071.48967
Overall Steps per Second: 10767.91391

Timestep Collection Time: 3.82665
Timestep Consumption Time: 0.81863
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 4.64528

Cumulative Model Updates: 3678
Cumulative Timesteps: 61378980

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02413
Policy Entropy: 1.10823
Value Function Loss: 0.06752

Mean KL Divergence: 0.03387
SB3 Clip Fraction: 0.18893
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.08504

Collected Steps per Second: 12812.66575
Overall Steps per Second: 10807.37982

Timestep Collection Time: 3.90629
Timestep Consumption Time: 0.72480
PPO Batch Consumption Time: 0.02649
Total Iteration Time: 4.63109

Cumulative Model Updates: 3681
Cumulative Timesteps: 61429030

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 61429030...
Checkpoint 61429030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05998
Policy Entropy: 1.10979
Value Function Loss: 0.05329

Mean KL Divergence: 0.02483
SB3 Clip Fraction: 0.18736
Policy Update Magnitude: 0.05038
Value Function Update Magnitude: 0.06681

Collected Steps per Second: 13250.39302
Overall Steps per Second: 10928.89939

Timestep Collection Time: 3.77679
Timestep Consumption Time: 0.80226
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 4.57905

Cumulative Model Updates: 3684
Cumulative Timesteps: 61479074

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00375
Policy Entropy: 1.11347
Value Function Loss: 0.05483

Mean KL Divergence: 0.02889
SB3 Clip Fraction: 0.17794
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.05791

Collected Steps per Second: 12690.80637
Overall Steps per Second: 10557.70054

Timestep Collection Time: 3.94096
Timestep Consumption Time: 0.79624
PPO Batch Consumption Time: 0.02888
Total Iteration Time: 4.73721

Cumulative Model Updates: 3687
Cumulative Timesteps: 61529088

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 61529088...
Checkpoint 61529088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01996
Policy Entropy: 1.12419
Value Function Loss: 0.05807

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.18800
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.06964

Collected Steps per Second: 13102.85346
Overall Steps per Second: 10790.66213

Timestep Collection Time: 3.81825
Timestep Consumption Time: 0.81816
PPO Batch Consumption Time: 0.02860
Total Iteration Time: 4.63642

Cumulative Model Updates: 3690
Cumulative Timesteps: 61579118

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00749
Policy Entropy: 1.06888
Value Function Loss: 0.05117

Mean KL Divergence: 0.09104
SB3 Clip Fraction: 0.31741
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.07185

Collected Steps per Second: 13119.47823
Overall Steps per Second: 10841.00218

Timestep Collection Time: 3.81479
Timestep Consumption Time: 0.80176
PPO Batch Consumption Time: 0.02661
Total Iteration Time: 4.61655

Cumulative Model Updates: 3693
Cumulative Timesteps: 61629166

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 61629166...
Checkpoint 61629166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00051
Policy Entropy: 1.09778
Value Function Loss: 0.05357

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.04698
Value Function Update Magnitude: 0.06861

Collected Steps per Second: 12821.53970
Overall Steps per Second: 10820.71960

Timestep Collection Time: 3.90078
Timestep Consumption Time: 0.72128
PPO Batch Consumption Time: 0.02645
Total Iteration Time: 4.62206

Cumulative Model Updates: 3696
Cumulative Timesteps: 61679180

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00546
Policy Entropy: 1.09106
Value Function Loss: 0.05450

Mean KL Divergence: 0.01994
SB3 Clip Fraction: 0.15869
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.07334

Collected Steps per Second: 13199.39239
Overall Steps per Second: 10860.22012

Timestep Collection Time: 3.79199
Timestep Consumption Time: 0.81675
PPO Batch Consumption Time: 0.02934
Total Iteration Time: 4.60875

Cumulative Model Updates: 3699
Cumulative Timesteps: 61729232

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 61729232...
Checkpoint 61729232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01444
Policy Entropy: 1.06927
Value Function Loss: 0.05423

Mean KL Divergence: 0.02846
SB3 Clip Fraction: 0.17647
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.07649

Collected Steps per Second: 12808.40939
Overall Steps per Second: 10687.14926

Timestep Collection Time: 3.90400
Timestep Consumption Time: 0.77489
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 4.67889

Cumulative Model Updates: 3702
Cumulative Timesteps: 61779236

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03276
Policy Entropy: 1.05301
Value Function Loss: 0.04693

Mean KL Divergence: 0.02803
SB3 Clip Fraction: 0.20744
Policy Update Magnitude: 0.04742
Value Function Update Magnitude: 0.07769

Collected Steps per Second: 13378.23725
Overall Steps per Second: 10983.23665

Timestep Collection Time: 3.74130
Timestep Consumption Time: 0.81583
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 4.55713

Cumulative Model Updates: 3705
Cumulative Timesteps: 61829288

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 61829288...
Checkpoint 61829288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07703
Policy Entropy: 1.08978
Value Function Loss: 0.05914

Mean KL Divergence: 0.02446
SB3 Clip Fraction: 0.18169
Policy Update Magnitude: 0.04960
Value Function Update Magnitude: 0.08152

Collected Steps per Second: 13038.65370
Overall Steps per Second: 10752.40871

Timestep Collection Time: 3.83475
Timestep Consumption Time: 0.81537
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 4.65012

Cumulative Model Updates: 3708
Cumulative Timesteps: 61879288

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02632
Policy Entropy: 1.10003
Value Function Loss: 0.05663

Mean KL Divergence: 0.03370
SB3 Clip Fraction: 0.22151
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.07756

Collected Steps per Second: 13058.39552
Overall Steps per Second: 10993.08854

Timestep Collection Time: 3.82972
Timestep Consumption Time: 0.71950
PPO Batch Consumption Time: 0.02733
Total Iteration Time: 4.54922

Cumulative Model Updates: 3711
Cumulative Timesteps: 61929298

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 61929298...
Checkpoint 61929298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00308
Policy Entropy: 1.07635
Value Function Loss: 0.05223

Mean KL Divergence: 0.02923
SB3 Clip Fraction: 0.16831
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.07319

Collected Steps per Second: 13396.99083
Overall Steps per Second: 11046.72918

Timestep Collection Time: 3.73457
Timestep Consumption Time: 0.79455
PPO Batch Consumption Time: 0.02856
Total Iteration Time: 4.52912

Cumulative Model Updates: 3714
Cumulative Timesteps: 61979330

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00259
Policy Entropy: 1.09144
Value Function Loss: 0.02490

Mean KL Divergence: 0.02580
SB3 Clip Fraction: 0.18221
Policy Update Magnitude: 0.04702
Value Function Update Magnitude: 0.05789

Collected Steps per Second: 13106.25486
Overall Steps per Second: 10917.28032

Timestep Collection Time: 3.81726
Timestep Consumption Time: 0.76538
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.58264

Cumulative Model Updates: 3717
Cumulative Timesteps: 62029360

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 62029360...
Checkpoint 62029360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00279
Policy Entropy: 1.09869
Value Function Loss: 0.03260

Mean KL Divergence: 0.02560
SB3 Clip Fraction: 0.19647
Policy Update Magnitude: 0.04359
Value Function Update Magnitude: 0.05402

Collected Steps per Second: 13451.78872
Overall Steps per Second: 11031.09391

Timestep Collection Time: 3.71891
Timestep Consumption Time: 0.81609
PPO Batch Consumption Time: 0.02953
Total Iteration Time: 4.53500

Cumulative Model Updates: 3720
Cumulative Timesteps: 62079386

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05858
Policy Entropy: 1.06999
Value Function Loss: 0.03461

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.15595
Policy Update Magnitude: 0.04501
Value Function Update Magnitude: 0.06019

Collected Steps per Second: 13208.73580
Overall Steps per Second: 10889.81703

Timestep Collection Time: 3.78598
Timestep Consumption Time: 0.80620
PPO Batch Consumption Time: 0.02921
Total Iteration Time: 4.59218

Cumulative Model Updates: 3723
Cumulative Timesteps: 62129394

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 62129394...
Checkpoint 62129394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02469
Policy Entropy: 1.06414
Value Function Loss: 0.05566

Mean KL Divergence: 0.02256
SB3 Clip Fraction: 0.18711
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.05625

Collected Steps per Second: 13154.48168
Overall Steps per Second: 10914.64653

Timestep Collection Time: 3.80266
Timestep Consumption Time: 0.78036
PPO Batch Consumption Time: 0.02881
Total Iteration Time: 4.58302

Cumulative Model Updates: 3726
Cumulative Timesteps: 62179416

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02290
Policy Entropy: 1.09670
Value Function Loss: 0.05137

Mean KL Divergence: 0.02884
SB3 Clip Fraction: 0.18947
Policy Update Magnitude: 0.04472
Value Function Update Magnitude: 0.06669

Collected Steps per Second: 13079.04882
Overall Steps per Second: 10754.64768

Timestep Collection Time: 3.82643
Timestep Consumption Time: 0.82700
PPO Batch Consumption Time: 0.03225
Total Iteration Time: 4.65343

Cumulative Model Updates: 3729
Cumulative Timesteps: 62229462

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 62229462...
Checkpoint 62229462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01896
Policy Entropy: 1.11875
Value Function Loss: 0.05197

Mean KL Divergence: 0.03098
SB3 Clip Fraction: 0.21335
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.07875

Collected Steps per Second: 12732.95367
Overall Steps per Second: 10541.88198

Timestep Collection Time: 3.92760
Timestep Consumption Time: 0.81633
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 4.74393

Cumulative Model Updates: 3732
Cumulative Timesteps: 62279472

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00807
Policy Entropy: 1.09054
Value Function Loss: 0.06085

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.07617

Collected Steps per Second: 12759.32575
Overall Steps per Second: 10762.29205

Timestep Collection Time: 3.92105
Timestep Consumption Time: 0.72758
PPO Batch Consumption Time: 0.02986
Total Iteration Time: 4.64864

Cumulative Model Updates: 3735
Cumulative Timesteps: 62329502

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 62329502...
Checkpoint 62329502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02415
Policy Entropy: 1.10478
Value Function Loss: 0.06927

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.06875

Collected Steps per Second: 13086.25106
Overall Steps per Second: 10780.21924

Timestep Collection Time: 3.82218
Timestep Consumption Time: 0.81761
PPO Batch Consumption Time: 0.03075
Total Iteration Time: 4.63979

Cumulative Model Updates: 3738
Cumulative Timesteps: 62379520

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01891
Policy Entropy: 1.10529
Value Function Loss: 0.06485

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.07504
Value Function Update Magnitude: 0.06503

Collected Steps per Second: 12983.38841
Overall Steps per Second: 10759.24600

Timestep Collection Time: 3.85400
Timestep Consumption Time: 0.79670
PPO Batch Consumption Time: 0.02970
Total Iteration Time: 4.65070

Cumulative Model Updates: 3741
Cumulative Timesteps: 62429558

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 62429558...
Checkpoint 62429558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02626
Policy Entropy: 1.11155
Value Function Loss: 0.05961

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.07449
Value Function Update Magnitude: 0.06201

Collected Steps per Second: 13325.22102
Overall Steps per Second: 10980.93755

Timestep Collection Time: 3.75468
Timestep Consumption Time: 0.80157
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 4.55626

Cumulative Model Updates: 3744
Cumulative Timesteps: 62479590

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02931
Policy Entropy: 1.11046
Value Function Loss: 0.03971

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.06587
Value Function Update Magnitude: 0.05520

Collected Steps per Second: 12625.41819
Overall Steps per Second: 10456.35803

Timestep Collection Time: 3.96090
Timestep Consumption Time: 0.82165
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 4.78254

Cumulative Model Updates: 3747
Cumulative Timesteps: 62529598

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 62529598...
Checkpoint 62529598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09008
Policy Entropy: 1.11476
Value Function Loss: 0.04767

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.05268

Collected Steps per Second: 13271.93097
Overall Steps per Second: 11102.23214

Timestep Collection Time: 3.76976
Timestep Consumption Time: 0.73672
PPO Batch Consumption Time: 0.02868
Total Iteration Time: 4.50648

Cumulative Model Updates: 3750
Cumulative Timesteps: 62579630

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00699
Policy Entropy: 1.10146
Value Function Loss: 0.04606

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.05554

Collected Steps per Second: 13147.65819
Overall Steps per Second: 10855.50030

Timestep Collection Time: 3.80296
Timestep Consumption Time: 0.80300
PPO Batch Consumption Time: 0.03011
Total Iteration Time: 4.60596

Cumulative Model Updates: 3753
Cumulative Timesteps: 62629630

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 62629630...
Checkpoint 62629630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06333
Policy Entropy: 1.11682
Value Function Loss: 0.05582

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.05933
Value Function Update Magnitude: 0.05463

Collected Steps per Second: 12899.28975
Overall Steps per Second: 10746.99692

Timestep Collection Time: 3.87866
Timestep Consumption Time: 0.77678
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 4.65544

Cumulative Model Updates: 3756
Cumulative Timesteps: 62679662

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13121
Policy Entropy: 1.12831
Value Function Loss: 0.05628

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.05792
Value Function Update Magnitude: 0.06582

Collected Steps per Second: 13245.77574
Overall Steps per Second: 10959.63752

Timestep Collection Time: 3.77585
Timestep Consumption Time: 0.78763
PPO Batch Consumption Time: 0.02834
Total Iteration Time: 4.56347

Cumulative Model Updates: 3759
Cumulative Timesteps: 62729676

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 62729676...
Checkpoint 62729676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07774
Policy Entropy: 1.12969
Value Function Loss: 0.06006

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.06842

Collected Steps per Second: 12753.52845
Overall Steps per Second: 10597.04614

Timestep Collection Time: 3.92237
Timestep Consumption Time: 0.79820
PPO Batch Consumption Time: 0.02625
Total Iteration Time: 4.72056

Cumulative Model Updates: 3762
Cumulative Timesteps: 62779700

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02494
Policy Entropy: 1.11320
Value Function Loss: 0.06704

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.06138

Collected Steps per Second: 13274.01379
Overall Steps per Second: 10987.82979

Timestep Collection Time: 3.76917
Timestep Consumption Time: 0.78423
PPO Batch Consumption Time: 0.02982
Total Iteration Time: 4.55340

Cumulative Model Updates: 3765
Cumulative Timesteps: 62829732

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 62829732...
Checkpoint 62829732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01229
Policy Entropy: 1.10804
Value Function Loss: 0.05297

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.05588
Value Function Update Magnitude: 0.06651

Collected Steps per Second: 13322.94458
Overall Steps per Second: 10920.45384

Timestep Collection Time: 3.75503
Timestep Consumption Time: 0.82610
PPO Batch Consumption Time: 0.02796
Total Iteration Time: 4.58113

Cumulative Model Updates: 3768
Cumulative Timesteps: 62879760

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02180
Policy Entropy: 1.10579
Value Function Loss: 0.03367

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.05218
Value Function Update Magnitude: 0.06575

Collected Steps per Second: 13162.45017
Overall Steps per Second: 10859.02081

Timestep Collection Time: 3.79960
Timestep Consumption Time: 0.80598
PPO Batch Consumption Time: 0.02851
Total Iteration Time: 4.60557

Cumulative Model Updates: 3771
Cumulative Timesteps: 62929772

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 62929772...
Checkpoint 62929772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00876
Policy Entropy: 1.11074
Value Function Loss: 0.01929

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.04961
Value Function Update Magnitude: 0.06096

Collected Steps per Second: 13039.39870
Overall Steps per Second: 10969.62129

Timestep Collection Time: 3.83469
Timestep Consumption Time: 0.72354
PPO Batch Consumption Time: 0.02825
Total Iteration Time: 4.55822

Cumulative Model Updates: 3774
Cumulative Timesteps: 62979774

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01826
Policy Entropy: 1.11819
Value Function Loss: 0.01198

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.05132

Collected Steps per Second: 12745.63522
Overall Steps per Second: 10589.80252

Timestep Collection Time: 3.92589
Timestep Consumption Time: 0.79922
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 4.72511

Cumulative Model Updates: 3777
Cumulative Timesteps: 63029812

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 63029812...
Checkpoint 63029812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01291
Policy Entropy: 1.11827
Value Function Loss: 0.01798

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.04905

Collected Steps per Second: 13000.75361
Overall Steps per Second: 10818.18162

Timestep Collection Time: 3.84747
Timestep Consumption Time: 0.77623
PPO Batch Consumption Time: 0.02822
Total Iteration Time: 4.62370

Cumulative Model Updates: 3780
Cumulative Timesteps: 63079832

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00980
Policy Entropy: 1.12775
Value Function Loss: 0.01987

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.05428
Value Function Update Magnitude: 0.04884

Collected Steps per Second: 13259.50784
Overall Steps per Second: 10951.76512

Timestep Collection Time: 3.77329
Timestep Consumption Time: 0.79510
PPO Batch Consumption Time: 0.02969
Total Iteration Time: 4.56840

Cumulative Model Updates: 3783
Cumulative Timesteps: 63129864

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 63129864...
Checkpoint 63129864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05967
Policy Entropy: 1.13026
Value Function Loss: 0.03105

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.06442

Collected Steps per Second: 13157.66608
Overall Steps per Second: 10826.20308

Timestep Collection Time: 3.80143
Timestep Consumption Time: 0.81865
PPO Batch Consumption Time: 0.02893
Total Iteration Time: 4.62009

Cumulative Model Updates: 3786
Cumulative Timesteps: 63179882

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07231
Policy Entropy: 1.12265
Value Function Loss: 0.03180

Mean KL Divergence: 0.02258
SB3 Clip Fraction: 0.16217
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.05081

Collected Steps per Second: 13148.74433
Overall Steps per Second: 11059.82141

Timestep Collection Time: 3.80295
Timestep Consumption Time: 0.71828
PPO Batch Consumption Time: 0.02914
Total Iteration Time: 4.52123

Cumulative Model Updates: 3789
Cumulative Timesteps: 63229886

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 63229886...
Checkpoint 63229886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07360
Policy Entropy: 1.13376
Value Function Loss: 0.05625

Mean KL Divergence: 0.02681
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.04550
Value Function Update Magnitude: 0.05180

Collected Steps per Second: 13141.76636
Overall Steps per Second: 10899.05045

Timestep Collection Time: 3.80649
Timestep Consumption Time: 0.78327
PPO Batch Consumption Time: 0.02608
Total Iteration Time: 4.58976

Cumulative Model Updates: 3792
Cumulative Timesteps: 63279910

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14018
Policy Entropy: 1.13127
Value Function Loss: 0.06233

Mean KL Divergence: 0.03076
SB3 Clip Fraction: 0.19209
Policy Update Magnitude: 0.04433
Value Function Update Magnitude: 0.05990

Collected Steps per Second: 13070.29800
Overall Steps per Second: 10864.12572

Timestep Collection Time: 3.82577
Timestep Consumption Time: 0.77690
PPO Batch Consumption Time: 0.02930
Total Iteration Time: 4.60267

Cumulative Model Updates: 3795
Cumulative Timesteps: 63329914

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 63329914...
Checkpoint 63329914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03974
Policy Entropy: 1.10257
Value Function Loss: 0.06535

Mean KL Divergence: 0.04462
SB3 Clip Fraction: 0.19257
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.07031

Collected Steps per Second: 13309.69581
Overall Steps per Second: 10977.80959

Timestep Collection Time: 3.75681
Timestep Consumption Time: 0.79801
PPO Batch Consumption Time: 0.02810
Total Iteration Time: 4.55482

Cumulative Model Updates: 3798
Cumulative Timesteps: 63379916

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01005
Policy Entropy: 1.14674
Value Function Loss: 0.03928

Mean KL Divergence: 0.03479
SB3 Clip Fraction: 0.19992
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.06411

Collected Steps per Second: 13220.78430
Overall Steps per Second: 10885.53906

Timestep Collection Time: 3.78434
Timestep Consumption Time: 0.81185
PPO Batch Consumption Time: 0.02940
Total Iteration Time: 4.59619

Cumulative Model Updates: 3801
Cumulative Timesteps: 63429948

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 63429948...
Checkpoint 63429948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00531
Policy Entropy: 1.11240
Value Function Loss: 0.01955

Mean KL Divergence: 0.04680
SB3 Clip Fraction: 0.21982
Policy Update Magnitude: 0.04735
Value Function Update Magnitude: 0.05394

Collected Steps per Second: 12959.47387
Overall Steps per Second: 10800.84541

Timestep Collection Time: 3.85849
Timestep Consumption Time: 0.77115
PPO Batch Consumption Time: 0.02801
Total Iteration Time: 4.62964

Cumulative Model Updates: 3804
Cumulative Timesteps: 63479952

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00720
Policy Entropy: 1.12822
Value Function Loss: 0.02027

Mean KL Divergence: 0.03539
SB3 Clip Fraction: 0.21011
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.04796

Collected Steps per Second: 13434.67021
Overall Steps per Second: 11042.46483

Timestep Collection Time: 3.72171
Timestep Consumption Time: 0.80626
PPO Batch Consumption Time: 0.02807
Total Iteration Time: 4.52797

Cumulative Model Updates: 3807
Cumulative Timesteps: 63529952

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 63529952...
Checkpoint 63529952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09752
Policy Entropy: 1.11747
Value Function Loss: 0.02588

Mean KL Divergence: 0.02724
SB3 Clip Fraction: 0.16483
Policy Update Magnitude: 0.04123
Value Function Update Magnitude: 0.05266

Collected Steps per Second: 13091.99288
Overall Steps per Second: 10718.69454

Timestep Collection Time: 3.82020
Timestep Consumption Time: 0.84586
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 4.66605

Cumulative Model Updates: 3810
Cumulative Timesteps: 63579966

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06775
Policy Entropy: 1.11831
Value Function Loss: 0.03892

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.04149
Value Function Update Magnitude: 0.06431

Collected Steps per Second: 13166.85147
Overall Steps per Second: 11078.65884

Timestep Collection Time: 3.79787
Timestep Consumption Time: 0.71585
PPO Batch Consumption Time: 0.02861
Total Iteration Time: 4.51372

Cumulative Model Updates: 3813
Cumulative Timesteps: 63629972

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 63629972...
Checkpoint 63629972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04401
Policy Entropy: 1.10507
Value Function Loss: 0.05644

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.05123
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 13257.35898
Overall Steps per Second: 10951.16349

Timestep Collection Time: 3.77300
Timestep Consumption Time: 0.79455
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 4.56755

Cumulative Model Updates: 3816
Cumulative Timesteps: 63679992

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00431
Policy Entropy: 1.08745
Value Function Loss: 0.05781

Mean KL Divergence: 0.03444
SB3 Clip Fraction: 0.20377
Policy Update Magnitude: 0.05118
Value Function Update Magnitude: 0.07163

Collected Steps per Second: 13208.68232
Overall Steps per Second: 10954.56577

Timestep Collection Time: 3.78933
Timestep Consumption Time: 0.77973
PPO Batch Consumption Time: 0.02705
Total Iteration Time: 4.56905

Cumulative Model Updates: 3819
Cumulative Timesteps: 63730044

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 63730044...
Checkpoint 63730044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00953
Policy Entropy: 1.12125
Value Function Loss: 0.06938

Mean KL Divergence: 0.02273
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.04913
Value Function Update Magnitude: 0.07030

Collected Steps per Second: 13569.31128
Overall Steps per Second: 11180.18907

Timestep Collection Time: 3.68508
Timestep Consumption Time: 0.78747
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 4.47255

Cumulative Model Updates: 3822
Cumulative Timesteps: 63780048

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01769
Policy Entropy: 1.10631
Value Function Loss: 0.06535

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.06708

Collected Steps per Second: 11847.13988
Overall Steps per Second: 9874.85616

Timestep Collection Time: 4.22127
Timestep Consumption Time: 0.84311
PPO Batch Consumption Time: 0.02845
Total Iteration Time: 5.06438

Cumulative Model Updates: 3825
Cumulative Timesteps: 63830058

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 63830058...
Checkpoint 63830058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00719
Policy Entropy: 1.09064
Value Function Loss: 0.05466

Mean KL Divergence: 0.02677
SB3 Clip Fraction: 0.15957
Policy Update Magnitude: 0.05205
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 12168.68631
Overall Steps per Second: 10226.05093

Timestep Collection Time: 4.11039
Timestep Consumption Time: 0.78085
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 4.89123

Cumulative Model Updates: 3828
Cumulative Timesteps: 63880076

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01221
Policy Entropy: 1.10436
Value Function Loss: 0.04006

Mean KL Divergence: 0.02260
SB3 Clip Fraction: 0.17259
Policy Update Magnitude: 0.05142
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 13366.74265
Overall Steps per Second: 11062.78840

Timestep Collection Time: 3.74078
Timestep Consumption Time: 0.77906
PPO Batch Consumption Time: 0.02616
Total Iteration Time: 4.51984

Cumulative Model Updates: 3831
Cumulative Timesteps: 63930078

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 63930078...
Checkpoint 63930078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01513
Policy Entropy: 1.12253
Value Function Loss: 0.04435

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.06842

Collected Steps per Second: 13205.04903
Overall Steps per Second: 10992.75026

Timestep Collection Time: 3.78976
Timestep Consumption Time: 0.76269
PPO Batch Consumption Time: 0.02636
Total Iteration Time: 4.55245

Cumulative Model Updates: 3834
Cumulative Timesteps: 63980122

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02371
Policy Entropy: 1.13100
Value Function Loss: 0.03613

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.06833

Collected Steps per Second: 13036.01923
Overall Steps per Second: 10974.18249

Timestep Collection Time: 3.83553
Timestep Consumption Time: 0.72062
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 4.55615

Cumulative Model Updates: 3837
Cumulative Timesteps: 64030122

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 64030122...
Checkpoint 64030122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02110
Policy Entropy: 1.10093
Value Function Loss: 0.05124

Mean KL Divergence: 0.03409
SB3 Clip Fraction: 0.17469
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.06965

Collected Steps per Second: 12857.98739
Overall Steps per Second: 10667.42802

Timestep Collection Time: 3.88926
Timestep Consumption Time: 0.79866
PPO Batch Consumption Time: 0.02816
Total Iteration Time: 4.68792

Cumulative Model Updates: 3840
Cumulative Timesteps: 64080130

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00211
Policy Entropy: 1.09971
Value Function Loss: 0.04103

Mean KL Divergence: 0.02747
SB3 Clip Fraction: 0.19011
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.06377

Collected Steps per Second: 12054.15316
Overall Steps per Second: 10026.05909

Timestep Collection Time: 4.14845
Timestep Consumption Time: 0.83916
PPO Batch Consumption Time: 0.03000
Total Iteration Time: 4.98760

Cumulative Model Updates: 3843
Cumulative Timesteps: 64130136

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 64130136...
Checkpoint 64130136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03870
Policy Entropy: 1.11914
Value Function Loss: 0.05981

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.16065
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.05840

Collected Steps per Second: 10670.27456
Overall Steps per Second: 9106.28596

Timestep Collection Time: 4.68779
Timestep Consumption Time: 0.80512
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 5.49291

Cumulative Model Updates: 3846
Cumulative Timesteps: 64180156

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00035
Policy Entropy: 1.12112
Value Function Loss: 0.04673

Mean KL Divergence: 0.02677
SB3 Clip Fraction: 0.18833
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.05642

Collected Steps per Second: 12730.35055
Overall Steps per Second: 10545.82864

Timestep Collection Time: 3.93061
Timestep Consumption Time: 0.81421
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 4.74481

Cumulative Model Updates: 3849
Cumulative Timesteps: 64230194

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 64230194...
Checkpoint 64230194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01502
Policy Entropy: 1.08544
Value Function Loss: 0.05405

Mean KL Divergence: 0.04211
SB3 Clip Fraction: 0.20066
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.09183

Collected Steps per Second: 13165.78033
Overall Steps per Second: 11104.80136

Timestep Collection Time: 3.79970
Timestep Consumption Time: 0.70520
PPO Batch Consumption Time: 0.02865
Total Iteration Time: 4.50490

Cumulative Model Updates: 3852
Cumulative Timesteps: 64280220

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03428
Policy Entropy: 1.12729
Value Function Loss: 0.04704

Mean KL Divergence: 0.03014
SB3 Clip Fraction: 0.19903
Policy Update Magnitude: 0.05347
Value Function Update Magnitude: 0.11392

Collected Steps per Second: 12945.01986
Overall Steps per Second: 10722.29592

Timestep Collection Time: 3.86388
Timestep Consumption Time: 0.80098
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 4.66486

Cumulative Model Updates: 3855
Cumulative Timesteps: 64330238

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 64330238...
Checkpoint 64330238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06639
Policy Entropy: 1.08116
Value Function Loss: 0.05033

Mean KL Divergence: 0.05226
SB3 Clip Fraction: 0.22949
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.11398

Collected Steps per Second: 12923.76239
Overall Steps per Second: 10765.29557

Timestep Collection Time: 3.86962
Timestep Consumption Time: 0.77587
PPO Batch Consumption Time: 0.02755
Total Iteration Time: 4.64548

Cumulative Model Updates: 3858
Cumulative Timesteps: 64380248

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02551
Policy Entropy: 1.09938
Value Function Loss: 0.04172

Mean KL Divergence: 0.03619
SB3 Clip Fraction: 0.22729
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.09835

Collected Steps per Second: 12899.02614
Overall Steps per Second: 10672.64624

Timestep Collection Time: 3.87905
Timestep Consumption Time: 0.80919
PPO Batch Consumption Time: 0.02865
Total Iteration Time: 4.68825

Cumulative Model Updates: 3861
Cumulative Timesteps: 64430284

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 64430284...
Checkpoint 64430284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00511
Policy Entropy: 1.09970
Value Function Loss: 0.03313

Mean KL Divergence: 0.02595
SB3 Clip Fraction: 0.16960
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.08154

Collected Steps per Second: 12820.53526
Overall Steps per Second: 10614.20706

Timestep Collection Time: 3.90327
Timestep Consumption Time: 0.81136
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 4.71462

Cumulative Model Updates: 3864
Cumulative Timesteps: 64480326

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05720
Policy Entropy: 1.12448
Value Function Loss: 0.02192

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.15240
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.07106

Collected Steps per Second: 13374.13366
Overall Steps per Second: 11240.03403

Timestep Collection Time: 3.74125
Timestep Consumption Time: 0.71034
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 4.45159

Cumulative Model Updates: 3867
Cumulative Timesteps: 64530362

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 64530362...
Checkpoint 64530362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03150
Policy Entropy: 1.10175
Value Function Loss: 0.02234

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.04832
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 13070.44337
Overall Steps per Second: 10773.24011

Timestep Collection Time: 3.82619
Timestep Consumption Time: 0.81587
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 4.64206

Cumulative Model Updates: 3870
Cumulative Timesteps: 64580372

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01208
Policy Entropy: 1.12763
Value Function Loss: 0.01598

Mean KL Divergence: 0.02395
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.05892

Collected Steps per Second: 12544.88563
Overall Steps per Second: 10391.83357

Timestep Collection Time: 3.98728
Timestep Consumption Time: 0.82611
PPO Batch Consumption Time: 0.03469
Total Iteration Time: 4.81340

Cumulative Model Updates: 3873
Cumulative Timesteps: 64630392

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 64630392...
Checkpoint 64630392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01140
Policy Entropy: 1.12844
Value Function Loss: 0.02745

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.04500
Value Function Update Magnitude: 0.04963

Collected Steps per Second: 13542.53491
Overall Steps per Second: 11093.38772

Timestep Collection Time: 3.69517
Timestep Consumption Time: 0.81580
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 4.51098

Cumulative Model Updates: 3876
Cumulative Timesteps: 64680434

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03558
Policy Entropy: 1.10915
Value Function Loss: 0.03992

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.05460

Collected Steps per Second: 12752.84427
Overall Steps per Second: 10578.55087

Timestep Collection Time: 3.92289
Timestep Consumption Time: 0.80630
PPO Batch Consumption Time: 0.02845
Total Iteration Time: 4.72919

Cumulative Model Updates: 3879
Cumulative Timesteps: 64730462

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 64730462...
Checkpoint 64730462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01192
Policy Entropy: 1.14677
Value Function Loss: 0.04334

Mean KL Divergence: 0.04316
SB3 Clip Fraction: 0.21315
Policy Update Magnitude: 0.05892
Value Function Update Magnitude: 0.06696

Collected Steps per Second: 12837.27080
Overall Steps per Second: 10888.74410

Timestep Collection Time: 3.89584
Timestep Consumption Time: 0.69716
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 4.59300

Cumulative Model Updates: 3882
Cumulative Timesteps: 64780474

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02179
Policy Entropy: 1.15344
Value Function Loss: 0.03876

Mean KL Divergence: 0.04783
SB3 Clip Fraction: 0.21757
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.07145

Collected Steps per Second: 13097.21378
Overall Steps per Second: 10847.24627

Timestep Collection Time: 3.82035
Timestep Consumption Time: 0.79243
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 4.61278

Cumulative Model Updates: 3885
Cumulative Timesteps: 64830510

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 64830510...
Checkpoint 64830510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00196
Policy Entropy: 1.14357
Value Function Loss: 0.02671

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.14710
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.06238

Collected Steps per Second: 12585.99698
Overall Steps per Second: 10496.32431

Timestep Collection Time: 3.97632
Timestep Consumption Time: 0.79163
PPO Batch Consumption Time: 0.02949
Total Iteration Time: 4.76795

Cumulative Model Updates: 3888
Cumulative Timesteps: 64880556

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04835
Policy Entropy: 1.16615
Value Function Loss: 0.03703

Mean KL Divergence: 0.03759
SB3 Clip Fraction: 0.17204
Policy Update Magnitude: 0.05102
Value Function Update Magnitude: 0.05811

Collected Steps per Second: 12778.85191
Overall Steps per Second: 10776.54834

Timestep Collection Time: 3.91350
Timestep Consumption Time: 0.72714
PPO Batch Consumption Time: 0.02937
Total Iteration Time: 4.64063

Cumulative Model Updates: 3891
Cumulative Timesteps: 64930566

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 64930566...
Checkpoint 64930566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00409
Policy Entropy: 1.17102
Value Function Loss: 0.05254

Mean KL Divergence: 0.03191
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.05135
Value Function Update Magnitude: 0.05368

Collected Steps per Second: 12634.69792
Overall Steps per Second: 10443.28938

Timestep Collection Time: 3.95941
Timestep Consumption Time: 0.83084
PPO Batch Consumption Time: 0.02971
Total Iteration Time: 4.79025

Cumulative Model Updates: 3894
Cumulative Timesteps: 64980592

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02172
Policy Entropy: 1.17808
Value Function Loss: 0.05513

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.05172

Collected Steps per Second: 12984.60407
Overall Steps per Second: 10790.82316

Timestep Collection Time: 3.85364
Timestep Consumption Time: 0.78345
PPO Batch Consumption Time: 0.02874
Total Iteration Time: 4.63709

Cumulative Model Updates: 3897
Cumulative Timesteps: 65030630

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 65030630...
Checkpoint 65030630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00260
Policy Entropy: 1.17897
Value Function Loss: 0.04758

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.05569

Collected Steps per Second: 13381.80594
Overall Steps per Second: 10993.45748

Timestep Collection Time: 3.73642
Timestep Consumption Time: 0.81174
PPO Batch Consumption Time: 0.02949
Total Iteration Time: 4.54816

Cumulative Model Updates: 3900
Cumulative Timesteps: 65080630

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02567
Policy Entropy: 1.18664
Value Function Loss: 0.03325

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.05787

Collected Steps per Second: 13037.99252
Overall Steps per Second: 10610.22544

Timestep Collection Time: 3.83571
Timestep Consumption Time: 0.87766
PPO Batch Consumption Time: 0.02956
Total Iteration Time: 4.71338

Cumulative Model Updates: 3903
Cumulative Timesteps: 65130640

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 65130640...
Checkpoint 65130640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02481
Policy Entropy: 1.19400
Value Function Loss: 0.03594

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.06302

Collected Steps per Second: 13104.90894
Overall Steps per Second: 11051.39824

Timestep Collection Time: 3.81765
Timestep Consumption Time: 0.70938
PPO Batch Consumption Time: 0.02840
Total Iteration Time: 4.52703

Cumulative Model Updates: 3906
Cumulative Timesteps: 65180670

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01624
Policy Entropy: 1.18678
Value Function Loss: 0.04253

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.06501

Collected Steps per Second: 13085.61062
Overall Steps per Second: 10807.21369

Timestep Collection Time: 3.82221
Timestep Consumption Time: 0.80581
PPO Batch Consumption Time: 0.02845
Total Iteration Time: 4.62802

Cumulative Model Updates: 3909
Cumulative Timesteps: 65230686

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 65230686...
Checkpoint 65230686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01102
Policy Entropy: 1.18165
Value Function Loss: 0.04585

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.05941

Collected Steps per Second: 13039.11220
Overall Steps per Second: 10736.11421

Timestep Collection Time: 3.83508
Timestep Consumption Time: 0.82266
PPO Batch Consumption Time: 0.02837
Total Iteration Time: 4.65774

Cumulative Model Updates: 3912
Cumulative Timesteps: 65280692

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01655
Policy Entropy: 1.15501
Value Function Loss: 0.04676

Mean KL Divergence: 0.04171
SB3 Clip Fraction: 0.19038
Policy Update Magnitude: 0.04367
Value Function Update Magnitude: 0.05452

Collected Steps per Second: 13393.74247
Overall Steps per Second: 10992.61800

Timestep Collection Time: 3.73712
Timestep Consumption Time: 0.81630
PPO Batch Consumption Time: 0.02542
Total Iteration Time: 4.55342

Cumulative Model Updates: 3915
Cumulative Timesteps: 65330746

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 65330746...
Checkpoint 65330746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00942
Policy Entropy: 1.18215
Value Function Loss: 0.04308

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.04347
Value Function Update Magnitude: 0.05860

Collected Steps per Second: 13016.78102
Overall Steps per Second: 10695.76168

Timestep Collection Time: 3.84335
Timestep Consumption Time: 0.83402
PPO Batch Consumption Time: 0.02683
Total Iteration Time: 4.67737

Cumulative Model Updates: 3918
Cumulative Timesteps: 65380774

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10033
Policy Entropy: 1.18010
Value Function Loss: 0.03884

Mean KL Divergence: 0.02181
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.06777

Collected Steps per Second: 12769.06566
Overall Steps per Second: 10633.70255

Timestep Collection Time: 3.91587
Timestep Consumption Time: 0.78635
PPO Batch Consumption Time: 0.02748
Total Iteration Time: 4.70222

Cumulative Model Updates: 3921
Cumulative Timesteps: 65430776

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 65430776...
Checkpoint 65430776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00993
Policy Entropy: 1.15388
Value Function Loss: 0.03367

Mean KL Divergence: 0.05762
SB3 Clip Fraction: 0.20601
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.07608

Collected Steps per Second: 13482.92587
Overall Steps per Second: 11090.24073

Timestep Collection Time: 3.70914
Timestep Consumption Time: 0.80023
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 4.50937

Cumulative Model Updates: 3924
Cumulative Timesteps: 65480786

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03168
Policy Entropy: 1.18224
Value Function Loss: 0.03390

Mean KL Divergence: 0.03074
SB3 Clip Fraction: 0.16507
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.08390

Collected Steps per Second: 12906.60388
Overall Steps per Second: 10716.67273

Timestep Collection Time: 3.87523
Timestep Consumption Time: 0.79189
PPO Batch Consumption Time: 0.02941
Total Iteration Time: 4.66712

Cumulative Model Updates: 3927
Cumulative Timesteps: 65530802

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 65530802...
Checkpoint 65530802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01159
Policy Entropy: 1.15024
Value Function Loss: 0.05034

Mean KL Divergence: 0.06011
SB3 Clip Fraction: 0.19749
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.07796

Collected Steps per Second: 13138.11914
Overall Steps per Second: 11089.69193

Timestep Collection Time: 3.80907
Timestep Consumption Time: 0.70359
PPO Batch Consumption Time: 0.02637
Total Iteration Time: 4.51266

Cumulative Model Updates: 3930
Cumulative Timesteps: 65580846

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00154
Policy Entropy: 1.17335
Value Function Loss: 0.06315

Mean KL Divergence: 0.02981
SB3 Clip Fraction: 0.15884
Policy Update Magnitude: 0.05709
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 13036.23686
Overall Steps per Second: 10768.07108

Timestep Collection Time: 3.83638
Timestep Consumption Time: 0.80809
PPO Batch Consumption Time: 0.02866
Total Iteration Time: 4.64447

Cumulative Model Updates: 3933
Cumulative Timesteps: 65630858

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 65630858...
Checkpoint 65630858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03060
Policy Entropy: 1.16897
Value Function Loss: 0.05755

Mean KL Divergence: 0.02853
SB3 Clip Fraction: 0.17296
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 12795.14691
Overall Steps per Second: 10690.08791

Timestep Collection Time: 3.91117
Timestep Consumption Time: 0.77018
PPO Batch Consumption Time: 0.02622
Total Iteration Time: 4.68135

Cumulative Model Updates: 3936
Cumulative Timesteps: 65680902

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00603
Policy Entropy: 1.18532
Value Function Loss: 0.04409

Mean KL Divergence: 0.02438
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.08670

Collected Steps per Second: 13235.11338
Overall Steps per Second: 10908.06551

Timestep Collection Time: 3.77949
Timestep Consumption Time: 0.80629
PPO Batch Consumption Time: 0.02574
Total Iteration Time: 4.58578

Cumulative Model Updates: 3939
Cumulative Timesteps: 65730924

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 65730924...
Checkpoint 65730924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00246
Policy Entropy: 1.16581
Value Function Loss: 0.03678

Mean KL Divergence: 0.02675
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.04930
Value Function Update Magnitude: 0.08029

Collected Steps per Second: 13050.81909
Overall Steps per Second: 10788.50865

Timestep Collection Time: 3.83409
Timestep Consumption Time: 0.80399
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 4.63808

Cumulative Model Updates: 3942
Cumulative Timesteps: 65780962

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02514
Policy Entropy: 1.16450
Value Function Loss: 0.03350

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.04648
Value Function Update Magnitude: 0.07173

Collected Steps per Second: 12728.77072
Overall Steps per Second: 10773.72266

Timestep Collection Time: 3.92952
Timestep Consumption Time: 0.71307
PPO Batch Consumption Time: 0.02725
Total Iteration Time: 4.64259

Cumulative Model Updates: 3945
Cumulative Timesteps: 65830980

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 65830980...
Checkpoint 65830980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04533
Policy Entropy: 1.16419
Value Function Loss: 0.03888

Mean KL Divergence: 0.02038
SB3 Clip Fraction: 0.14803
Policy Update Magnitude: 0.04173
Value Function Update Magnitude: 0.06459

Collected Steps per Second: 13343.00591
Overall Steps per Second: 10938.75767

Timestep Collection Time: 3.74743
Timestep Consumption Time: 0.82365
PPO Batch Consumption Time: 0.02666
Total Iteration Time: 4.57109

Cumulative Model Updates: 3948
Cumulative Timesteps: 65880982

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02713
Policy Entropy: 1.17104
Value Function Loss: 0.03351

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.04324
Value Function Update Magnitude: 0.06889

Collected Steps per Second: 13129.61860
Overall Steps per Second: 10828.54563

Timestep Collection Time: 3.80986
Timestep Consumption Time: 0.80960
PPO Batch Consumption Time: 0.03463
Total Iteration Time: 4.61946

Cumulative Model Updates: 3951
Cumulative Timesteps: 65931004

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 65931004...
Checkpoint 65931004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05875
Policy Entropy: 1.16431
Value Function Loss: 0.03087

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.06707

Collected Steps per Second: 13254.96159
Overall Steps per Second: 10717.97060

Timestep Collection Time: 3.77640
Timestep Consumption Time: 0.89389
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 4.67029

Cumulative Model Updates: 3954
Cumulative Timesteps: 65981060

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06146
Policy Entropy: 1.15057
Value Function Loss: 0.02424

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.04116
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 13028.51291
Overall Steps per Second: 10743.53367

Timestep Collection Time: 3.83973
Timestep Consumption Time: 0.81665
PPO Batch Consumption Time: 0.02976
Total Iteration Time: 4.65638

Cumulative Model Updates: 3957
Cumulative Timesteps: 66031086

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 66031086...
Checkpoint 66031086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00634
Policy Entropy: 1.15385
Value Function Loss: 0.03337

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.11698
Policy Update Magnitude: 0.04081
Value Function Update Magnitude: 0.05450

Collected Steps per Second: 12526.87598
Overall Steps per Second: 10546.80558

Timestep Collection Time: 3.99365
Timestep Consumption Time: 0.74977
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 4.74343

Cumulative Model Updates: 3960
Cumulative Timesteps: 66081114

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01956
Policy Entropy: 1.14075
Value Function Loss: 0.04613

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.15971
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.06208

Collected Steps per Second: 12854.00401
Overall Steps per Second: 10661.25414

Timestep Collection Time: 3.89311
Timestep Consumption Time: 0.80071
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 4.69382

Cumulative Model Updates: 3963
Cumulative Timesteps: 66131156

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 66131156...
Checkpoint 66131156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02540
Policy Entropy: 1.14956
Value Function Loss: 0.03834

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.04109
Value Function Update Magnitude: 0.06139

Collected Steps per Second: 13020.44097
Overall Steps per Second: 10794.62397

Timestep Collection Time: 3.84303
Timestep Consumption Time: 0.79242
PPO Batch Consumption Time: 0.02729
Total Iteration Time: 4.63546

Cumulative Model Updates: 3966
Cumulative Timesteps: 66181194

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00504
Policy Entropy: 1.15518
Value Function Loss: 0.04304

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.06064

Collected Steps per Second: 13171.21636
Overall Steps per Second: 10854.38661

Timestep Collection Time: 3.79965
Timestep Consumption Time: 0.81102
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 4.61067

Cumulative Model Updates: 3969
Cumulative Timesteps: 66231240

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 66231240...
Checkpoint 66231240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01519
Policy Entropy: 1.13644
Value Function Loss: 0.04343

Mean KL Divergence: 0.03234
SB3 Clip Fraction: 0.18717
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.05664

Collected Steps per Second: 12921.01729
Overall Steps per Second: 10699.35284

Timestep Collection Time: 3.87137
Timestep Consumption Time: 0.80387
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 4.67524

Cumulative Model Updates: 3972
Cumulative Timesteps: 66281262

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01050
Policy Entropy: 1.10310
Value Function Loss: 0.05836

Mean KL Divergence: 0.08018
SB3 Clip Fraction: 0.27128
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 13305.66855
Overall Steps per Second: 11032.06803

Timestep Collection Time: 3.76020
Timestep Consumption Time: 0.77494
PPO Batch Consumption Time: 0.02848
Total Iteration Time: 4.53514

Cumulative Model Updates: 3975
Cumulative Timesteps: 66331294

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 66331294...
Checkpoint 66331294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00807
Policy Entropy: 1.14199
Value Function Loss: 0.05702

Mean KL Divergence: 0.02718
SB3 Clip Fraction: 0.18333
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.04980

Collected Steps per Second: 13492.94533
Overall Steps per Second: 11086.05843

Timestep Collection Time: 3.70653
Timestep Consumption Time: 0.80472
PPO Batch Consumption Time: 0.02787
Total Iteration Time: 4.51125

Cumulative Model Updates: 3978
Cumulative Timesteps: 66381306

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02767
Policy Entropy: 1.11644
Value Function Loss: 0.05440

Mean KL Divergence: 0.03025
SB3 Clip Fraction: 0.16994
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.05185

Collected Steps per Second: 13152.40220
Overall Steps per Second: 10915.12491

Timestep Collection Time: 3.80478
Timestep Consumption Time: 0.77987
PPO Batch Consumption Time: 0.02856
Total Iteration Time: 4.58465

Cumulative Model Updates: 3981
Cumulative Timesteps: 66431348

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 66431348...
Checkpoint 66431348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01347
Policy Entropy: 1.13050
Value Function Loss: 0.04762

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.05500

Collected Steps per Second: 12641.86192
Overall Steps per Second: 10689.08614

Timestep Collection Time: 3.95622
Timestep Consumption Time: 0.72276
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 4.67898

Cumulative Model Updates: 3984
Cumulative Timesteps: 66481362

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00516
Policy Entropy: 1.14403
Value Function Loss: 0.03263

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.05402

Collected Steps per Second: 13051.72010
Overall Steps per Second: 10778.24713

Timestep Collection Time: 3.83091
Timestep Consumption Time: 0.80806
PPO Batch Consumption Time: 0.02864
Total Iteration Time: 4.63897

Cumulative Model Updates: 3987
Cumulative Timesteps: 66531362

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 66531362...
Checkpoint 66531362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04532
Policy Entropy: 1.15069
Value Function Loss: 0.03483

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.04610
Value Function Update Magnitude: 0.04748

Collected Steps per Second: 12909.36822
Overall Steps per Second: 10666.68225

Timestep Collection Time: 3.87749
Timestep Consumption Time: 0.81525
PPO Batch Consumption Time: 0.02936
Total Iteration Time: 4.69274

Cumulative Model Updates: 3990
Cumulative Timesteps: 66581418

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04934
Policy Entropy: 1.14392
Value Function Loss: 0.04666

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.10609
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.04621

Collected Steps per Second: 13464.06662
Overall Steps per Second: 11083.47349

Timestep Collection Time: 3.71463
Timestep Consumption Time: 0.79786
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 4.51248

Cumulative Model Updates: 3993
Cumulative Timesteps: 66631432

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 66631432...
Checkpoint 66631432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01771
Policy Entropy: 1.14084
Value Function Loss: 0.04968

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.05643

Collected Steps per Second: 13250.91537
Overall Steps per Second: 10859.12472

Timestep Collection Time: 3.77423
Timestep Consumption Time: 0.83130
PPO Batch Consumption Time: 0.03029
Total Iteration Time: 4.60553

Cumulative Model Updates: 3996
Cumulative Timesteps: 66681444

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00529
Policy Entropy: 1.18374
Value Function Loss: 0.03573

Mean KL Divergence: 0.03613
SB3 Clip Fraction: 0.19104
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.06307

Collected Steps per Second: 12890.87609
Overall Steps per Second: 10793.19898

Timestep Collection Time: 3.88166
Timestep Consumption Time: 0.75441
PPO Batch Consumption Time: 0.03081
Total Iteration Time: 4.63607

Cumulative Model Updates: 3999
Cumulative Timesteps: 66731482

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 66731482...
Checkpoint 66731482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00724
Policy Entropy: 1.17147
Value Function Loss: 0.01896

Mean KL Divergence: 0.03380
SB3 Clip Fraction: 0.18663
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.05987

Collected Steps per Second: 10639.30515
Overall Steps per Second: 9070.31969

Timestep Collection Time: 4.70068
Timestep Consumption Time: 0.81312
PPO Batch Consumption Time: 0.02952
Total Iteration Time: 5.51381

Cumulative Model Updates: 4002
Cumulative Timesteps: 66781494

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00185
Policy Entropy: 1.19763
Value Function Loss: 0.03870

Mean KL Divergence: 0.04004
SB3 Clip Fraction: 0.18077
Policy Update Magnitude: 0.03937
Value Function Update Magnitude: 0.05720

Collected Steps per Second: 12419.63798
Overall Steps per Second: 10375.69734

Timestep Collection Time: 4.02781
Timestep Consumption Time: 0.79345
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 4.82127

Cumulative Model Updates: 4005
Cumulative Timesteps: 66831518

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 66831518...
Checkpoint 66831518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01620
Policy Entropy: 1.19709
Value Function Loss: 0.07106

Mean KL Divergence: 0.04058
SB3 Clip Fraction: 0.15900
Policy Update Magnitude: 0.04937
Value Function Update Magnitude: 0.06093

Collected Steps per Second: 12661.06485
Overall Steps per Second: 10536.54595

Timestep Collection Time: 3.94927
Timestep Consumption Time: 0.79631
PPO Batch Consumption Time: 0.02673
Total Iteration Time: 4.74558

Cumulative Model Updates: 4008
Cumulative Timesteps: 66881520

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00150
Policy Entropy: 1.20069
Value Function Loss: 0.07808

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.06929

Collected Steps per Second: 13285.27863
Overall Steps per Second: 10918.25117

Timestep Collection Time: 3.76432
Timestep Consumption Time: 0.81609
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 4.58040

Cumulative Model Updates: 4011
Cumulative Timesteps: 66931530

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 66931530...
Checkpoint 66931530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00235
Policy Entropy: 1.20371
Value Function Loss: 0.07341

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09310
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.07568

Collected Steps per Second: 12766.99543
Overall Steps per Second: 10644.37240

Timestep Collection Time: 3.91948
Timestep Consumption Time: 0.78159
PPO Batch Consumption Time: 0.02791
Total Iteration Time: 4.70108

Cumulative Model Updates: 4014
Cumulative Timesteps: 66981570

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01585
Policy Entropy: 1.19949
Value Function Loss: 0.05577

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.06666

Collected Steps per Second: 13437.48897
Overall Steps per Second: 10997.74735

Timestep Collection Time: 3.72153
Timestep Consumption Time: 0.82558
PPO Batch Consumption Time: 0.03112
Total Iteration Time: 4.54711

Cumulative Model Updates: 4017
Cumulative Timesteps: 67031578

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 67031578...
Checkpoint 67031578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05547
Policy Entropy: 1.20102
Value Function Loss: 0.05260

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.04248
Value Function Update Magnitude: 0.06578

Collected Steps per Second: 13222.46839
Overall Steps per Second: 10930.48080

Timestep Collection Time: 3.78311
Timestep Consumption Time: 0.79327
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 4.57638

Cumulative Model Updates: 4020
Cumulative Timesteps: 67081600

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04028
Policy Entropy: 1.21072
Value Function Loss: 0.04608

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.04339
Value Function Update Magnitude: 0.06397

Collected Steps per Second: 12789.56982
Overall Steps per Second: 10823.49455

Timestep Collection Time: 3.91084
Timestep Consumption Time: 0.71040
PPO Batch Consumption Time: 0.02713
Total Iteration Time: 4.62124

Cumulative Model Updates: 4023
Cumulative Timesteps: 67131618

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 67131618...
Checkpoint 67131618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00019
Policy Entropy: 1.22272
Value Function Loss: 0.03435

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.04227
Value Function Update Magnitude: 0.05539

Collected Steps per Second: 13185.24462
Overall Steps per Second: 10849.13374

Timestep Collection Time: 3.79470
Timestep Consumption Time: 0.81710
PPO Batch Consumption Time: 0.02847
Total Iteration Time: 4.61180

Cumulative Model Updates: 4026
Cumulative Timesteps: 67181652

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03909
Policy Entropy: 1.21837
Value Function Loss: 0.03971

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.04124
Value Function Update Magnitude: 0.05825

Collected Steps per Second: 12939.27716
Overall Steps per Second: 10789.91263

Timestep Collection Time: 3.86513
Timestep Consumption Time: 0.76994
PPO Batch Consumption Time: 0.02778
Total Iteration Time: 4.63507

Cumulative Model Updates: 4029
Cumulative Timesteps: 67231664

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 67231664...
Checkpoint 67231664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02724
Policy Entropy: 1.21496
Value Function Loss: 0.03024

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.03985
Value Function Update Magnitude: 0.05175

Collected Steps per Second: 13049.19292
Overall Steps per Second: 10630.49618

Timestep Collection Time: 3.83257
Timestep Consumption Time: 0.87200
PPO Batch Consumption Time: 0.03568
Total Iteration Time: 4.70458

Cumulative Model Updates: 4032
Cumulative Timesteps: 67281676

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01576
Policy Entropy: 1.22075
Value Function Loss: 0.03574

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.03533
Value Function Update Magnitude: 0.05075

Collected Steps per Second: 13037.60031
Overall Steps per Second: 10746.57874

Timestep Collection Time: 3.83767
Timestep Consumption Time: 0.81814
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 4.65581

Cumulative Model Updates: 4035
Cumulative Timesteps: 67331710

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 67331710...
Checkpoint 67331710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00535
Policy Entropy: 1.22248
Value Function Loss: 0.02675

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.03701
Value Function Update Magnitude: 0.04920

Collected Steps per Second: 12751.49815
Overall Steps per Second: 10791.75366

Timestep Collection Time: 3.92252
Timestep Consumption Time: 0.71232
PPO Batch Consumption Time: 0.02690
Total Iteration Time: 4.63484

Cumulative Model Updates: 4038
Cumulative Timesteps: 67381728

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00307
Policy Entropy: 1.21952
Value Function Loss: 0.02968

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.03806
Value Function Update Magnitude: 0.05144

Collected Steps per Second: 13223.81010
Overall Steps per Second: 10850.23787

Timestep Collection Time: 3.78151
Timestep Consumption Time: 0.82723
PPO Batch Consumption Time: 0.02968
Total Iteration Time: 4.60875

Cumulative Model Updates: 4041
Cumulative Timesteps: 67431734

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 67431734...
Checkpoint 67431734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02760
Policy Entropy: 1.22397
Value Function Loss: 0.02428

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05218
Policy Update Magnitude: 0.04170
Value Function Update Magnitude: 0.05342

Collected Steps per Second: 12631.00950
Overall Steps per Second: 10541.37216

Timestep Collection Time: 3.96231
Timestep Consumption Time: 0.78546
PPO Batch Consumption Time: 0.02920
Total Iteration Time: 4.74777

Cumulative Model Updates: 4044
Cumulative Timesteps: 67481782

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00161
Policy Entropy: 1.22346
Value Function Loss: 0.02198

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06339
Policy Update Magnitude: 0.04317
Value Function Update Magnitude: 0.05767

Collected Steps per Second: 12849.61676
Overall Steps per Second: 10669.34675

Timestep Collection Time: 3.89537
Timestep Consumption Time: 0.79601
PPO Batch Consumption Time: 0.02922
Total Iteration Time: 4.69138

Cumulative Model Updates: 4047
Cumulative Timesteps: 67531836

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 67531836...
Checkpoint 67531836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00101
Policy Entropy: 1.22049
Value Function Loss: 0.02957

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.04041
Value Function Update Magnitude: 0.05108

Collected Steps per Second: 12747.48040
Overall Steps per Second: 10569.12455

Timestep Collection Time: 3.92344
Timestep Consumption Time: 0.80864
PPO Batch Consumption Time: 0.02730
Total Iteration Time: 4.73209

Cumulative Model Updates: 4050
Cumulative Timesteps: 67581850

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02296
Policy Entropy: 1.21916
Value Function Loss: 0.03874

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06834
Policy Update Magnitude: 0.04351
Value Function Update Magnitude: 0.05042

Collected Steps per Second: 12863.46187
Overall Steps per Second: 10652.17344

Timestep Collection Time: 3.89024
Timestep Consumption Time: 0.80758
PPO Batch Consumption Time: 0.02749
Total Iteration Time: 4.69782

Cumulative Model Updates: 4053
Cumulative Timesteps: 67631892

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 67631892...
Checkpoint 67631892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03749
Policy Entropy: 1.20823
Value Function Loss: 0.04357

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.04716
Value Function Update Magnitude: 0.05457

Collected Steps per Second: 13293.40751
Overall Steps per Second: 10905.68776

Timestep Collection Time: 3.76427
Timestep Consumption Time: 0.82416
PPO Batch Consumption Time: 0.02779
Total Iteration Time: 4.58843

Cumulative Model Updates: 4056
Cumulative Timesteps: 67681932

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03122
Policy Entropy: 1.20862
Value Function Loss: 0.03867

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.05100

Collected Steps per Second: 13113.60070
Overall Steps per Second: 10867.30409

Timestep Collection Time: 3.81512
Timestep Consumption Time: 0.78859
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 4.60372

Cumulative Model Updates: 4059
Cumulative Timesteps: 67731962

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 67731962...
Checkpoint 67731962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01862
Policy Entropy: 1.20569
Value Function Loss: 0.03113

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.05251

Collected Steps per Second: 12843.21101
Overall Steps per Second: 10806.90961

Timestep Collection Time: 3.89357
Timestep Consumption Time: 0.73365
PPO Batch Consumption Time: 0.02899
Total Iteration Time: 4.62722

Cumulative Model Updates: 4062
Cumulative Timesteps: 67781968

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04021
Policy Entropy: 1.20439
Value Function Loss: 0.03056

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.04491
Value Function Update Magnitude: 0.04893

Collected Steps per Second: 12829.12260
Overall Steps per Second: 10641.31609

Timestep Collection Time: 3.89879
Timestep Consumption Time: 0.80157
PPO Batch Consumption Time: 0.02761
Total Iteration Time: 4.70036

Cumulative Model Updates: 4065
Cumulative Timesteps: 67831986

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 67831986...
Checkpoint 67831986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02989
Policy Entropy: 1.20505
Value Function Loss: 0.02372

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.04320
Value Function Update Magnitude: 0.04431

Collected Steps per Second: 13019.34234
Overall Steps per Second: 10795.51367

Timestep Collection Time: 3.84382
Timestep Consumption Time: 0.79181
PPO Batch Consumption Time: 0.02844
Total Iteration Time: 4.63563

Cumulative Model Updates: 4068
Cumulative Timesteps: 67882030

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00765
Policy Entropy: 1.20776
Value Function Loss: 0.04147

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.04538

Collected Steps per Second: 13282.79586
Overall Steps per Second: 10953.74293

Timestep Collection Time: 3.76487
Timestep Consumption Time: 0.80051
PPO Batch Consumption Time: 0.02815
Total Iteration Time: 4.56538

Cumulative Model Updates: 4071
Cumulative Timesteps: 67932038

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 67932038...
Checkpoint 67932038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08381
Policy Entropy: 1.19299
Value Function Loss: 0.04742

Mean KL Divergence: 0.03896
SB3 Clip Fraction: 0.21105
Policy Update Magnitude: 0.04662
Value Function Update Magnitude: 0.04712

Collected Steps per Second: 13136.84994
Overall Steps per Second: 10861.62873

Timestep Collection Time: 3.80746
Timestep Consumption Time: 0.79756
PPO Batch Consumption Time: 0.02643
Total Iteration Time: 4.60502

Cumulative Model Updates: 4074
Cumulative Timesteps: 67982056

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02148
Policy Entropy: 1.21316
Value Function Loss: 0.04337

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.15120
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.04384

Collected Steps per Second: 12962.20418
Overall Steps per Second: 10907.92758

Timestep Collection Time: 3.85999
Timestep Consumption Time: 0.72695
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 4.58694

Cumulative Model Updates: 4077
Cumulative Timesteps: 68032090

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 68032090...
Checkpoint 68032090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02352
Policy Entropy: 1.17484
Value Function Loss: 0.02542

Mean KL Divergence: 0.05782
SB3 Clip Fraction: 0.21487
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.04215

Collected Steps per Second: 12086.06546
Overall Steps per Second: 10075.32663

Timestep Collection Time: 4.13749
Timestep Consumption Time: 0.82572
PPO Batch Consumption Time: 0.02900
Total Iteration Time: 4.96321

Cumulative Model Updates: 4080
Cumulative Timesteps: 68082096

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00941
Policy Entropy: 1.16474
Value Function Loss: 0.01786

Mean KL Divergence: 0.06979
SB3 Clip Fraction: 0.22095
Policy Update Magnitude: 0.04945
Value Function Update Magnitude: 0.04311

Collected Steps per Second: 12189.60390
Overall Steps per Second: 10231.84734

Timestep Collection Time: 4.10497
Timestep Consumption Time: 0.78544
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 4.89042

Cumulative Model Updates: 4083
Cumulative Timesteps: 68132134

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 68132134...
Checkpoint 68132134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01401
Policy Entropy: 1.16357
Value Function Loss: 0.02440

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.15059
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.03806

Collected Steps per Second: 13254.42698
Overall Steps per Second: 10928.38463

Timestep Collection Time: 3.77338
Timestep Consumption Time: 0.80314
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 4.57652

Cumulative Model Updates: 4086
Cumulative Timesteps: 68182148

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02487
Policy Entropy: 1.15757
Value Function Loss: 0.02092

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.05227
Value Function Update Magnitude: 0.04467

Collected Steps per Second: 12819.89531
Overall Steps per Second: 10535.35619

Timestep Collection Time: 3.90034
Timestep Consumption Time: 0.84577
PPO Batch Consumption Time: 0.02712
Total Iteration Time: 4.74611

Cumulative Model Updates: 4089
Cumulative Timesteps: 68232150

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 68232150...
Checkpoint 68232150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01377
Policy Entropy: 1.13948
Value Function Loss: 0.02813

Mean KL Divergence: 0.02196
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.04548

Collected Steps per Second: 12885.20025
Overall Steps per Second: 10686.97308

Timestep Collection Time: 3.88058
Timestep Consumption Time: 0.79820
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 4.67878

Cumulative Model Updates: 4092
Cumulative Timesteps: 68282152

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03382
Policy Entropy: 1.14550
Value Function Loss: 0.03838

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.04744
Value Function Update Magnitude: 0.03534

Collected Steps per Second: 13355.46715
Overall Steps per Second: 10991.25317

Timestep Collection Time: 3.74603
Timestep Consumption Time: 0.80577
PPO Batch Consumption Time: 0.02797
Total Iteration Time: 4.55180

Cumulative Model Updates: 4095
Cumulative Timesteps: 68332182

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 68332182...
Checkpoint 68332182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03727
Policy Entropy: 1.14140
Value Function Loss: 0.04120

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.05139

Collected Steps per Second: 12990.75566
Overall Steps per Second: 10811.01259

Timestep Collection Time: 3.84997
Timestep Consumption Time: 0.77624
PPO Batch Consumption Time: 0.02759
Total Iteration Time: 4.62621

Cumulative Model Updates: 4098
Cumulative Timesteps: 68382196

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00465
Policy Entropy: 1.15931
Value Function Loss: 0.03387

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.04451
Value Function Update Magnitude: 0.05316

Collected Steps per Second: 12820.17369
Overall Steps per Second: 10828.86834

Timestep Collection Time: 3.90151
Timestep Consumption Time: 0.71744
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 4.61895

Cumulative Model Updates: 4101
Cumulative Timesteps: 68432214

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 68432214...
Checkpoint 68432214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00369
Policy Entropy: 1.15879
Value Function Loss: 0.02425

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.04162
Value Function Update Magnitude: 0.05795

Collected Steps per Second: 13217.71001
Overall Steps per Second: 10900.23086

Timestep Collection Time: 3.78568
Timestep Consumption Time: 0.80487
PPO Batch Consumption Time: 0.02925
Total Iteration Time: 4.59054

Cumulative Model Updates: 4104
Cumulative Timesteps: 68482252

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09760
Policy Entropy: 1.15189
Value Function Loss: 0.02585

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.04168
Value Function Update Magnitude: 0.05620

Collected Steps per Second: 12673.44554
Overall Steps per Second: 10569.31577

Timestep Collection Time: 3.94841
Timestep Consumption Time: 0.78605
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 4.73446

Cumulative Model Updates: 4107
Cumulative Timesteps: 68532292

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 68532292...
Checkpoint 68532292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00768
Policy Entropy: 1.13442
Value Function Loss: 0.02719

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.03991
Value Function Update Magnitude: 0.05716

Collected Steps per Second: 12919.52385
Overall Steps per Second: 10690.88367

Timestep Collection Time: 3.87042
Timestep Consumption Time: 0.80683
PPO Batch Consumption Time: 0.02973
Total Iteration Time: 4.67726

Cumulative Model Updates: 4110
Cumulative Timesteps: 68582296

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03640
Policy Entropy: 1.13414
Value Function Loss: 0.04076

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.04239
Value Function Update Magnitude: 0.04679

Collected Steps per Second: 12316.96015
Overall Steps per Second: 10284.69484

Timestep Collection Time: 4.06237
Timestep Consumption Time: 0.80273
PPO Batch Consumption Time: 0.02803
Total Iteration Time: 4.86509

Cumulative Model Updates: 4113
Cumulative Timesteps: 68632332

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 68632332...
Checkpoint 68632332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02225
Policy Entropy: 1.13442
Value Function Loss: 0.04525

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.04634
Value Function Update Magnitude: 0.04001

Collected Steps per Second: 13026.68471
Overall Steps per Second: 10954.04214

Timestep Collection Time: 3.83935
Timestep Consumption Time: 0.72645
PPO Batch Consumption Time: 0.03115
Total Iteration Time: 4.56580

Cumulative Model Updates: 4116
Cumulative Timesteps: 68682346

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04402
Policy Entropy: 1.12918
Value Function Loss: 0.05037

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.04970
Value Function Update Magnitude: 0.05815

Collected Steps per Second: 12808.61291
Overall Steps per Second: 10627.00325

Timestep Collection Time: 3.90518
Timestep Consumption Time: 0.80169
PPO Batch Consumption Time: 0.02710
Total Iteration Time: 4.70688

Cumulative Model Updates: 4119
Cumulative Timesteps: 68732366

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 68732366...
Checkpoint 68732366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04002
Policy Entropy: 1.12557
Value Function Loss: 0.04798

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.08217

Collected Steps per Second: 12573.26461
Overall Steps per Second: 10506.79310

Timestep Collection Time: 3.97971
Timestep Consumption Time: 0.78273
PPO Batch Consumption Time: 0.03032
Total Iteration Time: 4.76244

Cumulative Model Updates: 4122
Cumulative Timesteps: 68782404

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00086
Policy Entropy: 1.13054
Value Function Loss: 0.04150

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.04361
Value Function Update Magnitude: 0.07815

Collected Steps per Second: 13224.13397
Overall Steps per Second: 10919.65560

Timestep Collection Time: 3.78172
Timestep Consumption Time: 0.79809
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 4.57981

Cumulative Model Updates: 4125
Cumulative Timesteps: 68832414

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 68832414...
Checkpoint 68832414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05418
Policy Entropy: 1.13076
Value Function Loss: 0.04902

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.04221
Value Function Update Magnitude: 0.06757

Collected Steps per Second: 12934.77318
Overall Steps per Second: 10528.59709

Timestep Collection Time: 3.86957
Timestep Consumption Time: 0.88434
PPO Batch Consumption Time: 0.03210
Total Iteration Time: 4.75391

Cumulative Model Updates: 4128
Cumulative Timesteps: 68882466

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04087
Policy Entropy: 1.12923
Value Function Loss: 0.04105

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.04552
Value Function Update Magnitude: 0.05434

Collected Steps per Second: 12847.84983
Overall Steps per Second: 10696.05034

Timestep Collection Time: 3.89201
Timestep Consumption Time: 0.78298
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 4.67500

Cumulative Model Updates: 4131
Cumulative Timesteps: 68932470

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 68932470...
Checkpoint 68932470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00438
Policy Entropy: 1.12748
Value Function Loss: 0.04703

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.04613
Value Function Update Magnitude: 0.05127

Collected Steps per Second: 13657.49719
Overall Steps per Second: 11226.53262

Timestep Collection Time: 3.66099
Timestep Consumption Time: 0.79274
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 4.45373

Cumulative Model Updates: 4134
Cumulative Timesteps: 68982470

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00869
Policy Entropy: 1.13250
Value Function Loss: 0.03351

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.04478
Value Function Update Magnitude: 0.04957

Collected Steps per Second: 12704.70571
Overall Steps per Second: 10461.39333

Timestep Collection Time: 3.93744
Timestep Consumption Time: 0.84433
PPO Batch Consumption Time: 0.03047
Total Iteration Time: 4.78177

Cumulative Model Updates: 4137
Cumulative Timesteps: 69032494

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 69032494...
Checkpoint 69032494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00143
Policy Entropy: 1.12228
Value Function Loss: 0.04120

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.05050

Collected Steps per Second: 12898.32691
Overall Steps per Second: 10780.85789

Timestep Collection Time: 3.87849
Timestep Consumption Time: 0.76177
PPO Batch Consumption Time: 0.03013
Total Iteration Time: 4.64026

Cumulative Model Updates: 4140
Cumulative Timesteps: 69082520

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02574
Policy Entropy: 1.13871
Value Function Loss: 0.04722

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.05669

Collected Steps per Second: 12932.55755
Overall Steps per Second: 10683.29022

Timestep Collection Time: 3.86884
Timestep Consumption Time: 0.81455
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 4.68339

Cumulative Model Updates: 4143
Cumulative Timesteps: 69132554

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 69132554...
Checkpoint 69132554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00360
Policy Entropy: 1.14372
Value Function Loss: 0.04321

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.06475

Collected Steps per Second: 12932.69488
Overall Steps per Second: 10755.64245

Timestep Collection Time: 3.86710
Timestep Consumption Time: 0.78274
PPO Batch Consumption Time: 0.02769
Total Iteration Time: 4.64984

Cumulative Model Updates: 4146
Cumulative Timesteps: 69182566

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00164
Policy Entropy: 1.16523
Value Function Loss: 0.03801

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.06125

Collected Steps per Second: 13342.51947
Overall Steps per Second: 10985.59319

Timestep Collection Time: 3.74832
Timestep Consumption Time: 0.80419
PPO Batch Consumption Time: 0.02806
Total Iteration Time: 4.55251

Cumulative Model Updates: 4149
Cumulative Timesteps: 69232578

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 69232578...
Checkpoint 69232578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02703
Policy Entropy: 1.11224
Value Function Loss: 0.04666

Mean KL Divergence: 0.03001
SB3 Clip Fraction: 0.19311
Policy Update Magnitude: 0.05045
Value Function Update Magnitude: 0.05534

Collected Steps per Second: 13058.78925
Overall Steps per Second: 10771.51656

Timestep Collection Time: 3.83129
Timestep Consumption Time: 0.81355
PPO Batch Consumption Time: 0.02699
Total Iteration Time: 4.64484

Cumulative Model Updates: 4152
Cumulative Timesteps: 69282610

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12091
Policy Entropy: 1.12126
Value Function Loss: 0.04091

Mean KL Divergence: 0.02433
SB3 Clip Fraction: 0.18248
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.05099

Collected Steps per Second: 12539.29444
Overall Steps per Second: 10655.85306

Timestep Collection Time: 3.99113
Timestep Consumption Time: 0.70544
PPO Batch Consumption Time: 0.02646
Total Iteration Time: 4.69657

Cumulative Model Updates: 4155
Cumulative Timesteps: 69332656

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 69332656...
Checkpoint 69332656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02574
Policy Entropy: 1.11221
Value Function Loss: 0.05106

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.17193
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.04060

Collected Steps per Second: 12591.40364
Overall Steps per Second: 10431.61631

Timestep Collection Time: 3.97112
Timestep Consumption Time: 0.82219
PPO Batch Consumption Time: 0.02701
Total Iteration Time: 4.79331

Cumulative Model Updates: 4158
Cumulative Timesteps: 69382658

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01178
Policy Entropy: 1.10837
Value Function Loss: 0.05287

Mean KL Divergence: 0.03051
SB3 Clip Fraction: 0.17915
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.04133

Collected Steps per Second: 12728.56400
Overall Steps per Second: 10628.47274

Timestep Collection Time: 3.93069
Timestep Consumption Time: 0.77667
PPO Batch Consumption Time: 0.02884
Total Iteration Time: 4.70736

Cumulative Model Updates: 4161
Cumulative Timesteps: 69432690

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 69432690...
Checkpoint 69432690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04933
Policy Entropy: 1.08933
Value Function Loss: 0.05448

Mean KL Divergence: 0.04008
SB3 Clip Fraction: 0.23474
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.04343

Collected Steps per Second: 13380.70820
Overall Steps per Second: 11022.41191

Timestep Collection Time: 3.73717
Timestep Consumption Time: 0.79959
PPO Batch Consumption Time: 0.02628
Total Iteration Time: 4.53676

Cumulative Model Updates: 4164
Cumulative Timesteps: 69482696

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01976
Policy Entropy: 1.11070
Value Function Loss: 0.06051

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.04171

Collected Steps per Second: 12962.07444
Overall Steps per Second: 10737.57483

Timestep Collection Time: 3.85941
Timestep Consumption Time: 0.79955
PPO Batch Consumption Time: 0.02621
Total Iteration Time: 4.65897

Cumulative Model Updates: 4167
Cumulative Timesteps: 69532722

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 69532722...
Checkpoint 69532722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02766
Policy Entropy: 1.13200
Value Function Loss: 0.04971

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.16809
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.04309

Collected Steps per Second: 12375.02282
Overall Steps per Second: 10467.10863

Timestep Collection Time: 4.04314
Timestep Consumption Time: 0.73697
PPO Batch Consumption Time: 0.02976
Total Iteration Time: 4.78012

Cumulative Model Updates: 4170
Cumulative Timesteps: 69582756

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00146
Policy Entropy: 1.11266
Value Function Loss: 0.06197

Mean KL Divergence: 0.02713
SB3 Clip Fraction: 0.18613
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.04955

Collected Steps per Second: 13119.91608
Overall Steps per Second: 10847.92143

Timestep Collection Time: 3.81161
Timestep Consumption Time: 0.79831
PPO Batch Consumption Time: 0.02774
Total Iteration Time: 4.60992

Cumulative Model Updates: 4173
Cumulative Timesteps: 69632764

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 69632764...
Checkpoint 69632764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08714
Policy Entropy: 1.09754
Value Function Loss: 0.05152

Mean KL Divergence: 0.03384
SB3 Clip Fraction: 0.22201
Policy Update Magnitude: 0.04809
Value Function Update Magnitude: 0.06001

Collected Steps per Second: 12949.62229
Overall Steps per Second: 10701.89346

Timestep Collection Time: 3.86312
Timestep Consumption Time: 0.81138
PPO Batch Consumption Time: 0.02883
Total Iteration Time: 4.67450

Cumulative Model Updates: 4176
Cumulative Timesteps: 69682790

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02450
Policy Entropy: 1.10711
Value Function Loss: 0.05924

Mean KL Divergence: 0.02772
SB3 Clip Fraction: 0.17317
Policy Update Magnitude: 0.04657
Value Function Update Magnitude: 0.05632

Collected Steps per Second: 13005.78425
Overall Steps per Second: 10734.73628

Timestep Collection Time: 3.84613
Timestep Consumption Time: 0.81369
PPO Batch Consumption Time: 0.02631
Total Iteration Time: 4.65983

Cumulative Model Updates: 4179
Cumulative Timesteps: 69732812

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 69732812...
Checkpoint 69732812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00227
Policy Entropy: 1.11151
Value Function Loss: 0.04985

Mean KL Divergence: 0.02845
SB3 Clip Fraction: 0.19620
Policy Update Magnitude: 0.04192
Value Function Update Magnitude: 0.04307

Collected Steps per Second: 13181.45484
Overall Steps per Second: 10862.66121

Timestep Collection Time: 3.79624
Timestep Consumption Time: 0.81036
PPO Batch Consumption Time: 0.02943
Total Iteration Time: 4.60661

Cumulative Model Updates: 4182
Cumulative Timesteps: 69782852

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00749
Policy Entropy: 1.08594
Value Function Loss: 0.03826

Mean KL Divergence: 0.03391
SB3 Clip Fraction: 0.19457
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.04587

Collected Steps per Second: 12739.80033
Overall Steps per Second: 10595.51764

Timestep Collection Time: 3.92706
Timestep Consumption Time: 0.79474
PPO Batch Consumption Time: 0.02716
Total Iteration Time: 4.72181

Cumulative Model Updates: 4185
Cumulative Timesteps: 69832882

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 69832882...
Checkpoint 69832882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04240
Policy Entropy: 1.13148
Value Function Loss: 0.03169

Mean KL Divergence: 0.02623
SB3 Clip Fraction: 0.18484
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.04432

Collected Steps per Second: 13245.19144
Overall Steps per Second: 10920.82386

Timestep Collection Time: 3.77526
Timestep Consumption Time: 0.80352
PPO Batch Consumption Time: 0.02764
Total Iteration Time: 4.57878

Cumulative Model Updates: 4188
Cumulative Timesteps: 69882886

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03903
Policy Entropy: 1.10606
Value Function Loss: 0.03745

Mean KL Divergence: 0.03521
SB3 Clip Fraction: 0.20980
Policy Update Magnitude: 0.04307
Value Function Update Magnitude: 0.04011

Collected Steps per Second: 12922.66474
Overall Steps per Second: 10688.88220

Timestep Collection Time: 3.87289
Timestep Consumption Time: 0.80936
PPO Batch Consumption Time: 0.02762
Total Iteration Time: 4.68225

Cumulative Model Updates: 4191
Cumulative Timesteps: 69932934

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 69932934...
Checkpoint 69932934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02781
Policy Entropy: 1.11890
Value Function Loss: 0.04083

Mean KL Divergence: 0.03128
SB3 Clip Fraction: 0.21777
Policy Update Magnitude: 0.04296
Value Function Update Magnitude: 0.04163

Collected Steps per Second: 12642.05764
Overall Steps per Second: 10657.18572

Timestep Collection Time: 3.95679
Timestep Consumption Time: 0.73694
PPO Batch Consumption Time: 0.02956
Total Iteration Time: 4.69373

Cumulative Model Updates: 4194
Cumulative Timesteps: 69982956

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03032
Policy Entropy: 1.10863
Value Function Loss: 0.03449

Mean KL Divergence: 0.02603
SB3 Clip Fraction: 0.19300
Policy Update Magnitude: 0.04345
Value Function Update Magnitude: 0.05578

Collected Steps per Second: 12848.27608
Overall Steps per Second: 10675.88870

Timestep Collection Time: 3.89313
Timestep Consumption Time: 0.79219
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 4.68532

Cumulative Model Updates: 4197
Cumulative Timesteps: 70032976

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 70032976...
Checkpoint 70032976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00136
Policy Entropy: 1.11314
Value Function Loss: 0.02901

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.04461
Value Function Update Magnitude: 0.04798

Collected Steps per Second: 13097.31581
Overall Steps per Second: 10836.82606

Timestep Collection Time: 3.81910
Timestep Consumption Time: 0.79664
PPO Batch Consumption Time: 0.02889
Total Iteration Time: 4.61574

Cumulative Model Updates: 4200
Cumulative Timesteps: 70082996

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05123
Policy Entropy: 1.11578
Value Function Loss: 0.03604

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.04646

Collected Steps per Second: 13084.97298
Overall Steps per Second: 10848.80860

Timestep Collection Time: 3.82148
Timestep Consumption Time: 0.78769
PPO Batch Consumption Time: 0.02823
Total Iteration Time: 4.60917

Cumulative Model Updates: 4203
Cumulative Timesteps: 70133000

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 70133000...
Checkpoint 70133000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01513
Policy Entropy: 1.10282
Value Function Loss: 0.03655

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.04620
Value Function Update Magnitude: 0.03956

Collected Steps per Second: 12742.47299
Overall Steps per Second: 10558.83709

Timestep Collection Time: 3.92655
Timestep Consumption Time: 0.81204
PPO Batch Consumption Time: 0.02772
Total Iteration Time: 4.73859

Cumulative Model Updates: 4206
Cumulative Timesteps: 70183034

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00427
Policy Entropy: 1.08212
Value Function Loss: 0.03767

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.04493
Value Function Update Magnitude: 0.04154

Collected Steps per Second: 12976.16584
Overall Steps per Second: 10956.29063

Timestep Collection Time: 3.85430
Timestep Consumption Time: 0.71057
PPO Batch Consumption Time: 0.02767
Total Iteration Time: 4.56487

Cumulative Model Updates: 4209
Cumulative Timesteps: 70233048

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 70233048...
Checkpoint 70233048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00959
Policy Entropy: 1.08981
Value Function Loss: 0.03436

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.04201
Value Function Update Magnitude: 0.04101

Collected Steps per Second: 13096.74446
Overall Steps per Second: 10772.52792

Timestep Collection Time: 3.81881
Timestep Consumption Time: 0.82392
PPO Batch Consumption Time: 0.03094
Total Iteration Time: 4.64274

Cumulative Model Updates: 4212
Cumulative Timesteps: 70283062

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04504
Policy Entropy: 1.10735
Value Function Loss: 0.05096

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.05153

Collected Steps per Second: 12957.98379
Overall Steps per Second: 10795.87279

Timestep Collection Time: 3.86017
Timestep Consumption Time: 0.77308
PPO Batch Consumption Time: 0.02577
Total Iteration Time: 4.63325

Cumulative Model Updates: 4215
Cumulative Timesteps: 70333082

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 70333082...
Checkpoint 70333082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02097
Policy Entropy: 1.11531
Value Function Loss: 0.04267

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.04683
Value Function Update Magnitude: 0.06392

Collected Steps per Second: 12988.56495
Overall Steps per Second: 10784.57972

Timestep Collection Time: 3.84969
Timestep Consumption Time: 0.78674
PPO Batch Consumption Time: 0.02758
Total Iteration Time: 4.63643

Cumulative Model Updates: 4218
Cumulative Timesteps: 70383084

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06566
Policy Entropy: 1.11127
Value Function Loss: 0.05044

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.04597
Value Function Update Magnitude: 0.05586

Collected Steps per Second: 12862.87163
Overall Steps per Second: 10603.01751

Timestep Collection Time: 3.88933
Timestep Consumption Time: 0.82895
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 4.71828

Cumulative Model Updates: 4221
Cumulative Timesteps: 70433112

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 70433112...
Checkpoint 70433112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02147
Policy Entropy: 1.09957
Value Function Loss: 0.04045

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.04633
Value Function Update Magnitude: 0.06831

Collected Steps per Second: 13070.27591
Overall Steps per Second: 11013.26039

Timestep Collection Time: 3.82609
Timestep Consumption Time: 0.71462
PPO Batch Consumption Time: 0.02937
Total Iteration Time: 4.54071

Cumulative Model Updates: 4224
Cumulative Timesteps: 70483120

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00679
Policy Entropy: 1.11297
Value Function Loss: 0.03599

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12032
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.05189

Collected Steps per Second: 13128.79737
Overall Steps per Second: 10812.42338

Timestep Collection Time: 3.81208
Timestep Consumption Time: 0.81667
PPO Batch Consumption Time: 0.02811
Total Iteration Time: 4.62875

Cumulative Model Updates: 4227
Cumulative Timesteps: 70533168

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 70533168...
Checkpoint 70533168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02647
Policy Entropy: 1.12737
Value Function Loss: 0.02622

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.11976
Policy Update Magnitude: 0.04221
Value Function Update Magnitude: 0.05233

Collected Steps per Second: 12024.55639
Overall Steps per Second: 10038.11549

Timestep Collection Time: 4.15849
Timestep Consumption Time: 0.82292
PPO Batch Consumption Time: 0.02917
Total Iteration Time: 4.98141

Cumulative Model Updates: 4230
Cumulative Timesteps: 70583172

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00325
Policy Entropy: 1.11445
Value Function Loss: 0.02930

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.03989
Value Function Update Magnitude: 0.04121

Collected Steps per Second: 13357.73017
Overall Steps per Second: 11006.47359

Timestep Collection Time: 3.74525
Timestep Consumption Time: 0.80008
PPO Batch Consumption Time: 0.02684
Total Iteration Time: 4.54533

Cumulative Model Updates: 4233
Cumulative Timesteps: 70633200

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 70633200...
Checkpoint 70633200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03433
Policy Entropy: 1.10522
Value Function Loss: 0.04233

Mean KL Divergence: 0.02015
SB3 Clip Fraction: 0.16529
Policy Update Magnitude: 0.04408
Value Function Update Magnitude: 0.05158

Collected Steps per Second: 12958.22538
Overall Steps per Second: 10692.07527

Timestep Collection Time: 3.85871
Timestep Consumption Time: 0.81784
PPO Batch Consumption Time: 0.02880
Total Iteration Time: 4.67655

Cumulative Model Updates: 4236
Cumulative Timesteps: 70683202

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00801
Policy Entropy: 1.13324
Value Function Loss: 0.04217

Mean KL Divergence: 0.02533
SB3 Clip Fraction: 0.17253
Policy Update Magnitude: 0.04361
Value Function Update Magnitude: 0.06550

Collected Steps per Second: 12998.79458
Overall Steps per Second: 10756.81046

Timestep Collection Time: 3.84790
Timestep Consumption Time: 0.80200
PPO Batch Consumption Time: 0.02674
Total Iteration Time: 4.64989

Cumulative Model Updates: 4239
Cumulative Timesteps: 70733220

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 70733220...
Checkpoint 70733220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15854
Policy Entropy: 1.13110
Value Function Loss: 0.03305

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.04105
Value Function Update Magnitude: 0.06238

Collected Steps per Second: 12972.54787
Overall Steps per Second: 10752.16305

Timestep Collection Time: 3.85691
Timestep Consumption Time: 0.79648
PPO Batch Consumption Time: 0.02788
Total Iteration Time: 4.65339

Cumulative Model Updates: 4242
Cumulative Timesteps: 70783254

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01146
Policy Entropy: 1.11095
Value Function Loss: 0.02108

Mean KL Divergence: 0.02791
SB3 Clip Fraction: 0.16139
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.05555

Collected Steps per Second: 12798.54067
Overall Steps per Second: 10570.57844

Timestep Collection Time: 3.90795
Timestep Consumption Time: 0.82368
PPO Batch Consumption Time: 0.02838
Total Iteration Time: 4.73162

Cumulative Model Updates: 4245
Cumulative Timesteps: 70833270

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 70833270...
Checkpoint 70833270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03807
Policy Entropy: 1.12962
Value Function Loss: 0.02649

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.16221
Policy Update Magnitude: 0.04339
Value Function Update Magnitude: 0.05459

Collected Steps per Second: 12942.91424
Overall Steps per Second: 10836.65373

Timestep Collection Time: 3.86389
Timestep Consumption Time: 0.75100
PPO Batch Consumption Time: 0.03016
Total Iteration Time: 4.61489

Cumulative Model Updates: 4248
Cumulative Timesteps: 70883280

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00331
Policy Entropy: 1.12507
Value Function Loss: 0.03377

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.05961

Collected Steps per Second: 12887.05479
Overall Steps per Second: 10621.64806

Timestep Collection Time: 3.88219
Timestep Consumption Time: 0.82800
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 4.71019

Cumulative Model Updates: 4251
Cumulative Timesteps: 70933310

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 70933310...
Checkpoint 70933310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08480
Policy Entropy: 1.13248
Value Function Loss: 0.03413

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07997
Policy Update Magnitude: 0.04205
Value Function Update Magnitude: 0.06140

Collected Steps per Second: 13219.31445
Overall Steps per Second: 10931.71274

Timestep Collection Time: 3.78492
Timestep Consumption Time: 0.79204
PPO Batch Consumption Time: 0.02746
Total Iteration Time: 4.57696

Cumulative Model Updates: 4254
Cumulative Timesteps: 70983344

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00648
Policy Entropy: 1.12221
Value Function Loss: 0.06128

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.04980

Collected Steps per Second: 13517.84937
Overall Steps per Second: 11067.80393

Timestep Collection Time: 3.70177
Timestep Consumption Time: 0.81945
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 4.52122

Cumulative Model Updates: 4257
Cumulative Timesteps: 71033384

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 71033384...
Checkpoint 71033384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00465
Policy Entropy: 1.10940
Value Function Loss: 0.05843

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.05752

Collected Steps per Second: 12590.73978
Overall Steps per Second: 10450.37335

Timestep Collection Time: 3.97356
Timestep Consumption Time: 0.81383
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 4.78739

Cumulative Model Updates: 4260
Cumulative Timesteps: 71083414

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00826
Policy Entropy: 1.10835
Value Function Loss: 0.06911

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.07256

Collected Steps per Second: 12688.78820
Overall Steps per Second: 10542.71783

Timestep Collection Time: 3.94269
Timestep Consumption Time: 0.80257
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 4.74527

Cumulative Model Updates: 4263
Cumulative Timesteps: 71133442

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 71133442...
Checkpoint 71133442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08672
Policy Entropy: 1.12529
Value Function Loss: 0.06098

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.06575

Collected Steps per Second: 12951.70740
Overall Steps per Second: 10696.84656

Timestep Collection Time: 3.86204
Timestep Consumption Time: 0.81411
PPO Batch Consumption Time: 0.03123
Total Iteration Time: 4.67614

Cumulative Model Updates: 4266
Cumulative Timesteps: 71183462

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03197
Policy Entropy: 1.13322
Value Function Loss: 0.07702

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.06328

Collected Steps per Second: 13117.96017
Overall Steps per Second: 10898.09212

Timestep Collection Time: 3.81309
Timestep Consumption Time: 0.77670
PPO Batch Consumption Time: 0.02702
Total Iteration Time: 4.58979

Cumulative Model Updates: 4269
Cumulative Timesteps: 71233482

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 71233482...
Checkpoint 71233482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00889
Policy Entropy: 1.14406
Value Function Loss: 0.06054

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.05958

Collected Steps per Second: 13444.02177
Overall Steps per Second: 10996.15932

Timestep Collection Time: 3.72091
Timestep Consumption Time: 0.82831
PPO Batch Consumption Time: 0.02766
Total Iteration Time: 4.54922

Cumulative Model Updates: 4272
Cumulative Timesteps: 71283506

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01282
Policy Entropy: 1.14125
Value Function Loss: 0.04617

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.06195

Collected Steps per Second: 12664.87109
Overall Steps per Second: 10505.01819

Timestep Collection Time: 3.94809
Timestep Consumption Time: 0.81173
PPO Batch Consumption Time: 0.02681
Total Iteration Time: 4.75982

Cumulative Model Updates: 4275
Cumulative Timesteps: 71333508

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 71333508...
Checkpoint 71333508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08938
Policy Entropy: 1.13897
Value Function Loss: 0.03454

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.04518
Value Function Update Magnitude: 0.04981

Collected Steps per Second: 13061.83762
Overall Steps per Second: 10873.40647

Timestep Collection Time: 3.83024
Timestep Consumption Time: 0.77089
PPO Batch Consumption Time: 0.02898
Total Iteration Time: 4.60113

Cumulative Model Updates: 4278
Cumulative Timesteps: 71383538

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09735
Policy Entropy: 1.12033
Value Function Loss: 0.04817

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.04351
Value Function Update Magnitude: 0.04500

Collected Steps per Second: 13087.75886
Overall Steps per Second: 10760.71862

Timestep Collection Time: 3.82449
Timestep Consumption Time: 0.82706
PPO Batch Consumption Time: 0.02815
Total Iteration Time: 4.65155

Cumulative Model Updates: 4281
Cumulative Timesteps: 71433592

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 71433592...
Checkpoint 71433592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00983
Policy Entropy: 1.11451
Value Function Loss: 0.03891

Mean KL Divergence: 0.03276
SB3 Clip Fraction: 0.20179
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.04414

Collected Steps per Second: 13369.41802
Overall Steps per Second: 11048.90495

Timestep Collection Time: 3.74033
Timestep Consumption Time: 0.78555
PPO Batch Consumption Time: 0.02536
Total Iteration Time: 4.52588

Cumulative Model Updates: 4284
Cumulative Timesteps: 71483598

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08702
Policy Entropy: 1.14170
Value Function Loss: 0.05941

Mean KL Divergence: 0.02097
SB3 Clip Fraction: 0.15035
Policy Update Magnitude: 0.04944
Value Function Update Magnitude: 0.05150

Collected Steps per Second: 12785.25714
Overall Steps per Second: 10829.03836

Timestep Collection Time: 3.91404
Timestep Consumption Time: 0.70705
PPO Batch Consumption Time: 0.02601
Total Iteration Time: 4.62109

Cumulative Model Updates: 4287
Cumulative Timesteps: 71533640

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 71533640...
Checkpoint 71533640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00107
Policy Entropy: 1.13324
Value Function Loss: 0.06073

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.05253

Collected Steps per Second: 13196.18789
Overall Steps per Second: 10821.32967

Timestep Collection Time: 3.79261
Timestep Consumption Time: 0.83233
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 4.62494

Cumulative Model Updates: 4290
Cumulative Timesteps: 71583688

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02444
Policy Entropy: 1.11238
Value Function Loss: 0.06634

Mean KL Divergence: 0.03065
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.06061

Collected Steps per Second: 12983.42795
Overall Steps per Second: 10797.04588

Timestep Collection Time: 3.85414
Timestep Consumption Time: 0.78046
PPO Batch Consumption Time: 0.02852
Total Iteration Time: 4.63460

Cumulative Model Updates: 4293
Cumulative Timesteps: 71633728

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 71633728...
Checkpoint 71633728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00259
Policy Entropy: 1.11379
Value Function Loss: 0.04699

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14434
Policy Update Magnitude: 0.04986
Value Function Update Magnitude: 0.05335

Collected Steps per Second: 13241.75567
Overall Steps per Second: 10904.59073

Timestep Collection Time: 3.77896
Timestep Consumption Time: 0.80994
PPO Batch Consumption Time: 0.02619
Total Iteration Time: 4.58889

Cumulative Model Updates: 4296
Cumulative Timesteps: 71683768

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05055
Policy Entropy: 1.12093
Value Function Loss: 0.06066

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.04593
Value Function Update Magnitude: 0.04947

Collected Steps per Second: 12884.17626
Overall Steps per Second: 10701.44162

Timestep Collection Time: 3.88306
Timestep Consumption Time: 0.79201
PPO Batch Consumption Time: 0.02579
Total Iteration Time: 4.67507

Cumulative Model Updates: 4299
Cumulative Timesteps: 71733798

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 71733798...
Checkpoint 71733798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00270
Policy Entropy: 1.12119
Value Function Loss: 0.05841

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.05129

Collected Steps per Second: 12729.41050
Overall Steps per Second: 10751.94423

Timestep Collection Time: 3.93027
Timestep Consumption Time: 0.72284
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 4.65311

Cumulative Model Updates: 4302
Cumulative Timesteps: 71783828

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03213
Policy Entropy: 1.10867
Value Function Loss: 0.07082

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.17718
Policy Update Magnitude: 0.04666
Value Function Update Magnitude: 0.05270

Collected Steps per Second: 13224.90087
Overall Steps per Second: 10940.43620

Timestep Collection Time: 3.78196
Timestep Consumption Time: 0.78971
PPO Batch Consumption Time: 0.02680
Total Iteration Time: 4.57166

Cumulative Model Updates: 4305
Cumulative Timesteps: 71833844

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 71833844...
Checkpoint 71833844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03093
Policy Entropy: 1.13886
Value Function Loss: 0.04275

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.16398
Policy Update Magnitude: 0.04261
Value Function Update Magnitude: 0.05551

Collected Steps per Second: 12892.91072
Overall Steps per Second: 10719.73361

Timestep Collection Time: 3.87857
Timestep Consumption Time: 0.78629
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 4.66485

Cumulative Model Updates: 4308
Cumulative Timesteps: 71883850

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04603
Policy Entropy: 1.12393
Value Function Loss: 0.04045

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.17669
Policy Update Magnitude: 0.04397
Value Function Update Magnitude: 0.06315

Collected Steps per Second: 13308.98904
Overall Steps per Second: 10981.16034

Timestep Collection Time: 3.75896
Timestep Consumption Time: 0.79684
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 4.55580

Cumulative Model Updates: 4311
Cumulative Timesteps: 71933878

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 71933878...
Checkpoint 71933878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00972
Policy Entropy: 1.11523
Value Function Loss: 0.03047

Mean KL Divergence: 0.02455
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.04391
Value Function Update Magnitude: 0.05454

Collected Steps per Second: 11783.30158
Overall Steps per Second: 9875.05673

Timestep Collection Time: 4.24414
Timestep Consumption Time: 0.82013
PPO Batch Consumption Time: 0.03060
Total Iteration Time: 5.06427

Cumulative Model Updates: 4314
Cumulative Timesteps: 71983888

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02175
Policy Entropy: 1.13670
Value Function Loss: 0.05724

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15283
Policy Update Magnitude: 0.04330
Value Function Update Magnitude: 0.05584

Collected Steps per Second: 12480.18666
Overall Steps per Second: 10479.17604

Timestep Collection Time: 4.00651
Timestep Consumption Time: 0.76505
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 4.77156

Cumulative Model Updates: 4317
Cumulative Timesteps: 72033890

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 72033890...
Checkpoint 72033890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02577
Policy Entropy: 1.13565
Value Function Loss: 0.05465

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.06392

Collected Steps per Second: 13100.34504
Overall Steps per Second: 10795.46826

Timestep Collection Time: 3.81761
Timestep Consumption Time: 0.81508
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 4.63268

Cumulative Model Updates: 4320
Cumulative Timesteps: 72083902

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03552
Policy Entropy: 1.12913
Value Function Loss: 0.04883

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.06330

Collected Steps per Second: 12932.39466
Overall Steps per Second: 10784.52202

Timestep Collection Time: 3.86781
Timestep Consumption Time: 0.77032
PPO Batch Consumption Time: 0.02876
Total Iteration Time: 4.63813

Cumulative Model Updates: 4323
Cumulative Timesteps: 72133922

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 72133922...
Checkpoint 72133922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02911
Policy Entropy: 1.10571
Value Function Loss: 0.03434

Mean KL Divergence: 0.03689
SB3 Clip Fraction: 0.22785
Policy Update Magnitude: 0.04457
Value Function Update Magnitude: 0.06246

Collected Steps per Second: 12999.78016
Overall Steps per Second: 10699.17195

Timestep Collection Time: 3.84960
Timestep Consumption Time: 0.82777
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.67737

Cumulative Model Updates: 4326
Cumulative Timesteps: 72183966

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13705
Policy Entropy: 1.13373
Value Function Loss: 0.04130

Mean KL Divergence: 0.01983
SB3 Clip Fraction: 0.16029
Policy Update Magnitude: 0.04247
Value Function Update Magnitude: 0.06082

Collected Steps per Second: 12706.01567
Overall Steps per Second: 10537.38119

Timestep Collection Time: 3.93640
Timestep Consumption Time: 0.81013
PPO Batch Consumption Time: 0.02694
Total Iteration Time: 4.74653

Cumulative Model Updates: 4329
Cumulative Timesteps: 72233982

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 72233982...
Checkpoint 72233982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03208
Policy Entropy: 1.10868
Value Function Loss: 0.03417

Mean KL Divergence: 0.03071
SB3 Clip Fraction: 0.19791
Policy Update Magnitude: 0.04388
Value Function Update Magnitude: 0.05505

Collected Steps per Second: 11277.30035
Overall Steps per Second: 9623.05856

Timestep Collection Time: 4.43635
Timestep Consumption Time: 0.76263
PPO Batch Consumption Time: 0.02943
Total Iteration Time: 5.19897

Cumulative Model Updates: 4332
Cumulative Timesteps: 72284012

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02667
Policy Entropy: 1.10603
Value Function Loss: 0.02632

Mean KL Divergence: 0.03439
SB3 Clip Fraction: 0.17666
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.05233

Collected Steps per Second: 12047.47087
Overall Steps per Second: 10078.99014

Timestep Collection Time: 4.15307
Timestep Consumption Time: 0.81112
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 4.96419

Cumulative Model Updates: 4335
Cumulative Timesteps: 72334046

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 72334046...
Checkpoint 72334046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03757
Policy Entropy: 1.11078
Value Function Loss: 0.02331

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.17011
Policy Update Magnitude: 0.04018
Value Function Update Magnitude: 0.05326

Collected Steps per Second: 13057.66322
Overall Steps per Second: 10862.97208

Timestep Collection Time: 3.83101
Timestep Consumption Time: 0.77399
PPO Batch Consumption Time: 0.02742
Total Iteration Time: 4.60500

Cumulative Model Updates: 4338
Cumulative Timesteps: 72384070

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01499
Policy Entropy: 1.11592
Value Function Loss: 0.02969

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.04075
Value Function Update Magnitude: 0.05432

Collected Steps per Second: 12920.98762
Overall Steps per Second: 10717.09410

Timestep Collection Time: 3.87169
Timestep Consumption Time: 0.79618
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 4.66787

Cumulative Model Updates: 4341
Cumulative Timesteps: 72434096

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 72434096...
Checkpoint 72434096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01773
Policy Entropy: 1.11489
Value Function Loss: 0.03089

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.12014
Policy Update Magnitude: 0.03975
Value Function Update Magnitude: 0.05742

Collected Steps per Second: 13086.32826
Overall Steps per Second: 10839.70532

Timestep Collection Time: 3.82170
Timestep Consumption Time: 0.79208
PPO Batch Consumption Time: 0.02745
Total Iteration Time: 4.61378

Cumulative Model Updates: 4344
Cumulative Timesteps: 72484108

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03996
Policy Entropy: 1.11039
Value Function Loss: 0.02342

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.03929
Value Function Update Magnitude: 0.05785

Collected Steps per Second: 12741.33222
Overall Steps per Second: 10592.80642

Timestep Collection Time: 3.92581
Timestep Consumption Time: 0.79627
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 4.72207

Cumulative Model Updates: 4347
Cumulative Timesteps: 72534128

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 72534128...
Checkpoint 72534128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07507
Policy Entropy: 1.10122
Value Function Loss: 0.02089

Mean KL Divergence: 0.02562
SB3 Clip Fraction: 0.19992
Policy Update Magnitude: 0.03920
Value Function Update Magnitude: 0.05123

Collected Steps per Second: 13532.15894
Overall Steps per Second: 11160.04676

Timestep Collection Time: 3.69638
Timestep Consumption Time: 0.78568
PPO Batch Consumption Time: 0.02512
Total Iteration Time: 4.48206

Cumulative Model Updates: 4350
Cumulative Timesteps: 72584148

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01797
Policy Entropy: 1.11426
Value Function Loss: 0.02957

Mean KL Divergence: 0.02751
SB3 Clip Fraction: 0.17443
Policy Update Magnitude: 0.04128
Value Function Update Magnitude: 0.05143

Collected Steps per Second: 12874.64996
Overall Steps per Second: 10658.36332

Timestep Collection Time: 3.88531
Timestep Consumption Time: 0.80791
PPO Batch Consumption Time: 0.02757
Total Iteration Time: 4.69322

Cumulative Model Updates: 4353
Cumulative Timesteps: 72634170

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 72634170...
Checkpoint 72634170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06795
Policy Entropy: 1.10397
Value Function Loss: 0.04734

Mean KL Divergence: 0.03448
SB3 Clip Fraction: 0.22276
Policy Update Magnitude: 0.04088
Value Function Update Magnitude: 0.06640

Collected Steps per Second: 12823.25398
Overall Steps per Second: 10801.28465

Timestep Collection Time: 3.90135
Timestep Consumption Time: 0.73032
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 4.63167

Cumulative Model Updates: 4356
Cumulative Timesteps: 72684198

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01742
Policy Entropy: 1.07679
Value Function Loss: 0.05083

Mean KL Divergence: 0.06023
SB3 Clip Fraction: 0.27043
Policy Update Magnitude: 0.04176
Value Function Update Magnitude: 0.07867

Collected Steps per Second: 13046.33788
Overall Steps per Second: 10831.65653

Timestep Collection Time: 3.83341
Timestep Consumption Time: 0.78379
PPO Batch Consumption Time: 0.02657
Total Iteration Time: 4.61721

Cumulative Model Updates: 4359
Cumulative Timesteps: 72734210

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 72734210...
Checkpoint 72734210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00473
Policy Entropy: 1.10372
Value Function Loss: 0.03776

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.16519
Policy Update Magnitude: 0.04131
Value Function Update Magnitude: 0.07510

Collected Steps per Second: 13261.18576
Overall Steps per Second: 10961.26425

Timestep Collection Time: 3.77055
Timestep Consumption Time: 0.79115
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 4.56170

Cumulative Model Updates: 4362
Cumulative Timesteps: 72784212

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01318
Policy Entropy: 1.09055
Value Function Loss: 0.03045

Mean KL Divergence: 0.02001
SB3 Clip Fraction: 0.17455
Policy Update Magnitude: 0.03813
Value Function Update Magnitude: 0.05988

Collected Steps per Second: 13456.22600
Overall Steps per Second: 11045.21091

Timestep Collection Time: 3.71664
Timestep Consumption Time: 0.81129
PPO Batch Consumption Time: 0.02770
Total Iteration Time: 4.52794

Cumulative Model Updates: 4365
Cumulative Timesteps: 72834224

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 72834224...
Checkpoint 72834224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02951
Policy Entropy: 1.06209
Value Function Loss: 0.03226

Mean KL Divergence: 0.05043
SB3 Clip Fraction: 0.25407
Policy Update Magnitude: 0.03988
Value Function Update Magnitude: 0.04851

Collected Steps per Second: 13407.85419
Overall Steps per Second: 10983.86549

Timestep Collection Time: 3.73110
Timestep Consumption Time: 0.82340
PPO Batch Consumption Time: 0.02641
Total Iteration Time: 4.55450

Cumulative Model Updates: 4368
Cumulative Timesteps: 72884250

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00936
Policy Entropy: 1.11300
Value Function Loss: 0.04765

Mean KL Divergence: 0.02461
SB3 Clip Fraction: 0.19180
Policy Update Magnitude: 0.04249
Value Function Update Magnitude: 0.05570

Collected Steps per Second: 12796.97657
Overall Steps per Second: 10804.26786

Timestep Collection Time: 3.90842
Timestep Consumption Time: 0.72086
PPO Batch Consumption Time: 0.02724
Total Iteration Time: 4.62928

Cumulative Model Updates: 4371
Cumulative Timesteps: 72934266

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 72934266...
Checkpoint 72934266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14041
Policy Entropy: 1.08497
Value Function Loss: 0.04565

Mean KL Divergence: 0.03997
SB3 Clip Fraction: 0.23593
Policy Update Magnitude: 0.04596
Value Function Update Magnitude: 0.06035

Collected Steps per Second: 13223.74276
Overall Steps per Second: 10925.03707

Timestep Collection Time: 3.78214
Timestep Consumption Time: 0.79579
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 4.57792

Cumulative Model Updates: 4374
Cumulative Timesteps: 72984280

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04112
Policy Entropy: 1.06668
Value Function Loss: 0.04239

Mean KL Divergence: 0.05788
SB3 Clip Fraction: 0.28018
Policy Update Magnitude: 0.04588
Value Function Update Magnitude: 0.05302

Collected Steps per Second: 13093.30780
Overall Steps per Second: 10882.43273

Timestep Collection Time: 3.82012
Timestep Consumption Time: 0.77610
PPO Batch Consumption Time: 0.03026
Total Iteration Time: 4.59621

Cumulative Model Updates: 4377
Cumulative Timesteps: 73034298

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 73034298...
Checkpoint 73034298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01938
Policy Entropy: 1.07481
Value Function Loss: 0.04041

Mean KL Divergence: 0.03284
SB3 Clip Fraction: 0.19615
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.04927

Collected Steps per Second: 13263.13231
Overall Steps per Second: 10966.88500

Timestep Collection Time: 3.77332
Timestep Consumption Time: 0.79006
PPO Batch Consumption Time: 0.02595
Total Iteration Time: 4.56337

Cumulative Model Updates: 4380
Cumulative Timesteps: 73084344

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04389
Policy Entropy: 1.07562
Value Function Loss: 0.05049

Mean KL Divergence: 0.03618
SB3 Clip Fraction: 0.23491
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.06696

Collected Steps per Second: 13075.64343
Overall Steps per Second: 10762.32884

Timestep Collection Time: 3.82604
Timestep Consumption Time: 0.82239
PPO Batch Consumption Time: 0.03031
Total Iteration Time: 4.64844

Cumulative Model Updates: 4383
Cumulative Timesteps: 73134372

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 73134372...
Checkpoint 73134372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00685
Policy Entropy: 1.04606
Value Function Loss: 0.05504

Mean KL Divergence: 0.05014
SB3 Clip Fraction: 0.24075
Policy Update Magnitude: 0.05430
Value Function Update Magnitude: 0.08114

Collected Steps per Second: 13006.77136
Overall Steps per Second: 10809.11132

Timestep Collection Time: 3.84461
Timestep Consumption Time: 0.78167
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 4.62628

Cumulative Model Updates: 4386
Cumulative Timesteps: 73184378

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00144
Policy Entropy: 1.08795
Value Function Loss: 0.04657

Mean KL Divergence: 0.02533
SB3 Clip Fraction: 0.19694
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.09072

Collected Steps per Second: 12626.95133
Overall Steps per Second: 10378.68555

Timestep Collection Time: 3.96264
Timestep Consumption Time: 0.85840
PPO Batch Consumption Time: 0.03340
Total Iteration Time: 4.82103

Cumulative Model Updates: 4389
Cumulative Timesteps: 73234414

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 73234414...
Checkpoint 73234414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03473
Policy Entropy: 1.04262
Value Function Loss: 0.04118

Mean KL Divergence: 0.04936
SB3 Clip Fraction: 0.25977
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.08694

Collected Steps per Second: 12868.64122
Overall Steps per Second: 10683.37292

Timestep Collection Time: 3.88588
Timestep Consumption Time: 0.79485
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 4.68073

Cumulative Model Updates: 4392
Cumulative Timesteps: 73284420

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01794
Policy Entropy: 1.06222
Value Function Loss: 0.03192

Mean KL Divergence: 0.04153
SB3 Clip Fraction: 0.25085
Policy Update Magnitude: 0.06584
Value Function Update Magnitude: 0.08981

Collected Steps per Second: 12665.52610
Overall Steps per Second: 10692.36266

Timestep Collection Time: 3.95104
Timestep Consumption Time: 0.72912
PPO Batch Consumption Time: 0.02948
Total Iteration Time: 4.68016

Cumulative Model Updates: 4395
Cumulative Timesteps: 73334462

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 73334462...
Checkpoint 73334462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02006
Policy Entropy: 1.06547
Value Function Loss: 0.03361

Mean KL Divergence: 0.03821
SB3 Clip Fraction: 0.21287
Policy Update Magnitude: 0.05957
Value Function Update Magnitude: 0.08402

Collected Steps per Second: 13087.14947
Overall Steps per Second: 10798.64443

Timestep Collection Time: 3.82314
Timestep Consumption Time: 0.81022
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 4.63336

Cumulative Model Updates: 4398
Cumulative Timesteps: 73384496

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03519
Policy Entropy: 1.07363
Value Function Loss: 0.03327

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.05610
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 12881.21739
Overall Steps per Second: 10645.96354

Timestep Collection Time: 3.88457
Timestep Consumption Time: 0.81561
PPO Batch Consumption Time: 0.02653
Total Iteration Time: 4.70019

Cumulative Model Updates: 4401
Cumulative Timesteps: 73434534

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 73434534...
Checkpoint 73434534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01457
Policy Entropy: 1.06066
Value Function Loss: 0.03008

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.06924

Collected Steps per Second: 13710.43674
Overall Steps per Second: 11192.79239

Timestep Collection Time: 3.64788
Timestep Consumption Time: 0.82053
PPO Batch Consumption Time: 0.02719
Total Iteration Time: 4.46841

Cumulative Model Updates: 4404
Cumulative Timesteps: 73484548

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01264
Policy Entropy: 1.06374
Value Function Loss: 0.03064

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.05812

Collected Steps per Second: 13005.65449
Overall Steps per Second: 10735.88898

Timestep Collection Time: 3.84448
Timestep Consumption Time: 0.81279
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 4.65728

Cumulative Model Updates: 4407
Cumulative Timesteps: 73534548

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 73534548...
Checkpoint 73534548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04132
Policy Entropy: 1.06931
Value Function Loss: 0.03679

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.05275
Value Function Update Magnitude: 0.05267

Collected Steps per Second: 13006.16175
Overall Steps per Second: 10973.08651

Timestep Collection Time: 3.84572
Timestep Consumption Time: 0.71253
PPO Batch Consumption Time: 0.02669
Total Iteration Time: 4.55824

Cumulative Model Updates: 4410
Cumulative Timesteps: 73584566

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01310
Policy Entropy: 1.06930
Value Function Loss: 0.05290

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.04932

Collected Steps per Second: 12657.36794
Overall Steps per Second: 10392.17795

Timestep Collection Time: 3.95137
Timestep Consumption Time: 0.86128
PPO Batch Consumption Time: 0.02876
Total Iteration Time: 4.81266

Cumulative Model Updates: 4413
Cumulative Timesteps: 73634580

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 73634580...
Checkpoint 73634580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00503
Policy Entropy: 1.07123
Value Function Loss: 0.04935

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.05017

Collected Steps per Second: 12921.23045
Overall Steps per Second: 10573.20716

Timestep Collection Time: 3.86960
Timestep Consumption Time: 0.85933
PPO Batch Consumption Time: 0.02941
Total Iteration Time: 4.72893

Cumulative Model Updates: 4416
Cumulative Timesteps: 73684580

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03305
Policy Entropy: 1.06494
Value Function Loss: 0.03671

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.04487
Value Function Update Magnitude: 0.05195

Collected Steps per Second: 12776.13339
Overall Steps per Second: 10553.63309

Timestep Collection Time: 3.91433
Timestep Consumption Time: 0.82432
PPO Batch Consumption Time: 0.02775
Total Iteration Time: 4.73865

Cumulative Model Updates: 4419
Cumulative Timesteps: 73734590

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 73734590...
Checkpoint 73734590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02611
Policy Entropy: 1.06316
Value Function Loss: 0.02437

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07681
Policy Update Magnitude: 0.04216
Value Function Update Magnitude: 0.04791

Collected Steps per Second: 13258.49154
Overall Steps per Second: 10913.90266

Timestep Collection Time: 3.77313
Timestep Consumption Time: 0.81057
PPO Batch Consumption Time: 0.02692
Total Iteration Time: 4.58369

Cumulative Model Updates: 4422
Cumulative Timesteps: 73784616

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04365
Policy Entropy: 1.06210
Value Function Loss: 0.02607

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.03851
Value Function Update Magnitude: 0.04336

Collected Steps per Second: 13077.01565
Overall Steps per Second: 10787.08514

Timestep Collection Time: 3.82717
Timestep Consumption Time: 0.81245
PPO Batch Consumption Time: 0.02687
Total Iteration Time: 4.63962

Cumulative Model Updates: 4425
Cumulative Timesteps: 73834664

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 73834664...
Checkpoint 73834664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01664
Policy Entropy: 1.05433
Value Function Loss: 0.02619

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.03651
Value Function Update Magnitude: 0.04711

Collected Steps per Second: 13232.68157
Overall Steps per Second: 10954.90346

Timestep Collection Time: 3.78004
Timestep Consumption Time: 0.78596
PPO Batch Consumption Time: 0.02677
Total Iteration Time: 4.56599

Cumulative Model Updates: 4428
Cumulative Timesteps: 73884684

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00146
Policy Entropy: 1.06622
Value Function Loss: 0.03643

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.03729
Value Function Update Magnitude: 0.05685

Collected Steps per Second: 12820.01162
Overall Steps per Second: 10517.16480

Timestep Collection Time: 3.90015
Timestep Consumption Time: 0.85398
PPO Batch Consumption Time: 0.02805
Total Iteration Time: 4.75413

Cumulative Model Updates: 4431
Cumulative Timesteps: 73934684

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 73934684...
Checkpoint 73934684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02238
Policy Entropy: 1.06366
Value Function Loss: 0.02655

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.04114
Value Function Update Magnitude: 0.05310

Collected Steps per Second: 13077.67237
Overall Steps per Second: 11045.06763

Timestep Collection Time: 3.82438
Timestep Consumption Time: 0.70379
PPO Batch Consumption Time: 0.02633
Total Iteration Time: 4.52818

Cumulative Model Updates: 4434
Cumulative Timesteps: 73984698

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02980
Policy Entropy: 1.06705
Value Function Loss: 0.03547

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.04205
Value Function Update Magnitude: 0.05377

Collected Steps per Second: 12698.38399
Overall Steps per Second: 10494.50182

Timestep Collection Time: 3.93830
Timestep Consumption Time: 0.82706
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.76535

Cumulative Model Updates: 4437
Cumulative Timesteps: 74034708

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 74034708...
Checkpoint 74034708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00253
Policy Entropy: 1.07837
Value Function Loss: 0.02919

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06556
Policy Update Magnitude: 0.04311
Value Function Update Magnitude: 0.05697

Collected Steps per Second: 12874.36595
Overall Steps per Second: 10624.40305

Timestep Collection Time: 3.88586
Timestep Consumption Time: 0.82292
PPO Batch Consumption Time: 0.02898
Total Iteration Time: 4.70878

Cumulative Model Updates: 4440
Cumulative Timesteps: 74084736

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06450
Policy Entropy: 1.07695
Value Function Loss: 0.03710

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.04491
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 13380.85107
Overall Steps per Second: 11018.45397

Timestep Collection Time: 3.74042
Timestep Consumption Time: 0.80196
PPO Batch Consumption Time: 0.02836
Total Iteration Time: 4.54238

Cumulative Model Updates: 4443
Cumulative Timesteps: 74134786

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 74134786...
Checkpoint 74134786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03166
Policy Entropy: 1.07117
Value Function Loss: 0.03492

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.05828

Collected Steps per Second: 13239.49067
Overall Steps per Second: 10929.15203

Timestep Collection Time: 3.77900
Timestep Consumption Time: 0.79885
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.57785

Cumulative Model Updates: 4446
Cumulative Timesteps: 74184818

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00524
Policy Entropy: 1.07205
Value Function Loss: 0.04028

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.04280
Value Function Update Magnitude: 0.05445

Collected Steps per Second: 12868.11132
Overall Steps per Second: 10847.65657

Timestep Collection Time: 3.88837
Timestep Consumption Time: 0.72424
PPO Batch Consumption Time: 0.02671
Total Iteration Time: 4.61261

Cumulative Model Updates: 4449
Cumulative Timesteps: 74234854

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 74234854...
Checkpoint 74234854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00562
Policy Entropy: 1.07424
Value Function Loss: 0.03791

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.03845
Value Function Update Magnitude: 0.05831

Collected Steps per Second: 12796.79145
Overall Steps per Second: 10573.25695

Timestep Collection Time: 3.90895
Timestep Consumption Time: 0.82204
PPO Batch Consumption Time: 0.02821
Total Iteration Time: 4.73099

Cumulative Model Updates: 4452
Cumulative Timesteps: 74284876

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00764
Policy Entropy: 1.07827
Value Function Loss: 0.03381

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.05905

Collected Steps per Second: 12935.68905
Overall Steps per Second: 10763.96088

Timestep Collection Time: 3.86821
Timestep Consumption Time: 0.78045
PPO Batch Consumption Time: 0.02598
Total Iteration Time: 4.64866

Cumulative Model Updates: 4455
Cumulative Timesteps: 74334914

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 74334914...
Checkpoint 74334914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02089
Policy Entropy: 1.07304
Value Function Loss: 0.03219

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08171
Policy Update Magnitude: 0.04254
Value Function Update Magnitude: 0.05398

Collected Steps per Second: 13460.63791
Overall Steps per Second: 11045.28842

Timestep Collection Time: 3.71661
Timestep Consumption Time: 0.81274
PPO Batch Consumption Time: 0.02928
Total Iteration Time: 4.52935

Cumulative Model Updates: 4458
Cumulative Timesteps: 74384942

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00185
Policy Entropy: 1.07009
Value Function Loss: 0.03797

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.04748
Value Function Update Magnitude: 0.05206

Collected Steps per Second: 12803.17330
Overall Steps per Second: 10601.20188

Timestep Collection Time: 3.90747
Timestep Consumption Time: 0.81162
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 4.71909

Cumulative Model Updates: 4461
Cumulative Timesteps: 74434970

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 74434970...
Checkpoint 74434970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06526
Policy Entropy: 1.07022
Value Function Loss: 0.03789

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.05023
Value Function Update Magnitude: 0.05152

Collected Steps per Second: 13122.74972
Overall Steps per Second: 10909.84818

Timestep Collection Time: 3.81033
Timestep Consumption Time: 0.77287
PPO Batch Consumption Time: 0.02635
Total Iteration Time: 4.58320

Cumulative Model Updates: 4464
Cumulative Timesteps: 74484972

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02138
Policy Entropy: 1.06824
Value Function Loss: 0.02781

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.05710

Collected Steps per Second: 13157.53884
Overall Steps per Second: 10867.54248

Timestep Collection Time: 3.80269
Timestep Consumption Time: 0.80130
PPO Batch Consumption Time: 0.02703
Total Iteration Time: 4.60398

Cumulative Model Updates: 4467
Cumulative Timesteps: 74535006

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 74535006...
Checkpoint 74535006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01637
Policy Entropy: 1.06654
Value Function Loss: 0.02186

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.04474
Value Function Update Magnitude: 0.05297

Collected Steps per Second: 13079.17638
Overall Steps per Second: 10806.32310

Timestep Collection Time: 3.82379
Timestep Consumption Time: 0.80424
PPO Batch Consumption Time: 0.02650
Total Iteration Time: 4.62803

Cumulative Model Updates: 4470
Cumulative Timesteps: 74585018

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03807
Policy Entropy: 1.07715
Value Function Loss: 0.01666

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.04194
Value Function Update Magnitude: 0.04667

Collected Steps per Second: 13122.64891
Overall Steps per Second: 10961.56189

Timestep Collection Time: 3.81295
Timestep Consumption Time: 0.75173
PPO Batch Consumption Time: 0.02830
Total Iteration Time: 4.56468

Cumulative Model Updates: 4473
Cumulative Timesteps: 74635054

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 74635054...
Checkpoint 74635054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05505
Policy Entropy: 1.07876
Value Function Loss: 0.02888

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07285
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.03813

Collected Steps per Second: 13146.64668
Overall Steps per Second: 10869.46694

Timestep Collection Time: 3.80416
Timestep Consumption Time: 0.79698
PPO Batch Consumption Time: 0.02919
Total Iteration Time: 4.60115

Cumulative Model Updates: 4476
Cumulative Timesteps: 74685066

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03624
Policy Entropy: 1.10656
Value Function Loss: 0.03178

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.04667
Value Function Update Magnitude: 0.04310

Collected Steps per Second: 13349.45096
Overall Steps per Second: 10587.60136

Timestep Collection Time: 3.74952
Timestep Consumption Time: 0.97809
PPO Batch Consumption Time: 0.02663
Total Iteration Time: 4.72761

Cumulative Model Updates: 4479
Cumulative Timesteps: 74735120

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 74735120...
Checkpoint 74735120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02396
Policy Entropy: 1.11052
Value Function Loss: 0.03086

Mean KL Divergence: 0.02488
SB3 Clip Fraction: 0.17240
Policy Update Magnitude: 0.04731
Value Function Update Magnitude: 0.04808

Collected Steps per Second: 13515.04569
Overall Steps per Second: 11148.06355

Timestep Collection Time: 3.69988
Timestep Consumption Time: 0.78557
PPO Batch Consumption Time: 0.02721
Total Iteration Time: 4.48544

Cumulative Model Updates: 4482
Cumulative Timesteps: 74785124

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03360
Policy Entropy: 1.09883
Value Function Loss: 0.01640

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.04313
Value Function Update Magnitude: 0.05142

Collected Steps per Second: 12716.84561
Overall Steps per Second: 10435.25745

Timestep Collection Time: 3.93305
Timestep Consumption Time: 0.85993
PPO Batch Consumption Time: 0.03556
Total Iteration Time: 4.79298

Cumulative Model Updates: 4485
Cumulative Timesteps: 74835140

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 74835140...
Checkpoint 74835140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04872
Policy Entropy: 1.10760
Value Function Loss: 0.01931

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15363
Policy Update Magnitude: 0.03758
Value Function Update Magnitude: 0.05099

Collected Steps per Second: 13055.09732
Overall Steps per Second: 10837.69658

Timestep Collection Time: 3.83345
Timestep Consumption Time: 0.78433
PPO Batch Consumption Time: 0.02813
Total Iteration Time: 4.61777

Cumulative Model Updates: 4488
Cumulative Timesteps: 74885186

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04128
Policy Entropy: 1.12038
Value Function Loss: 0.03549

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.05398

Collected Steps per Second: 13396.19485
Overall Steps per Second: 11048.53854

Timestep Collection Time: 3.73494
Timestep Consumption Time: 0.79362
PPO Batch Consumption Time: 0.02709
Total Iteration Time: 4.52856

Cumulative Model Updates: 4491
Cumulative Timesteps: 74935220

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 74935220...
Checkpoint 74935220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02273
Policy Entropy: 1.13319
Value Function Loss: 0.05411

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.07448

Collected Steps per Second: 13218.26515
Overall Steps per Second: 10947.60960

Timestep Collection Time: 3.78507
Timestep Consumption Time: 0.78506
PPO Batch Consumption Time: 0.02946
Total Iteration Time: 4.57013

Cumulative Model Updates: 4494
Cumulative Timesteps: 74985252

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01247
Policy Entropy: 1.13011
Value Function Loss: 0.05824

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.08143
Policy Update Magnitude: 0.06013
Value Function Update Magnitude: 0.10073

Collected Steps per Second: 12966.31618
Overall Steps per Second: 10920.80406

Timestep Collection Time: 3.85738
Timestep Consumption Time: 0.72250
PPO Batch Consumption Time: 0.02839
Total Iteration Time: 4.57988

Cumulative Model Updates: 4497
Cumulative Timesteps: 75035268

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 75035268...
Checkpoint 75035268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04246
Policy Entropy: 1.12152
Value Function Loss: 0.05197

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.09813

Collected Steps per Second: 13427.64103
Overall Steps per Second: 11040.74252

Timestep Collection Time: 3.72366
Timestep Consumption Time: 0.80502
PPO Batch Consumption Time: 0.02532
Total Iteration Time: 4.52868

Cumulative Model Updates: 4500
Cumulative Timesteps: 75085268

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01773
Policy Entropy: 1.11739
Value Function Loss: 0.03904

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.05223
Value Function Update Magnitude: 0.08541

Collected Steps per Second: 12987.81124
Overall Steps per Second: 10792.55611

Timestep Collection Time: 3.85346
Timestep Consumption Time: 0.78381
PPO Batch Consumption Time: 0.02711
Total Iteration Time: 4.63727

Cumulative Model Updates: 4503
Cumulative Timesteps: 75135316

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 75135316...
Checkpoint 75135316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03830
Policy Entropy: 1.10963
Value Function Loss: 0.02946

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.06190

Collected Steps per Second: 13426.85299
Overall Steps per Second: 11052.53035

Timestep Collection Time: 3.72552
Timestep Consumption Time: 0.80032
PPO Batch Consumption Time: 0.02994
Total Iteration Time: 4.52584

Cumulative Model Updates: 4506
Cumulative Timesteps: 75185338

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01510
Policy Entropy: 1.11821
Value Function Loss: 0.02595

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.04631
Value Function Update Magnitude: 0.05007

Collected Steps per Second: 13130.39451
Overall Steps per Second: 10787.31872

Timestep Collection Time: 3.81116
Timestep Consumption Time: 0.82781
PPO Batch Consumption Time: 0.02918
Total Iteration Time: 4.63897

Cumulative Model Updates: 4509
Cumulative Timesteps: 75235380

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 75235380...
Checkpoint 75235380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00131
Policy Entropy: 1.11833
Value Function Loss: 0.02394

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.04478

Collected Steps per Second: 12434.25484
Overall Steps per Second: 10506.75988

Timestep Collection Time: 4.02276
Timestep Consumption Time: 0.73799
PPO Batch Consumption Time: 0.02508
Total Iteration Time: 4.76074

Cumulative Model Updates: 4512
Cumulative Timesteps: 75285400

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00155
Policy Entropy: 1.11260
Value Function Loss: 0.02921

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.15755
Policy Update Magnitude: 0.04368
Value Function Update Magnitude: 0.04322

Collected Steps per Second: 12934.31769
Overall Steps per Second: 10653.14686

Timestep Collection Time: 3.86677
Timestep Consumption Time: 0.82800
PPO Batch Consumption Time: 0.02808
Total Iteration Time: 4.69476

Cumulative Model Updates: 4515
Cumulative Timesteps: 75335414

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 75335414...
Checkpoint 75335414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00133
Policy Entropy: 1.16247
Value Function Loss: 0.03013

Mean KL Divergence: 0.03915
SB3 Clip Fraction: 0.20512
Policy Update Magnitude: 0.04485
Value Function Update Magnitude: 0.05173

Collected Steps per Second: 13185.67564
Overall Steps per Second: 10944.66206

Timestep Collection Time: 3.79245
Timestep Consumption Time: 0.77654
PPO Batch Consumption Time: 0.02626
Total Iteration Time: 4.56899

Cumulative Model Updates: 4518
Cumulative Timesteps: 75385420

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02818
Policy Entropy: 1.14141
Value Function Loss: 0.03218

Mean KL Divergence: 0.02605
SB3 Clip Fraction: 0.16811
Policy Update Magnitude: 0.04506
Value Function Update Magnitude: 0.05510

Collected Steps per Second: 12568.82855
Overall Steps per Second: 10490.63593

Timestep Collection Time: 3.97921
Timestep Consumption Time: 0.78828
PPO Batch Consumption Time: 0.02558
Total Iteration Time: 4.76749

Cumulative Model Updates: 4521
Cumulative Timesteps: 75435434

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 75435434...
Checkpoint 75435434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02291
Policy Entropy: 1.14494
Value Function Loss: 0.03141

Mean KL Divergence: 0.03200
SB3 Clip Fraction: 0.16992
Policy Update Magnitude: 0.04319
Value Function Update Magnitude: 0.04929

Collected Steps per Second: 12672.98948
Overall Steps per Second: 10494.24571

Timestep Collection Time: 3.94729
Timestep Consumption Time: 0.81951
PPO Batch Consumption Time: 0.02737
Total Iteration Time: 4.76680

Cumulative Model Updates: 4524
Cumulative Timesteps: 75485458

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01186
Policy Entropy: 1.16447
Value Function Loss: 0.02315

Mean KL Divergence: 0.04332
SB3 Clip Fraction: 0.19009
Policy Update Magnitude: 0.03873
Value Function Update Magnitude: 0.05603

Collected Steps per Second: 12830.68838
Overall Steps per Second: 10751.13802

Timestep Collection Time: 3.89753
Timestep Consumption Time: 0.75388
PPO Batch Consumption Time: 0.03255
Total Iteration Time: 4.65141

Cumulative Model Updates: 4527
Cumulative Timesteps: 75535466

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 75535466...
Checkpoint 75535466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00067
Policy Entropy: 1.17047
Value Function Loss: 0.02150

Mean KL Divergence: 0.02808
SB3 Clip Fraction: 0.17360
Policy Update Magnitude: 0.03466
Value Function Update Magnitude: 0.05239

Collected Steps per Second: 12925.14350
Overall Steps per Second: 10712.95699

Timestep Collection Time: 3.86905
Timestep Consumption Time: 0.79894
PPO Batch Consumption Time: 0.02744
Total Iteration Time: 4.66799

Cumulative Model Updates: 4530
Cumulative Timesteps: 75585474

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03940
Policy Entropy: 1.14926
Value Function Loss: 0.02224

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.03636
Value Function Update Magnitude: 0.05599

Collected Steps per Second: 12802.51611
Overall Steps per Second: 10670.68878

Timestep Collection Time: 3.90642
Timestep Consumption Time: 0.78044
PPO Batch Consumption Time: 0.02700
Total Iteration Time: 4.68686

Cumulative Model Updates: 4533
Cumulative Timesteps: 75635486

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 75635486...
Checkpoint 75635486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00516
Policy Entropy: 1.14669
Value Function Loss: 0.03779

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.16158
Policy Update Magnitude: 0.03708
Value Function Update Magnitude: 0.05985

Collected Steps per Second: 13673.27649
Overall Steps per Second: 11177.98494

Timestep Collection Time: 3.66042
Timestep Consumption Time: 0.81713
PPO Batch Consumption Time: 0.02780
Total Iteration Time: 4.47755

Cumulative Model Updates: 4536
Cumulative Timesteps: 75685536

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02955
Policy Entropy: 1.15808
Value Function Loss: 0.04224

Mean KL Divergence: 0.03147
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.06801

Collected Steps per Second: 13213.98960
Overall Steps per Second: 10910.88820

Timestep Collection Time: 3.78599
Timestep Consumption Time: 0.79916
PPO Batch Consumption Time: 0.02738
Total Iteration Time: 4.58514

Cumulative Model Updates: 4539
Cumulative Timesteps: 75735564

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 75735564...
Checkpoint 75735564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16345
Policy Entropy: 1.17203
Value Function Loss: 0.04335

Mean KL Divergence: 0.04014
SB3 Clip Fraction: 0.19007
Policy Update Magnitude: 0.04253
Value Function Update Magnitude: 0.07877

Collected Steps per Second: 13006.41442
Overall Steps per Second: 10799.00898

Timestep Collection Time: 3.84687
Timestep Consumption Time: 0.78633
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 4.63320

Cumulative Model Updates: 4542
Cumulative Timesteps: 75785598

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00462
Policy Entropy: 1.12789
Value Function Loss: 0.03898

Mean KL Divergence: 0.05395
SB3 Clip Fraction: 0.18957
Policy Update Magnitude: 0.04549
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 12925.80149
Overall Steps per Second: 10687.14947

Timestep Collection Time: 3.87179
Timestep Consumption Time: 0.81103
PPO Batch Consumption Time: 0.02776
Total Iteration Time: 4.68282

Cumulative Model Updates: 4545
Cumulative Timesteps: 75835644

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 75835644...
Checkpoint 75835644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00917
Policy Entropy: 1.18784
Value Function Loss: 0.02883

Mean KL Divergence: 0.04987
SB3 Clip Fraction: 0.21781
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.06445

Collected Steps per Second: 13150.42850
Overall Steps per Second: 10922.37348

Timestep Collection Time: 3.80505
Timestep Consumption Time: 0.77619
PPO Batch Consumption Time: 0.02644
Total Iteration Time: 4.58124

Cumulative Model Updates: 4548
Cumulative Timesteps: 75885682

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13617
Policy Entropy: 1.13096
Value Function Loss: 0.03959

Mean KL Divergence: 0.07698
SB3 Clip Fraction: 0.22479
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.05723

Collected Steps per Second: 12902.72568
Overall Steps per Second: 10908.91431

Timestep Collection Time: 3.87655
Timestep Consumption Time: 0.70851
PPO Batch Consumption Time: 0.02615
Total Iteration Time: 4.58506

Cumulative Model Updates: 4551
Cumulative Timesteps: 75935700

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 75935700...
Checkpoint 75935700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00366
Policy Entropy: 1.19544
Value Function Loss: 0.03002

Mean KL Divergence: 0.04861
SB3 Clip Fraction: 0.18428
Policy Update Magnitude: 0.04258
Value Function Update Magnitude: 0.06264

Collected Steps per Second: 13026.95208
Overall Steps per Second: 10764.55532

Timestep Collection Time: 3.83989
Timestep Consumption Time: 0.80703
PPO Batch Consumption Time: 0.02596
Total Iteration Time: 4.64692

Cumulative Model Updates: 4554
Cumulative Timesteps: 75985722

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00568
Policy Entropy: 1.17185
Value Function Loss: 0.03505

Mean KL Divergence: 0.03485
SB3 Clip Fraction: 0.16709
Policy Update Magnitude: 0.04142
Value Function Update Magnitude: 0.06755

Collected Steps per Second: 12536.67801
Overall Steps per Second: 10327.30463

Timestep Collection Time: 3.98910
Timestep Consumption Time: 0.85341
PPO Batch Consumption Time: 0.02841
Total Iteration Time: 4.84250

Cumulative Model Updates: 4557
Cumulative Timesteps: 76035732

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 76035732...
Checkpoint 76035732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15817
Policy Entropy: 1.18439
Value Function Loss: 0.03095

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.04272
Value Function Update Magnitude: 0.05942

Collected Steps per Second: 13199.96406
Overall Steps per Second: 10909.10028

Timestep Collection Time: 3.79001
Timestep Consumption Time: 0.79589
PPO Batch Consumption Time: 0.02652
Total Iteration Time: 4.58590

Cumulative Model Updates: 4560
Cumulative Timesteps: 76085760

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00622
Policy Entropy: 1.17839
Value Function Loss: 0.04674

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.05462

Collected Steps per Second: 13087.37528
Overall Steps per Second: 10821.49864

Timestep Collection Time: 3.82323
Timestep Consumption Time: 0.80053
PPO Batch Consumption Time: 0.02975
Total Iteration Time: 4.62376

Cumulative Model Updates: 4563
Cumulative Timesteps: 76135796

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 76135796...
Checkpoint 76135796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01550
Policy Entropy: 1.18420
Value Function Loss: 0.03431

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.05356

Collected Steps per Second: 12904.67354
Overall Steps per Second: 10904.85400

Timestep Collection Time: 3.87828
Timestep Consumption Time: 0.71123
PPO Batch Consumption Time: 0.03004
Total Iteration Time: 4.58952

Cumulative Model Updates: 4566
Cumulative Timesteps: 76185844

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00125
Policy Entropy: 1.18450
Value Function Loss: 0.03094

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07711
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.06056

Collected Steps per Second: 13110.21185
Overall Steps per Second: 10793.83797

Timestep Collection Time: 3.81519
Timestep Consumption Time: 0.81875
PPO Batch Consumption Time: 0.02875
Total Iteration Time: 4.63394

Cumulative Model Updates: 4569
Cumulative Timesteps: 76235862

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 76235862...
Checkpoint 76235862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00410
Policy Entropy: 1.18820
Value Function Loss: 0.02760

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.05945

Collected Steps per Second: 12804.74030
Overall Steps per Second: 10649.31863

Timestep Collection Time: 3.90668
Timestep Consumption Time: 0.79071
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 4.69739

Cumulative Model Updates: 4572
Cumulative Timesteps: 76285886

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02837
Policy Entropy: 1.19119
Value Function Loss: 0.03255

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.04484
Value Function Update Magnitude: 0.06008

Collected Steps per Second: 13451.72521
Overall Steps per Second: 11056.27272

Timestep Collection Time: 3.71789
Timestep Consumption Time: 0.80552
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 4.52341

Cumulative Model Updates: 4575
Cumulative Timesteps: 76335898

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 76335898...
Checkpoint 76335898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02115
Policy Entropy: 1.17247
Value Function Loss: 0.04550

Mean KL Divergence: 0.02930
SB3 Clip Fraction: 0.16552
Policy Update Magnitude: 0.04477
Value Function Update Magnitude: 0.05569

Collected Steps per Second: 13253.73774
Overall Steps per Second: 10902.96291

Timestep Collection Time: 3.77328
Timestep Consumption Time: 0.81355
PPO Batch Consumption Time: 0.02627
Total Iteration Time: 4.58683

Cumulative Model Updates: 4578
Cumulative Timesteps: 76385908

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02540
Policy Entropy: 1.20496
Value Function Loss: 0.03931

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.15096
Policy Update Magnitude: 0.04175
Value Function Update Magnitude: 0.05022

Collected Steps per Second: 13296.41123
Overall Steps per Second: 11164.31002

Timestep Collection Time: 3.76071
Timestep Consumption Time: 0.71820
PPO Batch Consumption Time: 0.02768
Total Iteration Time: 4.47892

Cumulative Model Updates: 4581
Cumulative Timesteps: 76435912

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 76435912...
Checkpoint 76435912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.18416
Policy Entropy: 1.17782
Value Function Loss: 0.05014

Mean KL Divergence: 0.04009
SB3 Clip Fraction: 0.18047
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.04778

Collected Steps per Second: 13464.88186
Overall Steps per Second: 11000.09052

Timestep Collection Time: 3.71663
Timestep Consumption Time: 0.83279
PPO Batch Consumption Time: 0.03031
Total Iteration Time: 4.54942

Cumulative Model Updates: 4584
Cumulative Timesteps: 76485956

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01883
Policy Entropy: 1.17556
Value Function Loss: 0.05521

Mean KL Divergence: 0.05059
SB3 Clip Fraction: 0.17859
Policy Update Magnitude: 0.04629
Value Function Update Magnitude: 0.04571

Collected Steps per Second: 13091.37886
Overall Steps per Second: 10843.28604

Timestep Collection Time: 3.82007
Timestep Consumption Time: 0.79200
PPO Batch Consumption Time: 0.02743
Total Iteration Time: 4.61207

Cumulative Model Updates: 4587
Cumulative Timesteps: 76535966

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 76535966...
Checkpoint 76535966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00153
Policy Entropy: 1.22842
Value Function Loss: 0.06156

Mean KL Divergence: 0.06243
SB3 Clip Fraction: 0.21273
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.04282

Collected Steps per Second: 13340.96447
Overall Steps per Second: 10998.71579

Timestep Collection Time: 3.75070
Timestep Consumption Time: 0.79874
PPO Batch Consumption Time: 0.02727
Total Iteration Time: 4.54944

Cumulative Model Updates: 4590
Cumulative Timesteps: 76586004

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02023
Policy Entropy: 1.18458
Value Function Loss: 0.07286

Mean KL Divergence: 0.07130
SB3 Clip Fraction: 0.20156
Policy Update Magnitude: 0.04824
Value Function Update Magnitude: 0.04614

Collected Steps per Second: 13282.10214
Overall Steps per Second: 10963.54227

Timestep Collection Time: 3.76733
Timestep Consumption Time: 0.79671
PPO Batch Consumption Time: 0.02609
Total Iteration Time: 4.56404

Cumulative Model Updates: 4593
Cumulative Timesteps: 76636042

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 76636042...
Checkpoint 76636042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01686
Policy Entropy: 1.22198
Value Function Loss: 0.05232

Mean KL Divergence: 0.04756
SB3 Clip Fraction: 0.18647
Policy Update Magnitude: 0.05226
Value Function Update Magnitude: 0.03574

Collected Steps per Second: 13166.27679
Overall Steps per Second: 10901.69169

Timestep Collection Time: 3.79773
Timestep Consumption Time: 0.78889
PPO Batch Consumption Time: 0.02639
Total Iteration Time: 4.58663

Cumulative Model Updates: 4596
Cumulative Timesteps: 76686044

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00789
Policy Entropy: 1.21293
Value Function Loss: 0.05183

Mean KL Divergence: 0.03790
SB3 Clip Fraction: 0.16366
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.03682

Collected Steps per Second: 13778.88724
Overall Steps per Second: 11308.65510

Timestep Collection Time: 3.63164
Timestep Consumption Time: 0.79329
PPO Batch Consumption Time: 0.02708
Total Iteration Time: 4.42493

Cumulative Model Updates: 4599
Cumulative Timesteps: 76736084

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 76736084...
Checkpoint 76736084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01734
Policy Entropy: 1.20617
Value Function Loss: 0.03363

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.04344
Value Function Update Magnitude: 0.03515

Collected Steps per Second: 12846.41496
Overall Steps per Second: 10667.32945

Timestep Collection Time: 3.89525
Timestep Consumption Time: 0.79571
PPO Batch Consumption Time: 0.02682
Total Iteration Time: 4.69096

Cumulative Model Updates: 4602
Cumulative Timesteps: 76786124

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01382
Policy Entropy: 1.20344
Value Function Loss: 0.03087

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.04036
Value Function Update Magnitude: 0.02975

Collected Steps per Second: 13236.99552
Overall Steps per Second: 11101.86146

Timestep Collection Time: 3.77805
Timestep Consumption Time: 0.72660
PPO Batch Consumption Time: 0.02895
Total Iteration Time: 4.50465

Cumulative Model Updates: 4605
Cumulative Timesteps: 76836134

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 76836134...
Checkpoint 76836134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03044
Policy Entropy: 1.20622
Value Function Loss: 0.02074

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06802
Policy Update Magnitude: 0.03668
Value Function Update Magnitude: 0.02756

Collected Steps per Second: 11914.53603
Overall Steps per Second: 9848.73223

Timestep Collection Time: 4.20042
Timestep Consumption Time: 0.88105
PPO Batch Consumption Time: 0.03138
Total Iteration Time: 5.08147

Cumulative Model Updates: 4608
Cumulative Timesteps: 76886180

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08241
Policy Entropy: 1.20978
Value Function Loss: 0.01484

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.03345
Value Function Update Magnitude: 0.02874

Collected Steps per Second: 13072.58410
Overall Steps per Second: 10738.06245

Timestep Collection Time: 3.82633
Timestep Consumption Time: 0.83187
PPO Batch Consumption Time: 0.02942
Total Iteration Time: 4.65820

Cumulative Model Updates: 4611
Cumulative Timesteps: 76936200

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 76936200...
Checkpoint 76936200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03026
Policy Entropy: 1.21889
Value Function Loss: 0.02983

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06515
Policy Update Magnitude: 0.03474
Value Function Update Magnitude: 0.02892

Collected Steps per Second: 13437.32995
Overall Steps per Second: 11029.86738

Timestep Collection Time: 3.72142
Timestep Consumption Time: 0.81227
PPO Batch Consumption Time: 0.02735
Total Iteration Time: 4.53369

Cumulative Model Updates: 4614
Cumulative Timesteps: 76986206

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03327
Policy Entropy: 1.21675
Value Function Loss: 0.02986

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05433
Policy Update Magnitude: 0.03578
Value Function Update Magnitude: 0.04265

Collected Steps per Second: 12504.78282
Overall Steps per Second: 10394.28275

Timestep Collection Time: 4.00103
Timestep Consumption Time: 0.81239
PPO Batch Consumption Time: 0.02785
Total Iteration Time: 4.81342

Cumulative Model Updates: 4617
Cumulative Timesteps: 77036238

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 77036238...
Checkpoint 77036238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04188
Policy Entropy: 1.21089
Value Function Loss: 0.03803

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07233
Policy Update Magnitude: 0.03622
Value Function Update Magnitude: 0.05256

Collected Steps per Second: 12961.77065
Overall Steps per Second: 10462.88229

Timestep Collection Time: 3.85935
Timestep Consumption Time: 0.92174
PPO Batch Consumption Time: 0.02997
Total Iteration Time: 4.78109

Cumulative Model Updates: 4620
Cumulative Timesteps: 77086262

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01879
Policy Entropy: 1.22341
Value Function Loss: 0.02967

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.03656
Value Function Update Magnitude: 0.04961

Collected Steps per Second: 10780.81931
Overall Steps per Second: 9144.34269

Timestep Collection Time: 4.64065
Timestep Consumption Time: 0.83049
PPO Batch Consumption Time: 0.03146
Total Iteration Time: 5.47114

Cumulative Model Updates: 4623
Cumulative Timesteps: 77136292

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 77136292...
Checkpoint 77136292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01029
Policy Entropy: 1.23036
Value Function Loss: 0.02959

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.03950
Value Function Update Magnitude: 0.04005

Collected Steps per Second: 12713.28632
Overall Steps per Second: 10583.97654

Timestep Collection Time: 3.93525
Timestep Consumption Time: 0.79170
PPO Batch Consumption Time: 0.02948
Total Iteration Time: 4.72696

Cumulative Model Updates: 4626
Cumulative Timesteps: 77186322

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04254
Policy Entropy: 1.23845
Value Function Loss: 0.02127

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.03699
Value Function Update Magnitude: 0.04286

Collected Steps per Second: 10892.50216
Overall Steps per Second: 9297.13770

Timestep Collection Time: 4.59123
Timestep Consumption Time: 0.78784
PPO Batch Consumption Time: 0.03245
Total Iteration Time: 5.37907

Cumulative Model Updates: 4629
Cumulative Timesteps: 77236332

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 77236332...
Checkpoint 77236332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00660
Policy Entropy: 1.19759
Value Function Loss: 0.02878

Mean KL Divergence: 0.04328
SB3 Clip Fraction: 0.18676
Policy Update Magnitude: 0.03547
Value Function Update Magnitude: 0.03722

Collected Steps per Second: 10339.99809
Overall Steps per Second: 8703.24541

Timestep Collection Time: 4.84062
Timestep Consumption Time: 0.91034
PPO Batch Consumption Time: 0.02941
Total Iteration Time: 5.75096

Cumulative Model Updates: 4632
Cumulative Timesteps: 77286384

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00125
Policy Entropy: 1.21602
Value Function Loss: 0.03038

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.03757
Value Function Update Magnitude: 0.03636

Collected Steps per Second: 11668.33600
Overall Steps per Second: 9843.08522

Timestep Collection Time: 4.28544
Timestep Consumption Time: 0.79467
PPO Batch Consumption Time: 0.02896
Total Iteration Time: 5.08011

Cumulative Model Updates: 4635
Cumulative Timesteps: 77336388

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 77336388...
Checkpoint 77336388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01437
Policy Entropy: 1.19658
Value Function Loss: 0.04209

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.03710
Value Function Update Magnitude: 0.04032

Collected Steps per Second: 13223.14487
Overall Steps per Second: 10927.68625

Timestep Collection Time: 3.78125
Timestep Consumption Time: 0.79429
PPO Batch Consumption Time: 0.02573
Total Iteration Time: 4.57553

Cumulative Model Updates: 4638
Cumulative Timesteps: 77386388

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04480
Policy Entropy: 1.18378
Value Function Loss: 0.03476

Mean KL Divergence: 0.03272
SB3 Clip Fraction: 0.15765
Policy Update Magnitude: 0.03898
Value Function Update Magnitude: 0.04117

Collected Steps per Second: 12840.50716
Overall Steps per Second: 10568.78431

Timestep Collection Time: 3.89798
Timestep Consumption Time: 0.83786
PPO Batch Consumption Time: 0.03018
Total Iteration Time: 4.73583

Cumulative Model Updates: 4641
Cumulative Timesteps: 77436440

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 77436440...
Checkpoint 77436440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01254
Policy Entropy: 1.19522
Value Function Loss: 0.03092

Mean KL Divergence: 0.02860
SB3 Clip Fraction: 0.15805
Policy Update Magnitude: 0.04202
Value Function Update Magnitude: 0.05241

Collected Steps per Second: 13083.50955
Overall Steps per Second: 10984.21781

Timestep Collection Time: 3.82329
Timestep Consumption Time: 0.73070
PPO Batch Consumption Time: 0.02676
Total Iteration Time: 4.55399

Cumulative Model Updates: 4644
Cumulative Timesteps: 77486462

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00755
Policy Entropy: 1.18224
Value Function Loss: 0.03700

Mean KL Divergence: 0.03357
SB3 Clip Fraction: 0.18388
Policy Update Magnitude: 0.03760
Value Function Update Magnitude: 0.04400

Collected Steps per Second: 13237.01891
Overall Steps per Second: 10878.32892

Timestep Collection Time: 3.77849
Timestep Consumption Time: 0.81927
PPO Batch Consumption Time: 0.02781
Total Iteration Time: 4.59777

Cumulative Model Updates: 4647
Cumulative Timesteps: 77536478

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 77536478...
Checkpoint 77536478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03703
Policy Entropy: 1.17416
Value Function Loss: 0.02925

Mean KL Divergence: 0.04231
SB3 Clip Fraction: 0.16944
Policy Update Magnitude: 0.03795
Value Function Update Magnitude: 0.03746

Collected Steps per Second: 11653.11715
Overall Steps per Second: 9815.62810

Timestep Collection Time: 4.29156
Timestep Consumption Time: 0.80338
PPO Batch Consumption Time: 0.02983
Total Iteration Time: 5.09494

Cumulative Model Updates: 4650
Cumulative Timesteps: 77586488

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00357
Policy Entropy: 1.18918
Value Function Loss: 0.03053

Mean KL Divergence: 0.03551
SB3 Clip Fraction: 0.18947
Policy Update Magnitude: 0.03982
Value Function Update Magnitude: 0.03526

Collected Steps per Second: 13129.10856
Overall Steps per Second: 10848.17990

Timestep Collection Time: 3.81153
Timestep Consumption Time: 0.80141
PPO Batch Consumption Time: 0.02720
Total Iteration Time: 4.61294

Cumulative Model Updates: 4653
Cumulative Timesteps: 77636530

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 77636530...
Checkpoint 77636530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02031
Policy Entropy: 1.18183
Value Function Loss: 0.02993

Mean KL Divergence: 0.04399
SB3 Clip Fraction: 0.20535
Policy Update Magnitude: 0.03517
Value Function Update Magnitude: 0.03835

Collected Steps per Second: 12260.22872
Overall Steps per Second: 10231.87402

Timestep Collection Time: 4.07904
Timestep Consumption Time: 0.80862
PPO Batch Consumption Time: 0.02672
Total Iteration Time: 4.88767

Cumulative Model Updates: 4656
Cumulative Timesteps: 77686540

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03328
Policy Entropy: 1.17044
Value Function Loss: 0.03692

Mean KL Divergence: 0.04796
SB3 Clip Fraction: 0.19772
Policy Update Magnitude: 0.03720
Value Function Update Magnitude: 0.05246

Collected Steps per Second: 11374.66432
Overall Steps per Second: 9709.67054

Timestep Collection Time: 4.39626
Timestep Consumption Time: 0.75386
PPO Batch Consumption Time: 0.02707
Total Iteration Time: 5.15012

Cumulative Model Updates: 4659
Cumulative Timesteps: 77736546

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 77736546...
Checkpoint 77736546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01671
Policy Entropy: 1.18943
Value Function Loss: 0.04628

Mean KL Divergence: 0.03254
SB3 Clip Fraction: 0.17577
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.05537

Collected Steps per Second: 11832.75356
Overall Steps per Second: 9917.91277

Timestep Collection Time: 4.22826
Timestep Consumption Time: 0.81635
PPO Batch Consumption Time: 0.02697
Total Iteration Time: 5.04461

Cumulative Model Updates: 4662
Cumulative Timesteps: 77786578

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04702
Policy Entropy: 1.18374
Value Function Loss: 0.05058

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.04863

Collected Steps per Second: 12658.56812
Overall Steps per Second: 10570.08289

Timestep Collection Time: 3.95053
Timestep Consumption Time: 0.78056
PPO Batch Consumption Time: 0.02689
Total Iteration Time: 4.73109

Cumulative Model Updates: 4665
Cumulative Timesteps: 77836586

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 77836586...
Checkpoint 77836586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02093
Policy Entropy: 1.16484
Value Function Loss: 0.06589

Mean KL Divergence: 0.03131
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.04714
Value Function Update Magnitude: 0.04498

Collected Steps per Second: 11436.62690
Overall Steps per Second: 9435.17359

Timestep Collection Time: 4.37314
Timestep Consumption Time: 0.92766
PPO Batch Consumption Time: 0.03180
Total Iteration Time: 5.30080

Cumulative Model Updates: 4668
Cumulative Timesteps: 77886600

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01014
Policy Entropy: 1.16809
Value Function Loss: 0.06823

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.04609
Value Function Update Magnitude: 0.04830

Collected Steps per Second: 10986.34763
Overall Steps per Second: 9095.83146

Timestep Collection Time: 4.55402
Timestep Consumption Time: 0.94653
PPO Batch Consumption Time: 0.03126
Total Iteration Time: 5.50054

Cumulative Model Updates: 4671
Cumulative Timesteps: 77936632

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 77936632...
Checkpoint 77936632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03106
Policy Entropy: 1.18800
Value Function Loss: 0.05384

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11359
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.04535

Collected Steps per Second: 10552.69672
Overall Steps per Second: 8914.47985

Timestep Collection Time: 4.74135
Timestep Consumption Time: 0.87132
PPO Batch Consumption Time: 0.02938
Total Iteration Time: 5.61267

Cumulative Model Updates: 4674
Cumulative Timesteps: 77986666

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00642
Policy Entropy: 1.17535
Value Function Loss: 0.04265

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.05070

Collected Steps per Second: 11823.66441
Overall Steps per Second: 9852.09123

Timestep Collection Time: 4.23118
Timestep Consumption Time: 0.84673
PPO Batch Consumption Time: 0.02722
Total Iteration Time: 5.07791

Cumulative Model Updates: 4677
Cumulative Timesteps: 78036694

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 78036694...
Checkpoint 78036694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00298
Policy Entropy: 1.17464
Value Function Loss: 0.02943

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.04523
Value Function Update Magnitude: 0.04719

Collected Steps per Second: 12478.54806
Overall Steps per Second: 10286.49809

Timestep Collection Time: 4.00896
Timestep Consumption Time: 0.85431
PPO Batch Consumption Time: 0.02789
Total Iteration Time: 4.86327

Cumulative Model Updates: 4680
Cumulative Timesteps: 78086720

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03931
Policy Entropy: 1.17806
Value Function Loss: 0.02543

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.03885
Value Function Update Magnitude: 0.04490

Collected Steps per Second: 12775.63301
Overall Steps per Second: 10842.05736

Timestep Collection Time: 3.91511
Timestep Consumption Time: 0.69822
PPO Batch Consumption Time: 0.02678
Total Iteration Time: 4.61333

Cumulative Model Updates: 4683
Cumulative Timesteps: 78136738

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 78136738...
Checkpoint 78136738 saved!

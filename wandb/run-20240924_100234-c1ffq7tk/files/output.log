Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11378
Policy Entropy: 1.09702
Value Function Loss: 0.16902

Mean KL Divergence: -0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.02188
Value Function Update Magnitude: 0.02035

Collected Steps per Second: 10099.33099
Overall Steps per Second: 8063.56406

Timestep Collection Time: 4.95261
Timestep Consumption Time: 1.25036
PPO Batch Consumption Time: 0.41193
Total Iteration Time: 6.20296

Cumulative Model Updates: 4684
Cumulative Timesteps: 78186756

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09072
Policy Entropy: 1.05683
Value Function Loss: 0.18016

Mean KL Divergence: 0.03678
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.04371
Value Function Update Magnitude: 0.05083

Collected Steps per Second: 11729.77983
Overall Steps per Second: 9278.18431

Timestep Collection Time: 4.26402
Timestep Consumption Time: 1.12669
PPO Batch Consumption Time: 0.15975
Total Iteration Time: 5.39071

Cumulative Model Updates: 4686
Cumulative Timesteps: 78236772

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 78236772...
Checkpoint 78236772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02794
Policy Entropy: 1.06287
Value Function Loss: 0.15777

Mean KL Divergence: 0.02716
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.07151
Value Function Update Magnitude: 0.10449

Collected Steps per Second: 12373.84580
Overall Steps per Second: 10020.37343

Timestep Collection Time: 4.04288
Timestep Consumption Time: 0.94955
PPO Batch Consumption Time: 0.09738
Total Iteration Time: 4.99243

Cumulative Model Updates: 4689
Cumulative Timesteps: 78286798

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01094
Policy Entropy: 1.06721
Value Function Loss: 0.18013

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.07760
Value Function Update Magnitude: 0.11844

Collected Steps per Second: 12881.46326
Overall Steps per Second: 10472.89080

Timestep Collection Time: 3.88232
Timestep Consumption Time: 0.89286
PPO Batch Consumption Time: 0.06004
Total Iteration Time: 4.77519

Cumulative Model Updates: 4692
Cumulative Timesteps: 78336808

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 78336808...
Checkpoint 78336808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14160
Policy Entropy: 1.06209
Value Function Loss: 0.19944

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.10601
Policy Update Magnitude: 0.08782
Value Function Update Magnitude: 0.12232

Collected Steps per Second: 11478.04427
Overall Steps per Second: 9262.94221

Timestep Collection Time: 4.35928
Timestep Consumption Time: 1.04246
PPO Batch Consumption Time: 0.10964
Total Iteration Time: 5.40174

Cumulative Model Updates: 4695
Cumulative Timesteps: 78386844

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01590
Policy Entropy: 1.06166
Value Function Loss: 0.22385

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.08908
Value Function Update Magnitude: 0.14810

Collected Steps per Second: 10903.69848
Overall Steps per Second: 8802.25966

Timestep Collection Time: 4.58615
Timestep Consumption Time: 1.09489
PPO Batch Consumption Time: 0.07458
Total Iteration Time: 5.68104

Cumulative Model Updates: 4698
Cumulative Timesteps: 78436850

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 78436850...
Checkpoint 78436850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16457
Policy Entropy: 1.04714
Value Function Loss: 0.19394

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.09209
Value Function Update Magnitude: 0.16433

Collected Steps per Second: 8028.40491
Overall Steps per Second: 6683.60957

Timestep Collection Time: 6.23038
Timestep Consumption Time: 1.25360
PPO Batch Consumption Time: 0.11462
Total Iteration Time: 7.48398

Cumulative Model Updates: 4701
Cumulative Timesteps: 78486870

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01324
Policy Entropy: 1.04420
Value Function Loss: 0.18520

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.09886
Value Function Update Magnitude: 0.14918

Collected Steps per Second: 9944.22542
Overall Steps per Second: 8401.88046

Timestep Collection Time: 5.02945
Timestep Consumption Time: 0.92326
PPO Batch Consumption Time: 0.07501
Total Iteration Time: 5.95272

Cumulative Model Updates: 4704
Cumulative Timesteps: 78536884

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 78536884...
Checkpoint 78536884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20913
Policy Entropy: 1.05132
Value Function Loss: 0.16617

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.11635
Policy Update Magnitude: 0.09609
Value Function Update Magnitude: 0.14331

Collected Steps per Second: 9444.34683
Overall Steps per Second: 7778.73232

Timestep Collection Time: 5.29629
Timestep Consumption Time: 1.13406
PPO Batch Consumption Time: 0.09384
Total Iteration Time: 6.43035

Cumulative Model Updates: 4707
Cumulative Timesteps: 78586904

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10845
Policy Entropy: 1.04022
Value Function Loss: 0.15306

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.14183
Policy Update Magnitude: 0.09181
Value Function Update Magnitude: 0.13662

Collected Steps per Second: 11379.63285
Overall Steps per Second: 8924.50611

Timestep Collection Time: 4.39698
Timestep Consumption Time: 1.20961
PPO Batch Consumption Time: 0.10849
Total Iteration Time: 5.60658

Cumulative Model Updates: 4710
Cumulative Timesteps: 78636940

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 78636940...
Checkpoint 78636940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02337
Policy Entropy: 1.05299
Value Function Loss: 0.14962

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.08354
Value Function Update Magnitude: 0.13696

Collected Steps per Second: 9513.30422
Overall Steps per Second: 7922.74621

Timestep Collection Time: 5.25916
Timestep Consumption Time: 1.05582
PPO Batch Consumption Time: 0.06730
Total Iteration Time: 6.31498

Cumulative Model Updates: 4713
Cumulative Timesteps: 78686972

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16624
Policy Entropy: 1.06079
Value Function Loss: 0.16061

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.15829
Policy Update Magnitude: 0.08142
Value Function Update Magnitude: 0.14938

Collected Steps per Second: 11043.42495
Overall Steps per Second: 8856.07366

Timestep Collection Time: 4.53211
Timestep Consumption Time: 1.11938
PPO Batch Consumption Time: 0.07998
Total Iteration Time: 5.65149

Cumulative Model Updates: 4716
Cumulative Timesteps: 78737022

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 78737022...
Checkpoint 78737022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09953
Policy Entropy: 1.04310
Value Function Loss: 0.17056

Mean KL Divergence: 0.02086
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.08255
Value Function Update Magnitude: 0.13762

Collected Steps per Second: 10837.68106
Overall Steps per Second: 8866.09682

Timestep Collection Time: 4.61556
Timestep Consumption Time: 1.02638
PPO Batch Consumption Time: 0.07479
Total Iteration Time: 5.64194

Cumulative Model Updates: 4719
Cumulative Timesteps: 78787044

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.25055
Policy Entropy: 1.04292
Value Function Loss: 0.16363

Mean KL Divergence: 0.02176
SB3 Clip Fraction: 0.15613
Policy Update Magnitude: 0.08144
Value Function Update Magnitude: 0.14299

Collected Steps per Second: 8655.67764
Overall Steps per Second: 7034.32140

Timestep Collection Time: 5.78118
Timestep Consumption Time: 1.33252
PPO Batch Consumption Time: 0.14217
Total Iteration Time: 7.11369

Cumulative Model Updates: 4722
Cumulative Timesteps: 78837084

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 78837084...
Checkpoint 78837084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10742
Policy Entropy: 1.06913
Value Function Loss: 0.14778

Mean KL Divergence: 0.02131
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.08218
Value Function Update Magnitude: 0.13570

Collected Steps per Second: 10868.52979
Overall Steps per Second: 8955.14218

Timestep Collection Time: 4.60301
Timestep Consumption Time: 0.98350
PPO Batch Consumption Time: 0.06383
Total Iteration Time: 5.58651

Cumulative Model Updates: 4725
Cumulative Timesteps: 78887112

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12937
Policy Entropy: 1.06469
Value Function Loss: 0.15281

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.15933
Policy Update Magnitude: 0.07863
Value Function Update Magnitude: 0.13397

Collected Steps per Second: 10077.81137
Overall Steps per Second: 8338.14291

Timestep Collection Time: 4.96397
Timestep Consumption Time: 1.03568
PPO Batch Consumption Time: 0.08445
Total Iteration Time: 5.99966

Cumulative Model Updates: 4728
Cumulative Timesteps: 78937138

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 78937138...
Checkpoint 78937138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00862
Policy Entropy: 1.05130
Value Function Loss: 0.14883

Mean KL Divergence: 0.02550
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.07963
Value Function Update Magnitude: 0.14135

Collected Steps per Second: 10935.66368
Overall Steps per Second: 8670.09285

Timestep Collection Time: 4.57274
Timestep Consumption Time: 1.19490
PPO Batch Consumption Time: 0.09848
Total Iteration Time: 5.76764

Cumulative Model Updates: 4731
Cumulative Timesteps: 78987144

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00234
Policy Entropy: 1.05759
Value Function Loss: 0.19256

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.08416
Value Function Update Magnitude: 0.14801

Collected Steps per Second: 10679.48492
Overall Steps per Second: 8763.98711

Timestep Collection Time: 4.68356
Timestep Consumption Time: 1.02366
PPO Batch Consumption Time: 0.07050
Total Iteration Time: 5.70722

Cumulative Model Updates: 4734
Cumulative Timesteps: 79037162

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 79037162...
Checkpoint 79037162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14263
Policy Entropy: 1.06889
Value Function Loss: 0.19117

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.08330
Value Function Update Magnitude: 0.13592

Collected Steps per Second: 10305.59820
Overall Steps per Second: 8241.03163

Timestep Collection Time: 4.85251
Timestep Consumption Time: 1.21566
PPO Batch Consumption Time: 0.11107
Total Iteration Time: 6.06817

Cumulative Model Updates: 4737
Cumulative Timesteps: 79087170

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12448
Policy Entropy: 1.06992
Value Function Loss: 0.18467

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.08237
Value Function Update Magnitude: 0.14656

Collected Steps per Second: 10834.92850
Overall Steps per Second: 8877.30425

Timestep Collection Time: 4.61471
Timestep Consumption Time: 1.01764
PPO Batch Consumption Time: 0.06469
Total Iteration Time: 5.63234

Cumulative Model Updates: 4740
Cumulative Timesteps: 79137170

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 79137170...
Checkpoint 79137170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10839
Policy Entropy: 1.07444
Value Function Loss: 0.13064

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07407
Policy Update Magnitude: 0.08122
Value Function Update Magnitude: 0.14705

Collected Steps per Second: 8203.06221
Overall Steps per Second: 6985.00700

Timestep Collection Time: 6.10016
Timestep Consumption Time: 1.06375
PPO Batch Consumption Time: 0.09468
Total Iteration Time: 7.16392

Cumulative Model Updates: 4743
Cumulative Timesteps: 79187210

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05839
Policy Entropy: 1.07103
Value Function Loss: 0.13770

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.07629
Value Function Update Magnitude: 0.15032

Collected Steps per Second: 10242.25446
Overall Steps per Second: 8366.72711

Timestep Collection Time: 4.88291
Timestep Consumption Time: 1.09458
PPO Batch Consumption Time: 0.08540
Total Iteration Time: 5.97749

Cumulative Model Updates: 4746
Cumulative Timesteps: 79237222

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 79237222...
Checkpoint 79237222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06812
Policy Entropy: 1.06549
Value Function Loss: 0.12086

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.07187
Value Function Update Magnitude: 0.13743

Collected Steps per Second: 12786.08223
Overall Steps per Second: 10423.56174

Timestep Collection Time: 3.91081
Timestep Consumption Time: 0.88639
PPO Batch Consumption Time: 0.05771
Total Iteration Time: 4.79721

Cumulative Model Updates: 4749
Cumulative Timesteps: 79287226

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05321
Policy Entropy: 1.05936
Value Function Loss: 0.14494

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.07228
Value Function Update Magnitude: 0.13024

Collected Steps per Second: 11810.07820
Overall Steps per Second: 9317.07680

Timestep Collection Time: 4.23435
Timestep Consumption Time: 1.13300
PPO Batch Consumption Time: 0.12499
Total Iteration Time: 5.36735

Cumulative Model Updates: 4752
Cumulative Timesteps: 79337234

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 79337234...
Checkpoint 79337234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15916
Policy Entropy: 1.05798
Value Function Loss: 0.11812

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.06895
Value Function Update Magnitude: 0.13349

Collected Steps per Second: 12219.90989
Overall Steps per Second: 10064.80966

Timestep Collection Time: 4.09447
Timestep Consumption Time: 0.87672
PPO Batch Consumption Time: 0.05823
Total Iteration Time: 4.97118

Cumulative Model Updates: 4755
Cumulative Timesteps: 79387268

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06326
Policy Entropy: 1.07121
Value Function Loss: 0.11837

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.07507
Value Function Update Magnitude: 0.13308

Collected Steps per Second: 11353.39569
Overall Steps per Second: 9240.33770

Timestep Collection Time: 4.40714
Timestep Consumption Time: 1.00781
PPO Batch Consumption Time: 0.08655
Total Iteration Time: 5.41495

Cumulative Model Updates: 4758
Cumulative Timesteps: 79437304

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 79437304...
Checkpoint 79437304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13615
Policy Entropy: 1.06143
Value Function Loss: 0.13151

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.07703
Value Function Update Magnitude: 0.12193

Collected Steps per Second: 11389.14136
Overall Steps per Second: 9270.40274

Timestep Collection Time: 4.39155
Timestep Consumption Time: 1.00368
PPO Batch Consumption Time: 0.08293
Total Iteration Time: 5.39523

Cumulative Model Updates: 4761
Cumulative Timesteps: 79487320

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13521
Policy Entropy: 1.06581
Value Function Loss: 0.13926

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.07717
Value Function Update Magnitude: 0.12824

Collected Steps per Second: 12549.20018
Overall Steps per Second: 10041.96210

Timestep Collection Time: 3.98623
Timestep Consumption Time: 0.99527
PPO Batch Consumption Time: 0.08368
Total Iteration Time: 4.98150

Cumulative Model Updates: 4764
Cumulative Timesteps: 79537344

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 79537344...
Checkpoint 79537344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01332
Policy Entropy: 1.05005
Value Function Loss: 0.16803

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.08009
Value Function Update Magnitude: 0.13143

Collected Steps per Second: 10807.09750
Overall Steps per Second: 9252.80985

Timestep Collection Time: 4.63196
Timestep Consumption Time: 0.77808
PPO Batch Consumption Time: 0.03917
Total Iteration Time: 5.41003

Cumulative Model Updates: 4767
Cumulative Timesteps: 79587402

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14589
Policy Entropy: 1.08360
Value Function Loss: 0.16004

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.07366
Value Function Update Magnitude: 0.12418

Collected Steps per Second: 12376.94135
Overall Steps per Second: 9721.51903

Timestep Collection Time: 4.04252
Timestep Consumption Time: 1.10421
PPO Batch Consumption Time: 0.11821
Total Iteration Time: 5.14673

Cumulative Model Updates: 4770
Cumulative Timesteps: 79637436

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 79637436...
Checkpoint 79637436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06810
Policy Entropy: 1.06654
Value Function Loss: 0.17356

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.07365
Value Function Update Magnitude: 0.12621

Collected Steps per Second: 11677.23883
Overall Steps per Second: 9261.20316

Timestep Collection Time: 4.28303
Timestep Consumption Time: 1.11735
PPO Batch Consumption Time: 0.11316
Total Iteration Time: 5.40038

Cumulative Model Updates: 4773
Cumulative Timesteps: 79687450

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06160
Policy Entropy: 1.04659
Value Function Loss: 0.15337

Mean KL Divergence: 0.03795
SB3 Clip Fraction: 0.18227
Policy Update Magnitude: 0.07355
Value Function Update Magnitude: 0.13719

Collected Steps per Second: 11950.34623
Overall Steps per Second: 9633.05018

Timestep Collection Time: 4.18867
Timestep Consumption Time: 1.00761
PPO Batch Consumption Time: 0.08434
Total Iteration Time: 5.19628

Cumulative Model Updates: 4776
Cumulative Timesteps: 79737506

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 79737506...
Checkpoint 79737506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14877
Policy Entropy: 1.07441
Value Function Loss: 0.13769

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.07203
Value Function Update Magnitude: 0.14196

Collected Steps per Second: 12030.65524
Overall Steps per Second: 9649.72938

Timestep Collection Time: 4.16070
Timestep Consumption Time: 1.02659
PPO Batch Consumption Time: 0.08158
Total Iteration Time: 5.18730

Cumulative Model Updates: 4779
Cumulative Timesteps: 79787562

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03689
Policy Entropy: 1.06505
Value Function Loss: 0.11999

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.15712
Policy Update Magnitude: 0.06839
Value Function Update Magnitude: 0.14006

Collected Steps per Second: 12697.22163
Overall Steps per Second: 10555.04907

Timestep Collection Time: 3.93944
Timestep Consumption Time: 0.79952
PPO Batch Consumption Time: 0.05816
Total Iteration Time: 4.73896

Cumulative Model Updates: 4782
Cumulative Timesteps: 79837582

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 79837582...
Checkpoint 79837582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01646
Policy Entropy: 1.06223
Value Function Loss: 0.12318

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.07138
Value Function Update Magnitude: 0.13743

Collected Steps per Second: 12187.84961
Overall Steps per Second: 9921.62793

Timestep Collection Time: 4.10409
Timestep Consumption Time: 0.93742
PPO Batch Consumption Time: 0.06792
Total Iteration Time: 5.04151

Cumulative Model Updates: 4785
Cumulative Timesteps: 79887602

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06292
Policy Entropy: 1.06656
Value Function Loss: 0.14477

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.07383
Value Function Update Magnitude: 0.14503

Collected Steps per Second: 12334.43065
Overall Steps per Second: 10119.22802

Timestep Collection Time: 4.05726
Timestep Consumption Time: 0.88818
PPO Batch Consumption Time: 0.06305
Total Iteration Time: 4.94544

Cumulative Model Updates: 4788
Cumulative Timesteps: 79937646

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 79937646...
Checkpoint 79937646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04435
Policy Entropy: 1.06184
Value Function Loss: 0.14024

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.07209
Value Function Update Magnitude: 0.13636

Collected Steps per Second: 10743.36923
Overall Steps per Second: 8891.12801

Timestep Collection Time: 4.65757
Timestep Consumption Time: 0.97029
PPO Batch Consumption Time: 0.06717
Total Iteration Time: 5.62786

Cumulative Model Updates: 4791
Cumulative Timesteps: 79987684

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03871
Policy Entropy: 1.06415
Value Function Loss: 0.16080

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.07181
Value Function Update Magnitude: 0.12955

Collected Steps per Second: 9124.38784
Overall Steps per Second: 7373.29692

Timestep Collection Time: 5.48267
Timestep Consumption Time: 1.30208
PPO Batch Consumption Time: 0.11535
Total Iteration Time: 6.78475

Cumulative Model Updates: 4794
Cumulative Timesteps: 80037710

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 80037710...
Checkpoint 80037710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04875
Policy Entropy: 1.05534
Value Function Loss: 0.13915

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.07770
Value Function Update Magnitude: 0.12682

Collected Steps per Second: 10276.51464
Overall Steps per Second: 8385.96035

Timestep Collection Time: 4.86741
Timestep Consumption Time: 1.09732
PPO Batch Consumption Time: 0.11632
Total Iteration Time: 5.96473

Cumulative Model Updates: 4797
Cumulative Timesteps: 80087730

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00686
Policy Entropy: 1.06500
Value Function Loss: 0.15938

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.07904
Value Function Update Magnitude: 0.13336

Collected Steps per Second: 11303.96451
Overall Steps per Second: 9179.16797

Timestep Collection Time: 4.42482
Timestep Consumption Time: 1.02426
PPO Batch Consumption Time: 0.06927
Total Iteration Time: 5.44908

Cumulative Model Updates: 4800
Cumulative Timesteps: 80137748

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 80137748...
Checkpoint 80137748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04701
Policy Entropy: 1.05865
Value Function Loss: 0.12902

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.07742
Value Function Update Magnitude: 0.12763

Collected Steps per Second: 10590.96409
Overall Steps per Second: 8434.85750

Timestep Collection Time: 4.72119
Timestep Consumption Time: 1.20683
PPO Batch Consumption Time: 0.12669
Total Iteration Time: 5.92802

Cumulative Model Updates: 4803
Cumulative Timesteps: 80187750

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04511
Policy Entropy: 1.05842
Value Function Loss: 0.13180

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.07817
Value Function Update Magnitude: 0.12976

Collected Steps per Second: 11909.20279
Overall Steps per Second: 9729.11908

Timestep Collection Time: 4.20045
Timestep Consumption Time: 0.94123
PPO Batch Consumption Time: 0.07712
Total Iteration Time: 5.14168

Cumulative Model Updates: 4806
Cumulative Timesteps: 80237774

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 80237774...
Checkpoint 80237774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10749
Policy Entropy: 1.05481
Value Function Loss: 0.14107

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.06888
Value Function Update Magnitude: 0.12232

Collected Steps per Second: 9517.70798
Overall Steps per Second: 7762.14397

Timestep Collection Time: 5.25358
Timestep Consumption Time: 1.18820
PPO Batch Consumption Time: 0.09789
Total Iteration Time: 6.44178

Cumulative Model Updates: 4809
Cumulative Timesteps: 80287776

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07877
Policy Entropy: 1.05134
Value Function Loss: 0.14615

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.06856
Value Function Update Magnitude: 0.12244

Collected Steps per Second: 10034.60497
Overall Steps per Second: 8058.62581

Timestep Collection Time: 4.98734
Timestep Consumption Time: 1.22290
PPO Batch Consumption Time: 0.07590
Total Iteration Time: 6.21024

Cumulative Model Updates: 4812
Cumulative Timesteps: 80337822

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 80337822...
Checkpoint 80337822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08121
Policy Entropy: 1.05946
Value Function Loss: 0.14708

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.06959
Value Function Update Magnitude: 0.12054

Collected Steps per Second: 11240.05895
Overall Steps per Second: 9124.76513

Timestep Collection Time: 4.44962
Timestep Consumption Time: 1.03151
PPO Batch Consumption Time: 0.07441
Total Iteration Time: 5.48113

Cumulative Model Updates: 4815
Cumulative Timesteps: 80387836

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12468
Policy Entropy: 1.06113
Value Function Loss: 0.14417

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.07313
Value Function Update Magnitude: 0.11091

Collected Steps per Second: 11188.30366
Overall Steps per Second: 8819.88465

Timestep Collection Time: 4.46913
Timestep Consumption Time: 1.20010
PPO Batch Consumption Time: 0.13087
Total Iteration Time: 5.66924

Cumulative Model Updates: 4818
Cumulative Timesteps: 80437838

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 80437838...
Checkpoint 80437838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09686
Policy Entropy: 1.05811
Value Function Loss: 0.14867

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.07445
Value Function Update Magnitude: 0.09104

Collected Steps per Second: 10348.54790
Overall Steps per Second: 8352.38554

Timestep Collection Time: 4.83469
Timestep Consumption Time: 1.15546
PPO Batch Consumption Time: 0.10637
Total Iteration Time: 5.99014

Cumulative Model Updates: 4821
Cumulative Timesteps: 80487870

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03080
Policy Entropy: 1.06870
Value Function Loss: 0.16395

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.06901
Value Function Update Magnitude: 0.07632

Collected Steps per Second: 10615.60908
Overall Steps per Second: 8615.42053

Timestep Collection Time: 4.71287
Timestep Consumption Time: 1.09416
PPO Batch Consumption Time: 0.06823
Total Iteration Time: 5.80703

Cumulative Model Updates: 4824
Cumulative Timesteps: 80537900

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 80537900...
Checkpoint 80537900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01095
Policy Entropy: 1.07899
Value Function Loss: 0.14450

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.07181
Value Function Update Magnitude: 0.07210

Collected Steps per Second: 10760.88793
Overall Steps per Second: 8687.56402

Timestep Collection Time: 4.64794
Timestep Consumption Time: 1.10925
PPO Batch Consumption Time: 0.10694
Total Iteration Time: 5.75719

Cumulative Model Updates: 4827
Cumulative Timesteps: 80587916

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06605
Policy Entropy: 1.07714
Value Function Loss: 0.13526

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.06693
Value Function Update Magnitude: 0.06502

Collected Steps per Second: 11040.62909
Overall Steps per Second: 8924.65598

Timestep Collection Time: 4.53144
Timestep Consumption Time: 1.07437
PPO Batch Consumption Time: 0.06401
Total Iteration Time: 5.60582

Cumulative Model Updates: 4830
Cumulative Timesteps: 80637946

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 80637946...
Checkpoint 80637946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03283
Policy Entropy: 1.06285
Value Function Loss: 0.14920

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.07026
Value Function Update Magnitude: 0.07306

Collected Steps per Second: 10437.15685
Overall Steps per Second: 8389.42730

Timestep Collection Time: 4.79422
Timestep Consumption Time: 1.17019
PPO Batch Consumption Time: 0.12052
Total Iteration Time: 5.96441

Cumulative Model Updates: 4833
Cumulative Timesteps: 80687984

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14611
Policy Entropy: 1.05742
Value Function Loss: 0.14210

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.06708
Value Function Update Magnitude: 0.07844

Collected Steps per Second: 11341.34287
Overall Steps per Second: 9252.27729

Timestep Collection Time: 4.41288
Timestep Consumption Time: 0.99638
PPO Batch Consumption Time: 0.10223
Total Iteration Time: 5.40926

Cumulative Model Updates: 4836
Cumulative Timesteps: 80738032

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 80738032...
Checkpoint 80738032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10255
Policy Entropy: 1.06349
Value Function Loss: 0.15608

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.08947

Collected Steps per Second: 9391.76238
Overall Steps per Second: 7593.64965

Timestep Collection Time: 5.32765
Timestep Consumption Time: 1.26154
PPO Batch Consumption Time: 0.08854
Total Iteration Time: 6.58919

Cumulative Model Updates: 4839
Cumulative Timesteps: 80788068

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09514
Policy Entropy: 1.06555
Value Function Loss: 0.12249

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05724
Policy Update Magnitude: 0.06694
Value Function Update Magnitude: 0.09366

Collected Steps per Second: 9796.43608
Overall Steps per Second: 8065.92811

Timestep Collection Time: 5.10676
Timestep Consumption Time: 1.09563
PPO Batch Consumption Time: 0.09183
Total Iteration Time: 6.20239

Cumulative Model Updates: 4842
Cumulative Timesteps: 80838096

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 80838096...
Checkpoint 80838096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01262
Policy Entropy: 1.05063
Value Function Loss: 0.11422

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.10605

Collected Steps per Second: 11850.23977
Overall Steps per Second: 9652.68762

Timestep Collection Time: 4.22084
Timestep Consumption Time: 0.96093
PPO Batch Consumption Time: 0.06987
Total Iteration Time: 5.18177

Cumulative Model Updates: 4845
Cumulative Timesteps: 80888114

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13375
Policy Entropy: 1.06228
Value Function Loss: 0.10897

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06381
Policy Update Magnitude: 0.06273
Value Function Update Magnitude: 0.11024

Collected Steps per Second: 12904.34268
Overall Steps per Second: 10060.48051

Timestep Collection Time: 3.87466
Timestep Consumption Time: 1.09528
PPO Batch Consumption Time: 0.12689
Total Iteration Time: 4.96994

Cumulative Model Updates: 4848
Cumulative Timesteps: 80938114

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 80938114...
Checkpoint 80938114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03596
Policy Entropy: 1.06897
Value Function Loss: 0.13026

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06432
Policy Update Magnitude: 0.06743
Value Function Update Magnitude: 0.11216

Collected Steps per Second: 12456.25478
Overall Steps per Second: 10036.04807

Timestep Collection Time: 4.01742
Timestep Consumption Time: 0.96881
PPO Batch Consumption Time: 0.10191
Total Iteration Time: 4.98623

Cumulative Model Updates: 4851
Cumulative Timesteps: 80988156

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01730
Policy Entropy: 1.08065
Value Function Loss: 0.12394

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.12593

Collected Steps per Second: 12278.55461
Overall Steps per Second: 10006.73624

Timestep Collection Time: 4.07344
Timestep Consumption Time: 0.92479
PPO Batch Consumption Time: 0.06265
Total Iteration Time: 4.99823

Cumulative Model Updates: 4854
Cumulative Timesteps: 81038172

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 81038172...
Checkpoint 81038172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09028
Policy Entropy: 1.08290
Value Function Loss: 0.10709

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07016
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.12731

Collected Steps per Second: 11396.94066
Overall Steps per Second: 9286.70645

Timestep Collection Time: 4.38960
Timestep Consumption Time: 0.99746
PPO Batch Consumption Time: 0.09256
Total Iteration Time: 5.38706

Cumulative Model Updates: 4857
Cumulative Timesteps: 81088200

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06728
Policy Entropy: 1.09105
Value Function Loss: 0.09664

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06307
Policy Update Magnitude: 0.06545
Value Function Update Magnitude: 0.12818

Collected Steps per Second: 13377.86262
Overall Steps per Second: 10772.70755

Timestep Collection Time: 3.74051
Timestep Consumption Time: 0.90456
PPO Batch Consumption Time: 0.06292
Total Iteration Time: 4.64507

Cumulative Model Updates: 4860
Cumulative Timesteps: 81138240

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 81138240...
Checkpoint 81138240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08663
Policy Entropy: 1.08790
Value Function Loss: 0.12060

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06353
Policy Update Magnitude: 0.06262
Value Function Update Magnitude: 0.11553

Collected Steps per Second: 11845.69239
Overall Steps per Second: 9427.39129

Timestep Collection Time: 4.22246
Timestep Consumption Time: 1.08314
PPO Batch Consumption Time: 0.11134
Total Iteration Time: 5.30560

Cumulative Model Updates: 4863
Cumulative Timesteps: 81188258

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02769
Policy Entropy: 1.07618
Value Function Loss: 0.15490

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05295
Policy Update Magnitude: 0.06229
Value Function Update Magnitude: 0.11906

Collected Steps per Second: 12999.97445
Overall Steps per Second: 10732.78077

Timestep Collection Time: 3.84724
Timestep Consumption Time: 0.81269
PPO Batch Consumption Time: 0.06321
Total Iteration Time: 4.65993

Cumulative Model Updates: 4866
Cumulative Timesteps: 81238272

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 81238272...
Checkpoint 81238272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02555
Policy Entropy: 1.06447
Value Function Loss: 0.16489

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06734
Policy Update Magnitude: 0.07140
Value Function Update Magnitude: 0.10379

Collected Steps per Second: 11480.91766
Overall Steps per Second: 9349.63257

Timestep Collection Time: 4.35749
Timestep Consumption Time: 0.99331
PPO Batch Consumption Time: 0.08027
Total Iteration Time: 5.35080

Cumulative Model Updates: 4869
Cumulative Timesteps: 81288300

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16729
Policy Entropy: 1.06975
Value Function Loss: 0.18455

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.07726
Value Function Update Magnitude: 0.10423

Collected Steps per Second: 12567.62721
Overall Steps per Second: 10059.63921

Timestep Collection Time: 3.98039
Timestep Consumption Time: 0.99236
PPO Batch Consumption Time: 0.08703
Total Iteration Time: 4.97274

Cumulative Model Updates: 4872
Cumulative Timesteps: 81338324

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 81338324...
Checkpoint 81338324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05650
Policy Entropy: 1.06768
Value Function Loss: 0.18269

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.07610
Value Function Update Magnitude: 0.10657

Collected Steps per Second: 13046.88629
Overall Steps per Second: 10536.50018

Timestep Collection Time: 3.83540
Timestep Consumption Time: 0.91381
PPO Batch Consumption Time: 0.06535
Total Iteration Time: 4.74921

Cumulative Model Updates: 4875
Cumulative Timesteps: 81388364

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00522
Policy Entropy: 1.06221
Value Function Loss: 0.17574

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.07870
Value Function Update Magnitude: 0.10323

Collected Steps per Second: 11807.11930
Overall Steps per Second: 9540.30081

Timestep Collection Time: 4.23507
Timestep Consumption Time: 1.00627
PPO Batch Consumption Time: 0.08587
Total Iteration Time: 5.24134

Cumulative Model Updates: 4878
Cumulative Timesteps: 81438368

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 81438368...
Checkpoint 81438368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13341
Policy Entropy: 1.05559
Value Function Loss: 0.17537

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.08354
Value Function Update Magnitude: 0.09594

Collected Steps per Second: 12877.37208
Overall Steps per Second: 10446.13722

Timestep Collection Time: 3.88325
Timestep Consumption Time: 0.90379
PPO Batch Consumption Time: 0.07757
Total Iteration Time: 4.78703

Cumulative Model Updates: 4881
Cumulative Timesteps: 81488374

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01318
Policy Entropy: 1.04638
Value Function Loss: 0.15032

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.08059
Value Function Update Magnitude: 0.09026

Collected Steps per Second: 13013.76174
Overall Steps per Second: 10438.35772

Timestep Collection Time: 3.84485
Timestep Consumption Time: 0.94862
PPO Batch Consumption Time: 0.06836
Total Iteration Time: 4.79347

Cumulative Model Updates: 4884
Cumulative Timesteps: 81538410

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 81538410...
Checkpoint 81538410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.23254
Policy Entropy: 1.06864
Value Function Loss: 0.14279

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.07386
Value Function Update Magnitude: 0.07525

Collected Steps per Second: 12151.45333
Overall Steps per Second: 9666.47449

Timestep Collection Time: 4.11556
Timestep Consumption Time: 1.05799
PPO Batch Consumption Time: 0.09438
Total Iteration Time: 5.17355

Cumulative Model Updates: 4887
Cumulative Timesteps: 81588420

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09111
Policy Entropy: 1.05127
Value Function Loss: 0.11354

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.07030
Value Function Update Magnitude: 0.07081

Collected Steps per Second: 12959.57266
Overall Steps per Second: 10453.53424

Timestep Collection Time: 3.86108
Timestep Consumption Time: 0.92562
PPO Batch Consumption Time: 0.06095
Total Iteration Time: 4.78671

Cumulative Model Updates: 4890
Cumulative Timesteps: 81638458

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 81638458...
Checkpoint 81638458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01351
Policy Entropy: 1.05937
Value Function Loss: 0.10630

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.06371

Collected Steps per Second: 11596.00642
Overall Steps per Second: 9294.35346

Timestep Collection Time: 4.31355
Timestep Consumption Time: 1.06821
PPO Batch Consumption Time: 0.10766
Total Iteration Time: 5.38176

Cumulative Model Updates: 4893
Cumulative Timesteps: 81688478

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00179
Policy Entropy: 1.05853
Value Function Loss: 0.09419

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.06701
Value Function Update Magnitude: 0.06018

Collected Steps per Second: 12847.62766
Overall Steps per Second: 10610.67654

Timestep Collection Time: 3.89255
Timestep Consumption Time: 0.82063
PPO Batch Consumption Time: 0.06268
Total Iteration Time: 4.71318

Cumulative Model Updates: 4896
Cumulative Timesteps: 81738488

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 81738488...
Checkpoint 81738488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01640
Policy Entropy: 1.07251
Value Function Loss: 0.11579

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.05630

Collected Steps per Second: 11216.14571
Overall Steps per Second: 9132.35302

Timestep Collection Time: 4.45875
Timestep Consumption Time: 1.01738
PPO Batch Consumption Time: 0.08803
Total Iteration Time: 5.47614

Cumulative Model Updates: 4899
Cumulative Timesteps: 81788498

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09947
Policy Entropy: 1.07849
Value Function Loss: 0.12562

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 12151.35956
Overall Steps per Second: 9937.50529

Timestep Collection Time: 4.11789
Timestep Consumption Time: 0.91737
PPO Batch Consumption Time: 0.06623
Total Iteration Time: 5.03527

Cumulative Model Updates: 4902
Cumulative Timesteps: 81838536

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 81838536...
Checkpoint 81838536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11190
Policy Entropy: 1.06707
Value Function Loss: 0.12635

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.06092

Collected Steps per Second: 10976.32554
Overall Steps per Second: 9024.68676

Timestep Collection Time: 4.55617
Timestep Consumption Time: 0.98530
PPO Batch Consumption Time: 0.07190
Total Iteration Time: 5.54147

Cumulative Model Updates: 4905
Cumulative Timesteps: 81888546

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00041
Policy Entropy: 1.05754
Value Function Loss: 0.11326

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 12195.10352
Overall Steps per Second: 9843.56896

Timestep Collection Time: 4.10312
Timestep Consumption Time: 0.98020
PPO Batch Consumption Time: 0.06819
Total Iteration Time: 5.08332

Cumulative Model Updates: 4908
Cumulative Timesteps: 81938584

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 81938584...
Checkpoint 81938584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02928
Policy Entropy: 1.06550
Value Function Loss: 0.11747

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.06421
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 11988.10936
Overall Steps per Second: 9489.14858

Timestep Collection Time: 4.17080
Timestep Consumption Time: 1.09838
PPO Batch Consumption Time: 0.12336
Total Iteration Time: 5.26918

Cumulative Model Updates: 4911
Cumulative Timesteps: 81988584

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02031
Policy Entropy: 1.06410
Value Function Loss: 0.13304

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.09090

Collected Steps per Second: 12829.20163
Overall Steps per Second: 10399.63958

Timestep Collection Time: 3.90141
Timestep Consumption Time: 0.91145
PPO Batch Consumption Time: 0.06279
Total Iteration Time: 4.81286

Cumulative Model Updates: 4914
Cumulative Timesteps: 82038636

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 82038636...
Checkpoint 82038636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10390
Policy Entropy: 1.08726
Value Function Loss: 0.14471

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.09885

Collected Steps per Second: 11748.39185
Overall Steps per Second: 9322.04874

Timestep Collection Time: 4.25743
Timestep Consumption Time: 1.10812
PPO Batch Consumption Time: 0.11699
Total Iteration Time: 5.36556

Cumulative Model Updates: 4917
Cumulative Timesteps: 82088654

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15770
Policy Entropy: 1.07324
Value Function Loss: 0.12334

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.06944
Value Function Update Magnitude: 0.08531

Collected Steps per Second: 11837.80518
Overall Steps per Second: 9904.55845

Timestep Collection Time: 4.22781
Timestep Consumption Time: 0.82522
PPO Batch Consumption Time: 0.06633
Total Iteration Time: 5.05303

Cumulative Model Updates: 4920
Cumulative Timesteps: 82138702

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 82138702...
Checkpoint 82138702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07993
Policy Entropy: 1.07611
Value Function Loss: 0.12866

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.06673
Value Function Update Magnitude: 0.07931

Collected Steps per Second: 11161.95686
Overall Steps per Second: 9025.09851

Timestep Collection Time: 4.48076
Timestep Consumption Time: 1.06090
PPO Batch Consumption Time: 0.07861
Total Iteration Time: 5.54166

Cumulative Model Updates: 4923
Cumulative Timesteps: 82188716

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05306
Policy Entropy: 1.06967
Value Function Loss: 0.12413

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06630
Policy Update Magnitude: 0.06698
Value Function Update Magnitude: 0.07516

Collected Steps per Second: 12427.44929
Overall Steps per Second: 10119.49884

Timestep Collection Time: 4.02544
Timestep Consumption Time: 0.91808
PPO Batch Consumption Time: 0.06681
Total Iteration Time: 4.94353

Cumulative Model Updates: 4926
Cumulative Timesteps: 82238742

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 82238742...
Checkpoint 82238742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10457
Policy Entropy: 1.06526
Value Function Loss: 0.14659

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06431
Policy Update Magnitude: 0.06798
Value Function Update Magnitude: 0.08238

Collected Steps per Second: 11796.02458
Overall Steps per Second: 9544.49251

Timestep Collection Time: 4.24024
Timestep Consumption Time: 1.00027
PPO Batch Consumption Time: 0.07835
Total Iteration Time: 5.24051

Cumulative Model Updates: 4929
Cumulative Timesteps: 82288760

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.23094
Policy Entropy: 1.06555
Value Function Loss: 0.13885

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07043
Policy Update Magnitude: 0.06971
Value Function Update Magnitude: 0.07802

Collected Steps per Second: 11962.42123
Overall Steps per Second: 9728.85754

Timestep Collection Time: 4.18360
Timestep Consumption Time: 0.96048
PPO Batch Consumption Time: 0.06535
Total Iteration Time: 5.14408

Cumulative Model Updates: 4932
Cumulative Timesteps: 82338806

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 82338806...
Checkpoint 82338806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14357
Policy Entropy: 1.06185
Value Function Loss: 0.13000

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.06568
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 11932.22303
Overall Steps per Second: 9588.94147

Timestep Collection Time: 4.19167
Timestep Consumption Time: 1.02433
PPO Batch Consumption Time: 0.11499
Total Iteration Time: 5.21601

Cumulative Model Updates: 4935
Cumulative Timesteps: 82388822

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07072
Policy Entropy: 1.07143
Value Function Loss: 0.12285

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05681
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.06514

Collected Steps per Second: 12021.59805
Overall Steps per Second: 9853.73697

Timestep Collection Time: 4.15951
Timestep Consumption Time: 0.91511
PPO Batch Consumption Time: 0.06345
Total Iteration Time: 5.07462

Cumulative Model Updates: 4938
Cumulative Timesteps: 82438826

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 82438826...
Checkpoint 82438826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07796
Policy Entropy: 1.05632
Value Function Loss: 0.11465

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 11378.65987
Overall Steps per Second: 9105.74404

Timestep Collection Time: 4.39630
Timestep Consumption Time: 1.09738
PPO Batch Consumption Time: 0.11570
Total Iteration Time: 5.49368

Cumulative Model Updates: 4941
Cumulative Timesteps: 82488850

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00240
Policy Entropy: 1.05998
Value Function Loss: 0.15540

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05407
Policy Update Magnitude: 0.06691
Value Function Update Magnitude: 0.06399

Collected Steps per Second: 12484.14596
Overall Steps per Second: 10143.51512

Timestep Collection Time: 4.00652
Timestep Consumption Time: 0.92451
PPO Batch Consumption Time: 0.06771
Total Iteration Time: 4.93103

Cumulative Model Updates: 4944
Cumulative Timesteps: 82538868

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 82538868...
Checkpoint 82538868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13817
Policy Entropy: 1.05387
Value Function Loss: 0.15399

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.06907
Value Function Update Magnitude: 0.05427

Collected Steps per Second: 12485.37910
Overall Steps per Second: 9899.13743

Timestep Collection Time: 4.00565
Timestep Consumption Time: 1.04651
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 5.05216

Cumulative Model Updates: 4947
Cumulative Timesteps: 82588880

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09906
Policy Entropy: 1.06843
Value Function Loss: 0.16797

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06631
Policy Update Magnitude: 0.06747
Value Function Update Magnitude: 0.05080

Collected Steps per Second: 12835.11206
Overall Steps per Second: 10410.19359

Timestep Collection Time: 3.89743
Timestep Consumption Time: 0.90786
PPO Batch Consumption Time: 0.08019
Total Iteration Time: 4.80529

Cumulative Model Updates: 4950
Cumulative Timesteps: 82638904

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 82638904...
Checkpoint 82638904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11618
Policy Entropy: 1.05497
Value Function Loss: 0.14121

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07016
Policy Update Magnitude: 0.07041
Value Function Update Magnitude: 0.05294

Collected Steps per Second: 13052.89428
Overall Steps per Second: 10064.16935

Timestep Collection Time: 3.83363
Timestep Consumption Time: 1.13846
PPO Batch Consumption Time: 0.13083
Total Iteration Time: 4.97209

Cumulative Model Updates: 4953
Cumulative Timesteps: 82688944

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02050
Policy Entropy: 1.05570
Value Function Loss: 0.14337

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.05477

Collected Steps per Second: 12925.47735
Overall Steps per Second: 10519.33521

Timestep Collection Time: 3.86972
Timestep Consumption Time: 0.88514
PPO Batch Consumption Time: 0.07120
Total Iteration Time: 4.75486

Cumulative Model Updates: 4956
Cumulative Timesteps: 82738962

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 82738962...
Checkpoint 82738962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10713
Policy Entropy: 1.03672
Value Function Loss: 0.14118

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.05322

Collected Steps per Second: 13178.75201
Overall Steps per Second: 10350.11932

Timestep Collection Time: 3.79824
Timestep Consumption Time: 1.03804
PPO Batch Consumption Time: 0.08122
Total Iteration Time: 4.83627

Cumulative Model Updates: 4959
Cumulative Timesteps: 82789018

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08791
Policy Entropy: 1.05779
Value Function Loss: 0.15628

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.07148
Policy Update Magnitude: 0.06751
Value Function Update Magnitude: 0.04978

Collected Steps per Second: 12962.90581
Overall Steps per Second: 10526.75210

Timestep Collection Time: 3.85793
Timestep Consumption Time: 0.89282
PPO Batch Consumption Time: 0.06255
Total Iteration Time: 4.75075

Cumulative Model Updates: 4962
Cumulative Timesteps: 82839028

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 82839028...
Checkpoint 82839028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01894
Policy Entropy: 1.05482
Value Function Loss: 0.14421

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.06312
Value Function Update Magnitude: 0.05073

Collected Steps per Second: 12619.37711
Overall Steps per Second: 9950.88940

Timestep Collection Time: 3.96517
Timestep Consumption Time: 1.06332
PPO Batch Consumption Time: 0.10230
Total Iteration Time: 5.02850

Cumulative Model Updates: 4965
Cumulative Timesteps: 82889066

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11296
Policy Entropy: 1.06874
Value Function Loss: 0.13329

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05209
Policy Update Magnitude: 0.06722
Value Function Update Magnitude: 0.05043

Collected Steps per Second: 12371.14804
Overall Steps per Second: 10068.35792

Timestep Collection Time: 4.04425
Timestep Consumption Time: 0.92498
PPO Batch Consumption Time: 0.06537
Total Iteration Time: 4.96923

Cumulative Model Updates: 4968
Cumulative Timesteps: 82939098

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 82939098...
Checkpoint 82939098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17086
Policy Entropy: 1.05943
Value Function Loss: 0.12315

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.04413

Collected Steps per Second: 11974.49777
Overall Steps per Second: 9582.45463

Timestep Collection Time: 4.17571
Timestep Consumption Time: 1.04237
PPO Batch Consumption Time: 0.09960
Total Iteration Time: 5.21808

Cumulative Model Updates: 4971
Cumulative Timesteps: 82989100

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06683
Policy Entropy: 1.06130
Value Function Loss: 0.12489

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05842
Policy Update Magnitude: 0.06743
Value Function Update Magnitude: 0.04296

Collected Steps per Second: 13070.38020
Overall Steps per Second: 10758.94270

Timestep Collection Time: 3.82713
Timestep Consumption Time: 0.82221
PPO Batch Consumption Time: 0.06442
Total Iteration Time: 4.64934

Cumulative Model Updates: 4974
Cumulative Timesteps: 83039122

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 83039122...
Checkpoint 83039122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04813
Policy Entropy: 1.06157
Value Function Loss: 0.12995

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.06594
Value Function Update Magnitude: 0.03954

Collected Steps per Second: 12088.10920
Overall Steps per Second: 9755.16887

Timestep Collection Time: 4.13861
Timestep Consumption Time: 0.98975
PPO Batch Consumption Time: 0.07899
Total Iteration Time: 5.12836

Cumulative Model Updates: 4977
Cumulative Timesteps: 83089150

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12923
Policy Entropy: 1.06793
Value Function Loss: 0.12375

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.06152
Value Function Update Magnitude: 0.05054

Collected Steps per Second: 12908.50827
Overall Steps per Second: 10056.92073

Timestep Collection Time: 3.87527
Timestep Consumption Time: 1.09881
PPO Batch Consumption Time: 0.12112
Total Iteration Time: 4.97409

Cumulative Model Updates: 4980
Cumulative Timesteps: 83139174

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 83139174...
Checkpoint 83139174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08734
Policy Entropy: 1.05841
Value Function Loss: 0.11432

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.06894
Value Function Update Magnitude: 0.04686

Collected Steps per Second: 13197.74392
Overall Steps per Second: 10613.39706

Timestep Collection Time: 3.79019
Timestep Consumption Time: 0.92291
PPO Batch Consumption Time: 0.06614
Total Iteration Time: 4.71310

Cumulative Model Updates: 4983
Cumulative Timesteps: 83189196

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08609
Policy Entropy: 1.05777
Value Function Loss: 0.10870

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.06524
Value Function Update Magnitude: 0.04240

Collected Steps per Second: 12602.25425
Overall Steps per Second: 9881.20933

Timestep Collection Time: 3.96992
Timestep Consumption Time: 1.09322
PPO Batch Consumption Time: 0.11622
Total Iteration Time: 5.06315

Cumulative Model Updates: 4986
Cumulative Timesteps: 83239226

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 83239226...
Checkpoint 83239226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14072
Policy Entropy: 1.06275
Value Function Loss: 0.11498

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.06556
Value Function Update Magnitude: 0.05136

Collected Steps per Second: 12954.47237
Overall Steps per Second: 10633.20380

Timestep Collection Time: 3.86121
Timestep Consumption Time: 0.84292
PPO Batch Consumption Time: 0.06845
Total Iteration Time: 4.70413

Cumulative Model Updates: 4989
Cumulative Timesteps: 83289246

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06494
Policy Entropy: 1.06719
Value Function Loss: 0.11215

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.05218

Collected Steps per Second: 13070.29820
Overall Steps per Second: 10217.21919

Timestep Collection Time: 3.82562
Timestep Consumption Time: 1.06827
PPO Batch Consumption Time: 0.11106
Total Iteration Time: 4.89390

Cumulative Model Updates: 4992
Cumulative Timesteps: 83339248

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 83339248...
Checkpoint 83339248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15796
Policy Entropy: 1.05776
Value Function Loss: 0.13053

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.05830
Value Function Update Magnitude: 0.05954

Collected Steps per Second: 12956.38024
Overall Steps per Second: 10559.00298

Timestep Collection Time: 3.86018
Timestep Consumption Time: 0.87644
PPO Batch Consumption Time: 0.06159
Total Iteration Time: 4.73662

Cumulative Model Updates: 4995
Cumulative Timesteps: 83389262

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08018
Policy Entropy: 1.06322
Value Function Loss: 0.14771

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08402
Policy Update Magnitude: 0.05664
Value Function Update Magnitude: 0.06876

Collected Steps per Second: 12255.71432
Overall Steps per Second: 9924.38567

Timestep Collection Time: 4.08136
Timestep Consumption Time: 0.95875
PPO Batch Consumption Time: 0.07445
Total Iteration Time: 5.04011

Cumulative Model Updates: 4998
Cumulative Timesteps: 83439282

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 83439282...
Checkpoint 83439282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11583
Policy Entropy: 1.04786
Value Function Loss: 0.15528

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 13124.85391
Overall Steps per Second: 10452.79208

Timestep Collection Time: 3.81079
Timestep Consumption Time: 0.97416
PPO Batch Consumption Time: 0.07592
Total Iteration Time: 4.78494

Cumulative Model Updates: 5001
Cumulative Timesteps: 83489298

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15507
Policy Entropy: 1.05758
Value Function Loss: 0.14723

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.06101
Value Function Update Magnitude: 0.06292

Collected Steps per Second: 13236.81927
Overall Steps per Second: 10462.53463

Timestep Collection Time: 3.78097
Timestep Consumption Time: 1.00258
PPO Batch Consumption Time: 0.09720
Total Iteration Time: 4.78354

Cumulative Model Updates: 5004
Cumulative Timesteps: 83539346

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 83539346...
Checkpoint 83539346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17496
Policy Entropy: 1.05244
Value Function Loss: 0.12668

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.06535

Collected Steps per Second: 13354.92419
Overall Steps per Second: 10461.43336

Timestep Collection Time: 3.74514
Timestep Consumption Time: 1.03585
PPO Batch Consumption Time: 0.10010
Total Iteration Time: 4.78099

Cumulative Model Updates: 5007
Cumulative Timesteps: 83589362

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07525
Policy Entropy: 1.07770
Value Function Loss: 0.12957

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.14702
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.07478

Collected Steps per Second: 12977.01922
Overall Steps per Second: 10341.35894

Timestep Collection Time: 3.85512
Timestep Consumption Time: 0.98254
PPO Batch Consumption Time: 0.08418
Total Iteration Time: 4.83766

Cumulative Model Updates: 5010
Cumulative Timesteps: 83639390

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 83639390...
Checkpoint 83639390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10079
Policy Entropy: 1.06800
Value Function Loss: 0.12923

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.16867
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.07353

Collected Steps per Second: 13234.56107
Overall Steps per Second: 10867.70238

Timestep Collection Time: 3.78025
Timestep Consumption Time: 0.82330
PPO Batch Consumption Time: 0.06085
Total Iteration Time: 4.60355

Cumulative Model Updates: 5013
Cumulative Timesteps: 83689420

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02978
Policy Entropy: 1.05546
Value Function Loss: 0.14564

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.07195

Collected Steps per Second: 11546.83154
Overall Steps per Second: 9314.18611

Timestep Collection Time: 4.33192
Timestep Consumption Time: 1.03838
PPO Batch Consumption Time: 0.09975
Total Iteration Time: 5.37030

Cumulative Model Updates: 5016
Cumulative Timesteps: 83739440

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 83739440...
Checkpoint 83739440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07413
Policy Entropy: 1.06312
Value Function Loss: 0.13354

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.06210
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 13092.23334
Overall Steps per Second: 10660.44109

Timestep Collection Time: 3.81982
Timestep Consumption Time: 0.87135
PPO Batch Consumption Time: 0.06336
Total Iteration Time: 4.69118

Cumulative Model Updates: 5019
Cumulative Timesteps: 83789450

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03408
Policy Entropy: 1.06760
Value Function Loss: 0.11430

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.06559
Value Function Update Magnitude: 0.08515

Collected Steps per Second: 12722.86884
Overall Steps per Second: 9919.75228

Timestep Collection Time: 3.93166
Timestep Consumption Time: 1.11101
PPO Batch Consumption Time: 0.12156
Total Iteration Time: 5.04267

Cumulative Model Updates: 5022
Cumulative Timesteps: 83839472

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 83839472...
Checkpoint 83839472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11917
Policy Entropy: 1.04964
Value Function Loss: 0.10742

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08584
Policy Update Magnitude: 0.06720
Value Function Update Magnitude: 0.07377

Collected Steps per Second: 13026.94813
Overall Steps per Second: 10425.42171

Timestep Collection Time: 3.84142
Timestep Consumption Time: 0.95858
PPO Batch Consumption Time: 0.07700
Total Iteration Time: 4.80000

Cumulative Model Updates: 5025
Cumulative Timesteps: 83889514

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13459
Policy Entropy: 1.05519
Value Function Loss: 0.10482

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.06324

Collected Steps per Second: 12819.71864
Overall Steps per Second: 10435.66112

Timestep Collection Time: 3.90383
Timestep Consumption Time: 0.89184
PPO Batch Consumption Time: 0.07592
Total Iteration Time: 4.79567

Cumulative Model Updates: 5028
Cumulative Timesteps: 83939560

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 83939560...
Checkpoint 83939560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18440
Policy Entropy: 1.06173
Value Function Loss: 0.11700

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.06931
Value Function Update Magnitude: 0.07524

Collected Steps per Second: 13196.89157
Overall Steps per Second: 10466.78802

Timestep Collection Time: 3.78923
Timestep Consumption Time: 0.98836
PPO Batch Consumption Time: 0.08347
Total Iteration Time: 4.77759

Cumulative Model Updates: 5031
Cumulative Timesteps: 83989566

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00768
Policy Entropy: 1.07042
Value Function Loss: 0.11879

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.06406
Value Function Update Magnitude: 0.06950

Collected Steps per Second: 13203.57440
Overall Steps per Second: 10401.32746

Timestep Collection Time: 3.78746
Timestep Consumption Time: 1.02039
PPO Batch Consumption Time: 0.10379
Total Iteration Time: 4.80785

Cumulative Model Updates: 5034
Cumulative Timesteps: 84039574

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 84039574...
Checkpoint 84039574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05962
Policy Entropy: 1.06261
Value Function Loss: 0.10954

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.06515
Value Function Update Magnitude: 0.07239

Collected Steps per Second: 13093.56106
Overall Steps per Second: 10465.39346

Timestep Collection Time: 3.82264
Timestep Consumption Time: 0.95998
PPO Batch Consumption Time: 0.07316
Total Iteration Time: 4.78262

Cumulative Model Updates: 5037
Cumulative Timesteps: 84089626

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06674
Policy Entropy: 1.06171
Value Function Loss: 0.13460

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.06563
Value Function Update Magnitude: 0.07682

Collected Steps per Second: 13118.25181
Overall Steps per Second: 10451.61488

Timestep Collection Time: 3.81209
Timestep Consumption Time: 0.97262
PPO Batch Consumption Time: 0.07725
Total Iteration Time: 4.78472

Cumulative Model Updates: 5040
Cumulative Timesteps: 84139634

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 84139634...
Checkpoint 84139634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19558
Policy Entropy: 1.07106
Value Function Loss: 0.13584

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.07015
Value Function Update Magnitude: 0.07478

Collected Steps per Second: 12977.40732
Overall Steps per Second: 10470.39284

Timestep Collection Time: 3.85316
Timestep Consumption Time: 0.92259
PPO Batch Consumption Time: 0.09245
Total Iteration Time: 4.77575

Cumulative Model Updates: 5043
Cumulative Timesteps: 84189638

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20025
Policy Entropy: 1.06830
Value Function Loss: 0.16259

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.06671
Value Function Update Magnitude: 0.08750

Collected Steps per Second: 12987.25315
Overall Steps per Second: 10417.08875

Timestep Collection Time: 3.85316
Timestep Consumption Time: 0.95067
PPO Batch Consumption Time: 0.06774
Total Iteration Time: 4.80384

Cumulative Model Updates: 5046
Cumulative Timesteps: 84239680

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 84239680...
Checkpoint 84239680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07808
Policy Entropy: 1.07222
Value Function Loss: 0.15182

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.07759

Collected Steps per Second: 13059.84266
Overall Steps per Second: 10440.48405

Timestep Collection Time: 3.82914
Timestep Consumption Time: 0.96067
PPO Batch Consumption Time: 0.07541
Total Iteration Time: 4.78982

Cumulative Model Updates: 5049
Cumulative Timesteps: 84289688

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01644
Policy Entropy: 1.06693
Value Function Loss: 0.15588

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.06656
Value Function Update Magnitude: 0.07256

Collected Steps per Second: 13733.84822
Overall Steps per Second: 10892.17841

Timestep Collection Time: 3.64079
Timestep Consumption Time: 0.94985
PPO Batch Consumption Time: 0.07241
Total Iteration Time: 4.59063

Cumulative Model Updates: 5052
Cumulative Timesteps: 84339690

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 84339690...
Checkpoint 84339690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06218
Policy Entropy: 1.08178
Value Function Loss: 0.13607

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.06222
Value Function Update Magnitude: 0.07167

Collected Steps per Second: 13271.12618
Overall Steps per Second: 10774.94854

Timestep Collection Time: 3.76833
Timestep Consumption Time: 0.87299
PPO Batch Consumption Time: 0.06212
Total Iteration Time: 4.64132

Cumulative Model Updates: 5055
Cumulative Timesteps: 84389700

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04114
Policy Entropy: 1.08346
Value Function Loss: 0.12608

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06352
Policy Update Magnitude: 0.06431
Value Function Update Magnitude: 0.07981

Collected Steps per Second: 11947.56212
Overall Steps per Second: 9742.01098

Timestep Collection Time: 4.18730
Timestep Consumption Time: 0.94799
PPO Batch Consumption Time: 0.10006
Total Iteration Time: 5.13528

Cumulative Model Updates: 5058
Cumulative Timesteps: 84439728

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 84439728...
Checkpoint 84439728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.21595
Policy Entropy: 1.07727
Value Function Loss: 0.11527

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.06170
Value Function Update Magnitude: 0.09337

Collected Steps per Second: 13269.19210
Overall Steps per Second: 10462.26825

Timestep Collection Time: 3.77009
Timestep Consumption Time: 1.01148
PPO Batch Consumption Time: 0.07292
Total Iteration Time: 4.78156

Cumulative Model Updates: 5061
Cumulative Timesteps: 84489754

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06580
Policy Entropy: 1.06858
Value Function Loss: 0.12907

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.06071
Value Function Update Magnitude: 0.08385

Collected Steps per Second: 12506.63208
Overall Steps per Second: 10040.64538

Timestep Collection Time: 3.99996
Timestep Consumption Time: 0.98239
PPO Batch Consumption Time: 0.08254
Total Iteration Time: 4.98235

Cumulative Model Updates: 5064
Cumulative Timesteps: 84539780

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 84539780...
Checkpoint 84539780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11750
Policy Entropy: 1.06737
Value Function Loss: 0.12912

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.07587

Collected Steps per Second: 13259.54256
Overall Steps per Second: 10412.89845

Timestep Collection Time: 3.77087
Timestep Consumption Time: 1.03087
PPO Batch Consumption Time: 0.06572
Total Iteration Time: 4.80174

Cumulative Model Updates: 5067
Cumulative Timesteps: 84589780

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13155
Policy Entropy: 1.06521
Value Function Loss: 0.14367

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.05953
Policy Update Magnitude: 0.06453
Value Function Update Magnitude: 0.06581

Collected Steps per Second: 11438.41831
Overall Steps per Second: 9275.59554

Timestep Collection Time: 4.37368
Timestep Consumption Time: 1.01983
PPO Batch Consumption Time: 0.07725
Total Iteration Time: 5.39351

Cumulative Model Updates: 5070
Cumulative Timesteps: 84639808

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 84639808...
Checkpoint 84639808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06403
Policy Entropy: 1.07847
Value Function Loss: 0.14490

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.06762
Value Function Update Magnitude: 0.06346

Collected Steps per Second: 11900.45536
Overall Steps per Second: 9809.87311

Timestep Collection Time: 4.20202
Timestep Consumption Time: 0.89549
PPO Batch Consumption Time: 0.07234
Total Iteration Time: 5.09752

Cumulative Model Updates: 5073
Cumulative Timesteps: 84689814

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02518
Policy Entropy: 1.08025
Value Function Loss: 0.14454

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.07135
Value Function Update Magnitude: 0.06289

Collected Steps per Second: 12198.39486
Overall Steps per Second: 9860.11248

Timestep Collection Time: 4.09972
Timestep Consumption Time: 0.97223
PPO Batch Consumption Time: 0.07736
Total Iteration Time: 5.07195

Cumulative Model Updates: 5076
Cumulative Timesteps: 84739824

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 84739824...
Checkpoint 84739824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00555
Policy Entropy: 1.07994
Value Function Loss: 0.13215

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07300
Policy Update Magnitude: 0.06798
Value Function Update Magnitude: 0.06839

Collected Steps per Second: 13135.05655
Overall Steps per Second: 10643.89882

Timestep Collection Time: 3.80691
Timestep Consumption Time: 0.89099
PPO Batch Consumption Time: 0.06716
Total Iteration Time: 4.69790

Cumulative Model Updates: 5079
Cumulative Timesteps: 84789828

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01741
Policy Entropy: 1.06912
Value Function Loss: 0.12995

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.06739
Value Function Update Magnitude: 0.07607

Collected Steps per Second: 11054.75337
Overall Steps per Second: 8797.85530

Timestep Collection Time: 4.52566
Timestep Consumption Time: 1.16096
PPO Batch Consumption Time: 0.07281
Total Iteration Time: 5.68661

Cumulative Model Updates: 5082
Cumulative Timesteps: 84839858

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 84839858...
Checkpoint 84839858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07965
Policy Entropy: 1.07737
Value Function Loss: 0.11738

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.06449
Value Function Update Magnitude: 0.07461

Collected Steps per Second: 11248.65334
Overall Steps per Second: 8967.94685

Timestep Collection Time: 4.44747
Timestep Consumption Time: 1.13107
PPO Batch Consumption Time: 0.07996
Total Iteration Time: 5.57853

Cumulative Model Updates: 5085
Cumulative Timesteps: 84889886

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13910
Policy Entropy: 1.07987
Value Function Loss: 0.11113

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.07327

Collected Steps per Second: 10933.37913
Overall Steps per Second: 8972.99492

Timestep Collection Time: 4.57315
Timestep Consumption Time: 0.99912
PPO Batch Consumption Time: 0.08835
Total Iteration Time: 5.57228

Cumulative Model Updates: 5088
Cumulative Timesteps: 84939886

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 84939886...
Checkpoint 84939886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05135
Policy Entropy: 1.09222
Value Function Loss: 0.09862

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.06631

Collected Steps per Second: 11396.44822
Overall Steps per Second: 9190.03411

Timestep Collection Time: 4.38926
Timestep Consumption Time: 1.05381
PPO Batch Consumption Time: 0.07405
Total Iteration Time: 5.44307

Cumulative Model Updates: 5091
Cumulative Timesteps: 84989908

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01974
Policy Entropy: 1.09721
Value Function Loss: 0.09808

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06223
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.06386

Collected Steps per Second: 10525.84769
Overall Steps per Second: 8167.32579

Timestep Collection Time: 4.75306
Timestep Consumption Time: 1.37257
PPO Batch Consumption Time: 0.11709
Total Iteration Time: 6.12563

Cumulative Model Updates: 5094
Cumulative Timesteps: 85039938

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 85039938...
Checkpoint 85039938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03335
Policy Entropy: 1.09067
Value Function Loss: 0.09189

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 12006.08289
Overall Steps per Second: 9632.88814

Timestep Collection Time: 4.16622
Timestep Consumption Time: 1.02641
PPO Batch Consumption Time: 0.06264
Total Iteration Time: 5.19263

Cumulative Model Updates: 5097
Cumulative Timesteps: 85089958

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03287
Policy Entropy: 1.09433
Value Function Loss: 0.09954

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.07224

Collected Steps per Second: 10474.10594
Overall Steps per Second: 8364.53372

Timestep Collection Time: 4.77540
Timestep Consumption Time: 1.20438
PPO Batch Consumption Time: 0.11846
Total Iteration Time: 5.97977

Cumulative Model Updates: 5100
Cumulative Timesteps: 85139976

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 85139976...
Checkpoint 85139976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08745
Policy Entropy: 1.10216
Value Function Loss: 0.11119

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.07722

Collected Steps per Second: 11536.90243
Overall Steps per Second: 9317.36099

Timestep Collection Time: 4.33427
Timestep Consumption Time: 1.03249
PPO Batch Consumption Time: 0.07182
Total Iteration Time: 5.36676

Cumulative Model Updates: 5103
Cumulative Timesteps: 85189980

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10870
Policy Entropy: 1.09657
Value Function Loss: 0.12095

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.07367

Collected Steps per Second: 11470.44055
Overall Steps per Second: 9193.27513

Timestep Collection Time: 4.36199
Timestep Consumption Time: 1.08046
PPO Batch Consumption Time: 0.07644
Total Iteration Time: 5.44246

Cumulative Model Updates: 5106
Cumulative Timesteps: 85240014

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 85240014...
Checkpoint 85240014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04688
Policy Entropy: 1.09543
Value Function Loss: 0.11810

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.07206

Collected Steps per Second: 11688.83232
Overall Steps per Second: 9570.11705

Timestep Collection Time: 4.27776
Timestep Consumption Time: 0.94705
PPO Batch Consumption Time: 0.07214
Total Iteration Time: 5.22481

Cumulative Model Updates: 5109
Cumulative Timesteps: 85290016

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02785
Policy Entropy: 1.09442
Value Function Loss: 0.10546

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.07617

Collected Steps per Second: 10570.44122
Overall Steps per Second: 8694.61417

Timestep Collection Time: 4.73131
Timestep Consumption Time: 1.02076
PPO Batch Consumption Time: 0.06982
Total Iteration Time: 5.75207

Cumulative Model Updates: 5112
Cumulative Timesteps: 85340028

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 85340028...
Checkpoint 85340028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07097
Policy Entropy: 1.10032
Value Function Loss: 0.11754

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.05973
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.06880

Collected Steps per Second: 11663.06490
Overall Steps per Second: 9301.77454

Timestep Collection Time: 4.28755
Timestep Consumption Time: 1.08841
PPO Batch Consumption Time: 0.09229
Total Iteration Time: 5.37596

Cumulative Model Updates: 5115
Cumulative Timesteps: 85390034

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08016
Policy Entropy: 1.08170
Value Function Loss: 0.10453

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.07747

Collected Steps per Second: 11662.56113
Overall Steps per Second: 9304.10404

Timestep Collection Time: 4.28757
Timestep Consumption Time: 1.08684
PPO Batch Consumption Time: 0.09320
Total Iteration Time: 5.37440

Cumulative Model Updates: 5118
Cumulative Timesteps: 85440038

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 85440038...
Checkpoint 85440038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04309
Policy Entropy: 1.08142
Value Function Loss: 0.12061

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.08188

Collected Steps per Second: 12162.96546
Overall Steps per Second: 9821.32739

Timestep Collection Time: 4.11084
Timestep Consumption Time: 0.98012
PPO Batch Consumption Time: 0.07566
Total Iteration Time: 5.09096

Cumulative Model Updates: 5121
Cumulative Timesteps: 85490038

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11088
Policy Entropy: 1.07709
Value Function Loss: 0.13030

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.08539

Collected Steps per Second: 10520.69156
Overall Steps per Second: 8487.65939

Timestep Collection Time: 4.75368
Timestep Consumption Time: 1.13864
PPO Batch Consumption Time: 0.08419
Total Iteration Time: 5.89232

Cumulative Model Updates: 5124
Cumulative Timesteps: 85540050

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 85540050...
Checkpoint 85540050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06314
Policy Entropy: 1.08583
Value Function Loss: 0.12688

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06612
Policy Update Magnitude: 0.05599
Value Function Update Magnitude: 0.08195

Collected Steps per Second: 11875.68102
Overall Steps per Second: 9663.68444

Timestep Collection Time: 4.21197
Timestep Consumption Time: 0.96411
PPO Batch Consumption Time: 0.09352
Total Iteration Time: 5.17608

Cumulative Model Updates: 5127
Cumulative Timesteps: 85590070

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04410
Policy Entropy: 1.09066
Value Function Loss: 0.11380

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.08611

Collected Steps per Second: 11528.76795
Overall Steps per Second: 9245.19283

Timestep Collection Time: 4.34131
Timestep Consumption Time: 1.07231
PPO Batch Consumption Time: 0.07755
Total Iteration Time: 5.41362

Cumulative Model Updates: 5130
Cumulative Timesteps: 85640120

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 85640120...
Checkpoint 85640120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04088
Policy Entropy: 1.08123
Value Function Loss: 0.09824

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10983
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.08000

Collected Steps per Second: 10902.44534
Overall Steps per Second: 8693.72590

Timestep Collection Time: 4.58778
Timestep Consumption Time: 1.16557
PPO Batch Consumption Time: 0.10969
Total Iteration Time: 5.75334

Cumulative Model Updates: 5133
Cumulative Timesteps: 85690138

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05034
Policy Entropy: 1.09530
Value Function Loss: 0.10492

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.05057
Value Function Update Magnitude: 0.08353

Collected Steps per Second: 13070.11983
Overall Steps per Second: 10850.85203

Timestep Collection Time: 3.82613
Timestep Consumption Time: 0.78254
PPO Batch Consumption Time: 0.05767
Total Iteration Time: 4.60867

Cumulative Model Updates: 5136
Cumulative Timesteps: 85740146

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 85740146...
Checkpoint 85740146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05386
Policy Entropy: 1.09056
Value Function Loss: 0.09641

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05845
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.07589

Collected Steps per Second: 11490.70242
Overall Steps per Second: 9317.87588

Timestep Collection Time: 4.35378
Timestep Consumption Time: 1.01525
PPO Batch Consumption Time: 0.09142
Total Iteration Time: 5.36903

Cumulative Model Updates: 5139
Cumulative Timesteps: 85790174

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04032
Policy Entropy: 1.09125
Value Function Loss: 0.09728

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05980
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.08417

Collected Steps per Second: 13050.29178
Overall Steps per Second: 10446.47005

Timestep Collection Time: 3.83532
Timestep Consumption Time: 0.95597
PPO Batch Consumption Time: 0.08200
Total Iteration Time: 4.79128

Cumulative Model Updates: 5142
Cumulative Timesteps: 85840226

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 85840226...
Checkpoint 85840226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13404
Policy Entropy: 1.08908
Value Function Loss: 0.09833

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06024
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.09016

Collected Steps per Second: 13296.05963
Overall Steps per Second: 10464.72661

Timestep Collection Time: 3.76367
Timestep Consumption Time: 1.01830
PPO Batch Consumption Time: 0.09916
Total Iteration Time: 4.78197

Cumulative Model Updates: 5145
Cumulative Timesteps: 85890268

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.23097
Policy Entropy: 1.08951
Value Function Loss: 0.12316

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06039
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.07528

Collected Steps per Second: 12823.04979
Overall Steps per Second: 10016.24388

Timestep Collection Time: 3.90266
Timestep Consumption Time: 1.09362
PPO Batch Consumption Time: 0.10945
Total Iteration Time: 4.99628

Cumulative Model Updates: 5148
Cumulative Timesteps: 85940312

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 85940312...
Checkpoint 85940312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08842
Policy Entropy: 1.09366
Value Function Loss: 0.12828

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.07281

Collected Steps per Second: 13278.38625
Overall Steps per Second: 10851.37730

Timestep Collection Time: 3.76853
Timestep Consumption Time: 0.84287
PPO Batch Consumption Time: 0.06075
Total Iteration Time: 4.61140

Cumulative Model Updates: 5151
Cumulative Timesteps: 85990352

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13745
Policy Entropy: 1.07602
Value Function Loss: 0.13024

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.07276

Collected Steps per Second: 12265.80060
Overall Steps per Second: 9694.96908

Timestep Collection Time: 4.07996
Timestep Consumption Time: 1.08189
PPO Batch Consumption Time: 0.10919
Total Iteration Time: 5.16185

Cumulative Model Updates: 5154
Cumulative Timesteps: 86040396

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 86040396...
Checkpoint 86040396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05912
Policy Entropy: 1.09359
Value Function Loss: 0.11604

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.07128

Collected Steps per Second: 13243.57032
Overall Steps per Second: 10735.74036

Timestep Collection Time: 3.77557
Timestep Consumption Time: 0.88196
PPO Batch Consumption Time: 0.06148
Total Iteration Time: 4.65753

Cumulative Model Updates: 5157
Cumulative Timesteps: 86090398

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04449
Policy Entropy: 1.09007
Value Function Loss: 0.11453

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.05475
Value Function Update Magnitude: 0.06265

Collected Steps per Second: 12253.33486
Overall Steps per Second: 9763.73777

Timestep Collection Time: 4.08232
Timestep Consumption Time: 1.04093
PPO Batch Consumption Time: 0.10164
Total Iteration Time: 5.12324

Cumulative Model Updates: 5160
Cumulative Timesteps: 86140420

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 86140420...
Checkpoint 86140420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02393
Policy Entropy: 1.10009
Value Function Loss: 0.12104

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05977
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.05518

Collected Steps per Second: 13230.99562
Overall Steps per Second: 10456.75587

Timestep Collection Time: 3.77991
Timestep Consumption Time: 1.00283
PPO Batch Consumption Time: 0.09200
Total Iteration Time: 4.78275

Cumulative Model Updates: 5163
Cumulative Timesteps: 86190432

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07540
Policy Entropy: 1.07888
Value Function Loss: 0.10705

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.06342

Collected Steps per Second: 13114.24716
Overall Steps per Second: 10440.47261

Timestep Collection Time: 3.81326
Timestep Consumption Time: 0.97656
PPO Batch Consumption Time: 0.10698
Total Iteration Time: 4.78982

Cumulative Model Updates: 5166
Cumulative Timesteps: 86240440

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 86240440...
Checkpoint 86240440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04374
Policy Entropy: 1.09005
Value Function Loss: 0.10331

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05716
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.05768

Collected Steps per Second: 13009.77267
Overall Steps per Second: 10417.34063

Timestep Collection Time: 3.84434
Timestep Consumption Time: 0.95669
PPO Batch Consumption Time: 0.07172
Total Iteration Time: 4.80103

Cumulative Model Updates: 5169
Cumulative Timesteps: 86290454

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08072
Policy Entropy: 1.08390
Value Function Loss: 0.11009

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.05941

Collected Steps per Second: 12557.43765
Overall Steps per Second: 10032.40314

Timestep Collection Time: 3.98234
Timestep Consumption Time: 1.00231
PPO Batch Consumption Time: 0.09850
Total Iteration Time: 4.98465

Cumulative Model Updates: 5172
Cumulative Timesteps: 86340462

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 86340462...
Checkpoint 86340462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02417
Policy Entropy: 1.08656
Value Function Loss: 0.12021

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.06609

Collected Steps per Second: 13576.48421
Overall Steps per Second: 10954.28035

Timestep Collection Time: 3.68682
Timestep Consumption Time: 0.88254
PPO Batch Consumption Time: 0.05658
Total Iteration Time: 4.56936

Cumulative Model Updates: 5175
Cumulative Timesteps: 86390516

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12269
Policy Entropy: 1.08222
Value Function Loss: 0.10953

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.07130

Collected Steps per Second: 12081.98050
Overall Steps per Second: 9619.82623

Timestep Collection Time: 4.14121
Timestep Consumption Time: 1.05992
PPO Batch Consumption Time: 0.10776
Total Iteration Time: 5.20113

Cumulative Model Updates: 5178
Cumulative Timesteps: 86440550

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 86440550...
Checkpoint 86440550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01272
Policy Entropy: 1.09202
Value Function Loss: 0.09900

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.08310

Collected Steps per Second: 10441.45941
Overall Steps per Second: 8926.80758

Timestep Collection Time: 4.79128
Timestep Consumption Time: 0.81296
PPO Batch Consumption Time: 0.05236
Total Iteration Time: 5.60424

Cumulative Model Updates: 5181
Cumulative Timesteps: 86490578

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11453
Policy Entropy: 1.09593
Value Function Loss: 0.09635

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.07110

Collected Steps per Second: 10262.04700
Overall Steps per Second: 8377.76229

Timestep Collection Time: 4.87583
Timestep Consumption Time: 1.09665
PPO Batch Consumption Time: 0.08296
Total Iteration Time: 5.97248

Cumulative Model Updates: 5184
Cumulative Timesteps: 86540614

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 86540614...
Checkpoint 86540614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14078
Policy Entropy: 1.09725
Value Function Loss: 0.11268

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07254
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.06298

Collected Steps per Second: 11781.71390
Overall Steps per Second: 9298.12278

Timestep Collection Time: 4.24403
Timestep Consumption Time: 1.13361
PPO Batch Consumption Time: 0.10713
Total Iteration Time: 5.37764

Cumulative Model Updates: 5187
Cumulative Timesteps: 86590616

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15173
Policy Entropy: 1.09174
Value Function Loss: 0.12247

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05355
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.07011

Collected Steps per Second: 11260.81470
Overall Steps per Second: 8903.91031

Timestep Collection Time: 4.44248
Timestep Consumption Time: 1.17595
PPO Batch Consumption Time: 0.07242
Total Iteration Time: 5.61843

Cumulative Model Updates: 5190
Cumulative Timesteps: 86640642

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 86640642...
Checkpoint 86640642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07888
Policy Entropy: 1.09877
Value Function Loss: 0.14749

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07297
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.08095

Collected Steps per Second: 10939.07379
Overall Steps per Second: 8839.22642

Timestep Collection Time: 4.57260
Timestep Consumption Time: 1.08627
PPO Batch Consumption Time: 0.08022
Total Iteration Time: 5.65887

Cumulative Model Updates: 5193
Cumulative Timesteps: 86690662

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05055
Policy Entropy: 1.08312
Value Function Loss: 0.13597

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.07952

Collected Steps per Second: 9651.40713
Overall Steps per Second: 7957.71422

Timestep Collection Time: 5.18494
Timestep Consumption Time: 1.10355
PPO Batch Consumption Time: 0.12031
Total Iteration Time: 6.28849

Cumulative Model Updates: 5196
Cumulative Timesteps: 86740704

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 86740704...
Checkpoint 86740704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08589
Policy Entropy: 1.10363
Value Function Loss: 0.11850

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.05539
Value Function Update Magnitude: 0.09605

Collected Steps per Second: 10960.26450
Overall Steps per Second: 8796.95178

Timestep Collection Time: 4.56467
Timestep Consumption Time: 1.12253
PPO Batch Consumption Time: 0.03198
Total Iteration Time: 5.68720

Cumulative Model Updates: 5199
Cumulative Timesteps: 86790734

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00025
Policy Entropy: 1.09460
Value Function Loss: 0.09524

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.08952

Collected Steps per Second: 11087.17186
Overall Steps per Second: 9066.52698

Timestep Collection Time: 4.51242
Timestep Consumption Time: 1.00568
PPO Batch Consumption Time: 0.07448
Total Iteration Time: 5.51810

Cumulative Model Updates: 5202
Cumulative Timesteps: 86840764

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 86840764...
Checkpoint 86840764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17636
Policy Entropy: 1.10464
Value Function Loss: 0.09895

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07507
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.07919

Collected Steps per Second: 11694.31198
Overall Steps per Second: 9312.02310

Timestep Collection Time: 4.27729
Timestep Consumption Time: 1.09426
PPO Batch Consumption Time: 0.07696
Total Iteration Time: 5.37155

Cumulative Model Updates: 5205
Cumulative Timesteps: 86890784

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00477
Policy Entropy: 1.08616
Value Function Loss: 0.11332

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.07056

Collected Steps per Second: 11427.31816
Overall Steps per Second: 8981.47815

Timestep Collection Time: 4.37776
Timestep Consumption Time: 1.19215
PPO Batch Consumption Time: 0.11870
Total Iteration Time: 5.56991

Cumulative Model Updates: 5208
Cumulative Timesteps: 86940810

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 86940810...
Checkpoint 86940810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00989
Policy Entropy: 1.10446
Value Function Loss: 0.12246

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.06054
Value Function Update Magnitude: 0.08014

Collected Steps per Second: 11484.06780
Overall Steps per Second: 9569.35440

Timestep Collection Time: 4.35664
Timestep Consumption Time: 0.87171
PPO Batch Consumption Time: 0.06757
Total Iteration Time: 5.22836

Cumulative Model Updates: 5211
Cumulative Timesteps: 86990842

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03749
Policy Entropy: 1.09887
Value Function Loss: 0.12830

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.07978

Collected Steps per Second: 9901.44224
Overall Steps per Second: 8110.33715

Timestep Collection Time: 5.05159
Timestep Consumption Time: 1.11560
PPO Batch Consumption Time: 0.09320
Total Iteration Time: 6.16719

Cumulative Model Updates: 5214
Cumulative Timesteps: 87040860

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 87040860...
Checkpoint 87040860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08270
Policy Entropy: 1.09354
Value Function Loss: 0.11721

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.06208
Value Function Update Magnitude: 0.07715

Collected Steps per Second: 11194.52511
Overall Steps per Second: 9118.29769

Timestep Collection Time: 4.46683
Timestep Consumption Time: 1.01709
PPO Batch Consumption Time: 0.07662
Total Iteration Time: 5.48392

Cumulative Model Updates: 5217
Cumulative Timesteps: 87090864

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02727
Policy Entropy: 1.09099
Value Function Loss: 0.10339

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 10064.46343
Overall Steps per Second: 8208.81770

Timestep Collection Time: 4.97215
Timestep Consumption Time: 1.12398
PPO Batch Consumption Time: 0.07084
Total Iteration Time: 6.09613

Cumulative Model Updates: 5220
Cumulative Timesteps: 87140906

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 87140906...
Checkpoint 87140906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04548
Policy Entropy: 1.09772
Value Function Loss: 0.08926

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06756
Policy Update Magnitude: 0.05611
Value Function Update Magnitude: 0.07591

Collected Steps per Second: 11038.03417
Overall Steps per Second: 8920.80095

Timestep Collection Time: 4.53323
Timestep Consumption Time: 1.07590
PPO Batch Consumption Time: 0.07543
Total Iteration Time: 5.60914

Cumulative Model Updates: 5223
Cumulative Timesteps: 87190944

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00991
Policy Entropy: 1.08881
Value Function Loss: 0.09197

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.06198
Value Function Update Magnitude: 0.07841

Collected Steps per Second: 10280.28419
Overall Steps per Second: 8442.43593

Timestep Collection Time: 4.86582
Timestep Consumption Time: 1.05925
PPO Batch Consumption Time: 0.11934
Total Iteration Time: 5.92507

Cumulative Model Updates: 5226
Cumulative Timesteps: 87240966

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 87240966...
Checkpoint 87240966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12893
Policy Entropy: 1.09680
Value Function Loss: 0.08333

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.06078
Value Function Update Magnitude: 0.07725

Collected Steps per Second: 10962.72821
Overall Steps per Second: 8649.10181

Timestep Collection Time: 4.56200
Timestep Consumption Time: 1.22033
PPO Batch Consumption Time: 0.11942
Total Iteration Time: 5.78233

Cumulative Model Updates: 5229
Cumulative Timesteps: 87290978

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09314
Policy Entropy: 1.10144
Value Function Loss: 0.09396

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05530
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.07517

Collected Steps per Second: 11087.09352
Overall Steps per Second: 9089.93546

Timestep Collection Time: 4.51137
Timestep Consumption Time: 0.99120
PPO Batch Consumption Time: 0.06930
Total Iteration Time: 5.50257

Cumulative Model Updates: 5232
Cumulative Timesteps: 87340996

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 87340996...
Checkpoint 87340996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06509
Policy Entropy: 1.11004
Value Function Loss: 0.09696

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05695
Policy Update Magnitude: 0.05819
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 10230.40418
Overall Steps per Second: 7970.12045

Timestep Collection Time: 4.89091
Timestep Consumption Time: 1.38704
PPO Batch Consumption Time: 0.12396
Total Iteration Time: 6.27795

Cumulative Model Updates: 5235
Cumulative Timesteps: 87391032

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15456
Policy Entropy: 1.11943
Value Function Loss: 0.12104

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04787
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.06857

Collected Steps per Second: 10428.98114
Overall Steps per Second: 8390.39311

Timestep Collection Time: 4.79663
Timestep Consumption Time: 1.16542
PPO Batch Consumption Time: 0.08020
Total Iteration Time: 5.96206

Cumulative Model Updates: 5238
Cumulative Timesteps: 87441056

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 87441056...
Checkpoint 87441056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07252
Policy Entropy: 1.11727
Value Function Loss: 0.11526

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04785
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.06728

Collected Steps per Second: 11792.60104
Overall Steps per Second: 9567.63739

Timestep Collection Time: 4.24334
Timestep Consumption Time: 0.98679
PPO Batch Consumption Time: 0.07528
Total Iteration Time: 5.23013

Cumulative Model Updates: 5241
Cumulative Timesteps: 87491096

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10600
Policy Entropy: 1.10110
Value Function Loss: 0.13461

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.06071
Policy Update Magnitude: 0.05876
Value Function Update Magnitude: 0.07230

Collected Steps per Second: 11642.53233
Overall Steps per Second: 9329.11821

Timestep Collection Time: 4.29529
Timestep Consumption Time: 1.06514
PPO Batch Consumption Time: 0.10552
Total Iteration Time: 5.36042

Cumulative Model Updates: 5244
Cumulative Timesteps: 87541104

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 87541104...
Checkpoint 87541104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10341
Policy Entropy: 1.09464
Value Function Loss: 0.12605

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06438
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.08642

Collected Steps per Second: 12620.14314
Overall Steps per Second: 10034.97743

Timestep Collection Time: 3.96303
Timestep Consumption Time: 1.02094
PPO Batch Consumption Time: 0.09959
Total Iteration Time: 4.98397

Cumulative Model Updates: 5247
Cumulative Timesteps: 87591118

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03099
Policy Entropy: 1.09590
Value Function Loss: 0.11289

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.08913

Collected Steps per Second: 12415.72434
Overall Steps per Second: 10131.17110

Timestep Collection Time: 4.02908
Timestep Consumption Time: 0.90855
PPO Batch Consumption Time: 0.05884
Total Iteration Time: 4.93763

Cumulative Model Updates: 5250
Cumulative Timesteps: 87641142

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 87641142...
Checkpoint 87641142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11355
Policy Entropy: 1.10112
Value Function Loss: 0.09940

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04366
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.08999

Collected Steps per Second: 11474.31650
Overall Steps per Second: 9199.21481

Timestep Collection Time: 4.35895
Timestep Consumption Time: 1.07803
PPO Batch Consumption Time: 0.10668
Total Iteration Time: 5.43699

Cumulative Model Updates: 5253
Cumulative Timesteps: 87691158

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09899
Policy Entropy: 1.10099
Value Function Loss: 0.11933

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04827
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.10172

Collected Steps per Second: 11485.74158
Overall Steps per Second: 9685.66085

Timestep Collection Time: 4.35479
Timestep Consumption Time: 0.80934
PPO Batch Consumption Time: 0.02717
Total Iteration Time: 5.16413

Cumulative Model Updates: 5256
Cumulative Timesteps: 87741176

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 87741176...
Checkpoint 87741176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13767
Policy Entropy: 1.10578
Value Function Loss: 0.13426

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05315
Policy Update Magnitude: 0.05746
Value Function Update Magnitude: 0.10655

Collected Steps per Second: 12317.54256
Overall Steps per Second: 9919.40063

Timestep Collection Time: 4.05974
Timestep Consumption Time: 0.98149
PPO Batch Consumption Time: 0.07439
Total Iteration Time: 5.04123

Cumulative Model Updates: 5259
Cumulative Timesteps: 87791182

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07439
Policy Entropy: 1.10553
Value Function Loss: 0.13738

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04939
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.09829

Collected Steps per Second: 12670.17707
Overall Steps per Second: 10309.75372

Timestep Collection Time: 3.94675
Timestep Consumption Time: 0.90361
PPO Batch Consumption Time: 0.06667
Total Iteration Time: 4.85036

Cumulative Model Updates: 5262
Cumulative Timesteps: 87841188

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 87841188...
Checkpoint 87841188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13788
Policy Entropy: 1.10230
Value Function Loss: 0.10787

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05348
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.08769

Collected Steps per Second: 11097.78497
Overall Steps per Second: 9100.38374

Timestep Collection Time: 4.50991
Timestep Consumption Time: 0.98986
PPO Batch Consumption Time: 0.09928
Total Iteration Time: 5.49977

Cumulative Model Updates: 5265
Cumulative Timesteps: 87891238

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09669
Policy Entropy: 1.09581
Value Function Loss: 0.08791

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06061
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.07988

Collected Steps per Second: 11990.81121
Overall Steps per Second: 9605.39966

Timestep Collection Time: 4.16986
Timestep Consumption Time: 1.03555
PPO Batch Consumption Time: 0.09283
Total Iteration Time: 5.20541

Cumulative Model Updates: 5268
Cumulative Timesteps: 87941238

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 87941238...
Checkpoint 87941238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00736
Policy Entropy: 1.09796
Value Function Loss: 0.08623

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06502
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.07462

Collected Steps per Second: 12312.35059
Overall Steps per Second: 10004.09099

Timestep Collection Time: 4.06535
Timestep Consumption Time: 0.93800
PPO Batch Consumption Time: 0.07538
Total Iteration Time: 5.00335

Cumulative Model Updates: 5271
Cumulative Timesteps: 87991292

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09543
Policy Entropy: 1.10281
Value Function Loss: 0.09394

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.07410

Collected Steps per Second: 11127.90389
Overall Steps per Second: 9258.37312

Timestep Collection Time: 4.49465
Timestep Consumption Time: 0.90760
PPO Batch Consumption Time: 0.05081
Total Iteration Time: 5.40225

Cumulative Model Updates: 5274
Cumulative Timesteps: 88041308

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 88041308...
Checkpoint 88041308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13111
Policy Entropy: 1.11217
Value Function Loss: 0.10267

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06629
Policy Update Magnitude: 0.05434
Value Function Update Magnitude: 0.07294

Collected Steps per Second: 10856.57625
Overall Steps per Second: 8709.50584

Timestep Collection Time: 4.60642
Timestep Consumption Time: 1.13558
PPO Batch Consumption Time: 0.13327
Total Iteration Time: 5.74200

Cumulative Model Updates: 5277
Cumulative Timesteps: 88091318

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02820
Policy Entropy: 1.12241
Value Function Loss: 0.10307

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.07492

Collected Steps per Second: 10951.04631
Overall Steps per Second: 9280.54631

Timestep Collection Time: 4.56650
Timestep Consumption Time: 0.82197
PPO Batch Consumption Time: 0.04688
Total Iteration Time: 5.38848

Cumulative Model Updates: 5280
Cumulative Timesteps: 88141326

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 88141326...
Checkpoint 88141326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11127
Policy Entropy: 1.11375
Value Function Loss: 0.10868

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06763
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.07512

Collected Steps per Second: 10688.85630
Overall Steps per Second: 8596.65497

Timestep Collection Time: 4.68076
Timestep Consumption Time: 1.13918
PPO Batch Consumption Time: 0.09838
Total Iteration Time: 5.81994

Cumulative Model Updates: 5283
Cumulative Timesteps: 88191358

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18832
Policy Entropy: 1.11089
Value Function Loss: 0.09983

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06666
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.07611

Collected Steps per Second: 12231.57923
Overall Steps per Second: 10062.07737

Timestep Collection Time: 4.08974
Timestep Consumption Time: 0.88180
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 4.97154

Cumulative Model Updates: 5286
Cumulative Timesteps: 88241382

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 88241382...
Checkpoint 88241382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05919
Policy Entropy: 1.12078
Value Function Loss: 0.11668

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06527
Policy Update Magnitude: 0.06509
Value Function Update Magnitude: 0.08095

Collected Steps per Second: 9967.39658
Overall Steps per Second: 7833.46853

Timestep Collection Time: 5.01836
Timestep Consumption Time: 1.36706
PPO Batch Consumption Time: 0.12520
Total Iteration Time: 6.38542

Cumulative Model Updates: 5289
Cumulative Timesteps: 88291402

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06606
Policy Entropy: 1.11698
Value Function Loss: 0.13056

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.07333

Collected Steps per Second: 10423.54348
Overall Steps per Second: 8451.94533

Timestep Collection Time: 4.80029
Timestep Consumption Time: 1.11977
PPO Batch Consumption Time: 0.08347
Total Iteration Time: 5.92006

Cumulative Model Updates: 5292
Cumulative Timesteps: 88341438

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 88341438...
Checkpoint 88341438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08482
Policy Entropy: 1.11962
Value Function Loss: 0.13087

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.06140
Value Function Update Magnitude: 0.08174

Collected Steps per Second: 9947.60803
Overall Steps per Second: 8371.63141

Timestep Collection Time: 5.02915
Timestep Consumption Time: 0.94675
PPO Batch Consumption Time: 0.02890
Total Iteration Time: 5.97590

Cumulative Model Updates: 5295
Cumulative Timesteps: 88391466

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.21185
Policy Entropy: 1.10760
Value Function Loss: 0.11085

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.09254

Collected Steps per Second: 10354.14619
Overall Steps per Second: 8245.24448

Timestep Collection Time: 4.83091
Timestep Consumption Time: 1.23561
PPO Batch Consumption Time: 0.12282
Total Iteration Time: 6.06653

Cumulative Model Updates: 5298
Cumulative Timesteps: 88441486

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 88441486...
Checkpoint 88441486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.24041
Policy Entropy: 1.11207
Value Function Loss: 0.09346

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07317
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.09893

Collected Steps per Second: 11374.31713
Overall Steps per Second: 9121.72711

Timestep Collection Time: 4.39780
Timestep Consumption Time: 1.08603
PPO Batch Consumption Time: 0.08506
Total Iteration Time: 5.48383

Cumulative Model Updates: 5301
Cumulative Timesteps: 88491508

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01227
Policy Entropy: 1.10058
Value Function Loss: 0.10162

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.09327

Collected Steps per Second: 9889.45576
Overall Steps per Second: 7906.49612

Timestep Collection Time: 5.05731
Timestep Consumption Time: 1.26838
PPO Batch Consumption Time: 0.08787
Total Iteration Time: 6.32568

Cumulative Model Updates: 5304
Cumulative Timesteps: 88541522

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 88541522...
Checkpoint 88541522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13041
Policy Entropy: 1.10743
Value Function Loss: 0.10656

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07946
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.08848

Collected Steps per Second: 9352.39306
Overall Steps per Second: 7638.56659

Timestep Collection Time: 5.34708
Timestep Consumption Time: 1.19970
PPO Batch Consumption Time: 0.11186
Total Iteration Time: 6.54678

Cumulative Model Updates: 5307
Cumulative Timesteps: 88591530

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00757
Policy Entropy: 1.11819
Value Function Loss: 0.11925

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05763
Policy Update Magnitude: 0.05673
Value Function Update Magnitude: 0.09483

Collected Steps per Second: 10329.18341
Overall Steps per Second: 8578.38861

Timestep Collection Time: 4.84240
Timestep Consumption Time: 0.98830
PPO Batch Consumption Time: 0.07985
Total Iteration Time: 5.83070

Cumulative Model Updates: 5310
Cumulative Timesteps: 88641548

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 88641548...
Checkpoint 88641548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02838
Policy Entropy: 1.12230
Value Function Loss: 0.12159

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04857
Policy Update Magnitude: 0.05883
Value Function Update Magnitude: 0.08785

Collected Steps per Second: 11156.79878
Overall Steps per Second: 9008.41065

Timestep Collection Time: 4.48480
Timestep Consumption Time: 1.06957
PPO Batch Consumption Time: 0.08088
Total Iteration Time: 5.55436

Cumulative Model Updates: 5313
Cumulative Timesteps: 88691584

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01800
Policy Entropy: 1.11561
Value Function Loss: 0.12277

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.08864

Collected Steps per Second: 10929.32774
Overall Steps per Second: 8921.97559

Timestep Collection Time: 4.57540
Timestep Consumption Time: 1.02942
PPO Batch Consumption Time: 0.07201
Total Iteration Time: 5.60481

Cumulative Model Updates: 5316
Cumulative Timesteps: 88741590

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 88741590...
Checkpoint 88741590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00302
Policy Entropy: 1.10563
Value Function Loss: 0.11013

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.09334

Collected Steps per Second: 10917.94314
Overall Steps per Second: 8862.20885

Timestep Collection Time: 4.58127
Timestep Consumption Time: 1.06270
PPO Batch Consumption Time: 0.07076
Total Iteration Time: 5.64397

Cumulative Model Updates: 5319
Cumulative Timesteps: 88791608

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16027
Policy Entropy: 1.12390
Value Function Loss: 0.09774

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.05380
Value Function Update Magnitude: 0.09302

Collected Steps per Second: 10292.54381
Overall Steps per Second: 8439.15182

Timestep Collection Time: 4.85847
Timestep Consumption Time: 1.06701
PPO Batch Consumption Time: 0.07711
Total Iteration Time: 5.92548

Cumulative Model Updates: 5322
Cumulative Timesteps: 88841614

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 88841614...
Checkpoint 88841614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16548
Policy Entropy: 1.11178
Value Function Loss: 0.10652

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.08058

Collected Steps per Second: 10676.37037
Overall Steps per Second: 8678.65694

Timestep Collection Time: 4.68586
Timestep Consumption Time: 1.07862
PPO Batch Consumption Time: 0.09826
Total Iteration Time: 5.76449

Cumulative Model Updates: 5325
Cumulative Timesteps: 88891642

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01463
Policy Entropy: 1.10441
Value Function Loss: 0.11477

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.07363

Collected Steps per Second: 11226.40519
Overall Steps per Second: 9154.89917

Timestep Collection Time: 4.45788
Timestep Consumption Time: 1.00870
PPO Batch Consumption Time: 0.07042
Total Iteration Time: 5.46658

Cumulative Model Updates: 5328
Cumulative Timesteps: 88941688

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 88941688...
Checkpoint 88941688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04949
Policy Entropy: 1.11599
Value Function Loss: 0.13829

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07691
Policy Update Magnitude: 0.06387
Value Function Update Magnitude: 0.07140

Collected Steps per Second: 9724.66386
Overall Steps per Second: 7921.64174

Timestep Collection Time: 5.14280
Timestep Consumption Time: 1.17054
PPO Batch Consumption Time: 0.09879
Total Iteration Time: 6.31334

Cumulative Model Updates: 5331
Cumulative Timesteps: 88991700

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03830
Policy Entropy: 1.11753
Value Function Loss: 0.13981

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.07730

Collected Steps per Second: 11238.31307
Overall Steps per Second: 8942.24566

Timestep Collection Time: 4.45138
Timestep Consumption Time: 1.14296
PPO Batch Consumption Time: 0.10672
Total Iteration Time: 5.59434

Cumulative Model Updates: 5334
Cumulative Timesteps: 89041726

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 89041726...
Checkpoint 89041726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06377
Policy Entropy: 1.11498
Value Function Loss: 0.12074

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.09412

Collected Steps per Second: 10811.38382
Overall Steps per Second: 8659.42016

Timestep Collection Time: 4.62679
Timestep Consumption Time: 1.14981
PPO Batch Consumption Time: 0.08112
Total Iteration Time: 5.77660

Cumulative Model Updates: 5337
Cumulative Timesteps: 89091748

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00441
Policy Entropy: 1.10709
Value Function Loss: 0.11747

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.05790
Value Function Update Magnitude: 0.10194

Collected Steps per Second: 9716.75113
Overall Steps per Second: 8039.32757

Timestep Collection Time: 5.14699
Timestep Consumption Time: 1.07393
PPO Batch Consumption Time: 0.10739
Total Iteration Time: 6.22092

Cumulative Model Updates: 5340
Cumulative Timesteps: 89141760

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 89141760...
Checkpoint 89141760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02336
Policy Entropy: 1.11382
Value Function Loss: 0.09776

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07578
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.10553

Collected Steps per Second: 12014.71675
Overall Steps per Second: 9776.49990

Timestep Collection Time: 4.16323
Timestep Consumption Time: 0.95312
PPO Batch Consumption Time: 0.05954
Total Iteration Time: 5.11635

Cumulative Model Updates: 5343
Cumulative Timesteps: 89191780

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04676
Policy Entropy: 1.11714
Value Function Loss: 0.10688

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08286
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.09361

Collected Steps per Second: 11293.49729
Overall Steps per Second: 9559.51933

Timestep Collection Time: 4.43105
Timestep Consumption Time: 0.80374
PPO Batch Consumption Time: 0.02640
Total Iteration Time: 5.23478

Cumulative Model Updates: 5346
Cumulative Timesteps: 89241822

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 89241822...
Checkpoint 89241822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11717
Policy Entropy: 1.11983
Value Function Loss: 0.10741

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06641
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.09998

Collected Steps per Second: 12661.99078
Overall Steps per Second: 10282.32657

Timestep Collection Time: 3.94930
Timestep Consumption Time: 0.91400
PPO Batch Consumption Time: 0.05497
Total Iteration Time: 4.86330

Cumulative Model Updates: 5349
Cumulative Timesteps: 89291828

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08949
Policy Entropy: 1.11801
Value Function Loss: 0.11672

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06636
Policy Update Magnitude: 0.05427
Value Function Update Magnitude: 0.10724

Collected Steps per Second: 10942.82378
Overall Steps per Second: 9053.67125

Timestep Collection Time: 4.56975
Timestep Consumption Time: 0.95353
PPO Batch Consumption Time: 0.07327
Total Iteration Time: 5.52328

Cumulative Model Updates: 5352
Cumulative Timesteps: 89341834

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 89341834...
Checkpoint 89341834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06432
Policy Entropy: 1.12116
Value Function Loss: 0.13087

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.06128
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.08458

Collected Steps per Second: 12663.04492
Overall Steps per Second: 10098.00457

Timestep Collection Time: 3.95023
Timestep Consumption Time: 1.00342
PPO Batch Consumption Time: 0.11773
Total Iteration Time: 4.95365

Cumulative Model Updates: 5355
Cumulative Timesteps: 89391856

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01958
Policy Entropy: 1.12037
Value Function Loss: 0.10718

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.06377
Policy Update Magnitude: 0.05489
Value Function Update Magnitude: 0.07529

Collected Steps per Second: 11525.94408
Overall Steps per Second: 9398.93744

Timestep Collection Time: 4.34151
Timestep Consumption Time: 0.98250
PPO Batch Consumption Time: 0.07501
Total Iteration Time: 5.32401

Cumulative Model Updates: 5358
Cumulative Timesteps: 89441896

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 89441896...
Checkpoint 89441896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01159
Policy Entropy: 1.12293
Value Function Loss: 0.09731

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05278
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.07976

Collected Steps per Second: 12412.83958
Overall Steps per Second: 9871.41516

Timestep Collection Time: 4.02857
Timestep Consumption Time: 1.03717
PPO Batch Consumption Time: 0.10468
Total Iteration Time: 5.06574

Cumulative Model Updates: 5361
Cumulative Timesteps: 89491902

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05574
Policy Entropy: 1.11639
Value Function Loss: 0.09446

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06381
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.07596

Collected Steps per Second: 11726.16468
Overall Steps per Second: 9491.76131

Timestep Collection Time: 4.26636
Timestep Consumption Time: 1.00432
PPO Batch Consumption Time: 0.06604
Total Iteration Time: 5.27068

Cumulative Model Updates: 5364
Cumulative Timesteps: 89541930

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 89541930...
Checkpoint 89541930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04290
Policy Entropy: 1.11240
Value Function Loss: 0.10518

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06438
Policy Update Magnitude: 0.05039
Value Function Update Magnitude: 0.07707

Collected Steps per Second: 10571.36098
Overall Steps per Second: 8884.59768

Timestep Collection Time: 4.73090
Timestep Consumption Time: 0.89817
PPO Batch Consumption Time: 0.03314
Total Iteration Time: 5.62907

Cumulative Model Updates: 5367
Cumulative Timesteps: 89591942

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05466
Policy Entropy: 1.10515
Value Function Loss: 0.10215

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.07082

Collected Steps per Second: 9399.32441
Overall Steps per Second: 7734.35513

Timestep Collection Time: 5.32102
Timestep Consumption Time: 1.14545
PPO Batch Consumption Time: 0.12522
Total Iteration Time: 6.46647

Cumulative Model Updates: 5370
Cumulative Timesteps: 89641956

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 89641956...
Checkpoint 89641956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02071
Policy Entropy: 1.11799
Value Function Loss: 0.11876

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.07665

Collected Steps per Second: 10635.28869
Overall Steps per Second: 8638.36393

Timestep Collection Time: 4.70434
Timestep Consumption Time: 1.08750
PPO Batch Consumption Time: 0.07070
Total Iteration Time: 5.79184

Cumulative Model Updates: 5373
Cumulative Timesteps: 89691988

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15016
Policy Entropy: 1.11081
Value Function Loss: 0.10918

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.07453

Collected Steps per Second: 10229.31901
Overall Steps per Second: 8342.20394

Timestep Collection Time: 4.89084
Timestep Consumption Time: 1.10637
PPO Batch Consumption Time: 0.08921
Total Iteration Time: 5.99722

Cumulative Model Updates: 5376
Cumulative Timesteps: 89742018

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 89742018...
Checkpoint 89742018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11138
Policy Entropy: 1.12066
Value Function Loss: 0.11890

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06695
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.07782

Collected Steps per Second: 11435.47710
Overall Steps per Second: 9127.20607

Timestep Collection Time: 4.37603
Timestep Consumption Time: 1.10670
PPO Batch Consumption Time: 0.07979
Total Iteration Time: 5.48273

Cumulative Model Updates: 5379
Cumulative Timesteps: 89792060

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04287
Policy Entropy: 1.11918
Value Function Loss: 0.09201

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07298
Policy Update Magnitude: 0.06229
Value Function Update Magnitude: 0.07507

Collected Steps per Second: 9761.96360
Overall Steps per Second: 7935.86061

Timestep Collection Time: 5.12233
Timestep Consumption Time: 1.17869
PPO Batch Consumption Time: 0.06584
Total Iteration Time: 6.30102

Cumulative Model Updates: 5382
Cumulative Timesteps: 89842064

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 89842064...
Checkpoint 89842064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11941
Policy Entropy: 1.11360
Value Function Loss: 0.08953

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.07032

Collected Steps per Second: 10798.23682
Overall Steps per Second: 8701.85173

Timestep Collection Time: 4.63150
Timestep Consumption Time: 1.11579
PPO Batch Consumption Time: 0.12413
Total Iteration Time: 5.74728

Cumulative Model Updates: 5385
Cumulative Timesteps: 89892076

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11736
Policy Entropy: 1.11771
Value Function Loss: 0.08072

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.06547

Collected Steps per Second: 10461.78685
Overall Steps per Second: 8590.39416

Timestep Collection Time: 4.77968
Timestep Consumption Time: 1.04124
PPO Batch Consumption Time: 0.07548
Total Iteration Time: 5.82092

Cumulative Model Updates: 5388
Cumulative Timesteps: 89942080

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 89942080...
Checkpoint 89942080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14368
Policy Entropy: 1.11803
Value Function Loss: 0.09225

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.06065
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.06465

Collected Steps per Second: 10212.21160
Overall Steps per Second: 8401.67085

Timestep Collection Time: 4.90021
Timestep Consumption Time: 1.05598
PPO Batch Consumption Time: 0.04244
Total Iteration Time: 5.95620

Cumulative Model Updates: 5391
Cumulative Timesteps: 89992122

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05552
Policy Entropy: 1.12426
Value Function Loss: 0.10338

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.06966

Collected Steps per Second: 9754.15068
Overall Steps per Second: 8012.39500

Timestep Collection Time: 5.12910
Timestep Consumption Time: 1.11498
PPO Batch Consumption Time: 0.06006
Total Iteration Time: 6.24408

Cumulative Model Updates: 5394
Cumulative Timesteps: 90042152

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 90042152...
Checkpoint 90042152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15421
Policy Entropy: 1.10722
Value Function Loss: 0.10218

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.05460
Value Function Update Magnitude: 0.07524

Collected Steps per Second: 9919.25554
Overall Steps per Second: 8119.26289

Timestep Collection Time: 5.04151
Timestep Consumption Time: 1.11767
PPO Batch Consumption Time: 0.07554
Total Iteration Time: 6.15918

Cumulative Model Updates: 5397
Cumulative Timesteps: 90092160

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12031
Policy Entropy: 1.12250
Value Function Loss: 0.10999

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.07654

Collected Steps per Second: 10514.02303
Overall Steps per Second: 8518.58154

Timestep Collection Time: 4.75784
Timestep Consumption Time: 1.11450
PPO Batch Consumption Time: 0.04360
Total Iteration Time: 5.87234

Cumulative Model Updates: 5400
Cumulative Timesteps: 90142184

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 90142184...
Checkpoint 90142184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06521
Policy Entropy: 1.13305
Value Function Loss: 0.10545

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.07980

Collected Steps per Second: 10171.04047
Overall Steps per Second: 8217.86739

Timestep Collection Time: 4.91690
Timestep Consumption Time: 1.16862
PPO Batch Consumption Time: 0.08948
Total Iteration Time: 6.08552

Cumulative Model Updates: 5403
Cumulative Timesteps: 90192194

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06400
Policy Entropy: 1.13153
Value Function Loss: 0.10356

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.07804

Collected Steps per Second: 10648.19821
Overall Steps per Second: 8624.29985

Timestep Collection Time: 4.69638
Timestep Consumption Time: 1.10212
PPO Batch Consumption Time: 0.07889
Total Iteration Time: 5.79850

Cumulative Model Updates: 5406
Cumulative Timesteps: 90242202

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 90242202...
Checkpoint 90242202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02717
Policy Entropy: 1.12796
Value Function Loss: 0.10221

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.07171

Collected Steps per Second: 10610.84782
Overall Steps per Second: 8693.03592

Timestep Collection Time: 4.71235
Timestep Consumption Time: 1.03961
PPO Batch Consumption Time: 0.09601
Total Iteration Time: 5.75196

Cumulative Model Updates: 5409
Cumulative Timesteps: 90292204

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07277
Policy Entropy: 1.12976
Value Function Loss: 0.08471

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05977
Policy Update Magnitude: 0.06446
Value Function Update Magnitude: 0.06871

Collected Steps per Second: 10975.19734
Overall Steps per Second: 8963.23031

Timestep Collection Time: 4.55664
Timestep Consumption Time: 1.02282
PPO Batch Consumption Time: 0.07225
Total Iteration Time: 5.57946

Cumulative Model Updates: 5412
Cumulative Timesteps: 90342214

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 90342214...
Checkpoint 90342214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16594
Policy Entropy: 1.11935
Value Function Loss: 0.07445

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06133
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.07456

Collected Steps per Second: 9533.87815
Overall Steps per Second: 7826.55713

Timestep Collection Time: 5.24508
Timestep Consumption Time: 1.14419
PPO Batch Consumption Time: 0.10761
Total Iteration Time: 6.38927

Cumulative Model Updates: 5415
Cumulative Timesteps: 90392220

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04489
Policy Entropy: 1.12336
Value Function Loss: 0.06980

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05029
Policy Update Magnitude: 0.05683
Value Function Update Magnitude: 0.07600

Collected Steps per Second: 11669.84023
Overall Steps per Second: 9381.70257

Timestep Collection Time: 4.28609
Timestep Consumption Time: 1.04535
PPO Batch Consumption Time: 0.07754
Total Iteration Time: 5.33144

Cumulative Model Updates: 5418
Cumulative Timesteps: 90442238

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 90442238...
Checkpoint 90442238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17671
Policy Entropy: 1.12937
Value Function Loss: 0.07518

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05647
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.07388

Collected Steps per Second: 11606.28252
Overall Steps per Second: 9480.69218

Timestep Collection Time: 4.30818
Timestep Consumption Time: 0.96590
PPO Batch Consumption Time: 0.08202
Total Iteration Time: 5.27409

Cumulative Model Updates: 5421
Cumulative Timesteps: 90492240

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08302
Policy Entropy: 1.13700
Value Function Loss: 0.08890

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06075
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.07567

Collected Steps per Second: 12682.89349
Overall Steps per Second: 10072.88239

Timestep Collection Time: 3.94547
Timestep Consumption Time: 1.02232
PPO Batch Consumption Time: 0.11704
Total Iteration Time: 4.96779

Cumulative Model Updates: 5424
Cumulative Timesteps: 90542280

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 90542280...
Checkpoint 90542280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05585
Policy Entropy: 1.13793
Value Function Loss: 0.10058

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.07420

Collected Steps per Second: 12845.44618
Overall Steps per Second: 10435.98291

Timestep Collection Time: 3.89430
Timestep Consumption Time: 0.89912
PPO Batch Consumption Time: 0.06354
Total Iteration Time: 4.79342

Cumulative Model Updates: 5427
Cumulative Timesteps: 90592304

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02184
Policy Entropy: 1.14142
Value Function Loss: 0.11062

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.07380

Collected Steps per Second: 10284.80856
Overall Steps per Second: 8366.72663

Timestep Collection Time: 4.86173
Timestep Consumption Time: 1.11456
PPO Batch Consumption Time: 0.11699
Total Iteration Time: 5.97629

Cumulative Model Updates: 5430
Cumulative Timesteps: 90642306

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 90642306...
Checkpoint 90642306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01187
Policy Entropy: 1.14432
Value Function Loss: 0.09389

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.07833

Collected Steps per Second: 11635.53440
Overall Steps per Second: 9292.89395

Timestep Collection Time: 4.30010
Timestep Consumption Time: 1.08401
PPO Batch Consumption Time: 0.06797
Total Iteration Time: 5.38411

Cumulative Model Updates: 5433
Cumulative Timesteps: 90692340

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16731
Policy Entropy: 1.14134
Value Function Loss: 0.08664

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06768
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.07506

Collected Steps per Second: 10387.83579
Overall Steps per Second: 8576.38652

Timestep Collection Time: 4.81371
Timestep Consumption Time: 1.01672
PPO Batch Consumption Time: 0.08632
Total Iteration Time: 5.83043

Cumulative Model Updates: 5436
Cumulative Timesteps: 90742344

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 90742344...
Checkpoint 90742344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10834
Policy Entropy: 1.13786
Value Function Loss: 0.10091

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06047
Policy Update Magnitude: 0.05414
Value Function Update Magnitude: 0.07505

Collected Steps per Second: 12726.39998
Overall Steps per Second: 10115.77818

Timestep Collection Time: 3.93230
Timestep Consumption Time: 1.01482
PPO Batch Consumption Time: 0.11597
Total Iteration Time: 4.94712

Cumulative Model Updates: 5439
Cumulative Timesteps: 90792388

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11659
Policy Entropy: 1.12626
Value Function Loss: 0.11734

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.08078

Collected Steps per Second: 13048.68828
Overall Steps per Second: 10517.94248

Timestep Collection Time: 3.83364
Timestep Consumption Time: 0.92242
PPO Batch Consumption Time: 0.06972
Total Iteration Time: 4.75606

Cumulative Model Updates: 5442
Cumulative Timesteps: 90842412

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 90842412...
Checkpoint 90842412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02303
Policy Entropy: 1.12852
Value Function Loss: 0.12845

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.09324

Collected Steps per Second: 10719.58963
Overall Steps per Second: 8466.81170

Timestep Collection Time: 4.66585
Timestep Consumption Time: 1.24145
PPO Batch Consumption Time: 0.16397
Total Iteration Time: 5.90730

Cumulative Model Updates: 5445
Cumulative Timesteps: 90892428

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01762
Policy Entropy: 1.12627
Value Function Loss: 0.10322

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06029
Policy Update Magnitude: 0.05882
Value Function Update Magnitude: 0.09555

Collected Steps per Second: 12688.76314
Overall Steps per Second: 9572.05564

Timestep Collection Time: 3.94097
Timestep Consumption Time: 1.28320
PPO Batch Consumption Time: 0.16257
Total Iteration Time: 5.22417

Cumulative Model Updates: 5448
Cumulative Timesteps: 90942434

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 90942434...
Checkpoint 90942434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08598
Policy Entropy: 1.13969
Value Function Loss: 0.09598

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05189
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.09656

Collected Steps per Second: 12689.69006
Overall Steps per Second: 9495.30862

Timestep Collection Time: 3.94068
Timestep Consumption Time: 1.32571
PPO Batch Consumption Time: 0.14495
Total Iteration Time: 5.26639

Cumulative Model Updates: 5451
Cumulative Timesteps: 90992440

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00862
Policy Entropy: 1.13725
Value Function Loss: 0.09327

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.05924
Value Function Update Magnitude: 0.09606

Collected Steps per Second: 11378.63162
Overall Steps per Second: 8980.89386

Timestep Collection Time: 4.39877
Timestep Consumption Time: 1.17439
PPO Batch Consumption Time: 0.14760
Total Iteration Time: 5.57316

Cumulative Model Updates: 5454
Cumulative Timesteps: 91042492

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 91042492...
Checkpoint 91042492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04768
Policy Entropy: 1.13706
Value Function Loss: 0.11213

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07347
Policy Update Magnitude: 0.05532
Value Function Update Magnitude: 0.09922

Collected Steps per Second: 12199.17277
Overall Steps per Second: 9262.67154

Timestep Collection Time: 4.10241
Timestep Consumption Time: 1.30057
PPO Batch Consumption Time: 0.14083
Total Iteration Time: 5.40298

Cumulative Model Updates: 5457
Cumulative Timesteps: 91092538

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13135
Policy Entropy: 1.13288
Value Function Loss: 0.12420

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06943
Policy Update Magnitude: 0.05760
Value Function Update Magnitude: 0.10111

Collected Steps per Second: 11565.81733
Overall Steps per Second: 8955.50401

Timestep Collection Time: 4.32637
Timestep Consumption Time: 1.26103
PPO Batch Consumption Time: 0.13872
Total Iteration Time: 5.58740

Cumulative Model Updates: 5460
Cumulative Timesteps: 91142576

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 91142576...
Checkpoint 91142576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06113
Policy Entropy: 1.13563
Value Function Loss: 0.12507

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.09784

Collected Steps per Second: 12049.77992
Overall Steps per Second: 9693.39218

Timestep Collection Time: 4.15111
Timestep Consumption Time: 1.00910
PPO Batch Consumption Time: 0.07578
Total Iteration Time: 5.16022

Cumulative Model Updates: 5463
Cumulative Timesteps: 91192596

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10552
Policy Entropy: 1.14230
Value Function Loss: 0.11293

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.09405

Collected Steps per Second: 11909.41307
Overall Steps per Second: 8905.13294

Timestep Collection Time: 4.19937
Timestep Consumption Time: 1.41672
PPO Batch Consumption Time: 0.18686
Total Iteration Time: 5.61609

Cumulative Model Updates: 5466
Cumulative Timesteps: 91242608

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 91242608...
Checkpoint 91242608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06724
Policy Entropy: 1.13255
Value Function Loss: 0.11450

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.09368

Collected Steps per Second: 12242.43376
Overall Steps per Second: 9965.89527

Timestep Collection Time: 4.08628
Timestep Consumption Time: 0.93344
PPO Batch Consumption Time: 0.07057
Total Iteration Time: 5.01972

Cumulative Model Updates: 5469
Cumulative Timesteps: 91292634

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08920
Policy Entropy: 1.13975
Value Function Loss: 0.11653

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.06146
Value Function Update Magnitude: 0.09138

Collected Steps per Second: 11060.32015
Overall Steps per Second: 8395.03323

Timestep Collection Time: 4.52157
Timestep Consumption Time: 1.43552
PPO Batch Consumption Time: 0.19076
Total Iteration Time: 5.95709

Cumulative Model Updates: 5472
Cumulative Timesteps: 91342644

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 91342644...
Checkpoint 91342644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00486
Policy Entropy: 1.13342
Value Function Loss: 0.11708

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06951
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.09706

Collected Steps per Second: 12070.62225
Overall Steps per Second: 9330.53752

Timestep Collection Time: 4.14262
Timestep Consumption Time: 1.21656
PPO Batch Consumption Time: 0.14130
Total Iteration Time: 5.35918

Cumulative Model Updates: 5475
Cumulative Timesteps: 91392648

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17406
Policy Entropy: 1.14236
Value Function Loss: 0.10919

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.06044
Value Function Update Magnitude: 0.09811

Collected Steps per Second: 12315.56761
Overall Steps per Second: 9945.39594

Timestep Collection Time: 4.06445
Timestep Consumption Time: 0.96863
PPO Batch Consumption Time: 0.06912
Total Iteration Time: 5.03308

Cumulative Model Updates: 5478
Cumulative Timesteps: 91442704

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 91442704...
Checkpoint 91442704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05695
Policy Entropy: 1.14740
Value Function Loss: 0.09811

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06343
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.09518

Collected Steps per Second: 10694.93154
Overall Steps per Second: 8379.40563

Timestep Collection Time: 4.67829
Timestep Consumption Time: 1.29278
PPO Batch Consumption Time: 0.13752
Total Iteration Time: 5.97107

Cumulative Model Updates: 5481
Cumulative Timesteps: 91492738

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09723
Policy Entropy: 1.15463
Value Function Loss: 0.10039

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.08045

Collected Steps per Second: 11587.47486
Overall Steps per Second: 8964.74442

Timestep Collection Time: 4.31897
Timestep Consumption Time: 1.26356
PPO Batch Consumption Time: 0.16126
Total Iteration Time: 5.58254

Cumulative Model Updates: 5484
Cumulative Timesteps: 91542784

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 91542784...
Checkpoint 91542784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13838
Policy Entropy: 1.15574
Value Function Loss: 0.08843

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06287
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.08285

Collected Steps per Second: 11867.00983
Overall Steps per Second: 9586.66087

Timestep Collection Time: 4.21639
Timestep Consumption Time: 1.00294
PPO Batch Consumption Time: 0.07261
Total Iteration Time: 5.21934

Cumulative Model Updates: 5487
Cumulative Timesteps: 91592820

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12911
Policy Entropy: 1.15681
Value Function Loss: 0.09733

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.07157

Collected Steps per Second: 10544.62043
Overall Steps per Second: 8128.21202

Timestep Collection Time: 4.74365
Timestep Consumption Time: 1.41022
PPO Batch Consumption Time: 0.19366
Total Iteration Time: 6.15387

Cumulative Model Updates: 5490
Cumulative Timesteps: 91642840

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 91642840...
Checkpoint 91642840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07010
Policy Entropy: 1.15452
Value Function Loss: 0.08723

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06856
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.06843

Collected Steps per Second: 12063.44304
Overall Steps per Second: 9030.52420

Timestep Collection Time: 4.14906
Timestep Consumption Time: 1.39347
PPO Batch Consumption Time: 0.16815
Total Iteration Time: 5.54254

Cumulative Model Updates: 5493
Cumulative Timesteps: 91692892

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09305
Policy Entropy: 1.15372
Value Function Loss: 0.09732

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.07531

Collected Steps per Second: 11605.48979
Overall Steps per Second: 8918.60230

Timestep Collection Time: 4.30917
Timestep Consumption Time: 1.29821
PPO Batch Consumption Time: 0.16483
Total Iteration Time: 5.60738

Cumulative Model Updates: 5496
Cumulative Timesteps: 91742902

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 91742902...
Checkpoint 91742902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00518
Policy Entropy: 1.14818
Value Function Loss: 0.09738

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 11889.43941
Overall Steps per Second: 8957.29864

Timestep Collection Time: 4.20609
Timestep Consumption Time: 1.37685
PPO Batch Consumption Time: 0.19001
Total Iteration Time: 5.58293

Cumulative Model Updates: 5499
Cumulative Timesteps: 91792910

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00977
Policy Entropy: 1.16936
Value Function Loss: 0.10502

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.05972
Value Function Update Magnitude: 0.07146

Collected Steps per Second: 11954.42424
Overall Steps per Second: 9054.85075

Timestep Collection Time: 4.18707
Timestep Consumption Time: 1.34080
PPO Batch Consumption Time: 0.16240
Total Iteration Time: 5.52787

Cumulative Model Updates: 5502
Cumulative Timesteps: 91842964

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 91842964...
Checkpoint 91842964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16026
Policy Entropy: 1.18486
Value Function Loss: 0.08685

Mean KL Divergence: 0.01935
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.06063
Value Function Update Magnitude: 0.07309

Collected Steps per Second: 13213.41140
Overall Steps per Second: 10055.04883

Timestep Collection Time: 3.78555
Timestep Consumption Time: 1.18907
PPO Batch Consumption Time: 0.16199
Total Iteration Time: 4.97462

Cumulative Model Updates: 5505
Cumulative Timesteps: 91892984

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03440
Policy Entropy: 1.16842
Value Function Loss: 0.08051

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.07263

Collected Steps per Second: 13362.95929
Overall Steps per Second: 10220.59230

Timestep Collection Time: 3.74423
Timestep Consumption Time: 1.15118
PPO Batch Consumption Time: 0.15040
Total Iteration Time: 4.89541

Cumulative Model Updates: 5508
Cumulative Timesteps: 91943018

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 91943018...
Checkpoint 91943018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06107
Policy Entropy: 1.17292
Value Function Loss: 0.09215

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 13401.35823
Overall Steps per Second: 10049.12224

Timestep Collection Time: 3.73126
Timestep Consumption Time: 1.24469
PPO Batch Consumption Time: 0.15426
Total Iteration Time: 4.97596

Cumulative Model Updates: 5511
Cumulative Timesteps: 91993022

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02917
Policy Entropy: 1.17265
Value Function Loss: 0.08641

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.07436

Collected Steps per Second: 13086.88111
Overall Steps per Second: 10639.83512

Timestep Collection Time: 3.82154
Timestep Consumption Time: 0.87891
PPO Batch Consumption Time: 0.06474
Total Iteration Time: 4.70045

Cumulative Model Updates: 5514
Cumulative Timesteps: 92043034

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 92043034...
Checkpoint 92043034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04053
Policy Entropy: 1.16344
Value Function Loss: 0.08826

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 11870.47173
Overall Steps per Second: 9122.50033

Timestep Collection Time: 4.21550
Timestep Consumption Time: 1.26984
PPO Batch Consumption Time: 0.15568
Total Iteration Time: 5.48534

Cumulative Model Updates: 5517
Cumulative Timesteps: 92093074

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04314
Policy Entropy: 1.15832
Value Function Loss: 0.07307

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.07727

Collected Steps per Second: 13420.56567
Overall Steps per Second: 10870.56219

Timestep Collection Time: 3.72741
Timestep Consumption Time: 0.87437
PPO Batch Consumption Time: 0.06140
Total Iteration Time: 4.60179

Cumulative Model Updates: 5520
Cumulative Timesteps: 92143098

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 92143098...
Checkpoint 92143098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01778
Policy Entropy: 1.15533
Value Function Loss: 0.08679

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.07949

Collected Steps per Second: 12411.34069
Overall Steps per Second: 9682.27511

Timestep Collection Time: 4.03067
Timestep Consumption Time: 1.13609
PPO Batch Consumption Time: 0.14849
Total Iteration Time: 5.16676

Cumulative Model Updates: 5523
Cumulative Timesteps: 92193124

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08227
Policy Entropy: 1.16396
Value Function Loss: 0.08616

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06003
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.08657

Collected Steps per Second: 12823.71525
Overall Steps per Second: 10396.08257

Timestep Collection Time: 3.90152
Timestep Consumption Time: 0.91106
PPO Batch Consumption Time: 0.06334
Total Iteration Time: 4.81258

Cumulative Model Updates: 5526
Cumulative Timesteps: 92243156

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 92243156...
Checkpoint 92243156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04797
Policy Entropy: 1.15608
Value Function Loss: 0.09343

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.08678

Collected Steps per Second: 12317.78537
Overall Steps per Second: 9330.70672

Timestep Collection Time: 4.06242
Timestep Consumption Time: 1.30052
PPO Batch Consumption Time: 0.18453
Total Iteration Time: 5.36294

Cumulative Model Updates: 5529
Cumulative Timesteps: 92293196

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08500
Policy Entropy: 1.16456
Value Function Loss: 0.10848

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.08154

Collected Steps per Second: 13498.56991
Overall Steps per Second: 10883.02081

Timestep Collection Time: 3.70558
Timestep Consumption Time: 0.89057
PPO Batch Consumption Time: 0.06463
Total Iteration Time: 4.59615

Cumulative Model Updates: 5532
Cumulative Timesteps: 92343216

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 92343216...
Checkpoint 92343216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09233
Policy Entropy: 1.16073
Value Function Loss: 0.10778

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06608
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.08694

Collected Steps per Second: 12827.79437
Overall Steps per Second: 9635.41856

Timestep Collection Time: 3.89841
Timestep Consumption Time: 1.29161
PPO Batch Consumption Time: 0.17406
Total Iteration Time: 5.19002

Cumulative Model Updates: 5535
Cumulative Timesteps: 92393224

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11063
Policy Entropy: 1.16617
Value Function Loss: 0.11190

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.08902

Collected Steps per Second: 12717.27125
Overall Steps per Second: 9639.60930

Timestep Collection Time: 3.93276
Timestep Consumption Time: 1.25562
PPO Batch Consumption Time: 0.16818
Total Iteration Time: 5.18838

Cumulative Model Updates: 5538
Cumulative Timesteps: 92443238

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 92443238...
Checkpoint 92443238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00329
Policy Entropy: 1.17192
Value Function Loss: 0.10317

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.04935
Value Function Update Magnitude: 0.07587

Collected Steps per Second: 13524.63136
Overall Steps per Second: 10911.49511

Timestep Collection Time: 3.69888
Timestep Consumption Time: 0.88583
PPO Batch Consumption Time: 0.06378
Total Iteration Time: 4.58471

Cumulative Model Updates: 5541
Cumulative Timesteps: 92493264

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09274
Policy Entropy: 1.17507
Value Function Loss: 0.09275

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 12968.79260
Overall Steps per Second: 9618.88922

Timestep Collection Time: 3.85695
Timestep Consumption Time: 1.34323
PPO Batch Consumption Time: 0.19898
Total Iteration Time: 5.20018

Cumulative Model Updates: 5544
Cumulative Timesteps: 92543284

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 92543284...
Checkpoint 92543284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00173
Policy Entropy: 1.17215
Value Function Loss: 0.07514

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 13478.11605
Overall Steps per Second: 10521.75686

Timestep Collection Time: 3.71061
Timestep Consumption Time: 1.04259
PPO Batch Consumption Time: 0.13323
Total Iteration Time: 4.75320

Cumulative Model Updates: 5547
Cumulative Timesteps: 92593296

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03834
Policy Entropy: 1.17271
Value Function Loss: 0.06184

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08939
Policy Update Magnitude: 0.04685
Value Function Update Magnitude: 0.06816

Collected Steps per Second: 13257.17365
Overall Steps per Second: 9974.27464

Timestep Collection Time: 3.77200
Timestep Consumption Time: 1.24150
PPO Batch Consumption Time: 0.15832
Total Iteration Time: 5.01350

Cumulative Model Updates: 5550
Cumulative Timesteps: 92643302

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 92643302...
Checkpoint 92643302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13136
Policy Entropy: 1.17727
Value Function Loss: 0.07251

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06853
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.06613

Collected Steps per Second: 13167.02940
Overall Steps per Second: 10733.20214

Timestep Collection Time: 3.79903
Timestep Consumption Time: 0.86146
PPO Batch Consumption Time: 0.06460
Total Iteration Time: 4.66049

Cumulative Model Updates: 5553
Cumulative Timesteps: 92693324

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01999
Policy Entropy: 1.16794
Value Function Loss: 0.07237

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.04349
Value Function Update Magnitude: 0.07235

Collected Steps per Second: 12206.03575
Overall Steps per Second: 9392.61374

Timestep Collection Time: 4.10076
Timestep Consumption Time: 1.22832
PPO Batch Consumption Time: 0.14935
Total Iteration Time: 5.32908

Cumulative Model Updates: 5556
Cumulative Timesteps: 92743378

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 92743378...
Checkpoint 92743378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05912
Policy Entropy: 1.16300
Value Function Loss: 0.07596

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07614
Policy Update Magnitude: 0.04338
Value Function Update Magnitude: 0.06749

Collected Steps per Second: 12597.99832
Overall Steps per Second: 9655.58100

Timestep Collection Time: 3.96920
Timestep Consumption Time: 1.20956
PPO Batch Consumption Time: 0.15225
Total Iteration Time: 5.17877

Cumulative Model Updates: 5559
Cumulative Timesteps: 92793382

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20445
Policy Entropy: 1.16851
Value Function Loss: 0.07657

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06635
Policy Update Magnitude: 0.04532
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 13419.91506
Overall Steps per Second: 11059.56557

Timestep Collection Time: 3.72759
Timestep Consumption Time: 0.79555
PPO Batch Consumption Time: 0.06505
Total Iteration Time: 4.52314

Cumulative Model Updates: 5562
Cumulative Timesteps: 92843406

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 92843406...
Checkpoint 92843406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18290
Policy Entropy: 1.17939
Value Function Loss: 0.07930

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03953
Policy Update Magnitude: 0.04656
Value Function Update Magnitude: 0.08449

Collected Steps per Second: 11693.20150
Overall Steps per Second: 9174.33277

Timestep Collection Time: 4.27838
Timestep Consumption Time: 1.17466
PPO Batch Consumption Time: 0.13509
Total Iteration Time: 5.45304

Cumulative Model Updates: 5565
Cumulative Timesteps: 92893434

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19794
Policy Entropy: 1.17496
Value Function Loss: 0.07418

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04898
Policy Update Magnitude: 0.04652
Value Function Update Magnitude: 0.07937

Collected Steps per Second: 13440.30061
Overall Steps per Second: 10895.67849

Timestep Collection Time: 3.72135
Timestep Consumption Time: 0.86910
PPO Batch Consumption Time: 0.06493
Total Iteration Time: 4.59044

Cumulative Model Updates: 5568
Cumulative Timesteps: 92943450

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 92943450...
Checkpoint 92943450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.25210
Policy Entropy: 1.16604
Value Function Loss: 0.06754

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04720
Policy Update Magnitude: 0.04605
Value Function Update Magnitude: 0.07710

Collected Steps per Second: 12618.42624
Overall Steps per Second: 9650.22263

Timestep Collection Time: 3.96436
Timestep Consumption Time: 1.21935
PPO Batch Consumption Time: 0.15174
Total Iteration Time: 5.18371

Cumulative Model Updates: 5571
Cumulative Timesteps: 92993474

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09607
Policy Entropy: 1.16438
Value Function Loss: 0.08109

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05102
Policy Update Magnitude: 0.04847
Value Function Update Magnitude: 0.07494

Collected Steps per Second: 13414.22583
Overall Steps per Second: 10818.97056

Timestep Collection Time: 3.72903
Timestep Consumption Time: 0.89452
PPO Batch Consumption Time: 0.06104
Total Iteration Time: 4.62355

Cumulative Model Updates: 5574
Cumulative Timesteps: 93043496

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 93043496...
Checkpoint 93043496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00614
Policy Entropy: 1.16403
Value Function Loss: 0.07583

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05438
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.08122

Collected Steps per Second: 11908.68089
Overall Steps per Second: 9354.59625

Timestep Collection Time: 4.20164
Timestep Consumption Time: 1.14717
PPO Batch Consumption Time: 0.15624
Total Iteration Time: 5.34881

Cumulative Model Updates: 5577
Cumulative Timesteps: 93093532

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20538
Policy Entropy: 1.16297
Value Function Loss: 0.07213

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06615
Policy Update Magnitude: 0.04808
Value Function Update Magnitude: 0.09107

Collected Steps per Second: 13252.25181
Overall Steps per Second: 10719.98945

Timestep Collection Time: 3.77551
Timestep Consumption Time: 0.89185
PPO Batch Consumption Time: 0.06507
Total Iteration Time: 4.66736

Cumulative Model Updates: 5580
Cumulative Timesteps: 93143566

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 93143566...
Checkpoint 93143566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15107
Policy Entropy: 1.16998
Value Function Loss: 0.06468

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04937
Policy Update Magnitude: 0.04718
Value Function Update Magnitude: 0.09282

Collected Steps per Second: 11630.97821
Overall Steps per Second: 9066.81968

Timestep Collection Time: 4.30007
Timestep Consumption Time: 1.21609
PPO Batch Consumption Time: 0.15189
Total Iteration Time: 5.51616

Cumulative Model Updates: 5583
Cumulative Timesteps: 93193580

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05833
Policy Entropy: 1.16632
Value Function Loss: 0.07864

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.09454

Collected Steps per Second: 13909.62754
Overall Steps per Second: 11115.87350

Timestep Collection Time: 3.59492
Timestep Consumption Time: 0.90351
PPO Batch Consumption Time: 0.06617
Total Iteration Time: 4.49843

Cumulative Model Updates: 5586
Cumulative Timesteps: 93243584

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 93243584...
Checkpoint 93243584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03955
Policy Entropy: 1.17544
Value Function Loss: 0.09021

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06229
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.09428

Collected Steps per Second: 12840.64316
Overall Steps per Second: 9861.09095

Timestep Collection Time: 3.89622
Timestep Consumption Time: 1.17725
PPO Batch Consumption Time: 0.13454
Total Iteration Time: 5.07348

Cumulative Model Updates: 5589
Cumulative Timesteps: 93293614

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01710
Policy Entropy: 1.18194
Value Function Loss: 0.09599

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06222
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.09805

Collected Steps per Second: 12096.89030
Overall Steps per Second: 9699.44922

Timestep Collection Time: 4.13528
Timestep Consumption Time: 1.02213
PPO Batch Consumption Time: 0.07764
Total Iteration Time: 5.15741

Cumulative Model Updates: 5592
Cumulative Timesteps: 93343638

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 93343638...
Checkpoint 93343638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03861
Policy Entropy: 1.17644
Value Function Loss: 0.09796

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06808
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.09024

Collected Steps per Second: 11484.34999
Overall Steps per Second: 8583.88301

Timestep Collection Time: 4.35584
Timestep Consumption Time: 1.47182
PPO Batch Consumption Time: 0.19054
Total Iteration Time: 5.82767

Cumulative Model Updates: 5595
Cumulative Timesteps: 93393662

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00598
Policy Entropy: 1.15777
Value Function Loss: 0.10636

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.08839

Collected Steps per Second: 11432.46965
Overall Steps per Second: 8979.95274

Timestep Collection Time: 4.37561
Timestep Consumption Time: 1.19502
PPO Batch Consumption Time: 0.13677
Total Iteration Time: 5.57063

Cumulative Model Updates: 5598
Cumulative Timesteps: 93443686

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 93443686...
Checkpoint 93443686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01978
Policy Entropy: 1.14600
Value Function Loss: 0.10036

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.08786

Collected Steps per Second: 12132.09996
Overall Steps per Second: 9305.18074

Timestep Collection Time: 4.12344
Timestep Consumption Time: 1.25270
PPO Batch Consumption Time: 0.18771
Total Iteration Time: 5.37614

Cumulative Model Updates: 5601
Cumulative Timesteps: 93493712

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07768
Policy Entropy: 1.13885
Value Function Loss: 0.09288

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.08477

Collected Steps per Second: 12681.05030
Overall Steps per Second: 9589.40089

Timestep Collection Time: 3.94494
Timestep Consumption Time: 1.27186
PPO Batch Consumption Time: 0.15902
Total Iteration Time: 5.21680

Cumulative Model Updates: 5604
Cumulative Timesteps: 93543738

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 93543738...
Checkpoint 93543738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12436
Policy Entropy: 1.14719
Value Function Loss: 0.08218

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07834
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.09122

Collected Steps per Second: 11374.10301
Overall Steps per Second: 8999.63681

Timestep Collection Time: 4.39736
Timestep Consumption Time: 1.16020
PPO Batch Consumption Time: 0.15416
Total Iteration Time: 5.55756

Cumulative Model Updates: 5607
Cumulative Timesteps: 93593754

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10906
Policy Entropy: 1.15878
Value Function Loss: 0.07683

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06603
Policy Update Magnitude: 0.05179
Value Function Update Magnitude: 0.09340

Collected Steps per Second: 12607.80661
Overall Steps per Second: 9582.35903

Timestep Collection Time: 3.96691
Timestep Consumption Time: 1.25248
PPO Batch Consumption Time: 0.13915
Total Iteration Time: 5.21938

Cumulative Model Updates: 5610
Cumulative Timesteps: 93643768

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 93643768...
Checkpoint 93643768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00559
Policy Entropy: 1.16121
Value Function Loss: 0.08557

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05126
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.09893

Collected Steps per Second: 13186.62001
Overall Steps per Second: 9770.57833

Timestep Collection Time: 3.79521
Timestep Consumption Time: 1.32690
PPO Batch Consumption Time: 0.16791
Total Iteration Time: 5.12211

Cumulative Model Updates: 5613
Cumulative Timesteps: 93693814

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08524
Policy Entropy: 1.15647
Value Function Loss: 0.08455

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.04989
Value Function Update Magnitude: 0.09783

Collected Steps per Second: 12552.98347
Overall Steps per Second: 9952.07931

Timestep Collection Time: 3.98471
Timestep Consumption Time: 1.04138
PPO Batch Consumption Time: 0.14259
Total Iteration Time: 5.02609

Cumulative Model Updates: 5616
Cumulative Timesteps: 93743834

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 93743834...
Checkpoint 93743834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05774
Policy Entropy: 1.15394
Value Function Loss: 0.09752

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.09879

Collected Steps per Second: 12928.51127
Overall Steps per Second: 10436.78801

Timestep Collection Time: 3.87144
Timestep Consumption Time: 0.92428
PPO Batch Consumption Time: 0.06501
Total Iteration Time: 4.79573

Cumulative Model Updates: 5619
Cumulative Timesteps: 93793886

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15077
Policy Entropy: 1.14940
Value Function Loss: 0.08384

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.04928
Value Function Update Magnitude: 0.10366

Collected Steps per Second: 11860.01627
Overall Steps per Second: 9282.05244

Timestep Collection Time: 4.21956
Timestep Consumption Time: 1.17192
PPO Batch Consumption Time: 0.14314
Total Iteration Time: 5.39148

Cumulative Model Updates: 5622
Cumulative Timesteps: 93843930

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 93843930...
Checkpoint 93843930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00263
Policy Entropy: 1.15854
Value Function Loss: 0.07953

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07701
Policy Update Magnitude: 0.05323
Value Function Update Magnitude: 0.09401

Collected Steps per Second: 12302.62906
Overall Steps per Second: 9335.21904

Timestep Collection Time: 4.06433
Timestep Consumption Time: 1.29194
PPO Batch Consumption Time: 0.15554
Total Iteration Time: 5.35627

Cumulative Model Updates: 5625
Cumulative Timesteps: 93893932

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00329
Policy Entropy: 1.15814
Value Function Loss: 0.06557

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.04981
Value Function Update Magnitude: 0.08952

Collected Steps per Second: 11667.55363
Overall Steps per Second: 9000.79936

Timestep Collection Time: 4.28693
Timestep Consumption Time: 1.27013
PPO Batch Consumption Time: 0.16532
Total Iteration Time: 5.55706

Cumulative Model Updates: 5628
Cumulative Timesteps: 93943950

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 93943950...
Checkpoint 93943950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05656
Policy Entropy: 1.16260
Value Function Loss: 0.08487

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.04578
Value Function Update Magnitude: 0.08741

Collected Steps per Second: 11217.30556
Overall Steps per Second: 8603.21526

Timestep Collection Time: 4.46025
Timestep Consumption Time: 1.35525
PPO Batch Consumption Time: 0.18675
Total Iteration Time: 5.81550

Cumulative Model Updates: 5631
Cumulative Timesteps: 93993982

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08750
Policy Entropy: 1.14837
Value Function Loss: 0.08308

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06662
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.09035

Collected Steps per Second: 11305.45459
Overall Steps per Second: 8742.11050

Timestep Collection Time: 4.42353
Timestep Consumption Time: 1.29706
PPO Batch Consumption Time: 0.16835
Total Iteration Time: 5.72059

Cumulative Model Updates: 5634
Cumulative Timesteps: 94043992

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 94043992...
Checkpoint 94043992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06076
Policy Entropy: 1.15038
Value Function Loss: 0.10353

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.09290

Collected Steps per Second: 11742.18913
Overall Steps per Second: 9171.90692

Timestep Collection Time: 4.26156
Timestep Consumption Time: 1.19423
PPO Batch Consumption Time: 0.13473
Total Iteration Time: 5.45579

Cumulative Model Updates: 5637
Cumulative Timesteps: 94094032

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09303
Policy Entropy: 1.15099
Value Function Loss: 0.10169

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.08928

Collected Steps per Second: 12177.31580
Overall Steps per Second: 9779.37798

Timestep Collection Time: 4.10665
Timestep Consumption Time: 1.00697
PPO Batch Consumption Time: 0.07586
Total Iteration Time: 5.11362

Cumulative Model Updates: 5640
Cumulative Timesteps: 94144040

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 94144040...
Checkpoint 94144040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02722
Policy Entropy: 1.13395
Value Function Loss: 0.10849

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.08308

Collected Steps per Second: 10481.83534
Overall Steps per Second: 8222.91147

Timestep Collection Time: 4.77226
Timestep Consumption Time: 1.31099
PPO Batch Consumption Time: 0.14475
Total Iteration Time: 6.08325

Cumulative Model Updates: 5643
Cumulative Timesteps: 94194062

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07817
Policy Entropy: 1.13829
Value Function Loss: 0.10458

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.08178

Collected Steps per Second: 11665.98682
Overall Steps per Second: 8943.46391

Timestep Collection Time: 4.28665
Timestep Consumption Time: 1.30492
PPO Batch Consumption Time: 0.14931
Total Iteration Time: 5.59157

Cumulative Model Updates: 5646
Cumulative Timesteps: 94244070

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 94244070...
Checkpoint 94244070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12092
Policy Entropy: 1.15429
Value Function Loss: 0.10062

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.07507

Collected Steps per Second: 11488.69742
Overall Steps per Second: 8994.46446

Timestep Collection Time: 4.35489
Timestep Consumption Time: 1.20764
PPO Batch Consumption Time: 0.13989
Total Iteration Time: 5.56253

Cumulative Model Updates: 5649
Cumulative Timesteps: 94294102

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01853
Policy Entropy: 1.15322
Value Function Loss: 0.09473

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.06683

Collected Steps per Second: 12480.85747
Overall Steps per Second: 9633.33450

Timestep Collection Time: 4.00758
Timestep Consumption Time: 1.18460
PPO Batch Consumption Time: 0.14219
Total Iteration Time: 5.19218

Cumulative Model Updates: 5652
Cumulative Timesteps: 94344120

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 94344120...
Checkpoint 94344120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04612
Policy Entropy: 1.14539
Value Function Loss: 0.09088

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.06495

Collected Steps per Second: 11863.79363
Overall Steps per Second: 9768.39816

Timestep Collection Time: 4.21636
Timestep Consumption Time: 0.90444
PPO Batch Consumption Time: 0.07668
Total Iteration Time: 5.12080

Cumulative Model Updates: 5655
Cumulative Timesteps: 94394142

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12669
Policy Entropy: 1.15047
Value Function Loss: 0.09116

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.07509

Collected Steps per Second: 11084.08074
Overall Steps per Second: 8491.99732

Timestep Collection Time: 4.51260
Timestep Consumption Time: 1.37742
PPO Batch Consumption Time: 0.17467
Total Iteration Time: 5.89002

Cumulative Model Updates: 5658
Cumulative Timesteps: 94444160

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 94444160...
Checkpoint 94444160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.28623
Policy Entropy: 1.16323
Value Function Loss: 0.08882

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.09350

Collected Steps per Second: 11803.38440
Overall Steps per Second: 9002.66050

Timestep Collection Time: 4.23980
Timestep Consumption Time: 1.31900
PPO Batch Consumption Time: 0.16208
Total Iteration Time: 5.55880

Cumulative Model Updates: 5661
Cumulative Timesteps: 94494204

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06775
Policy Entropy: 1.15444
Value Function Loss: 0.09325

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.08478

Collected Steps per Second: 11594.07191
Overall Steps per Second: 8930.10226

Timestep Collection Time: 4.31703
Timestep Consumption Time: 1.28783
PPO Batch Consumption Time: 0.14268
Total Iteration Time: 5.60486

Cumulative Model Updates: 5664
Cumulative Timesteps: 94544256

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 94544256...
Checkpoint 94544256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15210
Policy Entropy: 1.16740
Value Function Loss: 0.08223

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07823
Policy Update Magnitude: 0.04547
Value Function Update Magnitude: 0.07748

Collected Steps per Second: 12374.08870
Overall Steps per Second: 9844.80453

Timestep Collection Time: 4.04280
Timestep Consumption Time: 1.03866
PPO Batch Consumption Time: 0.07494
Total Iteration Time: 5.08146

Cumulative Model Updates: 5667
Cumulative Timesteps: 94594282

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08101
Policy Entropy: 1.16494
Value Function Loss: 0.08394

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06923
Policy Update Magnitude: 0.04755
Value Function Update Magnitude: 0.07495

Collected Steps per Second: 11024.14537
Overall Steps per Second: 8494.99214

Timestep Collection Time: 4.53641
Timestep Consumption Time: 1.35059
PPO Batch Consumption Time: 0.20107
Total Iteration Time: 5.88700

Cumulative Model Updates: 5670
Cumulative Timesteps: 94644292

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 94644292...
Checkpoint 94644292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06591
Policy Entropy: 1.15899
Value Function Loss: 0.08269

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06190
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.08441

Collected Steps per Second: 11556.58671
Overall Steps per Second: 8989.82605

Timestep Collection Time: 4.32861
Timestep Consumption Time: 1.23590
PPO Batch Consumption Time: 0.14140
Total Iteration Time: 5.56451

Cumulative Model Updates: 5673
Cumulative Timesteps: 94694316

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03135
Policy Entropy: 1.16068
Value Function Loss: 0.08139

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.08932

Collected Steps per Second: 11531.81160
Overall Steps per Second: 8911.91116

Timestep Collection Time: 4.33687
Timestep Consumption Time: 1.27494
PPO Batch Consumption Time: 0.15798
Total Iteration Time: 5.61182

Cumulative Model Updates: 5676
Cumulative Timesteps: 94744328

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 94744328...
Checkpoint 94744328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12561
Policy Entropy: 1.16642
Value Function Loss: 0.09010

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.08428

Collected Steps per Second: 13404.44428
Overall Steps per Second: 10793.88942

Timestep Collection Time: 3.73130
Timestep Consumption Time: 0.90243
PPO Batch Consumption Time: 0.06590
Total Iteration Time: 4.63373

Cumulative Model Updates: 5679
Cumulative Timesteps: 94794344

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03777
Policy Entropy: 1.16503
Value Function Loss: 0.10324

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04761
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.07963

Collected Steps per Second: 12239.27028
Overall Steps per Second: 9358.94793

Timestep Collection Time: 4.08537
Timestep Consumption Time: 1.25732
PPO Batch Consumption Time: 0.16440
Total Iteration Time: 5.34269

Cumulative Model Updates: 5682
Cumulative Timesteps: 94844346

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 94844346...
Checkpoint 94844346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08808
Policy Entropy: 1.17684
Value Function Loss: 0.11510

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.08707

Collected Steps per Second: 12934.53356
Overall Steps per Second: 10047.42844

Timestep Collection Time: 3.86779
Timestep Consumption Time: 1.11140
PPO Batch Consumption Time: 0.14020
Total Iteration Time: 4.97918

Cumulative Model Updates: 5685
Cumulative Timesteps: 94894374

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20691
Policy Entropy: 1.18548
Value Function Loss: 0.11837

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06933
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.09369

Collected Steps per Second: 13635.32005
Overall Steps per Second: 10952.44987

Timestep Collection Time: 3.66973
Timestep Consumption Time: 0.89892
PPO Batch Consumption Time: 0.06257
Total Iteration Time: 4.56866

Cumulative Model Updates: 5688
Cumulative Timesteps: 94944412

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 94944412...
Checkpoint 94944412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06709
Policy Entropy: 1.17638
Value Function Loss: 0.11312

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05099
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.08767

Collected Steps per Second: 12280.93830
Overall Steps per Second: 9547.62549

Timestep Collection Time: 4.07249
Timestep Consumption Time: 1.16588
PPO Batch Consumption Time: 0.14406
Total Iteration Time: 5.23837

Cumulative Model Updates: 5691
Cumulative Timesteps: 94994426

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05964
Policy Entropy: 1.16249
Value Function Loss: 0.09245

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.09123

Collected Steps per Second: 13539.36360
Overall Steps per Second: 10287.81773

Timestep Collection Time: 3.69604
Timestep Consumption Time: 1.16816
PPO Batch Consumption Time: 0.16298
Total Iteration Time: 4.86420

Cumulative Model Updates: 5694
Cumulative Timesteps: 95044468

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 95044468...
Checkpoint 95044468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08700
Policy Entropy: 1.15715
Value Function Loss: 0.08369

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06401
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.09062

Collected Steps per Second: 13507.61755
Overall Steps per Second: 10244.59182

Timestep Collection Time: 3.70295
Timestep Consumption Time: 1.17943
PPO Batch Consumption Time: 0.13872
Total Iteration Time: 4.88238

Cumulative Model Updates: 5697
Cumulative Timesteps: 95094486

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03546
Policy Entropy: 1.15653
Value Function Loss: 0.06932

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05579
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.08668

Collected Steps per Second: 12965.93909
Overall Steps per Second: 9685.60460

Timestep Collection Time: 3.85965
Timestep Consumption Time: 1.30719
PPO Batch Consumption Time: 0.18612
Total Iteration Time: 5.16684

Cumulative Model Updates: 5700
Cumulative Timesteps: 95144530

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 95144530...
Checkpoint 95144530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08307
Policy Entropy: 1.15686
Value Function Loss: 0.07828

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.04865
Value Function Update Magnitude: 0.08169

Collected Steps per Second: 13832.97852
Overall Steps per Second: 11090.20438

Timestep Collection Time: 3.61600
Timestep Consumption Time: 0.89429
PPO Batch Consumption Time: 0.06787
Total Iteration Time: 4.51029

Cumulative Model Updates: 5703
Cumulative Timesteps: 95194550

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11597
Policy Entropy: 1.16434
Value Function Loss: 0.08760

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06486
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.07884

Collected Steps per Second: 12537.62638
Overall Steps per Second: 9444.99610

Timestep Collection Time: 3.98816
Timestep Consumption Time: 1.30586
PPO Batch Consumption Time: 0.17252
Total Iteration Time: 5.29402

Cumulative Model Updates: 5706
Cumulative Timesteps: 95244552

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 95244552...
Checkpoint 95244552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04953
Policy Entropy: 1.16164
Value Function Loss: 0.08925

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04569
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.08275

Collected Steps per Second: 13399.13085
Overall Steps per Second: 10053.83245

Timestep Collection Time: 3.73442
Timestep Consumption Time: 1.24259
PPO Batch Consumption Time: 0.17100
Total Iteration Time: 4.97701

Cumulative Model Updates: 5709
Cumulative Timesteps: 95294590

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03028
Policy Entropy: 1.15580
Value Function Loss: 0.08575

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04286
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.07638

Collected Steps per Second: 12371.15186
Overall Steps per Second: 10105.47600

Timestep Collection Time: 4.04231
Timestep Consumption Time: 0.90630
PPO Batch Consumption Time: 0.07190
Total Iteration Time: 4.94860

Cumulative Model Updates: 5712
Cumulative Timesteps: 95344598

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 95344598...
Checkpoint 95344598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05910
Policy Entropy: 1.14824
Value Function Loss: 0.09116

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.06893

Collected Steps per Second: 13103.92322
Overall Steps per Second: 9946.52789

Timestep Collection Time: 3.81825
Timestep Consumption Time: 1.21205
PPO Batch Consumption Time: 0.15172
Total Iteration Time: 5.03030

Cumulative Model Updates: 5715
Cumulative Timesteps: 95394632

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00074
Policy Entropy: 1.15931
Value Function Loss: 0.11130

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06915
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.06925

Collected Steps per Second: 14061.27924
Overall Steps per Second: 10422.43229

Timestep Collection Time: 3.55714
Timestep Consumption Time: 1.24193
PPO Batch Consumption Time: 0.16820
Total Iteration Time: 4.79907

Cumulative Model Updates: 5718
Cumulative Timesteps: 95444650

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 95444650...
Checkpoint 95444650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13918
Policy Entropy: 1.17299
Value Function Loss: 0.11833

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05690
Policy Update Magnitude: 0.05937
Value Function Update Magnitude: 0.07298

Collected Steps per Second: 12802.89927
Overall Steps per Second: 9655.67529

Timestep Collection Time: 3.90802
Timestep Consumption Time: 1.27380
PPO Batch Consumption Time: 0.16793
Total Iteration Time: 5.18182

Cumulative Model Updates: 5721
Cumulative Timesteps: 95494684

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04130
Policy Entropy: 1.17187
Value Function Loss: 0.11347

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.07007

Collected Steps per Second: 13363.02716
Overall Steps per Second: 10977.36925

Timestep Collection Time: 3.74526
Timestep Consumption Time: 0.81394
PPO Batch Consumption Time: 0.06467
Total Iteration Time: 4.55920

Cumulative Model Updates: 5724
Cumulative Timesteps: 95544732

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 95544732...
Checkpoint 95544732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06914
Policy Entropy: 1.17133
Value Function Loss: 0.10322

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05273
Policy Update Magnitude: 0.06186
Value Function Update Magnitude: 0.06326

Collected Steps per Second: 13184.98408
Overall Steps per Second: 9973.79958

Timestep Collection Time: 3.79462
Timestep Consumption Time: 1.22172
PPO Batch Consumption Time: 0.15142
Total Iteration Time: 5.01634

Cumulative Model Updates: 5727
Cumulative Timesteps: 95594764

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11430
Policy Entropy: 1.15776
Value Function Loss: 0.10258

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.06296

Collected Steps per Second: 13334.93620
Overall Steps per Second: 10774.76330

Timestep Collection Time: 3.75285
Timestep Consumption Time: 0.89171
PPO Batch Consumption Time: 0.06669
Total Iteration Time: 4.64456

Cumulative Model Updates: 5730
Cumulative Timesteps: 95644808

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 95644808...
Checkpoint 95644808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00524
Policy Entropy: 1.16307
Value Function Loss: 0.09579

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06130
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.07234

Collected Steps per Second: 12024.93519
Overall Steps per Second: 9381.70303

Timestep Collection Time: 4.15952
Timestep Consumption Time: 1.17192
PPO Batch Consumption Time: 0.13673
Total Iteration Time: 5.33144

Cumulative Model Updates: 5733
Cumulative Timesteps: 95694826

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15634
Policy Entropy: 1.15219
Value Function Loss: 0.09260

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06500
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.06996

Collected Steps per Second: 12574.61800
Overall Steps per Second: 10227.86842

Timestep Collection Time: 3.97642
Timestep Consumption Time: 0.91238
PPO Batch Consumption Time: 0.06923
Total Iteration Time: 4.88880

Cumulative Model Updates: 5736
Cumulative Timesteps: 95744828

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 95744828...
Checkpoint 95744828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06130
Policy Entropy: 1.15266
Value Function Loss: 0.07448

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05769
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.07511

Collected Steps per Second: 12189.14434
Overall Steps per Second: 9478.64275

Timestep Collection Time: 4.10431
Timestep Consumption Time: 1.17366
PPO Batch Consumption Time: 0.16465
Total Iteration Time: 5.27797

Cumulative Model Updates: 5739
Cumulative Timesteps: 95794856

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08199
Policy Entropy: 1.15752
Value Function Loss: 0.07312

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06869
Policy Update Magnitude: 0.05866
Value Function Update Magnitude: 0.07029

Collected Steps per Second: 13465.71399
Overall Steps per Second: 10890.80847

Timestep Collection Time: 3.71373
Timestep Consumption Time: 0.87803
PPO Batch Consumption Time: 0.06152
Total Iteration Time: 4.59176

Cumulative Model Updates: 5742
Cumulative Timesteps: 95844864

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 95844864...
Checkpoint 95844864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06457
Policy Entropy: 1.16501
Value Function Loss: 0.08247

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06409
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 12781.17524
Overall Steps per Second: 9644.34311

Timestep Collection Time: 3.91435
Timestep Consumption Time: 1.27315
PPO Batch Consumption Time: 0.17375
Total Iteration Time: 5.18750

Cumulative Model Updates: 5745
Cumulative Timesteps: 95894894

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03809
Policy Entropy: 1.17717
Value Function Loss: 0.09059

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.05955
Policy Update Magnitude: 0.06001
Value Function Update Magnitude: 0.08809

Collected Steps per Second: 13979.76566
Overall Steps per Second: 11183.86083

Timestep Collection Time: 3.57789
Timestep Consumption Time: 0.89445
PPO Batch Consumption Time: 0.06278
Total Iteration Time: 4.47234

Cumulative Model Updates: 5748
Cumulative Timesteps: 95944912

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 95944912...
Checkpoint 95944912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05645
Policy Entropy: 1.16857
Value Function Loss: 0.07676

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06233
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.09823

Collected Steps per Second: 12076.74558
Overall Steps per Second: 9087.49698

Timestep Collection Time: 4.14234
Timestep Consumption Time: 1.36259
PPO Batch Consumption Time: 0.19660
Total Iteration Time: 5.50493

Cumulative Model Updates: 5751
Cumulative Timesteps: 95994938

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05948
Policy Entropy: 1.16891
Value Function Loss: 0.06926

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.06820
Policy Update Magnitude: 0.05188
Value Function Update Magnitude: 0.07927

Collected Steps per Second: 11633.17169
Overall Steps per Second: 9039.72123

Timestep Collection Time: 4.30063
Timestep Consumption Time: 1.23383
PPO Batch Consumption Time: 0.16674
Total Iteration Time: 5.53446

Cumulative Model Updates: 5754
Cumulative Timesteps: 96044968

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 96044968...
Checkpoint 96044968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00240
Policy Entropy: 1.15908
Value Function Loss: 0.06345

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.08001

Collected Steps per Second: 12118.75995
Overall Steps per Second: 9242.67311

Timestep Collection Time: 4.12881
Timestep Consumption Time: 1.28478
PPO Batch Consumption Time: 0.16184
Total Iteration Time: 5.41359

Cumulative Model Updates: 5757
Cumulative Timesteps: 96095004

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01493
Policy Entropy: 1.16774
Value Function Loss: 0.06138

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05281
Policy Update Magnitude: 0.04576
Value Function Update Magnitude: 0.08708

Collected Steps per Second: 12182.72315
Overall Steps per Second: 9328.64691

Timestep Collection Time: 4.10729
Timestep Consumption Time: 1.25662
PPO Batch Consumption Time: 0.14608
Total Iteration Time: 5.36391

Cumulative Model Updates: 5760
Cumulative Timesteps: 96145042

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 96145042...
Checkpoint 96145042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12179
Policy Entropy: 1.16720
Value Function Loss: 0.06498

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.03785
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.08412

Collected Steps per Second: 12292.49761
Overall Steps per Second: 9943.82564

Timestep Collection Time: 4.06801
Timestep Consumption Time: 0.96084
PPO Batch Consumption Time: 0.06814
Total Iteration Time: 5.02885

Cumulative Model Updates: 5763
Cumulative Timesteps: 96195048

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08222
Policy Entropy: 1.16491
Value Function Loss: 0.07491

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05051
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.08422

Collected Steps per Second: 11237.37344
Overall Steps per Second: 8622.66746

Timestep Collection Time: 4.45122
Timestep Consumption Time: 1.34977
PPO Batch Consumption Time: 0.15894
Total Iteration Time: 5.80099

Cumulative Model Updates: 5766
Cumulative Timesteps: 96245068

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 96245068...
Checkpoint 96245068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04827
Policy Entropy: 1.16528
Value Function Loss: 0.09987

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05206
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.09461

Collected Steps per Second: 11021.93067
Overall Steps per Second: 8684.55619

Timestep Collection Time: 4.53786
Timestep Consumption Time: 1.22133
PPO Batch Consumption Time: 0.15370
Total Iteration Time: 5.75919

Cumulative Model Updates: 5769
Cumulative Timesteps: 96295084

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03226
Policy Entropy: 1.16539
Value Function Loss: 0.09924

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05681
Policy Update Magnitude: 0.05491
Value Function Update Magnitude: 0.11042

Collected Steps per Second: 11938.49342
Overall Steps per Second: 9644.79215

Timestep Collection Time: 4.18813
Timestep Consumption Time: 0.99601
PPO Batch Consumption Time: 0.07903
Total Iteration Time: 5.18414

Cumulative Model Updates: 5772
Cumulative Timesteps: 96345084

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 96345084...
Checkpoint 96345084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01013
Policy Entropy: 1.17030
Value Function Loss: 0.10759

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.11242

Collected Steps per Second: 11597.61958
Overall Steps per Second: 8911.61134

Timestep Collection Time: 4.31313
Timestep Consumption Time: 1.30000
PPO Batch Consumption Time: 0.14769
Total Iteration Time: 5.61313

Cumulative Model Updates: 5775
Cumulative Timesteps: 96395106

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19605
Policy Entropy: 1.16306
Value Function Loss: 0.11256

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06163
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.10096

Collected Steps per Second: 11786.40740
Overall Steps per Second: 9526.83735

Timestep Collection Time: 4.24370
Timestep Consumption Time: 1.00652
PPO Batch Consumption Time: 0.07420
Total Iteration Time: 5.25022

Cumulative Model Updates: 5778
Cumulative Timesteps: 96445124

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 96445124...
Checkpoint 96445124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08663
Policy Entropy: 1.15920
Value Function Loss: 0.11900

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06023
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.09789

Collected Steps per Second: 10739.57595
Overall Steps per Second: 8431.69819

Timestep Collection Time: 4.65903
Timestep Consumption Time: 1.27524
PPO Batch Consumption Time: 0.14805
Total Iteration Time: 5.93427

Cumulative Model Updates: 5781
Cumulative Timesteps: 96495160

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02020
Policy Entropy: 1.17669
Value Function Loss: 0.12036

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.10012

Collected Steps per Second: 11616.69774
Overall Steps per Second: 8940.26474

Timestep Collection Time: 4.30708
Timestep Consumption Time: 1.28940
PPO Batch Consumption Time: 0.16693
Total Iteration Time: 5.59648

Cumulative Model Updates: 5784
Cumulative Timesteps: 96545194

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 96545194...
Checkpoint 96545194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05945
Policy Entropy: 1.17411
Value Function Loss: 0.11063

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.09162

Collected Steps per Second: 12043.44170
Overall Steps per Second: 9054.30526

Timestep Collection Time: 4.15529
Timestep Consumption Time: 1.37180
PPO Batch Consumption Time: 0.14761
Total Iteration Time: 5.52709

Cumulative Model Updates: 5787
Cumulative Timesteps: 96595238

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.23373
Policy Entropy: 1.18342
Value Function Loss: 0.11392

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05260
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.10236

Collected Steps per Second: 11748.36036
Overall Steps per Second: 9037.41041

Timestep Collection Time: 4.25608
Timestep Consumption Time: 1.27670
PPO Batch Consumption Time: 0.16368
Total Iteration Time: 5.53278

Cumulative Model Updates: 5790
Cumulative Timesteps: 96645240

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 96645240...
Checkpoint 96645240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11428
Policy Entropy: 1.16475
Value Function Loss: 0.10822

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04281
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.10581

Collected Steps per Second: 12003.20677
Overall Steps per Second: 9120.56995

Timestep Collection Time: 4.16789
Timestep Consumption Time: 1.31730
PPO Batch Consumption Time: 0.14441
Total Iteration Time: 5.48518

Cumulative Model Updates: 5793
Cumulative Timesteps: 96695268

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05168
Policy Entropy: 1.17981
Value Function Loss: 0.09552

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06449
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.10782

Collected Steps per Second: 11274.47357
Overall Steps per Second: 8637.75006

Timestep Collection Time: 4.43675
Timestep Consumption Time: 1.35434
PPO Batch Consumption Time: 0.14951
Total Iteration Time: 5.79109

Cumulative Model Updates: 5796
Cumulative Timesteps: 96745290

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 96745290...
Checkpoint 96745290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00394
Policy Entropy: 1.17680
Value Function Loss: 0.08384

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.05877
Value Function Update Magnitude: 0.09659

Collected Steps per Second: 12207.99928
Overall Steps per Second: 9973.39562

Timestep Collection Time: 4.09731
Timestep Consumption Time: 0.91803
PPO Batch Consumption Time: 0.06735
Total Iteration Time: 5.01534

Cumulative Model Updates: 5799
Cumulative Timesteps: 96795310

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05988
Policy Entropy: 1.17767
Value Function Loss: 0.08357

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06029
Policy Update Magnitude: 0.05573
Value Function Update Magnitude: 0.08504

Collected Steps per Second: 11789.56255
Overall Steps per Second: 8986.97584

Timestep Collection Time: 4.24138
Timestep Consumption Time: 1.32267
PPO Batch Consumption Time: 0.14575
Total Iteration Time: 5.56405

Cumulative Model Updates: 5802
Cumulative Timesteps: 96845314

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 96845314...
Checkpoint 96845314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01893
Policy Entropy: 1.17036
Value Function Loss: 0.08798

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.05030
Value Function Update Magnitude: 0.08057

Collected Steps per Second: 12142.35775
Overall Steps per Second: 10014.32677

Timestep Collection Time: 4.11798
Timestep Consumption Time: 0.87507
PPO Batch Consumption Time: 0.06595
Total Iteration Time: 4.99305

Cumulative Model Updates: 5805
Cumulative Timesteps: 96895316

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13672
Policy Entropy: 1.18474
Value Function Loss: 0.09118

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.04956
Policy Update Magnitude: 0.04879
Value Function Update Magnitude: 0.08091

Collected Steps per Second: 12498.75942
Overall Steps per Second: 9668.10994

Timestep Collection Time: 4.00312
Timestep Consumption Time: 1.17204
PPO Batch Consumption Time: 0.13519
Total Iteration Time: 5.17516

Cumulative Model Updates: 5808
Cumulative Timesteps: 96945350

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 96945350...
Checkpoint 96945350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12686
Policy Entropy: 1.18104
Value Function Loss: 0.08106

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.04632
Value Function Update Magnitude: 0.08092

Collected Steps per Second: 13187.84049
Overall Steps per Second: 10630.39948

Timestep Collection Time: 3.79365
Timestep Consumption Time: 0.91267
PPO Batch Consumption Time: 0.06834
Total Iteration Time: 4.70631

Cumulative Model Updates: 5811
Cumulative Timesteps: 96995380

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08782
Policy Entropy: 1.17820
Value Function Loss: 0.06327

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.04468
Value Function Update Magnitude: 0.08451

Collected Steps per Second: 13355.30321
Overall Steps per Second: 10271.49555

Timestep Collection Time: 3.74563
Timestep Consumption Time: 1.12455
PPO Batch Consumption Time: 0.14730
Total Iteration Time: 4.87018

Cumulative Model Updates: 5814
Cumulative Timesteps: 97045404

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 97045404...
Checkpoint 97045404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01569
Policy Entropy: 1.17881
Value Function Loss: 0.06716

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.04449
Value Function Update Magnitude: 0.07852

Collected Steps per Second: 13737.00859
Overall Steps per Second: 11025.42877

Timestep Collection Time: 3.64155
Timestep Consumption Time: 0.89560
PPO Batch Consumption Time: 0.06648
Total Iteration Time: 4.53715

Cumulative Model Updates: 5817
Cumulative Timesteps: 97095428

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08930
Policy Entropy: 1.18422
Value Function Loss: 0.08397

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.04254
Value Function Update Magnitude: 0.06849

Collected Steps per Second: 13246.16318
Overall Steps per Second: 9920.73629

Timestep Collection Time: 3.77664
Timestep Consumption Time: 1.26593
PPO Batch Consumption Time: 0.17062
Total Iteration Time: 5.04257

Cumulative Model Updates: 5820
Cumulative Timesteps: 97145454

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 97145454...
Checkpoint 97145454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10605
Policy Entropy: 1.17466
Value Function Loss: 0.09719

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.04402
Value Function Update Magnitude: 0.07123

Collected Steps per Second: 13542.40077
Overall Steps per Second: 10919.03451

Timestep Collection Time: 3.69314
Timestep Consumption Time: 0.88730
PPO Batch Consumption Time: 0.06280
Total Iteration Time: 4.58044

Cumulative Model Updates: 5823
Cumulative Timesteps: 97195468

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02905
Policy Entropy: 1.17712
Value Function Loss: 0.09451

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05922
Policy Update Magnitude: 0.04637
Value Function Update Magnitude: 0.07509

Collected Steps per Second: 11387.07385
Overall Steps per Second: 8975.79732

Timestep Collection Time: 4.39375
Timestep Consumption Time: 1.18035
PPO Batch Consumption Time: 0.15147
Total Iteration Time: 5.57410

Cumulative Model Updates: 5826
Cumulative Timesteps: 97245500

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 97245500...
Checkpoint 97245500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11586
Policy Entropy: 1.17956
Value Function Loss: 0.08121

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04577
Policy Update Magnitude: 0.04761
Value Function Update Magnitude: 0.07384

Collected Steps per Second: 12325.02113
Overall Steps per Second: 10053.84434

Timestep Collection Time: 4.06068
Timestep Consumption Time: 0.91731
PPO Batch Consumption Time: 0.07165
Total Iteration Time: 4.97800

Cumulative Model Updates: 5829
Cumulative Timesteps: 97295548

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05952
Policy Entropy: 1.17940
Value Function Loss: 0.06804

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04863
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.07803

Collected Steps per Second: 11292.73320
Overall Steps per Second: 8591.74157

Timestep Collection Time: 4.42922
Timestep Consumption Time: 1.39242
PPO Batch Consumption Time: 0.17015
Total Iteration Time: 5.82164

Cumulative Model Updates: 5832
Cumulative Timesteps: 97345566

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 97345566...
Checkpoint 97345566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15433
Policy Entropy: 1.18035
Value Function Loss: 0.05936

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05490
Policy Update Magnitude: 0.05136
Value Function Update Magnitude: 0.08956

Collected Steps per Second: 12080.58629
Overall Steps per Second: 9707.56155

Timestep Collection Time: 4.13970
Timestep Consumption Time: 1.01195
PPO Batch Consumption Time: 0.07966
Total Iteration Time: 5.15165

Cumulative Model Updates: 5835
Cumulative Timesteps: 97395576

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20770
Policy Entropy: 1.18364
Value Function Loss: 0.07033

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.06461
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.08806

Collected Steps per Second: 12199.51801
Overall Steps per Second: 9223.93687

Timestep Collection Time: 4.10246
Timestep Consumption Time: 1.32343
PPO Batch Consumption Time: 0.15938
Total Iteration Time: 5.42588

Cumulative Model Updates: 5838
Cumulative Timesteps: 97445624

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 97445624...
Checkpoint 97445624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08307
Policy Entropy: 1.17985
Value Function Loss: 0.08665

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07007
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.08864

Collected Steps per Second: 11533.34150
Overall Steps per Second: 8694.70675

Timestep Collection Time: 4.33821
Timestep Consumption Time: 1.41633
PPO Batch Consumption Time: 0.18142
Total Iteration Time: 5.75454

Cumulative Model Updates: 5841
Cumulative Timesteps: 97495658

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02013
Policy Entropy: 1.17373
Value Function Loss: 0.08866

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.05539
Policy Update Magnitude: 0.04820
Value Function Update Magnitude: 0.08145

Collected Steps per Second: 12159.08101
Overall Steps per Second: 9991.17761

Timestep Collection Time: 4.11363
Timestep Consumption Time: 0.89258
PPO Batch Consumption Time: 0.06998
Total Iteration Time: 5.00622

Cumulative Model Updates: 5844
Cumulative Timesteps: 97545676

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 97545676...
Checkpoint 97545676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.21365
Policy Entropy: 1.17333
Value Function Loss: 0.09210

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.05640
Policy Update Magnitude: 0.04775
Value Function Update Magnitude: 0.07502

Collected Steps per Second: 11415.61197
Overall Steps per Second: 8631.44667

Timestep Collection Time: 4.38102
Timestep Consumption Time: 1.41314
PPO Batch Consumption Time: 0.16874
Total Iteration Time: 5.79416

Cumulative Model Updates: 5847
Cumulative Timesteps: 97595688

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00900
Policy Entropy: 1.17802
Value Function Loss: 0.07932

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.07842

Collected Steps per Second: 12346.52375
Overall Steps per Second: 9990.42408

Timestep Collection Time: 4.05037
Timestep Consumption Time: 0.95522
PPO Batch Consumption Time: 0.06916
Total Iteration Time: 5.00559

Cumulative Model Updates: 5850
Cumulative Timesteps: 97645696

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 97645696...
Checkpoint 97645696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05426
Policy Entropy: 1.18428
Value Function Loss: 0.09024

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05195
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.07905

Collected Steps per Second: 11299.17543
Overall Steps per Second: 8674.42946

Timestep Collection Time: 4.42953
Timestep Consumption Time: 1.34031
PPO Batch Consumption Time: 0.16086
Total Iteration Time: 5.76983

Cumulative Model Updates: 5853
Cumulative Timesteps: 97695746

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11681
Policy Entropy: 1.17900
Value Function Loss: 0.09087

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07045
Policy Update Magnitude: 0.05054
Value Function Update Magnitude: 0.07222

Collected Steps per Second: 12017.42257
Overall Steps per Second: 9331.55522

Timestep Collection Time: 4.16429
Timestep Consumption Time: 1.19859
PPO Batch Consumption Time: 0.13722
Total Iteration Time: 5.36288

Cumulative Model Updates: 5856
Cumulative Timesteps: 97745790

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 97745790...
Checkpoint 97745790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17804
Policy Entropy: 1.18385
Value Function Loss: 0.10443

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06158
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.07407

Collected Steps per Second: 12080.07509
Overall Steps per Second: 9374.32681

Timestep Collection Time: 4.14087
Timestep Consumption Time: 1.19519
PPO Batch Consumption Time: 0.14257
Total Iteration Time: 5.33606

Cumulative Model Updates: 5859
Cumulative Timesteps: 97795812

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16125
Policy Entropy: 1.18203
Value Function Loss: 0.10476

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06438
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.08505

Collected Steps per Second: 11829.81160
Overall Steps per Second: 8946.84674

Timestep Collection Time: 4.22661
Timestep Consumption Time: 1.36195
PPO Batch Consumption Time: 0.16562
Total Iteration Time: 5.58856

Cumulative Model Updates: 5862
Cumulative Timesteps: 97845812

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 97845812...
Checkpoint 97845812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08300
Policy Entropy: 1.18695
Value Function Loss: 0.11292

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06524
Policy Update Magnitude: 0.05576
Value Function Update Magnitude: 0.07633

Collected Steps per Second: 12131.43215
Overall Steps per Second: 9184.17300

Timestep Collection Time: 4.12548
Timestep Consumption Time: 1.32389
PPO Batch Consumption Time: 0.16851
Total Iteration Time: 5.44937

Cumulative Model Updates: 5865
Cumulative Timesteps: 97895860

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00606
Policy Entropy: 1.17108
Value Function Loss: 0.11789

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.08407

Collected Steps per Second: 12031.22133
Overall Steps per Second: 9267.79844

Timestep Collection Time: 4.15669
Timestep Consumption Time: 1.23942
PPO Batch Consumption Time: 0.16465
Total Iteration Time: 5.39610

Cumulative Model Updates: 5868
Cumulative Timesteps: 97945870

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 97945870...
Checkpoint 97945870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04664
Policy Entropy: 1.17064
Value Function Loss: 0.11553

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.06502
Value Function Update Magnitude: 0.08190

Collected Steps per Second: 11889.73957
Overall Steps per Second: 8970.77724

Timestep Collection Time: 4.20699
Timestep Consumption Time: 1.36889
PPO Batch Consumption Time: 0.17135
Total Iteration Time: 5.57588

Cumulative Model Updates: 5871
Cumulative Timesteps: 97995890

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00927
Policy Entropy: 1.16136
Value Function Loss: 0.09212

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06395
Policy Update Magnitude: 0.06440
Value Function Update Magnitude: 0.08269

Collected Steps per Second: 12051.68105
Overall Steps per Second: 9806.94851

Timestep Collection Time: 4.15013
Timestep Consumption Time: 0.94993
PPO Batch Consumption Time: 0.07433
Total Iteration Time: 5.10006

Cumulative Model Updates: 5874
Cumulative Timesteps: 98045906

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 98045906...
Checkpoint 98045906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00972
Policy Entropy: 1.17192
Value Function Loss: 0.08593

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.07886

Collected Steps per Second: 11634.90220
Overall Steps per Second: 8813.49442

Timestep Collection Time: 4.30137
Timestep Consumption Time: 1.37697
PPO Batch Consumption Time: 0.17132
Total Iteration Time: 5.67834

Cumulative Model Updates: 5877
Cumulative Timesteps: 98095952

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04102
Policy Entropy: 1.18001
Value Function Loss: 0.07341

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05514
Policy Update Magnitude: 0.05121
Value Function Update Magnitude: 0.07664

Collected Steps per Second: 11827.45787
Overall Steps per Second: 9092.02614

Timestep Collection Time: 4.22762
Timestep Consumption Time: 1.27192
PPO Batch Consumption Time: 0.14017
Total Iteration Time: 5.49954

Cumulative Model Updates: 5880
Cumulative Timesteps: 98145954

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 98145954...
Checkpoint 98145954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02441
Policy Entropy: 1.17453
Value Function Loss: 0.07233

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04695
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.08183

Collected Steps per Second: 12650.78071
Overall Steps per Second: 9908.51201

Timestep Collection Time: 3.95312
Timestep Consumption Time: 1.09406
PPO Batch Consumption Time: 0.15783
Total Iteration Time: 5.04718

Cumulative Model Updates: 5883
Cumulative Timesteps: 98195964

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04159
Policy Entropy: 1.17216
Value Function Loss: 0.06991

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.05831
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.09008

Collected Steps per Second: 13134.81425
Overall Steps per Second: 9956.85197

Timestep Collection Time: 3.80911
Timestep Consumption Time: 1.21577
PPO Batch Consumption Time: 0.15082
Total Iteration Time: 5.02488

Cumulative Model Updates: 5886
Cumulative Timesteps: 98245996

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 98245996...
Checkpoint 98245996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04392
Policy Entropy: 1.17789
Value Function Loss: 0.07292

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.09729

Collected Steps per Second: 13346.93643
Overall Steps per Second: 10833.25895

Timestep Collection Time: 3.74992
Timestep Consumption Time: 0.87011
PPO Batch Consumption Time: 0.06574
Total Iteration Time: 4.62003

Cumulative Model Updates: 5889
Cumulative Timesteps: 98296046

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19827
Policy Entropy: 1.19847
Value Function Loss: 0.08370

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.09165

Collected Steps per Second: 12566.16505
Overall Steps per Second: 9677.38384

Timestep Collection Time: 3.98101
Timestep Consumption Time: 1.18836
PPO Batch Consumption Time: 0.13663
Total Iteration Time: 5.16937

Cumulative Model Updates: 5892
Cumulative Timesteps: 98346072

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 98346072...
Checkpoint 98346072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08827
Policy Entropy: 1.18944
Value Function Loss: 0.08912

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.08012

Collected Steps per Second: 13699.76194
Overall Steps per Second: 10521.26547

Timestep Collection Time: 3.64999
Timestep Consumption Time: 1.10267
PPO Batch Consumption Time: 0.13457
Total Iteration Time: 4.75266

Cumulative Model Updates: 5895
Cumulative Timesteps: 98396076

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08452
Policy Entropy: 1.18596
Value Function Loss: 0.08771

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.07647

Collected Steps per Second: 13398.00779
Overall Steps per Second: 10885.23309

Timestep Collection Time: 3.73399
Timestep Consumption Time: 0.86196
PPO Batch Consumption Time: 0.06273
Total Iteration Time: 4.59595

Cumulative Model Updates: 5898
Cumulative Timesteps: 98446104

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 98446104...
Checkpoint 98446104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04041
Policy Entropy: 1.19273
Value Function Loss: 0.08078

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.05172
Value Function Update Magnitude: 0.07743

Collected Steps per Second: 12253.31075
Overall Steps per Second: 9256.77750

Timestep Collection Time: 4.08298
Timestep Consumption Time: 1.32171
PPO Batch Consumption Time: 0.16218
Total Iteration Time: 5.40469

Cumulative Model Updates: 5901
Cumulative Timesteps: 98496134

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01061
Policy Entropy: 1.19568
Value Function Loss: 0.07473

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.04991
Value Function Update Magnitude: 0.06459

Collected Steps per Second: 13549.66308
Overall Steps per Second: 10931.37826

Timestep Collection Time: 3.69352
Timestep Consumption Time: 0.88467
PPO Batch Consumption Time: 0.06479
Total Iteration Time: 4.57820

Cumulative Model Updates: 5904
Cumulative Timesteps: 98546180

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 98546180...
Checkpoint 98546180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02439
Policy Entropy: 1.18799
Value Function Loss: 0.07010

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.06639

Collected Steps per Second: 11843.70136
Overall Steps per Second: 9276.23146

Timestep Collection Time: 4.22469
Timestep Consumption Time: 1.16931
PPO Batch Consumption Time: 0.14245
Total Iteration Time: 5.39400

Cumulative Model Updates: 5907
Cumulative Timesteps: 98596216

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05253
Policy Entropy: 1.17786
Value Function Loss: 0.07310

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.07077

Collected Steps per Second: 13204.27787
Overall Steps per Second: 10024.25260

Timestep Collection Time: 3.78953
Timestep Consumption Time: 1.20216
PPO Batch Consumption Time: 0.14685
Total Iteration Time: 4.99169

Cumulative Model Updates: 5910
Cumulative Timesteps: 98646254

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 98646254...
Checkpoint 98646254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13159
Policy Entropy: 1.19199
Value Function Loss: 0.07331

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 13640.00043
Overall Steps per Second: 10980.00687

Timestep Collection Time: 3.66613
Timestep Consumption Time: 0.88815
PPO Batch Consumption Time: 0.06535
Total Iteration Time: 4.55428

Cumulative Model Updates: 5913
Cumulative Timesteps: 98696260

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18830
Policy Entropy: 1.18627
Value Function Loss: 0.07669

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.05354
Value Function Update Magnitude: 0.07358

Collected Steps per Second: 13185.07602
Overall Steps per Second: 9946.68449

Timestep Collection Time: 3.79581
Timestep Consumption Time: 1.23582
PPO Batch Consumption Time: 0.15532
Total Iteration Time: 5.03163

Cumulative Model Updates: 5916
Cumulative Timesteps: 98746308

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 98746308...
Checkpoint 98746308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04446
Policy Entropy: 1.18680
Value Function Loss: 0.09111

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.06650
Value Function Update Magnitude: 0.06755

Collected Steps per Second: 13245.06857
Overall Steps per Second: 10682.32347

Timestep Collection Time: 3.77892
Timestep Consumption Time: 0.90658
PPO Batch Consumption Time: 0.06887
Total Iteration Time: 4.68550

Cumulative Model Updates: 5919
Cumulative Timesteps: 98796360

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05651
Policy Entropy: 1.19027
Value Function Loss: 0.09195

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07153
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 11995.19872
Overall Steps per Second: 9461.02491

Timestep Collection Time: 4.17117
Timestep Consumption Time: 1.11726
PPO Batch Consumption Time: 0.14436
Total Iteration Time: 5.28843

Cumulative Model Updates: 5922
Cumulative Timesteps: 98846394

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 98846394...
Checkpoint 98846394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08403
Policy Entropy: 1.19733
Value Function Loss: 0.10067

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07407
Policy Update Magnitude: 0.06654
Value Function Update Magnitude: 0.06209

Collected Steps per Second: 13257.26444
Overall Steps per Second: 10028.75644

Timestep Collection Time: 3.77242
Timestep Consumption Time: 1.21444
PPO Batch Consumption Time: 0.15054
Total Iteration Time: 4.98686

Cumulative Model Updates: 5925
Cumulative Timesteps: 98896406

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02476
Policy Entropy: 1.19151
Value Function Loss: 0.08002

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.06053
Value Function Update Magnitude: 0.06282

Collected Steps per Second: 13436.50007
Overall Steps per Second: 10897.60571

Timestep Collection Time: 3.72493
Timestep Consumption Time: 0.86782
PPO Batch Consumption Time: 0.06131
Total Iteration Time: 4.59275

Cumulative Model Updates: 5928
Cumulative Timesteps: 98946456

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 98946456...
Checkpoint 98946456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00852
Policy Entropy: 1.18788
Value Function Loss: 0.07301

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06232
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.06308

Collected Steps per Second: 12359.01060
Overall Steps per Second: 9308.76106

Timestep Collection Time: 4.04838
Timestep Consumption Time: 1.32655
PPO Batch Consumption Time: 0.18600
Total Iteration Time: 5.37494

Cumulative Model Updates: 5931
Cumulative Timesteps: 98996490

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10320
Policy Entropy: 1.17987
Value Function Loss: 0.07450

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.05042
Value Function Update Magnitude: 0.05162

Collected Steps per Second: 13361.06210
Overall Steps per Second: 10009.77129

Timestep Collection Time: 3.74401
Timestep Consumption Time: 1.25350
PPO Batch Consumption Time: 0.16279
Total Iteration Time: 4.99752

Cumulative Model Updates: 5934
Cumulative Timesteps: 99046514

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 99046514...
Checkpoint 99046514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00762
Policy Entropy: 1.19197
Value Function Loss: 0.08269

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06107
Policy Update Magnitude: 0.04916
Value Function Update Magnitude: 0.05426

Collected Steps per Second: 13453.61994
Overall Steps per Second: 10927.70091

Timestep Collection Time: 3.71736
Timestep Consumption Time: 0.85926
PPO Batch Consumption Time: 0.06217
Total Iteration Time: 4.57663

Cumulative Model Updates: 5937
Cumulative Timesteps: 99096526

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06384
Policy Entropy: 1.19506
Value Function Loss: 0.08456

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.05943

Collected Steps per Second: 12223.20021
Overall Steps per Second: 9252.10334

Timestep Collection Time: 4.09304
Timestep Consumption Time: 1.31438
PPO Batch Consumption Time: 0.15019
Total Iteration Time: 5.40742

Cumulative Model Updates: 5940
Cumulative Timesteps: 99146556

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 99146556...
Checkpoint 99146556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20886
Policy Entropy: 1.19470
Value Function Loss: 0.06831

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05469
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.05540

Collected Steps per Second: 13103.52701
Overall Steps per Second: 10041.44067

Timestep Collection Time: 3.81745
Timestep Consumption Time: 1.16411
PPO Batch Consumption Time: 0.13587
Total Iteration Time: 4.98156

Cumulative Model Updates: 5943
Cumulative Timesteps: 99196578

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02384
Policy Entropy: 1.18695
Value Function Loss: 0.06630

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06861
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.05582

Collected Steps per Second: 13331.32473
Overall Steps per Second: 10982.93234

Timestep Collection Time: 3.75207
Timestep Consumption Time: 0.80227
PPO Batch Consumption Time: 0.06360
Total Iteration Time: 4.55434

Cumulative Model Updates: 5946
Cumulative Timesteps: 99246598

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 99246598...
Checkpoint 99246598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00627
Policy Entropy: 1.18818
Value Function Loss: 0.06609

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.04905
Value Function Update Magnitude: 0.05488

Collected Steps per Second: 13159.28845
Overall Steps per Second: 9965.29548

Timestep Collection Time: 3.80309
Timestep Consumption Time: 1.21894
PPO Batch Consumption Time: 0.15281
Total Iteration Time: 5.02203

Cumulative Model Updates: 5949
Cumulative Timesteps: 99296644

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00004
Policy Entropy: 1.19443
Value Function Loss: 0.06663

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07510
Policy Update Magnitude: 0.04404
Value Function Update Magnitude: 0.05398

Collected Steps per Second: 13447.88467
Overall Steps per Second: 10891.92758

Timestep Collection Time: 3.72088
Timestep Consumption Time: 0.87316
PPO Batch Consumption Time: 0.06102
Total Iteration Time: 4.59404

Cumulative Model Updates: 5952
Cumulative Timesteps: 99346682

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 99346682...
Checkpoint 99346682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04264
Policy Entropy: 1.20049
Value Function Loss: 0.08973

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04717
Policy Update Magnitude: 0.04152
Value Function Update Magnitude: 0.05871

Collected Steps per Second: 12951.22250
Overall Steps per Second: 9661.67797

Timestep Collection Time: 3.86326
Timestep Consumption Time: 1.31534
PPO Batch Consumption Time: 0.18191
Total Iteration Time: 5.17860

Cumulative Model Updates: 5955
Cumulative Timesteps: 99396716

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01439
Policy Entropy: 1.20176
Value Function Loss: 0.10224

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06753
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.06566

Collected Steps per Second: 13764.72014
Overall Steps per Second: 10995.26923

Timestep Collection Time: 3.63378
Timestep Consumption Time: 0.91526
PPO Batch Consumption Time: 0.06778
Total Iteration Time: 4.54905

Cumulative Model Updates: 5958
Cumulative Timesteps: 99446734

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 99446734...
Checkpoint 99446734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04232
Policy Entropy: 1.20326
Value Function Loss: 0.10629

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06201
Policy Update Magnitude: 0.04622
Value Function Update Magnitude: 0.07012

Collected Steps per Second: 12384.14206
Overall Steps per Second: 9558.25349

Timestep Collection Time: 4.03920
Timestep Consumption Time: 1.19419
PPO Batch Consumption Time: 0.16020
Total Iteration Time: 5.23338

Cumulative Model Updates: 5961
Cumulative Timesteps: 99496756

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10265
Policy Entropy: 1.20713
Value Function Loss: 0.09053

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04900
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.06675

Collected Steps per Second: 12679.57641
Overall Steps per Second: 9593.45682

Timestep Collection Time: 3.94508
Timestep Consumption Time: 1.26909
PPO Batch Consumption Time: 0.08252
Total Iteration Time: 5.21418

Cumulative Model Updates: 5964
Cumulative Timesteps: 99546778

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 99546778...
Checkpoint 99546778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07495
Policy Entropy: 1.19833
Value Function Loss: 0.08507

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04571
Policy Update Magnitude: 0.05939
Value Function Update Magnitude: 0.07013

Collected Steps per Second: 13286.99356
Overall Steps per Second: 10147.32278

Timestep Collection Time: 3.76549
Timestep Consumption Time: 1.16507
PPO Batch Consumption Time: 0.16288
Total Iteration Time: 4.93056

Cumulative Model Updates: 5967
Cumulative Timesteps: 99596810

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04166
Policy Entropy: 1.19102
Value Function Loss: 0.08571

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.06414

Collected Steps per Second: 13921.42032
Overall Steps per Second: 10299.38893

Timestep Collection Time: 3.59317
Timestep Consumption Time: 1.26363
PPO Batch Consumption Time: 0.16913
Total Iteration Time: 4.85679

Cumulative Model Updates: 5970
Cumulative Timesteps: 99646832

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 99646832...
Checkpoint 99646832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15859
Policy Entropy: 1.18341
Value Function Loss: 0.09337

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.06616

Collected Steps per Second: 11656.61128
Overall Steps per Second: 8690.79044

Timestep Collection Time: 4.28941
Timestep Consumption Time: 1.46381
PPO Batch Consumption Time: 0.18750
Total Iteration Time: 5.75322

Cumulative Model Updates: 5973
Cumulative Timesteps: 99696832

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05781
Policy Entropy: 1.19528
Value Function Loss: 0.08598

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.06122
Value Function Update Magnitude: 0.07997

Collected Steps per Second: 11613.61258
Overall Steps per Second: 9072.25423

Timestep Collection Time: 4.30719
Timestep Consumption Time: 1.20655
PPO Batch Consumption Time: 0.16325
Total Iteration Time: 5.51373

Cumulative Model Updates: 5976
Cumulative Timesteps: 99746854

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 99746854...
Checkpoint 99746854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12410
Policy Entropy: 1.20852
Value Function Loss: 0.07451

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.16024
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.08090

Collected Steps per Second: 11747.82302
Overall Steps per Second: 8816.31143

Timestep Collection Time: 4.25849
Timestep Consumption Time: 1.41599
PPO Batch Consumption Time: 0.18346
Total Iteration Time: 5.67448

Cumulative Model Updates: 5979
Cumulative Timesteps: 99796882

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12808
Policy Entropy: 1.18415
Value Function Loss: 0.07156

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.08077

Collected Steps per Second: 12285.69893
Overall Steps per Second: 9896.39448

Timestep Collection Time: 4.07319
Timestep Consumption Time: 0.98340
PPO Batch Consumption Time: 0.07380
Total Iteration Time: 5.05659

Cumulative Model Updates: 5982
Cumulative Timesteps: 99846924

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 99846924...
Checkpoint 99846924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17724
Policy Entropy: 1.19899
Value Function Loss: 0.07599

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.09670

Collected Steps per Second: 10990.46003
Overall Steps per Second: 8445.71005

Timestep Collection Time: 4.54995
Timestep Consumption Time: 1.37093
PPO Batch Consumption Time: 0.17156
Total Iteration Time: 5.92088

Cumulative Model Updates: 5985
Cumulative Timesteps: 99896930

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07307
Policy Entropy: 1.19464
Value Function Loss: 0.08376

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.09150

Collected Steps per Second: 11927.64936
Overall Steps per Second: 8966.67996

Timestep Collection Time: 4.19379
Timestep Consumption Time: 1.38487
PPO Batch Consumption Time: 0.16884
Total Iteration Time: 5.57865

Cumulative Model Updates: 5988
Cumulative Timesteps: 99946952

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 99946952...
Checkpoint 99946952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11193
Policy Entropy: 1.19407
Value Function Loss: 0.08159

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.05425
Value Function Update Magnitude: 0.08043

Collected Steps per Second: 11902.69161
Overall Steps per Second: 8965.86118

Timestep Collection Time: 4.20426
Timestep Consumption Time: 1.37713
PPO Batch Consumption Time: 0.17989
Total Iteration Time: 5.58139

Cumulative Model Updates: 5991
Cumulative Timesteps: 99996994

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02331
Policy Entropy: 1.19178
Value Function Loss: 0.07586

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.05143
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 12493.80836
Overall Steps per Second: 10027.97802

Timestep Collection Time: 4.00374
Timestep Consumption Time: 0.98450
PPO Batch Consumption Time: 0.06982
Total Iteration Time: 4.98824

Cumulative Model Updates: 5994
Cumulative Timesteps: 100047016

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 100047016...
Checkpoint 100047016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18213
Policy Entropy: 1.19507
Value Function Loss: 0.06435

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06473
Policy Update Magnitude: 0.05140
Value Function Update Magnitude: 0.07422

Collected Steps per Second: 10905.68444
Overall Steps per Second: 8360.58166

Timestep Collection Time: 4.58660
Timestep Consumption Time: 1.39624
PPO Batch Consumption Time: 0.17389
Total Iteration Time: 5.98284

Cumulative Model Updates: 5997
Cumulative Timesteps: 100097036

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05192
Policy Entropy: 1.20634
Value Function Loss: 0.07721

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05609
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.07874

Collected Steps per Second: 11966.41128
Overall Steps per Second: 9486.74648

Timestep Collection Time: 4.18003
Timestep Consumption Time: 1.09259
PPO Batch Consumption Time: 0.13096
Total Iteration Time: 5.27262

Cumulative Model Updates: 6000
Cumulative Timesteps: 100147056

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 100147056...
Checkpoint 100147056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02319
Policy Entropy: 1.20148
Value Function Loss: 0.09643

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.08070

Collected Steps per Second: 11485.88572
Overall Steps per Second: 8882.52280

Timestep Collection Time: 4.35352
Timestep Consumption Time: 1.27596
PPO Batch Consumption Time: 0.16565
Total Iteration Time: 5.62948

Cumulative Model Updates: 6003
Cumulative Timesteps: 100197060

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05970
Policy Entropy: 1.20334
Value Function Loss: 0.09329

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.08283

Collected Steps per Second: 12120.33217
Overall Steps per Second: 9159.84231

Timestep Collection Time: 4.12728
Timestep Consumption Time: 1.33395
PPO Batch Consumption Time: 0.16181
Total Iteration Time: 5.46123

Cumulative Model Updates: 6006
Cumulative Timesteps: 100247084

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 100247084...
Checkpoint 100247084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13507
Policy Entropy: 1.20009
Value Function Loss: 0.08226

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.05325
Value Function Update Magnitude: 0.08198

Collected Steps per Second: 12086.06895
Overall Steps per Second: 8964.86830

Timestep Collection Time: 4.14030
Timestep Consumption Time: 1.44148
PPO Batch Consumption Time: 0.18564
Total Iteration Time: 5.58179

Cumulative Model Updates: 6009
Cumulative Timesteps: 100297124

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18876
Policy Entropy: 1.19499
Value Function Loss: 0.07459

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05220
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 11944.70709
Overall Steps per Second: 9668.62367

Timestep Collection Time: 4.18780
Timestep Consumption Time: 0.98585
PPO Batch Consumption Time: 0.07288
Total Iteration Time: 5.17364

Cumulative Model Updates: 6012
Cumulative Timesteps: 100347146

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 100347146...
Checkpoint 100347146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05216
Policy Entropy: 1.19347
Value Function Loss: 0.07554

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.04873
Value Function Update Magnitude: 0.07672

Collected Steps per Second: 11749.52168
Overall Steps per Second: 8922.14758

Timestep Collection Time: 4.25617
Timestep Consumption Time: 1.34876
PPO Batch Consumption Time: 0.16399
Total Iteration Time: 5.60493

Cumulative Model Updates: 6015
Cumulative Timesteps: 100397154

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11660
Policy Entropy: 1.19286
Value Function Loss: 0.07352

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06345
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.07686

Collected Steps per Second: 11691.51738
Overall Steps per Second: 9126.03788

Timestep Collection Time: 4.27729
Timestep Consumption Time: 1.20242
PPO Batch Consumption Time: 0.13547
Total Iteration Time: 5.47971

Cumulative Model Updates: 6018
Cumulative Timesteps: 100447162

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 100447162...
Checkpoint 100447162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09312
Policy Entropy: 1.18837
Value Function Loss: 0.06881

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.08128

Collected Steps per Second: 11644.90135
Overall Steps per Second: 9132.15346

Timestep Collection Time: 4.29785
Timestep Consumption Time: 1.18257
PPO Batch Consumption Time: 0.13778
Total Iteration Time: 5.48042

Cumulative Model Updates: 6021
Cumulative Timesteps: 100497210

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05449
Policy Entropy: 1.18254
Value Function Loss: 0.06657

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06317
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.07488

Collected Steps per Second: 12633.99375
Overall Steps per Second: 9837.05993

Timestep Collection Time: 3.96138
Timestep Consumption Time: 1.12632
PPO Batch Consumption Time: 0.16225
Total Iteration Time: 5.08770

Cumulative Model Updates: 6024
Cumulative Timesteps: 100547258

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 100547258...
Checkpoint 100547258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06945
Policy Entropy: 1.19097
Value Function Loss: 0.07332

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06037
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.08117

Collected Steps per Second: 13295.35994
Overall Steps per Second: 10040.54516

Timestep Collection Time: 3.76267
Timestep Consumption Time: 1.21973
PPO Batch Consumption Time: 0.16263
Total Iteration Time: 4.98240

Cumulative Model Updates: 6027
Cumulative Timesteps: 100597284

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09814
Policy Entropy: 1.18774
Value Function Loss: 0.07471

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.08939

Collected Steps per Second: 13330.33938
Overall Steps per Second: 10253.80980

Timestep Collection Time: 3.75429
Timestep Consumption Time: 1.12643
PPO Batch Consumption Time: 0.14581
Total Iteration Time: 4.88072

Cumulative Model Updates: 6030
Cumulative Timesteps: 100647330

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 100647330...
Checkpoint 100647330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00644
Policy Entropy: 1.19643
Value Function Loss: 0.07454

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.05845
Value Function Update Magnitude: 0.08926

Collected Steps per Second: 13723.46544
Overall Steps per Second: 11008.93706

Timestep Collection Time: 3.64602
Timestep Consumption Time: 0.89902
PPO Batch Consumption Time: 0.06838
Total Iteration Time: 4.54503

Cumulative Model Updates: 6033
Cumulative Timesteps: 100697366

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04296
Policy Entropy: 1.19426
Value Function Loss: 0.06250

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.07883

Collected Steps per Second: 12678.92898
Overall Steps per Second: 9525.29294

Timestep Collection Time: 3.94734
Timestep Consumption Time: 1.30689
PPO Batch Consumption Time: 0.17541
Total Iteration Time: 5.25422

Cumulative Model Updates: 6036
Cumulative Timesteps: 100747414

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 100747414...
Checkpoint 100747414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05998
Policy Entropy: 1.20028
Value Function Loss: 0.06981

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05390
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.07924

Collected Steps per Second: 13475.27691
Overall Steps per Second: 10442.59128

Timestep Collection Time: 3.71124
Timestep Consumption Time: 1.07780
PPO Batch Consumption Time: 0.13567
Total Iteration Time: 4.78904

Cumulative Model Updates: 6039
Cumulative Timesteps: 100797424

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01430
Policy Entropy: 1.19927
Value Function Loss: 0.08038

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07671
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.07778

Collected Steps per Second: 13302.16723
Overall Steps per Second: 10018.45803

Timestep Collection Time: 3.76029
Timestep Consumption Time: 1.23249
PPO Batch Consumption Time: 0.15892
Total Iteration Time: 4.99278

Cumulative Model Updates: 6042
Cumulative Timesteps: 100847444

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 100847444...
Checkpoint 100847444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00495
Policy Entropy: 1.21239
Value Function Loss: 0.08269

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.07687

Collected Steps per Second: 13546.51900
Overall Steps per Second: 10961.29480

Timestep Collection Time: 3.69349
Timestep Consumption Time: 0.87111
PPO Batch Consumption Time: 0.06459
Total Iteration Time: 4.56461

Cumulative Model Updates: 6045
Cumulative Timesteps: 100897478

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11441
Policy Entropy: 1.21980
Value Function Loss: 0.06733

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.06845

Collected Steps per Second: 13280.95219
Overall Steps per Second: 9975.40174

Timestep Collection Time: 3.76494
Timestep Consumption Time: 1.24759
PPO Batch Consumption Time: 0.15932
Total Iteration Time: 5.01253

Cumulative Model Updates: 6048
Cumulative Timesteps: 100947480

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 100947480...
Checkpoint 100947480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12474
Policy Entropy: 1.21350
Value Function Loss: 0.05775

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.06808

Collected Steps per Second: 13528.29395
Overall Steps per Second: 10853.71516

Timestep Collection Time: 3.69788
Timestep Consumption Time: 0.91123
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 4.60911

Cumulative Model Updates: 6051
Cumulative Timesteps: 100997506

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10765
Policy Entropy: 1.19885
Value Function Loss: 0.05766

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.06622

Collected Steps per Second: 11899.85442
Overall Steps per Second: 9310.00797

Timestep Collection Time: 4.20207
Timestep Consumption Time: 1.16893
PPO Batch Consumption Time: 0.16175
Total Iteration Time: 5.37099

Cumulative Model Updates: 6054
Cumulative Timesteps: 101047510

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 101047510...
Checkpoint 101047510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02633
Policy Entropy: 1.19534
Value Function Loss: 0.06033

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07041
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.07415

Collected Steps per Second: 12238.34173
Overall Steps per Second: 9297.01508

Timestep Collection Time: 4.08601
Timestep Consumption Time: 1.29270
PPO Batch Consumption Time: 0.17593
Total Iteration Time: 5.37872

Cumulative Model Updates: 6057
Cumulative Timesteps: 101097516

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03301
Policy Entropy: 1.19651
Value Function Loss: 0.07302

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.04526
Value Function Update Magnitude: 0.06775

Collected Steps per Second: 12857.12486
Overall Steps per Second: 9667.17478

Timestep Collection Time: 3.88889
Timestep Consumption Time: 1.28325
PPO Batch Consumption Time: 0.18078
Total Iteration Time: 5.17214

Cumulative Model Updates: 6060
Cumulative Timesteps: 101147516

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 101147516...
Checkpoint 101147516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04295
Policy Entropy: 1.18745
Value Function Loss: 0.07587

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05306
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.06543

Collected Steps per Second: 13897.16970
Overall Steps per Second: 11177.35910

Timestep Collection Time: 3.60030
Timestep Consumption Time: 0.87607
PPO Batch Consumption Time: 0.06375
Total Iteration Time: 4.47637

Cumulative Model Updates: 6063
Cumulative Timesteps: 101197550

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07588
Policy Entropy: 1.19340
Value Function Loss: 0.07492

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.05263
Value Function Update Magnitude: 0.06397

Collected Steps per Second: 12740.76476
Overall Steps per Second: 9759.02443

Timestep Collection Time: 3.92645
Timestep Consumption Time: 1.19968
PPO Batch Consumption Time: 0.14184
Total Iteration Time: 5.12613

Cumulative Model Updates: 6066
Cumulative Timesteps: 101247576

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 101247576...
Checkpoint 101247576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01695
Policy Entropy: 1.20010
Value Function Loss: 0.07612

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.07454

Collected Steps per Second: 13508.28003
Overall Steps per Second: 10465.78773

Timestep Collection Time: 3.70232
Timestep Consumption Time: 1.07630
PPO Batch Consumption Time: 0.13388
Total Iteration Time: 4.77862

Cumulative Model Updates: 6069
Cumulative Timesteps: 101297588

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14271
Policy Entropy: 1.20119
Value Function Loss: 0.09175

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.07998

Collected Steps per Second: 13675.44114
Overall Steps per Second: 10487.76107

Timestep Collection Time: 3.65882
Timestep Consumption Time: 1.11207
PPO Batch Consumption Time: 0.14154
Total Iteration Time: 4.77089

Cumulative Model Updates: 6072
Cumulative Timesteps: 101347624

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 101347624...
Checkpoint 101347624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09788
Policy Entropy: 1.18522
Value Function Loss: 0.08836

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.05393
Value Function Update Magnitude: 0.07790

Collected Steps per Second: 13326.20461
Overall Steps per Second: 10593.99852

Timestep Collection Time: 3.75351
Timestep Consumption Time: 0.96803
PPO Batch Consumption Time: 0.07323
Total Iteration Time: 4.72154

Cumulative Model Updates: 6075
Cumulative Timesteps: 101397644

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00850
Policy Entropy: 1.19532
Value Function Loss: 0.08560

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.07168

Collected Steps per Second: 12361.93571
Overall Steps per Second: 9474.48972

Timestep Collection Time: 4.04484
Timestep Consumption Time: 1.23270
PPO Batch Consumption Time: 0.18226
Total Iteration Time: 5.27754

Cumulative Model Updates: 6078
Cumulative Timesteps: 101447646

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 101447646...
Checkpoint 101447646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11946
Policy Entropy: 1.18568
Value Function Loss: 0.06751

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.06520

Collected Steps per Second: 13051.99211
Overall Steps per Second: 10560.19415

Timestep Collection Time: 3.83083
Timestep Consumption Time: 0.90393
PPO Batch Consumption Time: 0.07020
Total Iteration Time: 4.73476

Cumulative Model Updates: 6081
Cumulative Timesteps: 101497646

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02457
Policy Entropy: 1.18990
Value Function Loss: 0.06314

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.05037
Value Function Update Magnitude: 0.06624

Collected Steps per Second: 11845.70281
Overall Steps per Second: 9161.23229

Timestep Collection Time: 4.22162
Timestep Consumption Time: 1.23704
PPO Batch Consumption Time: 0.16212
Total Iteration Time: 5.45865

Cumulative Model Updates: 6084
Cumulative Timesteps: 101547654

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 101547654...
Checkpoint 101547654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14706
Policy Entropy: 1.17724
Value Function Loss: 0.05162

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.04915
Value Function Update Magnitude: 0.07637

Collected Steps per Second: 13987.46169
Overall Steps per Second: 11159.23457

Timestep Collection Time: 3.57677
Timestep Consumption Time: 0.90651
PPO Batch Consumption Time: 0.06512
Total Iteration Time: 4.48328

Cumulative Model Updates: 6087
Cumulative Timesteps: 101597684

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06574
Policy Entropy: 1.18435
Value Function Loss: 0.06196

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.04590
Value Function Update Magnitude: 0.07967

Collected Steps per Second: 12421.69299
Overall Steps per Second: 9470.24289

Timestep Collection Time: 4.02683
Timestep Consumption Time: 1.25498
PPO Batch Consumption Time: 0.16047
Total Iteration Time: 5.28181

Cumulative Model Updates: 6090
Cumulative Timesteps: 101647704

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 101647704...
Checkpoint 101647704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16322
Policy Entropy: 1.19089
Value Function Loss: 0.06702

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05052
Policy Update Magnitude: 0.04968
Value Function Update Magnitude: 0.07793

Collected Steps per Second: 13522.48934
Overall Steps per Second: 11025.37786

Timestep Collection Time: 3.70169
Timestep Consumption Time: 0.83839
PPO Batch Consumption Time: 0.06807
Total Iteration Time: 4.54007

Cumulative Model Updates: 6093
Cumulative Timesteps: 101697760

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01665
Policy Entropy: 1.17808
Value Function Loss: 0.07315

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06124
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.08742

Collected Steps per Second: 12241.75350
Overall Steps per Second: 9210.55278

Timestep Collection Time: 4.08455
Timestep Consumption Time: 1.34423
PPO Batch Consumption Time: 0.18645
Total Iteration Time: 5.42877

Cumulative Model Updates: 6096
Cumulative Timesteps: 101747762

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 101747762...
Checkpoint 101747762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11252
Policy Entropy: 1.17525
Value Function Loss: 0.07356

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06954
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.09289

Collected Steps per Second: 13446.37748
Overall Steps per Second: 10609.17576

Timestep Collection Time: 3.72026
Timestep Consumption Time: 0.99491
PPO Batch Consumption Time: 0.07603
Total Iteration Time: 4.71516

Cumulative Model Updates: 6099
Cumulative Timesteps: 101797786

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04048
Policy Entropy: 1.17119
Value Function Loss: 0.07524

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.05645
Value Function Update Magnitude: 0.08905

Collected Steps per Second: 11055.79516
Overall Steps per Second: 8256.23577

Timestep Collection Time: 4.52541
Timestep Consumption Time: 1.53450
PPO Batch Consumption Time: 0.19776
Total Iteration Time: 6.05990

Cumulative Model Updates: 6102
Cumulative Timesteps: 101847818

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 101847818...
Checkpoint 101847818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06927
Policy Entropy: 1.17749
Value Function Loss: 0.07044

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05329
Policy Update Magnitude: 0.05471
Value Function Update Magnitude: 0.08475

Collected Steps per Second: 11951.04899
Overall Steps per Second: 9696.54947

Timestep Collection Time: 4.18524
Timestep Consumption Time: 0.97309
PPO Batch Consumption Time: 0.06818
Total Iteration Time: 5.15833

Cumulative Model Updates: 6105
Cumulative Timesteps: 101897836

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19239
Policy Entropy: 1.17978
Value Function Loss: 0.06595

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05965
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.07592

Collected Steps per Second: 11229.04732
Overall Steps per Second: 8909.03786

Timestep Collection Time: 4.45755
Timestep Consumption Time: 1.16079
PPO Batch Consumption Time: 0.13588
Total Iteration Time: 5.61834

Cumulative Model Updates: 6108
Cumulative Timesteps: 101947890

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 101947890...
Checkpoint 101947890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06496
Policy Entropy: 1.17395
Value Function Loss: 0.06537

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05658
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.07197

Collected Steps per Second: 12069.85878
Overall Steps per Second: 9721.69412

Timestep Collection Time: 4.14421
Timestep Consumption Time: 1.00099
PPO Batch Consumption Time: 0.07931
Total Iteration Time: 5.14519

Cumulative Model Updates: 6111
Cumulative Timesteps: 101997910

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07013
Policy Entropy: 1.17835
Value Function Loss: 0.06592

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.06598

Collected Steps per Second: 11473.24008
Overall Steps per Second: 8624.25029

Timestep Collection Time: 4.36041
Timestep Consumption Time: 1.44044
PPO Batch Consumption Time: 0.18609
Total Iteration Time: 5.80085

Cumulative Model Updates: 6114
Cumulative Timesteps: 102047938

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 102047938...
Checkpoint 102047938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04232
Policy Entropy: 1.18111
Value Function Loss: 0.08116

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06816
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.07089

Collected Steps per Second: 11713.25604
Overall Steps per Second: 9008.23406

Timestep Collection Time: 4.27003
Timestep Consumption Time: 1.28222
PPO Batch Consumption Time: 0.17007
Total Iteration Time: 5.55225

Cumulative Model Updates: 6117
Cumulative Timesteps: 102097954

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00528
Policy Entropy: 1.17361
Value Function Loss: 0.08579

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.06625
Value Function Update Magnitude: 0.07061

Collected Steps per Second: 11564.33709
Overall Steps per Second: 8591.48707

Timestep Collection Time: 4.32692
Timestep Consumption Time: 1.49721
PPO Batch Consumption Time: 0.18710
Total Iteration Time: 5.82414

Cumulative Model Updates: 6120
Cumulative Timesteps: 102147992

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 102147992...
Checkpoint 102147992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08254
Policy Entropy: 1.17140
Value Function Loss: 0.08205

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.06539
Value Function Update Magnitude: 0.07498

Collected Steps per Second: 12162.64905
Overall Steps per Second: 9465.51278

Timestep Collection Time: 4.11424
Timestep Consumption Time: 1.17232
PPO Batch Consumption Time: 0.13512
Total Iteration Time: 5.28656

Cumulative Model Updates: 6123
Cumulative Timesteps: 102198032

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07552
Policy Entropy: 1.16931
Value Function Loss: 0.07224

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.06336
Value Function Update Magnitude: 0.07918

Collected Steps per Second: 12423.67896
Overall Steps per Second: 9453.90451

Timestep Collection Time: 4.02457
Timestep Consumption Time: 1.26425
PPO Batch Consumption Time: 0.14820
Total Iteration Time: 5.28882

Cumulative Model Updates: 6126
Cumulative Timesteps: 102248032

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 102248032...
Checkpoint 102248032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04871
Policy Entropy: 1.16510
Value Function Loss: 0.06603

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07631
Policy Update Magnitude: 0.06096
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 12096.07469
Overall Steps per Second: 9640.23726

Timestep Collection Time: 4.13490
Timestep Consumption Time: 1.05336
PPO Batch Consumption Time: 0.07353
Total Iteration Time: 5.18825

Cumulative Model Updates: 6129
Cumulative Timesteps: 102298048

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05178
Policy Entropy: 1.16045
Value Function Loss: 0.07248

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.06505
Value Function Update Magnitude: 0.07907

Collected Steps per Second: 11552.89301
Overall Steps per Second: 8911.81000

Timestep Collection Time: 4.32896
Timestep Consumption Time: 1.28292
PPO Batch Consumption Time: 0.17326
Total Iteration Time: 5.61188

Cumulative Model Updates: 6132
Cumulative Timesteps: 102348060

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 102348060...
Checkpoint 102348060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05816
Policy Entropy: 1.16522
Value Function Loss: 0.06490

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.05692
Value Function Update Magnitude: 0.08426

Collected Steps per Second: 11905.74041
Overall Steps per Second: 9077.85158

Timestep Collection Time: 4.20100
Timestep Consumption Time: 1.30867
PPO Batch Consumption Time: 0.14286
Total Iteration Time: 5.50967

Cumulative Model Updates: 6135
Cumulative Timesteps: 102398076

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02191
Policy Entropy: 1.16479
Value Function Loss: 0.05465

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.05163
Value Function Update Magnitude: 0.07835

Collected Steps per Second: 12055.92550
Overall Steps per Second: 9234.60140

Timestep Collection Time: 4.14750
Timestep Consumption Time: 1.26713
PPO Batch Consumption Time: 0.16677
Total Iteration Time: 5.41464

Cumulative Model Updates: 6138
Cumulative Timesteps: 102448078

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 102448078...
Checkpoint 102448078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06246
Policy Entropy: 1.16516
Value Function Loss: 0.05370

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.05006
Value Function Update Magnitude: 0.06858

Collected Steps per Second: 12167.41309
Overall Steps per Second: 9451.28815

Timestep Collection Time: 4.10967
Timestep Consumption Time: 1.18104
PPO Batch Consumption Time: 0.13137
Total Iteration Time: 5.29071

Cumulative Model Updates: 6141
Cumulative Timesteps: 102498082

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15900
Policy Entropy: 1.17301
Value Function Loss: 0.07125

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07108
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.06401

Collected Steps per Second: 11684.67467
Overall Steps per Second: 9075.01967

Timestep Collection Time: 4.27997
Timestep Consumption Time: 1.23077
PPO Batch Consumption Time: 0.14374
Total Iteration Time: 5.51073

Cumulative Model Updates: 6144
Cumulative Timesteps: 102548092

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 102548092...
Checkpoint 102548092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01662
Policy Entropy: 1.15557
Value Function Loss: 0.07895

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.05456
Value Function Update Magnitude: 0.05079

Collected Steps per Second: 12164.63226
Overall Steps per Second: 9971.45535

Timestep Collection Time: 4.11356
Timestep Consumption Time: 0.90476
PPO Batch Consumption Time: 0.07309
Total Iteration Time: 5.01832

Cumulative Model Updates: 6147
Cumulative Timesteps: 102598132

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02831
Policy Entropy: 1.16452
Value Function Loss: 0.08285

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.05544
Value Function Update Magnitude: 0.04941

Collected Steps per Second: 10799.86378
Overall Steps per Second: 8355.41712

Timestep Collection Time: 4.63043
Timestep Consumption Time: 1.35467
PPO Batch Consumption Time: 0.16460
Total Iteration Time: 5.98510

Cumulative Model Updates: 6150
Cumulative Timesteps: 102648140

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 102648140...
Checkpoint 102648140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16976
Policy Entropy: 1.16579
Value Function Loss: 0.06928

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.05389
Value Function Update Magnitude: 0.05768

Collected Steps per Second: 11914.68839
Overall Steps per Second: 9286.65823

Timestep Collection Time: 4.19684
Timestep Consumption Time: 1.18766
PPO Batch Consumption Time: 0.14819
Total Iteration Time: 5.38450

Cumulative Model Updates: 6153
Cumulative Timesteps: 102698144

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01226
Policy Entropy: 1.17339
Value Function Loss: 0.07828

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.05704

Collected Steps per Second: 13593.15020
Overall Steps per Second: 10026.19168

Timestep Collection Time: 3.68244
Timestep Consumption Time: 1.31008
PPO Batch Consumption Time: 0.17979
Total Iteration Time: 4.99252

Cumulative Model Updates: 6156
Cumulative Timesteps: 102748200

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 102748200...
Checkpoint 102748200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18798
Policy Entropy: 1.16100
Value Function Loss: 0.07454

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.05843

Collected Steps per Second: 13377.56056
Overall Steps per Second: 10771.59077

Timestep Collection Time: 3.73790
Timestep Consumption Time: 0.90431
PPO Batch Consumption Time: 0.06564
Total Iteration Time: 4.64221

Cumulative Model Updates: 6159
Cumulative Timesteps: 102798204

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00305
Policy Entropy: 1.16167
Value Function Loss: 0.08713

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.05924

Collected Steps per Second: 12528.18814
Overall Steps per Second: 9412.01791

Timestep Collection Time: 3.99467
Timestep Consumption Time: 1.32257
PPO Batch Consumption Time: 0.19187
Total Iteration Time: 5.31724

Cumulative Model Updates: 6162
Cumulative Timesteps: 102848250

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 102848250...
Checkpoint 102848250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11925
Policy Entropy: 1.17659
Value Function Loss: 0.08788

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.05377
Value Function Update Magnitude: 0.06533

Collected Steps per Second: 13771.45880
Overall Steps per Second: 10080.39253

Timestep Collection Time: 3.63418
Timestep Consumption Time: 1.33070
PPO Batch Consumption Time: 0.18933
Total Iteration Time: 4.96489

Cumulative Model Updates: 6165
Cumulative Timesteps: 102898298

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09318
Policy Entropy: 1.17154
Value Function Loss: 0.07694

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.05254
Value Function Update Magnitude: 0.06589

Collected Steps per Second: 13540.45433
Overall Steps per Second: 10412.36194

Timestep Collection Time: 3.69574
Timestep Consumption Time: 1.11028
PPO Batch Consumption Time: 0.13243
Total Iteration Time: 4.80602

Cumulative Model Updates: 6168
Cumulative Timesteps: 102948340

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 102948340...
Checkpoint 102948340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06649
Policy Entropy: 1.17336
Value Function Loss: 0.06923

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.06153

Collected Steps per Second: 13560.41330
Overall Steps per Second: 11144.67222

Timestep Collection Time: 3.68853
Timestep Consumption Time: 0.79953
PPO Batch Consumption Time: 0.06526
Total Iteration Time: 4.48806

Cumulative Model Updates: 6171
Cumulative Timesteps: 102998358

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00468
Policy Entropy: 1.16523
Value Function Loss: 0.07584

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.05997

Collected Steps per Second: 12425.98803
Overall Steps per Second: 9440.44160

Timestep Collection Time: 4.02608
Timestep Consumption Time: 1.27325
PPO Batch Consumption Time: 0.16508
Total Iteration Time: 5.29933

Cumulative Model Updates: 6174
Cumulative Timesteps: 103048386

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 103048386...
Checkpoint 103048386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05773
Policy Entropy: 1.17019
Value Function Loss: 0.08357

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05739
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.07110

Collected Steps per Second: 13743.90413
Overall Steps per Second: 11059.59863

Timestep Collection Time: 3.63870
Timestep Consumption Time: 0.88316
PPO Batch Consumption Time: 0.06975
Total Iteration Time: 4.52186

Cumulative Model Updates: 6177
Cumulative Timesteps: 103098396

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07306
Policy Entropy: 1.16429
Value Function Loss: 0.07141

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 12940.90467
Overall Steps per Second: 9881.35327

Timestep Collection Time: 3.86604
Timestep Consumption Time: 1.19704
PPO Batch Consumption Time: 0.14854
Total Iteration Time: 5.06307

Cumulative Model Updates: 6180
Cumulative Timesteps: 103148426

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 103148426...
Checkpoint 103148426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07484
Policy Entropy: 1.16561
Value Function Loss: 0.05777

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.04568
Value Function Update Magnitude: 0.09168

Collected Steps per Second: 13442.28053
Overall Steps per Second: 10784.86575

Timestep Collection Time: 3.72184
Timestep Consumption Time: 0.91707
PPO Batch Consumption Time: 0.06890
Total Iteration Time: 4.63891

Cumulative Model Updates: 6183
Cumulative Timesteps: 103198456

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13239
Policy Entropy: 1.16344
Value Function Loss: 0.04072

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.04504
Value Function Update Magnitude: 0.08414

Collected Steps per Second: 12750.47227
Overall Steps per Second: 9747.07673

Timestep Collection Time: 3.92393
Timestep Consumption Time: 1.20909
PPO Batch Consumption Time: 0.16573
Total Iteration Time: 5.13303

Cumulative Model Updates: 6186
Cumulative Timesteps: 103248488

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 103248488...
Checkpoint 103248488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04337
Policy Entropy: 1.14723
Value Function Loss: 0.04994

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.04267
Value Function Update Magnitude: 0.07939

Collected Steps per Second: 13582.94531
Overall Steps per Second: 10099.14360

Timestep Collection Time: 3.68433
Timestep Consumption Time: 1.27095
PPO Batch Consumption Time: 0.16994
Total Iteration Time: 4.95527

Cumulative Model Updates: 6189
Cumulative Timesteps: 103298532

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19231
Policy Entropy: 1.14096
Value Function Loss: 0.05923

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.04275
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 13310.35758
Overall Steps per Second: 10370.61528

Timestep Collection Time: 3.75677
Timestep Consumption Time: 1.06493
PPO Batch Consumption Time: 0.07362
Total Iteration Time: 4.82170

Cumulative Model Updates: 6192
Cumulative Timesteps: 103348536

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 103348536...
Checkpoint 103348536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07895
Policy Entropy: 1.13339
Value Function Loss: 0.08386

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.05035
Value Function Update Magnitude: 0.07993

Collected Steps per Second: 10964.69587
Overall Steps per Second: 8366.13090

Timestep Collection Time: 4.56210
Timestep Consumption Time: 1.41701
PPO Batch Consumption Time: 0.17586
Total Iteration Time: 5.97911

Cumulative Model Updates: 6195
Cumulative Timesteps: 103398558

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09934
Policy Entropy: 1.14572
Value Function Loss: 0.09105

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.05513
Value Function Update Magnitude: 0.09162

Collected Steps per Second: 12292.78771
Overall Steps per Second: 9846.97351

Timestep Collection Time: 4.06808
Timestep Consumption Time: 1.01044
PPO Batch Consumption Time: 0.07282
Total Iteration Time: 5.07851

Cumulative Model Updates: 6198
Cumulative Timesteps: 103448566

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 103448566...
Checkpoint 103448566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07741
Policy Entropy: 1.13267
Value Function Loss: 0.08250

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.09236

Collected Steps per Second: 11157.21204
Overall Steps per Second: 8768.87890

Timestep Collection Time: 4.48320
Timestep Consumption Time: 1.22107
PPO Batch Consumption Time: 0.15520
Total Iteration Time: 5.70426

Cumulative Model Updates: 6201
Cumulative Timesteps: 103498586

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07719
Policy Entropy: 1.13837
Value Function Loss: 0.07215

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.04924
Value Function Update Magnitude: 0.08629

Collected Steps per Second: 12451.26306
Overall Steps per Second: 9994.27996

Timestep Collection Time: 4.01614
Timestep Consumption Time: 0.98732
PPO Batch Consumption Time: 0.06884
Total Iteration Time: 5.00346

Cumulative Model Updates: 6204
Cumulative Timesteps: 103548592

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 103548592...
Checkpoint 103548592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07598
Policy Entropy: 1.14088
Value Function Loss: 0.07181

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05600
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.06749

Collected Steps per Second: 11221.86640
Overall Steps per Second: 8671.66339

Timestep Collection Time: 4.45737
Timestep Consumption Time: 1.31084
PPO Batch Consumption Time: 0.15401
Total Iteration Time: 5.76821

Cumulative Model Updates: 6207
Cumulative Timesteps: 103598612

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06787
Policy Entropy: 1.13971
Value Function Loss: 0.06344

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06323
Policy Update Magnitude: 0.05063
Value Function Update Magnitude: 0.06623

Collected Steps per Second: 12514.90306
Overall Steps per Second: 9969.30045

Timestep Collection Time: 3.99715
Timestep Consumption Time: 1.02065
PPO Batch Consumption Time: 0.06925
Total Iteration Time: 5.01780

Cumulative Model Updates: 6210
Cumulative Timesteps: 103648636

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 103648636...
Checkpoint 103648636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09458
Policy Entropy: 1.12998
Value Function Loss: 0.06580

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06450
Policy Update Magnitude: 0.05356
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 10516.96981
Overall Steps per Second: 8128.37165

Timestep Collection Time: 4.75821
Timestep Consumption Time: 1.39825
PPO Batch Consumption Time: 0.18231
Total Iteration Time: 6.15646

Cumulative Model Updates: 6213
Cumulative Timesteps: 103698678

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02731
Policy Entropy: 1.12373
Value Function Loss: 0.06183

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.06888

Collected Steps per Second: 11991.42596
Overall Steps per Second: 9270.21505

Timestep Collection Time: 4.16981
Timestep Consumption Time: 1.22402
PPO Batch Consumption Time: 0.15686
Total Iteration Time: 5.39383

Cumulative Model Updates: 6216
Cumulative Timesteps: 103748680

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 103748680...
Checkpoint 103748680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16349
Policy Entropy: 1.14327
Value Function Loss: 0.06890

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 11691.40131
Overall Steps per Second: 8974.47292

Timestep Collection Time: 4.27973
Timestep Consumption Time: 1.29564
PPO Batch Consumption Time: 0.15013
Total Iteration Time: 5.57537

Cumulative Model Updates: 6219
Cumulative Timesteps: 103798716

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01278
Policy Entropy: 1.13044
Value Function Loss: 0.06771

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.07207

Collected Steps per Second: 12085.17471
Overall Steps per Second: 9768.80933

Timestep Collection Time: 4.13730
Timestep Consumption Time: 0.98103
PPO Batch Consumption Time: 0.07601
Total Iteration Time: 5.11833

Cumulative Model Updates: 6222
Cumulative Timesteps: 103848716

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 103848716...
Checkpoint 103848716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04510
Policy Entropy: 1.14430
Value Function Loss: 0.06389

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.06581

Collected Steps per Second: 11585.40754
Overall Steps per Second: 8811.27315

Timestep Collection Time: 4.31819
Timestep Consumption Time: 1.35954
PPO Batch Consumption Time: 0.16606
Total Iteration Time: 5.67773

Cumulative Model Updates: 6225
Cumulative Timesteps: 103898744

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19918
Policy Entropy: 1.14283
Value Function Loss: 0.06474

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.04897
Value Function Update Magnitude: 0.05611

Collected Steps per Second: 11894.87206
Overall Steps per Second: 9132.58950

Timestep Collection Time: 4.20551
Timestep Consumption Time: 1.27202
PPO Batch Consumption Time: 0.14149
Total Iteration Time: 5.47753

Cumulative Model Updates: 6228
Cumulative Timesteps: 103948768

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 103948768...
Checkpoint 103948768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03778
Policy Entropy: 1.15200
Value Function Loss: 0.05742

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.04953
Value Function Update Magnitude: 0.05705

Collected Steps per Second: 10981.49041
Overall Steps per Second: 8546.81229

Timestep Collection Time: 4.55330
Timestep Consumption Time: 1.29707
PPO Batch Consumption Time: 0.16645
Total Iteration Time: 5.85037

Cumulative Model Updates: 6231
Cumulative Timesteps: 103998770

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13495
Policy Entropy: 1.13712
Value Function Loss: 0.07143

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07147
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.06538

Collected Steps per Second: 12121.05964
Overall Steps per Second: 9702.93928

Timestep Collection Time: 4.12604
Timestep Consumption Time: 1.02827
PPO Batch Consumption Time: 0.07825
Total Iteration Time: 5.15431

Cumulative Model Updates: 6234
Cumulative Timesteps: 104048782

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 104048782...
Checkpoint 104048782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09131
Policy Entropy: 1.15720
Value Function Loss: 0.07928

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.06629

Collected Steps per Second: 11350.06155
Overall Steps per Second: 8859.75983

Timestep Collection Time: 4.40755
Timestep Consumption Time: 1.23888
PPO Batch Consumption Time: 0.13602
Total Iteration Time: 5.64643

Cumulative Model Updates: 6237
Cumulative Timesteps: 104098808

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09939
Policy Entropy: 1.14737
Value Function Loss: 0.08671

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08013
Policy Update Magnitude: 0.05260
Value Function Update Magnitude: 0.07844

Collected Steps per Second: 12641.26965
Overall Steps per Second: 10089.86831

Timestep Collection Time: 3.95609
Timestep Consumption Time: 1.00037
PPO Batch Consumption Time: 0.07410
Total Iteration Time: 4.95646

Cumulative Model Updates: 6240
Cumulative Timesteps: 104148818

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 104148818...
Checkpoint 104148818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00355
Policy Entropy: 1.14540
Value Function Loss: 0.06733

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.08089

Collected Steps per Second: 10770.95578
Overall Steps per Second: 8047.41813

Timestep Collection Time: 4.64527
Timestep Consumption Time: 1.57213
PPO Batch Consumption Time: 0.17631
Total Iteration Time: 6.21740

Cumulative Model Updates: 6243
Cumulative Timesteps: 104198852

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07772
Policy Entropy: 1.14306
Value Function Loss: 0.05022

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.04869
Value Function Update Magnitude: 0.07549

Collected Steps per Second: 12273.04172
Overall Steps per Second: 9605.46504

Timestep Collection Time: 4.07446
Timestep Consumption Time: 1.13154
PPO Batch Consumption Time: 0.13939
Total Iteration Time: 5.20599

Cumulative Model Updates: 6246
Cumulative Timesteps: 104248858

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 104248858...
Checkpoint 104248858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08131
Policy Entropy: 1.15652
Value Function Loss: 0.05668

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.05138
Value Function Update Magnitude: 0.07321

Collected Steps per Second: 13452.29451
Overall Steps per Second: 10206.53605

Timestep Collection Time: 3.71981
Timestep Consumption Time: 1.18293
PPO Batch Consumption Time: 0.16404
Total Iteration Time: 4.90274

Cumulative Model Updates: 6249
Cumulative Timesteps: 104298898

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10731
Policy Entropy: 1.15713
Value Function Loss: 0.06522

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.07440

Collected Steps per Second: 13052.90493
Overall Steps per Second: 9545.42368

Timestep Collection Time: 3.83087
Timestep Consumption Time: 1.40766
PPO Batch Consumption Time: 0.18861
Total Iteration Time: 5.23853

Cumulative Model Updates: 6252
Cumulative Timesteps: 104348902

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 104348902...
Checkpoint 104348902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04078
Policy Entropy: 1.16573
Value Function Loss: 0.08444

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.05391
Value Function Update Magnitude: 0.07639

Collected Steps per Second: 13764.30223
Overall Steps per Second: 11078.93923

Timestep Collection Time: 3.63404
Timestep Consumption Time: 0.88083
PPO Batch Consumption Time: 0.06596
Total Iteration Time: 4.51487

Cumulative Model Updates: 6255
Cumulative Timesteps: 104398922

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13552
Policy Entropy: 1.17350
Value Function Loss: 0.07538

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.07774

Collected Steps per Second: 10536.38453
Overall Steps per Second: 8461.38515

Timestep Collection Time: 4.74831
Timestep Consumption Time: 1.16444
PPO Batch Consumption Time: 0.07885
Total Iteration Time: 5.91274

Cumulative Model Updates: 6258
Cumulative Timesteps: 104448952

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 104448952...
Checkpoint 104448952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03185
Policy Entropy: 1.18187
Value Function Loss: 0.07239

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07417
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.08877

Collected Steps per Second: 11216.31308
Overall Steps per Second: 9313.07827

Timestep Collection Time: 4.45922
Timestep Consumption Time: 0.91129
PPO Batch Consumption Time: 0.08077
Total Iteration Time: 5.37051

Cumulative Model Updates: 6261
Cumulative Timesteps: 104498968

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09531
Policy Entropy: 1.18665
Value Function Loss: 0.07028

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.08338

Collected Steps per Second: 13128.02616
Overall Steps per Second: 10458.71942

Timestep Collection Time: 3.81032
Timestep Consumption Time: 0.97248
PPO Batch Consumption Time: 0.07894
Total Iteration Time: 4.78280

Cumulative Model Updates: 6264
Cumulative Timesteps: 104548990

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 104548990...
Checkpoint 104548990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04299
Policy Entropy: 1.18017
Value Function Loss: 0.07364

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.07986

Collected Steps per Second: 13078.58898
Overall Steps per Second: 10464.38507

Timestep Collection Time: 3.82534
Timestep Consumption Time: 0.95564
PPO Batch Consumption Time: 0.07929
Total Iteration Time: 4.78098

Cumulative Model Updates: 6267
Cumulative Timesteps: 104599020

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03486
Policy Entropy: 1.17341
Value Function Loss: 0.06526

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.05417
Value Function Update Magnitude: 0.07743

Collected Steps per Second: 12983.43277
Overall Steps per Second: 10410.29623

Timestep Collection Time: 3.85276
Timestep Consumption Time: 0.95229
PPO Batch Consumption Time: 0.07020
Total Iteration Time: 4.80505

Cumulative Model Updates: 6270
Cumulative Timesteps: 104649042

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 104649042...
Checkpoint 104649042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02290
Policy Entropy: 1.17497
Value Function Loss: 0.05079

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.05299
Value Function Update Magnitude: 0.07567

Collected Steps per Second: 13058.07939
Overall Steps per Second: 10462.41401

Timestep Collection Time: 3.83058
Timestep Consumption Time: 0.95034
PPO Batch Consumption Time: 0.07711
Total Iteration Time: 4.78092

Cumulative Model Updates: 6273
Cumulative Timesteps: 104699062

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01933
Policy Entropy: 1.18441
Value Function Loss: 0.04637

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.04858
Value Function Update Magnitude: 0.06838

Collected Steps per Second: 13231.96975
Overall Steps per Second: 10476.37190

Timestep Collection Time: 3.78009
Timestep Consumption Time: 0.99428
PPO Batch Consumption Time: 0.11447
Total Iteration Time: 4.77436

Cumulative Model Updates: 6276
Cumulative Timesteps: 104749080

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 104749080...
Checkpoint 104749080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01921
Policy Entropy: 1.15612
Value Function Loss: 0.04581

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.06435

Collected Steps per Second: 13337.82749
Overall Steps per Second: 10432.72043

Timestep Collection Time: 3.75024
Timestep Consumption Time: 1.04429
PPO Batch Consumption Time: 0.08138
Total Iteration Time: 4.79453

Cumulative Model Updates: 6279
Cumulative Timesteps: 104799100

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04634
Policy Entropy: 1.15775
Value Function Loss: 0.04616

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.04815
Value Function Update Magnitude: 0.06970

Collected Steps per Second: 12388.59258
Overall Steps per Second: 10011.82159

Timestep Collection Time: 4.03855
Timestep Consumption Time: 0.95874
PPO Batch Consumption Time: 0.08399
Total Iteration Time: 4.99729

Cumulative Model Updates: 6282
Cumulative Timesteps: 104849132

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 104849132...
Checkpoint 104849132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00728
Policy Entropy: 1.14930
Value Function Loss: 0.05194

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.06569

Collected Steps per Second: 13576.79391
Overall Steps per Second: 10785.48713

Timestep Collection Time: 3.68467
Timestep Consumption Time: 0.95360
PPO Batch Consumption Time: 0.06710
Total Iteration Time: 4.63827

Cumulative Model Updates: 6285
Cumulative Timesteps: 104899158

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04670
Policy Entropy: 1.16353
Value Function Loss: 0.06208

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08589
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.07217

Collected Steps per Second: 10239.38778
Overall Steps per Second: 8423.09821

Timestep Collection Time: 4.88564
Timestep Consumption Time: 1.05350
PPO Batch Consumption Time: 0.10360
Total Iteration Time: 5.93914

Cumulative Model Updates: 6288
Cumulative Timesteps: 104949184

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 104949184...
Checkpoint 104949184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17584
Policy Entropy: 1.15043
Value Function Loss: 0.07505

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.06715

Collected Steps per Second: 12880.65354
Overall Steps per Second: 10479.21130

Timestep Collection Time: 3.88536
Timestep Consumption Time: 0.89038
PPO Batch Consumption Time: 0.08445
Total Iteration Time: 4.77574

Cumulative Model Updates: 6291
Cumulative Timesteps: 104999230

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08537
Policy Entropy: 1.15285
Value Function Loss: 0.08388

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07182
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.07060

Collected Steps per Second: 13180.47055
Overall Steps per Second: 10439.01867

Timestep Collection Time: 3.79455
Timestep Consumption Time: 0.99651
PPO Batch Consumption Time: 0.08476
Total Iteration Time: 4.79106

Cumulative Model Updates: 6294
Cumulative Timesteps: 105049244

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 105049244...
Checkpoint 105049244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02222
Policy Entropy: 1.14538
Value Function Loss: 0.08083

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06439
Policy Update Magnitude: 0.05682
Value Function Update Magnitude: 0.07531

Collected Steps per Second: 13147.26191
Overall Steps per Second: 10465.87785

Timestep Collection Time: 3.80672
Timestep Consumption Time: 0.97529
PPO Batch Consumption Time: 0.08423
Total Iteration Time: 4.78202

Cumulative Model Updates: 6297
Cumulative Timesteps: 105099292

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11133
Policy Entropy: 1.14786
Value Function Loss: 0.07047

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06432
Policy Update Magnitude: 0.05700
Value Function Update Magnitude: 0.07254

Collected Steps per Second: 13423.21004
Overall Steps per Second: 10393.24358

Timestep Collection Time: 3.72787
Timestep Consumption Time: 1.08679
PPO Batch Consumption Time: 0.08082
Total Iteration Time: 4.81467

Cumulative Model Updates: 6300
Cumulative Timesteps: 105149332

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 105149332...
Checkpoint 105149332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04892
Policy Entropy: 1.15000
Value Function Loss: 0.06505

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10704
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.06064

Collected Steps per Second: 12852.56309
Overall Steps per Second: 10058.77704

Timestep Collection Time: 3.89059
Timestep Consumption Time: 1.08060
PPO Batch Consumption Time: 0.11454
Total Iteration Time: 4.97118

Cumulative Model Updates: 6303
Cumulative Timesteps: 105199336

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04221
Policy Entropy: 1.14943
Value Function Loss: 0.06499

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.05641

Collected Steps per Second: 13139.23461
Overall Steps per Second: 10888.64380

Timestep Collection Time: 3.80768
Timestep Consumption Time: 0.78702
PPO Batch Consumption Time: 0.05873
Total Iteration Time: 4.59470

Cumulative Model Updates: 6306
Cumulative Timesteps: 105249366

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 105249366...
Checkpoint 105249366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15773
Policy Entropy: 1.15416
Value Function Loss: 0.06722

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07528
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.05502

Collected Steps per Second: 12078.86673
Overall Steps per Second: 9636.75498

Timestep Collection Time: 4.14112
Timestep Consumption Time: 1.04943
PPO Batch Consumption Time: 0.09676
Total Iteration Time: 5.19054

Cumulative Model Updates: 6309
Cumulative Timesteps: 105299386

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02993
Policy Entropy: 1.14172
Value Function Loss: 0.07467

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.05076

Collected Steps per Second: 13316.98173
Overall Steps per Second: 10817.15155

Timestep Collection Time: 3.75746
Timestep Consumption Time: 0.86834
PPO Batch Consumption Time: 0.06300
Total Iteration Time: 4.62580

Cumulative Model Updates: 6312
Cumulative Timesteps: 105349424

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 105349424...
Checkpoint 105349424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09471
Policy Entropy: 1.13466
Value Function Loss: 0.07207

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.05983

Collected Steps per Second: 12529.37919
Overall Steps per Second: 10098.33965

Timestep Collection Time: 3.99206
Timestep Consumption Time: 0.96103
PPO Batch Consumption Time: 0.06575
Total Iteration Time: 4.95309

Cumulative Model Updates: 6315
Cumulative Timesteps: 105399442

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11042
Policy Entropy: 1.15578
Value Function Loss: 0.07674

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.07417

Collected Steps per Second: 12909.36747
Overall Steps per Second: 10073.43113

Timestep Collection Time: 3.87564
Timestep Consumption Time: 1.09109
PPO Batch Consumption Time: 0.11105
Total Iteration Time: 4.96673

Cumulative Model Updates: 6318
Cumulative Timesteps: 105449474

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 105449474...
Checkpoint 105449474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01590
Policy Entropy: 1.16647
Value Function Loss: 0.06199

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.07384

Collected Steps per Second: 12489.24516
Overall Steps per Second: 10026.57853

Timestep Collection Time: 4.00409
Timestep Consumption Time: 0.98346
PPO Batch Consumption Time: 0.10277
Total Iteration Time: 4.98754

Cumulative Model Updates: 6321
Cumulative Timesteps: 105499482

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14685
Policy Entropy: 1.15530
Value Function Loss: 0.06157

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.07245

Collected Steps per Second: 12845.94103
Overall Steps per Second: 10444.81047

Timestep Collection Time: 3.89508
Timestep Consumption Time: 0.89543
PPO Batch Consumption Time: 0.06229
Total Iteration Time: 4.79051

Cumulative Model Updates: 6324
Cumulative Timesteps: 105549518

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 105549518...
Checkpoint 105549518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03081
Policy Entropy: 1.14157
Value Function Loss: 0.05412

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.08345

Collected Steps per Second: 11825.16720
Overall Steps per Second: 9296.63639

Timestep Collection Time: 4.22979
Timestep Consumption Time: 1.15043
PPO Batch Consumption Time: 0.12394
Total Iteration Time: 5.38023

Cumulative Model Updates: 6327
Cumulative Timesteps: 105599536

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14185
Policy Entropy: 1.15316
Value Function Loss: 0.06249

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.05454
Value Function Update Magnitude: 0.08185

Collected Steps per Second: 13362.16343
Overall Steps per Second: 10756.54347

Timestep Collection Time: 3.74475
Timestep Consumption Time: 0.90711
PPO Batch Consumption Time: 0.06423
Total Iteration Time: 4.65187

Cumulative Model Updates: 6330
Cumulative Timesteps: 105649574

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 105649574...
Checkpoint 105649574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03843
Policy Entropy: 1.16070
Value Function Loss: 0.05580

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.05363
Value Function Update Magnitude: 0.08214

Collected Steps per Second: 11313.48371
Overall Steps per Second: 9033.31043

Timestep Collection Time: 4.41968
Timestep Consumption Time: 1.11561
PPO Batch Consumption Time: 0.09867
Total Iteration Time: 5.53529

Cumulative Model Updates: 6333
Cumulative Timesteps: 105699576

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14699
Policy Entropy: 1.16135
Value Function Loss: 0.06055

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.05005
Value Function Update Magnitude: 0.08226

Collected Steps per Second: 11031.47885
Overall Steps per Second: 9094.84587

Timestep Collection Time: 4.53321
Timestep Consumption Time: 0.96529
PPO Batch Consumption Time: 0.07571
Total Iteration Time: 5.49850

Cumulative Model Updates: 6336
Cumulative Timesteps: 105749584

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 105749584...
Checkpoint 105749584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08814
Policy Entropy: 1.17170
Value Function Loss: 0.06212

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.07574

Collected Steps per Second: 10706.44328
Overall Steps per Second: 8516.82659

Timestep Collection Time: 4.67214
Timestep Consumption Time: 1.20117
PPO Batch Consumption Time: 0.12138
Total Iteration Time: 5.87331

Cumulative Model Updates: 6339
Cumulative Timesteps: 105799606

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16133
Policy Entropy: 1.17627
Value Function Loss: 0.07510

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.07320

Collected Steps per Second: 11286.08339
Overall Steps per Second: 9065.77127

Timestep Collection Time: 4.43236
Timestep Consumption Time: 1.08554
PPO Batch Consumption Time: 0.07793
Total Iteration Time: 5.51790

Cumulative Model Updates: 6342
Cumulative Timesteps: 105849630

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 105849630...
Checkpoint 105849630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11952
Policy Entropy: 1.16440
Value Function Loss: 0.07182

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.07505

Collected Steps per Second: 10904.54688
Overall Steps per Second: 8811.40690

Timestep Collection Time: 4.58873
Timestep Consumption Time: 1.09005
PPO Batch Consumption Time: 0.06733
Total Iteration Time: 5.67878

Cumulative Model Updates: 6345
Cumulative Timesteps: 105899668

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09912
Policy Entropy: 1.16979
Value Function Loss: 0.06861

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.07617

Collected Steps per Second: 11226.88508
Overall Steps per Second: 8932.69675

Timestep Collection Time: 4.45377
Timestep Consumption Time: 1.14386
PPO Batch Consumption Time: 0.09783
Total Iteration Time: 5.59764

Cumulative Model Updates: 6348
Cumulative Timesteps: 105949670

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 105949670...
Checkpoint 105949670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07839
Policy Entropy: 1.16813
Value Function Loss: 0.06822

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.07469

Collected Steps per Second: 11548.52318
Overall Steps per Second: 9391.30824

Timestep Collection Time: 4.32956
Timestep Consumption Time: 0.99451
PPO Batch Consumption Time: 0.07239
Total Iteration Time: 5.32407

Cumulative Model Updates: 6351
Cumulative Timesteps: 105999670

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02310
Policy Entropy: 1.16607
Value Function Loss: 0.06940

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06170
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.06935

Collected Steps per Second: 11758.74275
Overall Steps per Second: 9209.87833

Timestep Collection Time: 4.25267
Timestep Consumption Time: 1.17694
PPO Batch Consumption Time: 0.11618
Total Iteration Time: 5.42960

Cumulative Model Updates: 6354
Cumulative Timesteps: 106049676

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 106049676...
Checkpoint 106049676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09901
Policy Entropy: 1.16533
Value Function Loss: 0.06622

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07668
Policy Update Magnitude: 0.05315
Value Function Update Magnitude: 0.06712

Collected Steps per Second: 12064.69904
Overall Steps per Second: 9705.12809

Timestep Collection Time: 4.14697
Timestep Consumption Time: 1.00824
PPO Batch Consumption Time: 0.07017
Total Iteration Time: 5.15521

Cumulative Model Updates: 6357
Cumulative Timesteps: 106099708

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03650
Policy Entropy: 1.16503
Value Function Loss: 0.06586

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.06229

Collected Steps per Second: 11437.53181
Overall Steps per Second: 9243.26798

Timestep Collection Time: 4.37559
Timestep Consumption Time: 1.03872
PPO Batch Consumption Time: 0.10640
Total Iteration Time: 5.41432

Cumulative Model Updates: 6360
Cumulative Timesteps: 106149754

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 106149754...
Checkpoint 106149754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05418
Policy Entropy: 1.16577
Value Function Loss: 0.06980

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.06137

Collected Steps per Second: 10677.24187
Overall Steps per Second: 8354.11154

Timestep Collection Time: 4.68379
Timestep Consumption Time: 1.30248
PPO Batch Consumption Time: 0.11964
Total Iteration Time: 5.98627

Cumulative Model Updates: 6363
Cumulative Timesteps: 106199764

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10802
Policy Entropy: 1.16638
Value Function Loss: 0.08768

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.06171
Value Function Update Magnitude: 0.08346

Collected Steps per Second: 11453.28346
Overall Steps per Second: 9235.46294

Timestep Collection Time: 4.36696
Timestep Consumption Time: 1.04869
PPO Batch Consumption Time: 0.07464
Total Iteration Time: 5.41565

Cumulative Model Updates: 6366
Cumulative Timesteps: 106249780

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 106249780...
Checkpoint 106249780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02294
Policy Entropy: 1.17388
Value Function Loss: 0.07666

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.06356
Value Function Update Magnitude: 0.08967

Collected Steps per Second: 12092.00006
Overall Steps per Second: 9640.44820

Timestep Collection Time: 4.13893
Timestep Consumption Time: 1.05253
PPO Batch Consumption Time: 0.07334
Total Iteration Time: 5.19146

Cumulative Model Updates: 6369
Cumulative Timesteps: 106299828

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15829
Policy Entropy: 1.17735
Value Function Loss: 0.07458

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.06319
Value Function Update Magnitude: 0.07355

Collected Steps per Second: 11511.66185
Overall Steps per Second: 9293.46075

Timestep Collection Time: 4.34360
Timestep Consumption Time: 1.03675
PPO Batch Consumption Time: 0.07364
Total Iteration Time: 5.38034

Cumulative Model Updates: 6372
Cumulative Timesteps: 106349830

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 106349830...
Checkpoint 106349830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08985
Policy Entropy: 1.17155
Value Function Loss: 0.07190

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.06207
Value Function Update Magnitude: 0.07246

Collected Steps per Second: 11502.32254
Overall Steps per Second: 9341.15622

Timestep Collection Time: 4.34764
Timestep Consumption Time: 1.00587
PPO Batch Consumption Time: 0.10688
Total Iteration Time: 5.35351

Cumulative Model Updates: 6375
Cumulative Timesteps: 106399838

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15698
Policy Entropy: 1.16057
Value Function Loss: 0.07914

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.06456

Collected Steps per Second: 11656.46783
Overall Steps per Second: 9445.28032

Timestep Collection Time: 4.28981
Timestep Consumption Time: 1.00427
PPO Batch Consumption Time: 0.07422
Total Iteration Time: 5.29407

Cumulative Model Updates: 6378
Cumulative Timesteps: 106449842

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 106449842...
Checkpoint 106449842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01051
Policy Entropy: 1.16250
Value Function Loss: 0.07998

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.06150
Value Function Update Magnitude: 0.05464

Collected Steps per Second: 10837.42706
Overall Steps per Second: 8486.44434

Timestep Collection Time: 4.61364
Timestep Consumption Time: 1.27811
PPO Batch Consumption Time: 0.11777
Total Iteration Time: 5.89175

Cumulative Model Updates: 6381
Cumulative Timesteps: 106499842

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11164
Policy Entropy: 1.16327
Value Function Loss: 0.07354

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.06697

Collected Steps per Second: 11461.34720
Overall Steps per Second: 9331.75191

Timestep Collection Time: 4.36493
Timestep Consumption Time: 0.99612
PPO Batch Consumption Time: 0.07404
Total Iteration Time: 5.36105

Cumulative Model Updates: 6384
Cumulative Timesteps: 106549870

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 106549870...
Checkpoint 106549870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03659
Policy Entropy: 1.18504
Value Function Loss: 0.06095

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.06146

Collected Steps per Second: 10883.63417
Overall Steps per Second: 8615.36722

Timestep Collection Time: 4.59626
Timestep Consumption Time: 1.21011
PPO Batch Consumption Time: 0.12174
Total Iteration Time: 5.80637

Cumulative Model Updates: 6387
Cumulative Timesteps: 106599894

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10819
Policy Entropy: 1.17355
Value Function Loss: 0.05900

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.05998

Collected Steps per Second: 11733.59873
Overall Steps per Second: 9582.42546

Timestep Collection Time: 4.26178
Timestep Consumption Time: 0.95673
PPO Batch Consumption Time: 0.07560
Total Iteration Time: 5.21851

Cumulative Model Updates: 6390
Cumulative Timesteps: 106649900

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 106649900...
Checkpoint 106649900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05677
Policy Entropy: 1.17071
Value Function Loss: 0.05615

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.06298

Collected Steps per Second: 13305.75737
Overall Steps per Second: 10747.54176

Timestep Collection Time: 3.75777
Timestep Consumption Time: 0.89445
PPO Batch Consumption Time: 0.06332
Total Iteration Time: 4.65223

Cumulative Model Updates: 6393
Cumulative Timesteps: 106699900

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04707
Policy Entropy: 1.17594
Value Function Loss: 0.05858

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.05494
Value Function Update Magnitude: 0.05440

Collected Steps per Second: 12043.18144
Overall Steps per Second: 9772.68910

Timestep Collection Time: 4.15538
Timestep Consumption Time: 0.96542
PPO Batch Consumption Time: 0.07335
Total Iteration Time: 5.12080

Cumulative Model Updates: 6396
Cumulative Timesteps: 106749944

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 106749944...
Checkpoint 106749944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00420
Policy Entropy: 1.17984
Value Function Loss: 0.06280

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.05125

Collected Steps per Second: 12938.57917
Overall Steps per Second: 10437.05066

Timestep Collection Time: 3.86472
Timestep Consumption Time: 0.92629
PPO Batch Consumption Time: 0.08150
Total Iteration Time: 4.79101

Cumulative Model Updates: 6399
Cumulative Timesteps: 106799948

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05071
Policy Entropy: 1.18175
Value Function Loss: 0.07268

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06601
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.05453

Collected Steps per Second: 13149.40705
Overall Steps per Second: 10457.88035

Timestep Collection Time: 3.80534
Timestep Consumption Time: 0.97937
PPO Batch Consumption Time: 0.07749
Total Iteration Time: 4.78472

Cumulative Model Updates: 6402
Cumulative Timesteps: 106849986

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 106849986...
Checkpoint 106849986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04906
Policy Entropy: 1.18334
Value Function Loss: 0.08385

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.07030

Collected Steps per Second: 12943.60206
Overall Steps per Second: 10474.48652

Timestep Collection Time: 3.86538
Timestep Consumption Time: 0.91117
PPO Batch Consumption Time: 0.08348
Total Iteration Time: 4.77656

Cumulative Model Updates: 6405
Cumulative Timesteps: 106900018

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08218
Policy Entropy: 1.19736
Value Function Loss: 0.07853

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 13078.84310
Overall Steps per Second: 10407.24738

Timestep Collection Time: 3.82434
Timestep Consumption Time: 0.98173
PPO Batch Consumption Time: 0.07652
Total Iteration Time: 4.80607

Cumulative Model Updates: 6408
Cumulative Timesteps: 106950036

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 106950036...
Checkpoint 106950036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06348
Policy Entropy: 1.19105
Value Function Loss: 0.07619

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.05936

Collected Steps per Second: 13366.59917
Overall Steps per Second: 10500.98602

Timestep Collection Time: 3.74411
Timestep Consumption Time: 1.02173
PPO Batch Consumption Time: 0.09722
Total Iteration Time: 4.76584

Cumulative Model Updates: 6411
Cumulative Timesteps: 107000082

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00992
Policy Entropy: 1.18632
Value Function Loss: 0.07945

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.05451

Collected Steps per Second: 13713.11647
Overall Steps per Second: 10845.57378

Timestep Collection Time: 3.64964
Timestep Consumption Time: 0.96496
PPO Batch Consumption Time: 0.07870
Total Iteration Time: 4.61460

Cumulative Model Updates: 6414
Cumulative Timesteps: 107050130

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 107050130...
Checkpoint 107050130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02811
Policy Entropy: 1.18577
Value Function Loss: 0.06772

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07378
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.05706

Collected Steps per Second: 12171.03915
Overall Steps per Second: 9936.92615

Timestep Collection Time: 4.10828
Timestep Consumption Time: 0.92366
PPO Batch Consumption Time: 0.06886
Total Iteration Time: 5.03194

Cumulative Model Updates: 6417
Cumulative Timesteps: 107100132

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04183
Policy Entropy: 1.18794
Value Function Loss: 0.08214

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.06218

Collected Steps per Second: 11930.55443
Overall Steps per Second: 9765.77005

Timestep Collection Time: 4.19243
Timestep Consumption Time: 0.92934
PPO Batch Consumption Time: 0.08245
Total Iteration Time: 5.12177

Cumulative Model Updates: 6420
Cumulative Timesteps: 107150150

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 107150150...
Checkpoint 107150150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14019
Policy Entropy: 1.17454
Value Function Loss: 0.06207

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.05766

Collected Steps per Second: 12882.01437
Overall Steps per Second: 10440.40124

Timestep Collection Time: 3.88433
Timestep Consumption Time: 0.90840
PPO Batch Consumption Time: 0.06027
Total Iteration Time: 4.79273

Cumulative Model Updates: 6423
Cumulative Timesteps: 107200188

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05942
Policy Entropy: 1.17110
Value Function Loss: 0.06289

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.05229

Collected Steps per Second: 12255.21980
Overall Steps per Second: 9673.18894

Timestep Collection Time: 4.08169
Timestep Consumption Time: 1.08951
PPO Batch Consumption Time: 0.11740
Total Iteration Time: 5.17120

Cumulative Model Updates: 6426
Cumulative Timesteps: 107250210

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 107250210...
Checkpoint 107250210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10764
Policy Entropy: 1.18264
Value Function Loss: 0.04129

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.04614
Value Function Update Magnitude: 0.05150

Collected Steps per Second: 12042.93044
Overall Steps per Second: 10003.99753

Timestep Collection Time: 4.15464
Timestep Consumption Time: 0.84676
PPO Batch Consumption Time: 0.06275
Total Iteration Time: 5.00140

Cumulative Model Updates: 6429
Cumulative Timesteps: 107300244

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08496
Policy Entropy: 1.16489
Value Function Loss: 0.04536

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.04887

Collected Steps per Second: 12179.16669
Overall Steps per Second: 9646.77419

Timestep Collection Time: 4.10619
Timestep Consumption Time: 1.07792
PPO Batch Consumption Time: 0.10625
Total Iteration Time: 5.18412

Cumulative Model Updates: 6432
Cumulative Timesteps: 107350254

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 107350254...
Checkpoint 107350254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09542
Policy Entropy: 1.18532
Value Function Loss: 0.05132

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.05059

Collected Steps per Second: 12751.50342
Overall Steps per Second: 10199.04508

Timestep Collection Time: 3.92299
Timestep Consumption Time: 0.98178
PPO Batch Consumption Time: 0.06560
Total Iteration Time: 4.90477

Cumulative Model Updates: 6435
Cumulative Timesteps: 107400278

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03448
Policy Entropy: 1.18692
Value Function Loss: 0.06543

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.04791
Value Function Update Magnitude: 0.05521

Collected Steps per Second: 12676.06948
Overall Steps per Second: 10186.09478

Timestep Collection Time: 3.94460
Timestep Consumption Time: 0.96425
PPO Batch Consumption Time: 0.07249
Total Iteration Time: 4.90885

Cumulative Model Updates: 6438
Cumulative Timesteps: 107450280

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 107450280...
Checkpoint 107450280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16073
Policy Entropy: 1.17450
Value Function Loss: 0.07518

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.05098

Collected Steps per Second: 13196.41356
Overall Steps per Second: 10610.46508

Timestep Collection Time: 3.78967
Timestep Consumption Time: 0.92361
PPO Batch Consumption Time: 0.06330
Total Iteration Time: 4.71327

Cumulative Model Updates: 6441
Cumulative Timesteps: 107500290

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09092
Policy Entropy: 1.17119
Value Function Loss: 0.08040

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.05638
Value Function Update Magnitude: 0.05014

Collected Steps per Second: 12812.30051
Overall Steps per Second: 10327.50410

Timestep Collection Time: 3.90297
Timestep Consumption Time: 0.93905
PPO Batch Consumption Time: 0.08943
Total Iteration Time: 4.84202

Cumulative Model Updates: 6444
Cumulative Timesteps: 107550296

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 107550296...
Checkpoint 107550296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11705
Policy Entropy: 1.17975
Value Function Loss: 0.07155

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14279
Policy Update Magnitude: 0.05992
Value Function Update Magnitude: 0.05824

Collected Steps per Second: 12375.57770
Overall Steps per Second: 9941.34829

Timestep Collection Time: 4.04280
Timestep Consumption Time: 0.98992
PPO Batch Consumption Time: 0.06784
Total Iteration Time: 5.03272

Cumulative Model Updates: 6447
Cumulative Timesteps: 107600328

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05672
Policy Entropy: 1.18527
Value Function Loss: 0.07609

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.05991
Value Function Update Magnitude: 0.06238

Collected Steps per Second: 10171.87103
Overall Steps per Second: 8164.99279

Timestep Collection Time: 4.91945
Timestep Consumption Time: 1.20915
PPO Batch Consumption Time: 0.12714
Total Iteration Time: 6.12860

Cumulative Model Updates: 6450
Cumulative Timesteps: 107650368

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 107650368...
Checkpoint 107650368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00806
Policy Entropy: 1.19558
Value Function Loss: 0.07436

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.06325
Value Function Update Magnitude: 0.05590

Collected Steps per Second: 11814.73599
Overall Steps per Second: 9530.28267

Timestep Collection Time: 4.23522
Timestep Consumption Time: 1.01520
PPO Batch Consumption Time: 0.06908
Total Iteration Time: 5.25042

Cumulative Model Updates: 6453
Cumulative Timesteps: 107700406

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08018
Policy Entropy: 1.20065
Value Function Loss: 0.07985

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.06264
Value Function Update Magnitude: 0.05908

Collected Steps per Second: 10861.16219
Overall Steps per Second: 8707.61385

Timestep Collection Time: 4.60374
Timestep Consumption Time: 1.13859
PPO Batch Consumption Time: 0.08670
Total Iteration Time: 5.74233

Cumulative Model Updates: 6456
Cumulative Timesteps: 107750408

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 107750408...
Checkpoint 107750408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00757
Policy Entropy: 1.20640
Value Function Loss: 0.08167

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.05969
Value Function Update Magnitude: 0.06573

Collected Steps per Second: 11824.44239
Overall Steps per Second: 9619.43337

Timestep Collection Time: 4.23242
Timestep Consumption Time: 0.97017
PPO Batch Consumption Time: 0.08045
Total Iteration Time: 5.20259

Cumulative Model Updates: 6459
Cumulative Timesteps: 107800454

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07595
Policy Entropy: 1.19898
Value Function Loss: 0.09301

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.08192

Collected Steps per Second: 11217.80026
Overall Steps per Second: 9120.62251

Timestep Collection Time: 4.46023
Timestep Consumption Time: 1.02558
PPO Batch Consumption Time: 0.07712
Total Iteration Time: 5.48581

Cumulative Model Updates: 6462
Cumulative Timesteps: 107850488

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 107850488...
Checkpoint 107850488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15348
Policy Entropy: 1.19366
Value Function Loss: 0.08186

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.06223
Value Function Update Magnitude: 0.08186

Collected Steps per Second: 10516.76641
Overall Steps per Second: 8524.38846

Timestep Collection Time: 4.75450
Timestep Consumption Time: 1.11125
PPO Batch Consumption Time: 0.10327
Total Iteration Time: 5.86576

Cumulative Model Updates: 6465
Cumulative Timesteps: 107900490

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05831
Policy Entropy: 1.19206
Value Function Loss: 0.07193

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 12069.48611
Overall Steps per Second: 9720.79495

Timestep Collection Time: 4.14417
Timestep Consumption Time: 1.00129
PPO Batch Consumption Time: 0.07141
Total Iteration Time: 5.14546

Cumulative Model Updates: 6468
Cumulative Timesteps: 107950508

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 107950508...
Checkpoint 107950508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10702
Policy Entropy: 1.18620
Value Function Loss: 0.06593

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.05727
Value Function Update Magnitude: 0.05533

Collected Steps per Second: 11270.56186
Overall Steps per Second: 8893.54490

Timestep Collection Time: 4.43793
Timestep Consumption Time: 1.18615
PPO Batch Consumption Time: 0.12039
Total Iteration Time: 5.62408

Cumulative Model Updates: 6471
Cumulative Timesteps: 108000526

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05941
Policy Entropy: 1.19241
Value Function Loss: 0.07068

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.05649

Collected Steps per Second: 11778.17846
Overall Steps per Second: 9591.10696

Timestep Collection Time: 4.24548
Timestep Consumption Time: 0.96810
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 5.21358

Cumulative Model Updates: 6474
Cumulative Timesteps: 108050530

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 108050530...
Checkpoint 108050530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03480
Policy Entropy: 1.19301
Value Function Loss: 0.07329

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.06524

Collected Steps per Second: 10645.36576
Overall Steps per Second: 8642.65140

Timestep Collection Time: 4.69763
Timestep Consumption Time: 1.08856
PPO Batch Consumption Time: 0.06967
Total Iteration Time: 5.78619

Cumulative Model Updates: 6477
Cumulative Timesteps: 108100538

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10525
Policy Entropy: 1.19608
Value Function Loss: 0.07081

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 0.05442
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 11388.13148
Overall Steps per Second: 8936.85379

Timestep Collection Time: 4.39299
Timestep Consumption Time: 1.20495
PPO Batch Consumption Time: 0.10297
Total Iteration Time: 5.59794

Cumulative Model Updates: 6480
Cumulative Timesteps: 108150566

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 108150566...
Checkpoint 108150566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02271
Policy Entropy: 1.19155
Value Function Loss: 0.07374

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06439
Policy Update Magnitude: 0.05577
Value Function Update Magnitude: 0.06814

Collected Steps per Second: 11626.93342
Overall Steps per Second: 9348.63150

Timestep Collection Time: 4.30088
Timestep Consumption Time: 1.04814
PPO Batch Consumption Time: 0.11806
Total Iteration Time: 5.34902

Cumulative Model Updates: 6483
Cumulative Timesteps: 108200572

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05488
Policy Entropy: 1.18640
Value Function Loss: 0.07142

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.05835
Value Function Update Magnitude: 0.07115

Collected Steps per Second: 11674.91821
Overall Steps per Second: 9252.06591

Timestep Collection Time: 4.28286
Timestep Consumption Time: 1.12156
PPO Batch Consumption Time: 0.08614
Total Iteration Time: 5.40441

Cumulative Model Updates: 6486
Cumulative Timesteps: 108250574

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 108250574...
Checkpoint 108250574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06370
Policy Entropy: 1.18000
Value Function Loss: 0.06745

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.07720

Collected Steps per Second: 11834.48529
Overall Steps per Second: 9311.79266

Timestep Collection Time: 4.22731
Timestep Consumption Time: 1.14524
PPO Batch Consumption Time: 0.11915
Total Iteration Time: 5.37254

Cumulative Model Updates: 6489
Cumulative Timesteps: 108300602

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05347
Policy Entropy: 1.17255
Value Function Loss: 0.05985

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.07985

Collected Steps per Second: 12300.97120
Overall Steps per Second: 9625.04829

Timestep Collection Time: 4.06488
Timestep Consumption Time: 1.13010
PPO Batch Consumption Time: 0.10488
Total Iteration Time: 5.19499

Cumulative Model Updates: 6492
Cumulative Timesteps: 108350604

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 108350604...
Checkpoint 108350604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15272
Policy Entropy: 1.17116
Value Function Loss: 0.06948

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.05955
Value Function Update Magnitude: 0.07492

Collected Steps per Second: 12052.68722
Overall Steps per Second: 9672.26384

Timestep Collection Time: 4.14895
Timestep Consumption Time: 1.02109
PPO Batch Consumption Time: 0.06776
Total Iteration Time: 5.17004

Cumulative Model Updates: 6495
Cumulative Timesteps: 108400610

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02230
Policy Entropy: 1.17083
Value Function Loss: 0.07729

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.08187

Collected Steps per Second: 10273.61939
Overall Steps per Second: 8277.96048

Timestep Collection Time: 4.86936
Timestep Consumption Time: 1.17391
PPO Batch Consumption Time: 0.09505
Total Iteration Time: 6.04328

Cumulative Model Updates: 6498
Cumulative Timesteps: 108450636

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 108450636...
Checkpoint 108450636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01500
Policy Entropy: 1.16759
Value Function Loss: 0.07923

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.06361
Value Function Update Magnitude: 0.08463

Collected Steps per Second: 12736.97236
Overall Steps per Second: 10275.16554

Timestep Collection Time: 3.92903
Timestep Consumption Time: 0.94135
PPO Batch Consumption Time: 0.06641
Total Iteration Time: 4.87038

Cumulative Model Updates: 6501
Cumulative Timesteps: 108500680

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00346
Policy Entropy: 1.16408
Value Function Loss: 0.07139

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.08256

Collected Steps per Second: 12708.01433
Overall Steps per Second: 10222.69372

Timestep Collection Time: 3.93468
Timestep Consumption Time: 0.95659
PPO Batch Consumption Time: 0.08171
Total Iteration Time: 4.89127

Cumulative Model Updates: 6504
Cumulative Timesteps: 108550682

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 108550682...
Checkpoint 108550682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03044
Policy Entropy: 1.17991
Value Function Loss: 0.06451

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06922
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.07789

Collected Steps per Second: 12841.75986
Overall Steps per Second: 10631.81223

Timestep Collection Time: 3.89355
Timestep Consumption Time: 0.80932
PPO Batch Consumption Time: 0.06327
Total Iteration Time: 4.70287

Cumulative Model Updates: 6507
Cumulative Timesteps: 108600682

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10075
Policy Entropy: 1.18357
Value Function Loss: 0.06362

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07889
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.08200

Collected Steps per Second: 12974.55758
Overall Steps per Second: 10281.11852

Timestep Collection Time: 3.85370
Timestep Consumption Time: 1.00959
PPO Batch Consumption Time: 0.09027
Total Iteration Time: 4.86328

Cumulative Model Updates: 6510
Cumulative Timesteps: 108650682

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 108650682...
Checkpoint 108650682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07651
Policy Entropy: 1.18566
Value Function Loss: 0.06632

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.08232

Collected Steps per Second: 12953.25120
Overall Steps per Second: 10533.54355

Timestep Collection Time: 3.86204
Timestep Consumption Time: 0.88717
PPO Batch Consumption Time: 0.06150
Total Iteration Time: 4.74921

Cumulative Model Updates: 6513
Cumulative Timesteps: 108700708

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18840
Policy Entropy: 1.18329
Value Function Loss: 0.06618

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06425
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.08324

Collected Steps per Second: 12358.63202
Overall Steps per Second: 9955.84102

Timestep Collection Time: 4.04721
Timestep Consumption Time: 0.97677
PPO Batch Consumption Time: 0.08039
Total Iteration Time: 5.02399

Cumulative Model Updates: 6516
Cumulative Timesteps: 108750726

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 108750726...
Checkpoint 108750726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06457
Policy Entropy: 1.17847
Value Function Loss: 0.06719

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07484
Policy Update Magnitude: 0.05524
Value Function Update Magnitude: 0.07384

Collected Steps per Second: 12872.42440
Overall Steps per Second: 10051.45327

Timestep Collection Time: 3.88458
Timestep Consumption Time: 1.09022
PPO Batch Consumption Time: 0.11362
Total Iteration Time: 4.97480

Cumulative Model Updates: 6519
Cumulative Timesteps: 108800730

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12215
Policy Entropy: 1.18286
Value Function Loss: 0.07626

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.06830

Collected Steps per Second: 13185.16382
Overall Steps per Second: 10902.91733

Timestep Collection Time: 3.79335
Timestep Consumption Time: 0.79404
PPO Batch Consumption Time: 0.06155
Total Iteration Time: 4.58740

Cumulative Model Updates: 6522
Cumulative Timesteps: 108850746

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 108850746...
Checkpoint 108850746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00361
Policy Entropy: 1.19385
Value Function Loss: 0.08501

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.05668
Value Function Update Magnitude: 0.06473

Collected Steps per Second: 12250.25975
Overall Steps per Second: 9632.60479

Timestep Collection Time: 4.08383
Timestep Consumption Time: 1.10978
PPO Batch Consumption Time: 0.12037
Total Iteration Time: 5.19361

Cumulative Model Updates: 6525
Cumulative Timesteps: 108900774

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01405
Policy Entropy: 1.18883
Value Function Loss: 0.07975

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.05942
Value Function Update Magnitude: 0.06546

Collected Steps per Second: 13344.47109
Overall Steps per Second: 10886.62928

Timestep Collection Time: 3.74687
Timestep Consumption Time: 0.84592
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 4.59279

Cumulative Model Updates: 6528
Cumulative Timesteps: 108950774

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 108950774...
Checkpoint 108950774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08256
Policy Entropy: 1.17730
Value Function Loss: 0.05939

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06551
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.08564

Collected Steps per Second: 11643.52400
Overall Steps per Second: 9242.52574

Timestep Collection Time: 4.29801
Timestep Consumption Time: 1.11653
PPO Batch Consumption Time: 0.07118
Total Iteration Time: 5.41454

Cumulative Model Updates: 6531
Cumulative Timesteps: 109000818

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04388
Policy Entropy: 1.16730
Value Function Loss: 0.05213

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.06432
Value Function Update Magnitude: 0.08918

Collected Steps per Second: 11351.18300
Overall Steps per Second: 9244.19361

Timestep Collection Time: 4.40677
Timestep Consumption Time: 1.00442
PPO Batch Consumption Time: 0.07026
Total Iteration Time: 5.41118

Cumulative Model Updates: 6534
Cumulative Timesteps: 109050840

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 109050840...
Checkpoint 109050840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02840
Policy Entropy: 1.17313
Value Function Loss: 0.06077

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.06828
Value Function Update Magnitude: 0.08802

Collected Steps per Second: 10887.72439
Overall Steps per Second: 8989.96028

Timestep Collection Time: 4.59545
Timestep Consumption Time: 0.97009
PPO Batch Consumption Time: 0.07854
Total Iteration Time: 5.56554

Cumulative Model Updates: 6537
Cumulative Timesteps: 109100874

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10613
Policy Entropy: 1.18241
Value Function Loss: 0.05961

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.08849

Collected Steps per Second: 11959.86008
Overall Steps per Second: 9632.89198

Timestep Collection Time: 4.18483
Timestep Consumption Time: 1.01091
PPO Batch Consumption Time: 0.08139
Total Iteration Time: 5.19574

Cumulative Model Updates: 6540
Cumulative Timesteps: 109150924

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 109150924...
Checkpoint 109150924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04598
Policy Entropy: 1.19147
Value Function Loss: 0.06441

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06998
Policy Update Magnitude: 0.05983
Value Function Update Magnitude: 0.08635

Collected Steps per Second: 11619.18819
Overall Steps per Second: 9418.31161

Timestep Collection Time: 4.30512
Timestep Consumption Time: 1.00602
PPO Batch Consumption Time: 0.07481
Total Iteration Time: 5.31114

Cumulative Model Updates: 6543
Cumulative Timesteps: 109200946

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12260
Policy Entropy: 1.18166
Value Function Loss: 0.06901

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.07549

Collected Steps per Second: 11959.60417
Overall Steps per Second: 9504.94907

Timestep Collection Time: 4.18308
Timestep Consumption Time: 1.08028
PPO Batch Consumption Time: 0.08270
Total Iteration Time: 5.26336

Cumulative Model Updates: 6546
Cumulative Timesteps: 109250974

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 109250974...
Checkpoint 109250974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01704
Policy Entropy: 1.17326
Value Function Loss: 0.07824

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.06950

Collected Steps per Second: 11710.84497
Overall Steps per Second: 9346.10875

Timestep Collection Time: 4.27330
Timestep Consumption Time: 1.08122
PPO Batch Consumption Time: 0.08313
Total Iteration Time: 5.35453

Cumulative Model Updates: 6549
Cumulative Timesteps: 109301018

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08314
Policy Entropy: 1.16844
Value Function Loss: 0.07532

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.08368

Collected Steps per Second: 11632.01297
Overall Steps per Second: 9275.99199

Timestep Collection Time: 4.29934
Timestep Consumption Time: 1.09200
PPO Batch Consumption Time: 0.11736
Total Iteration Time: 5.39134

Cumulative Model Updates: 6552
Cumulative Timesteps: 109351028

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 109351028...
Checkpoint 109351028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03257
Policy Entropy: 1.16950
Value Function Loss: 0.07629

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.08830

Collected Steps per Second: 11705.40699
Overall Steps per Second: 9272.75228

Timestep Collection Time: 4.27238
Timestep Consumption Time: 1.12084
PPO Batch Consumption Time: 0.08473
Total Iteration Time: 5.39322

Cumulative Model Updates: 6555
Cumulative Timesteps: 109401038

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14642
Policy Entropy: 1.18019
Value Function Loss: 0.07405

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.05503
Value Function Update Magnitude: 0.09280

Collected Steps per Second: 11689.11643
Overall Steps per Second: 9266.83941

Timestep Collection Time: 4.27783
Timestep Consumption Time: 1.11819
PPO Batch Consumption Time: 0.10631
Total Iteration Time: 5.39601

Cumulative Model Updates: 6558
Cumulative Timesteps: 109451042

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 109451042...
Checkpoint 109451042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09481
Policy Entropy: 1.18729
Value Function Loss: 0.06285

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06077
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.09183

Collected Steps per Second: 12364.92190
Overall Steps per Second: 9667.53433

Timestep Collection Time: 4.04629
Timestep Consumption Time: 1.12897
PPO Batch Consumption Time: 0.10961
Total Iteration Time: 5.17526

Cumulative Model Updates: 6561
Cumulative Timesteps: 109501074

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01230
Policy Entropy: 1.18475
Value Function Loss: 0.06982

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06635
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.07489

Collected Steps per Second: 11900.63054
Overall Steps per Second: 9592.66392

Timestep Collection Time: 4.20297
Timestep Consumption Time: 1.01122
PPO Batch Consumption Time: 0.06668
Total Iteration Time: 5.21419

Cumulative Model Updates: 6564
Cumulative Timesteps: 109551092

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 109551092...
Checkpoint 109551092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15206
Policy Entropy: 1.18800
Value Function Loss: 0.08796

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.07746

Collected Steps per Second: 10732.07547
Overall Steps per Second: 8666.95561

Timestep Collection Time: 4.66266
Timestep Consumption Time: 1.11100
PPO Batch Consumption Time: 0.10066
Total Iteration Time: 5.77365

Cumulative Model Updates: 6567
Cumulative Timesteps: 109601132

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02576
Policy Entropy: 1.19035
Value Function Loss: 0.09378

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.08346

Collected Steps per Second: 12170.86554
Overall Steps per Second: 9617.58770

Timestep Collection Time: 4.10916
Timestep Consumption Time: 1.09090
PPO Batch Consumption Time: 0.09050
Total Iteration Time: 5.20006

Cumulative Model Updates: 6570
Cumulative Timesteps: 109651144

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 109651144...
Checkpoint 109651144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03904
Policy Entropy: 1.19257
Value Function Loss: 0.08636

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.07720

Collected Steps per Second: 11530.69373
Overall Steps per Second: 9299.17735

Timestep Collection Time: 4.33643
Timestep Consumption Time: 1.04061
PPO Batch Consumption Time: 0.08392
Total Iteration Time: 5.37703

Cumulative Model Updates: 6573
Cumulative Timesteps: 109701146

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01184
Policy Entropy: 1.18985
Value Function Loss: 0.07356

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.07514

Collected Steps per Second: 11950.58176
Overall Steps per Second: 9847.64728

Timestep Collection Time: 4.18691
Timestep Consumption Time: 0.89410
PPO Batch Consumption Time: 0.07141
Total Iteration Time: 5.08101

Cumulative Model Updates: 6576
Cumulative Timesteps: 109751182

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 109751182...
Checkpoint 109751182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13798
Policy Entropy: 1.18705
Value Function Loss: 0.06899

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.06407

Collected Steps per Second: 10596.61334
Overall Steps per Second: 8478.71318

Timestep Collection Time: 4.71962
Timestep Consumption Time: 1.17892
PPO Batch Consumption Time: 0.07759
Total Iteration Time: 5.89854

Cumulative Model Updates: 6579
Cumulative Timesteps: 109801194

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01994
Policy Entropy: 1.19498
Value Function Loss: 0.05963

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 11845.80514
Overall Steps per Second: 9300.72430

Timestep Collection Time: 4.22124
Timestep Consumption Time: 1.15511
PPO Batch Consumption Time: 0.11244
Total Iteration Time: 5.37636

Cumulative Model Updates: 6582
Cumulative Timesteps: 109851198

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 109851198...
Checkpoint 109851198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04987
Policy Entropy: 1.18575
Value Function Loss: 0.05546

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07215
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.06689

Collected Steps per Second: 11843.50090
Overall Steps per Second: 9605.29483

Timestep Collection Time: 4.22274
Timestep Consumption Time: 0.98397
PPO Batch Consumption Time: 0.07882
Total Iteration Time: 5.20671

Cumulative Model Updates: 6585
Cumulative Timesteps: 109901210

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14294
Policy Entropy: 1.19499
Value Function Loss: 0.06776

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07757
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 12187.18367
Overall Steps per Second: 9970.12505

Timestep Collection Time: 4.10267
Timestep Consumption Time: 0.91231
PPO Batch Consumption Time: 0.06623
Total Iteration Time: 5.01498

Cumulative Model Updates: 6588
Cumulative Timesteps: 109951210

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 109951210...
Checkpoint 109951210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05286
Policy Entropy: 1.19001
Value Function Loss: 0.07311

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.07473

Collected Steps per Second: 11875.93234
Overall Steps per Second: 10022.98623

Timestep Collection Time: 4.21356
Timestep Consumption Time: 0.77896
PPO Batch Consumption Time: 0.02656
Total Iteration Time: 4.99252

Cumulative Model Updates: 6591
Cumulative Timesteps: 110001250

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08967
Policy Entropy: 1.19443
Value Function Loss: 0.08071

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.07207

Collected Steps per Second: 12887.02885
Overall Steps per Second: 10436.29458

Timestep Collection Time: 3.88096
Timestep Consumption Time: 0.91136
PPO Batch Consumption Time: 0.06978
Total Iteration Time: 4.79231

Cumulative Model Updates: 6594
Cumulative Timesteps: 110051264

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 110051264...
Checkpoint 110051264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04951
Policy Entropy: 1.19070
Value Function Loss: 0.08386

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05597
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.08066

Collected Steps per Second: 12171.64330
Overall Steps per Second: 9759.51588

Timestep Collection Time: 4.11152
Timestep Consumption Time: 1.01619
PPO Batch Consumption Time: 0.09537
Total Iteration Time: 5.12771

Cumulative Model Updates: 6597
Cumulative Timesteps: 110101308

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06361
Policy Entropy: 1.18631
Value Function Loss: 0.08498

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06020
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.08353

Collected Steps per Second: 12599.74203
Overall Steps per Second: 9983.61290

Timestep Collection Time: 3.97119
Timestep Consumption Time: 1.04062
PPO Batch Consumption Time: 0.07626
Total Iteration Time: 5.01181

Cumulative Model Updates: 6600
Cumulative Timesteps: 110151344

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 110151344...
Checkpoint 110151344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19594
Policy Entropy: 1.18199
Value Function Loss: 0.06565

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.08022

Collected Steps per Second: 13265.86496
Overall Steps per Second: 10694.63081

Timestep Collection Time: 3.77088
Timestep Consumption Time: 0.90661
PPO Batch Consumption Time: 0.06536
Total Iteration Time: 4.67749

Cumulative Model Updates: 6603
Cumulative Timesteps: 110201368

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00979
Policy Entropy: 1.18491
Value Function Loss: 0.06459

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.06415

Collected Steps per Second: 12154.74729
Overall Steps per Second: 9507.78654

Timestep Collection Time: 4.11477
Timestep Consumption Time: 1.14555
PPO Batch Consumption Time: 0.10594
Total Iteration Time: 5.26032

Cumulative Model Updates: 6606
Cumulative Timesteps: 110251382

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 110251382...
Checkpoint 110251382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16657
Policy Entropy: 1.18832
Value Function Loss: 0.06583

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06508
Policy Update Magnitude: 0.05758
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 11101.09861
Overall Steps per Second: 8908.81277

Timestep Collection Time: 4.50496
Timestep Consumption Time: 1.10858
PPO Batch Consumption Time: 0.08623
Total Iteration Time: 5.61354

Cumulative Model Updates: 6609
Cumulative Timesteps: 110301392

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01261
Policy Entropy: 1.18786
Value Function Loss: 0.07905

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.05637

Collected Steps per Second: 11688.51343
Overall Steps per Second: 9443.86464

Timestep Collection Time: 4.27788
Timestep Consumption Time: 1.01678
PPO Batch Consumption Time: 0.07086
Total Iteration Time: 5.29465

Cumulative Model Updates: 6612
Cumulative Timesteps: 110351394

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 110351394...
Checkpoint 110351394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13309
Policy Entropy: 1.17088
Value Function Loss: 0.07822

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08883
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.07598

Collected Steps per Second: 11827.24576
Overall Steps per Second: 9476.33678

Timestep Collection Time: 4.22989
Timestep Consumption Time: 1.04936
PPO Batch Consumption Time: 0.06974
Total Iteration Time: 5.27926

Cumulative Model Updates: 6615
Cumulative Timesteps: 110401422

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08423
Policy Entropy: 1.16547
Value Function Loss: 0.07972

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.05781
Value Function Update Magnitude: 0.07738

Collected Steps per Second: 11582.77203
Overall Steps per Second: 8991.24271

Timestep Collection Time: 4.31710
Timestep Consumption Time: 1.24431
PPO Batch Consumption Time: 0.12669
Total Iteration Time: 5.56141

Cumulative Model Updates: 6618
Cumulative Timesteps: 110451426

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 110451426...
Checkpoint 110451426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07773
Policy Entropy: 1.17347
Value Function Loss: 0.07908

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.07105

Collected Steps per Second: 11821.90052
Overall Steps per Second: 9570.77362

Timestep Collection Time: 4.23248
Timestep Consumption Time: 0.99552
PPO Batch Consumption Time: 0.06992
Total Iteration Time: 5.22800

Cumulative Model Updates: 6621
Cumulative Timesteps: 110501462

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10818
Policy Entropy: 1.18628
Value Function Loss: 0.07388

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06950
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.08403

Collected Steps per Second: 10685.84613
Overall Steps per Second: 8392.51854

Timestep Collection Time: 4.68189
Timestep Consumption Time: 1.27937
PPO Batch Consumption Time: 0.11115
Total Iteration Time: 5.96126

Cumulative Model Updates: 6624
Cumulative Timesteps: 110551492

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 110551492...
Checkpoint 110551492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11999
Policy Entropy: 1.18335
Value Function Loss: 0.08320

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.06763

Collected Steps per Second: 11481.59530
Overall Steps per Second: 9281.68783

Timestep Collection Time: 4.35654
Timestep Consumption Time: 1.03257
PPO Batch Consumption Time: 0.06982
Total Iteration Time: 5.38911

Cumulative Model Updates: 6627
Cumulative Timesteps: 110601512

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10745
Policy Entropy: 1.17755
Value Function Loss: 0.06966

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.07879

Collected Steps per Second: 11964.47660
Overall Steps per Second: 9625.15325

Timestep Collection Time: 4.18338
Timestep Consumption Time: 1.01674
PPO Batch Consumption Time: 0.09666
Total Iteration Time: 5.20012

Cumulative Model Updates: 6630
Cumulative Timesteps: 110651564

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 110651564...
Checkpoint 110651564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00357
Policy Entropy: 1.18984
Value Function Loss: 0.07263

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.08111

Collected Steps per Second: 11180.14230
Overall Steps per Second: 8989.29512

Timestep Collection Time: 4.47651
Timestep Consumption Time: 1.09100
PPO Batch Consumption Time: 0.07485
Total Iteration Time: 5.56751

Cumulative Model Updates: 6633
Cumulative Timesteps: 110701612

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08699
Policy Entropy: 1.19355
Value Function Loss: 0.05752

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.07535

Collected Steps per Second: 11933.38951
Overall Steps per Second: 9319.93591

Timestep Collection Time: 4.19076
Timestep Consumption Time: 1.17515
PPO Batch Consumption Time: 0.11980
Total Iteration Time: 5.36592

Cumulative Model Updates: 6636
Cumulative Timesteps: 110751622

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 110751622...
Checkpoint 110751622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01135
Policy Entropy: 1.19116
Value Function Loss: 0.06372

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.07204

Collected Steps per Second: 11446.39377
Overall Steps per Second: 8957.65382

Timestep Collection Time: 4.37116
Timestep Consumption Time: 1.21446
PPO Batch Consumption Time: 0.12007
Total Iteration Time: 5.58561

Cumulative Model Updates: 6639
Cumulative Timesteps: 110801656

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02254
Policy Entropy: 1.18708
Value Function Loss: 0.05438

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.07821

Collected Steps per Second: 11699.12450
Overall Steps per Second: 9338.17426

Timestep Collection Time: 4.27502
Timestep Consumption Time: 1.08084
PPO Batch Consumption Time: 0.07298
Total Iteration Time: 5.35586

Cumulative Model Updates: 6642
Cumulative Timesteps: 110851670

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 110851670...
Checkpoint 110851670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13309
Policy Entropy: 1.19331
Value Function Loss: 0.05999

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.06779

Collected Steps per Second: 11541.69060
Overall Steps per Second: 9216.41951

Timestep Collection Time: 4.33507
Timestep Consumption Time: 1.09372
PPO Batch Consumption Time: 0.11764
Total Iteration Time: 5.42879

Cumulative Model Updates: 6645
Cumulative Timesteps: 110901704

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18863
Policy Entropy: 1.19398
Value Function Loss: 0.06726

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.05231
Value Function Update Magnitude: 0.06719

Collected Steps per Second: 11887.37969
Overall Steps per Second: 9663.02810

Timestep Collection Time: 4.20631
Timestep Consumption Time: 0.96826
PPO Batch Consumption Time: 0.06911
Total Iteration Time: 5.17457

Cumulative Model Updates: 6648
Cumulative Timesteps: 110951706

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 110951706...
Checkpoint 110951706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05397
Policy Entropy: 1.19453
Value Function Loss: 0.06196

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.05083
Value Function Update Magnitude: 0.07509

Collected Steps per Second: 10621.23745
Overall Steps per Second: 8603.89841

Timestep Collection Time: 4.71150
Timestep Consumption Time: 1.10470
PPO Batch Consumption Time: 0.06585
Total Iteration Time: 5.81620

Cumulative Model Updates: 6651
Cumulative Timesteps: 111001748

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04969
Policy Entropy: 1.20857
Value Function Loss: 0.06540

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.04708
Value Function Update Magnitude: 0.07436

Collected Steps per Second: 12103.35467
Overall Steps per Second: 9676.05608

Timestep Collection Time: 4.13142
Timestep Consumption Time: 1.03639
PPO Batch Consumption Time: 0.08674
Total Iteration Time: 5.16781

Cumulative Model Updates: 6654
Cumulative Timesteps: 111051752

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 111051752...
Checkpoint 111051752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03410
Policy Entropy: 1.18991
Value Function Loss: 0.06564

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.07435

Collected Steps per Second: 11836.36018
Overall Steps per Second: 9297.48884

Timestep Collection Time: 4.22596
Timestep Consumption Time: 1.15399
PPO Batch Consumption Time: 0.07253
Total Iteration Time: 5.37995

Cumulative Model Updates: 6657
Cumulative Timesteps: 111101772

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11587
Policy Entropy: 1.18804
Value Function Loss: 0.06970

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 10490.37706
Overall Steps per Second: 8635.67789

Timestep Collection Time: 4.76742
Timestep Consumption Time: 1.02391
PPO Batch Consumption Time: 0.10310
Total Iteration Time: 5.79132

Cumulative Model Updates: 6660
Cumulative Timesteps: 111151784

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 111151784...
Checkpoint 111151784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00500
Policy Entropy: 1.20021
Value Function Loss: 0.05878

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.07652

Collected Steps per Second: 13379.30607
Overall Steps per Second: 10452.15689

Timestep Collection Time: 3.73741
Timestep Consumption Time: 1.04667
PPO Batch Consumption Time: 0.10087
Total Iteration Time: 4.78408

Cumulative Model Updates: 6663
Cumulative Timesteps: 111201788

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07120
Policy Entropy: 1.20324
Value Function Loss: 0.07238

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.05435
Value Function Update Magnitude: 0.08151

Collected Steps per Second: 13287.66234
Overall Steps per Second: 10413.41826

Timestep Collection Time: 3.76575
Timestep Consumption Time: 1.03940
PPO Batch Consumption Time: 0.10365
Total Iteration Time: 4.80515

Cumulative Model Updates: 6666
Cumulative Timesteps: 111251826

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 111251826...
Checkpoint 111251826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02627
Policy Entropy: 1.20815
Value Function Loss: 0.08500

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.08927

Collected Steps per Second: 13180.54095
Overall Steps per Second: 10512.42548

Timestep Collection Time: 3.79423
Timestep Consumption Time: 0.96300
PPO Batch Consumption Time: 0.10905
Total Iteration Time: 4.75723

Cumulative Model Updates: 6669
Cumulative Timesteps: 111301836

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12851
Policy Entropy: 1.20883
Value Function Loss: 0.08264

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.06127
Value Function Update Magnitude: 0.09200

Collected Steps per Second: 13204.30291
Overall Steps per Second: 10388.43100

Timestep Collection Time: 3.78937
Timestep Consumption Time: 1.02714
PPO Batch Consumption Time: 0.09754
Total Iteration Time: 4.81651

Cumulative Model Updates: 6672
Cumulative Timesteps: 111351872

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 111351872...
Checkpoint 111351872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12193
Policy Entropy: 1.22216
Value Function Loss: 0.07012

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.08792

Collected Steps per Second: 12897.73640
Overall Steps per Second: 10069.51629

Timestep Collection Time: 3.87742
Timestep Consumption Time: 1.08905
PPO Batch Consumption Time: 0.11994
Total Iteration Time: 4.96647

Cumulative Model Updates: 6675
Cumulative Timesteps: 111401882

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03981
Policy Entropy: 1.21488
Value Function Loss: 0.06822

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.08914

Collected Steps per Second: 13785.31013
Overall Steps per Second: 11056.94190

Timestep Collection Time: 3.62763
Timestep Consumption Time: 0.89514
PPO Batch Consumption Time: 0.06187
Total Iteration Time: 4.52277

Cumulative Model Updates: 6678
Cumulative Timesteps: 111451890

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 111451890...
Checkpoint 111451890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01809
Policy Entropy: 1.20796
Value Function Loss: 0.07070

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07639
Policy Update Magnitude: 0.05429
Value Function Update Magnitude: 0.08176

Collected Steps per Second: 13238.35529
Overall Steps per Second: 10248.34069

Timestep Collection Time: 3.77751
Timestep Consumption Time: 1.10211
PPO Batch Consumption Time: 0.11867
Total Iteration Time: 4.87962

Cumulative Model Updates: 6681
Cumulative Timesteps: 111501898

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11740
Policy Entropy: 1.20739
Value Function Loss: 0.08201

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.07848

Collected Steps per Second: 13291.11325
Overall Steps per Second: 10492.34758

Timestep Collection Time: 3.76312
Timestep Consumption Time: 1.00379
PPO Batch Consumption Time: 0.11683
Total Iteration Time: 4.76690

Cumulative Model Updates: 6684
Cumulative Timesteps: 111551914

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 111551914...
Checkpoint 111551914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09900
Policy Entropy: 1.20643
Value Function Loss: 0.06458

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.07557

Collected Steps per Second: 13301.54867
Overall Steps per Second: 10436.74870

Timestep Collection Time: 3.76122
Timestep Consumption Time: 1.03242
PPO Batch Consumption Time: 0.10117
Total Iteration Time: 4.79364

Cumulative Model Updates: 6687
Cumulative Timesteps: 111601944

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09260
Policy Entropy: 1.20808
Value Function Loss: 0.05153

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06140
Policy Update Magnitude: 0.05788
Value Function Update Magnitude: 0.07792

Collected Steps per Second: 13241.23072
Overall Steps per Second: 10411.88582

Timestep Collection Time: 3.77714
Timestep Consumption Time: 1.02641
PPO Batch Consumption Time: 0.10045
Total Iteration Time: 4.80355

Cumulative Model Updates: 6690
Cumulative Timesteps: 111651958

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 111651958...
Checkpoint 111651958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16522
Policy Entropy: 1.22034
Value Function Loss: 0.04784

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.07609

Collected Steps per Second: 13456.39476
Overall Steps per Second: 10479.82553

Timestep Collection Time: 3.71823
Timestep Consumption Time: 1.05608
PPO Batch Consumption Time: 0.10217
Total Iteration Time: 4.77432

Cumulative Model Updates: 6693
Cumulative Timesteps: 111701992

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10255
Policy Entropy: 1.22804
Value Function Loss: 0.05238

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10709
Policy Update Magnitude: 0.06083
Value Function Update Magnitude: 0.07386

Collected Steps per Second: 13288.30276
Overall Steps per Second: 10397.87011

Timestep Collection Time: 3.76512
Timestep Consumption Time: 1.04664
PPO Batch Consumption Time: 0.10086
Total Iteration Time: 4.81175

Cumulative Model Updates: 6696
Cumulative Timesteps: 111752024

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 111752024...
Checkpoint 111752024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03542
Policy Entropy: 1.22234
Value Function Loss: 0.06386

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05528
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.07158

Collected Steps per Second: 13245.48530
Overall Steps per Second: 10519.15302

Timestep Collection Time: 3.77699
Timestep Consumption Time: 0.97891
PPO Batch Consumption Time: 0.11251
Total Iteration Time: 4.75590

Cumulative Model Updates: 6699
Cumulative Timesteps: 111802052

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06923
Policy Entropy: 1.22523
Value Function Loss: 0.06083

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.05996
Value Function Update Magnitude: 0.07875

Collected Steps per Second: 13412.21144
Overall Steps per Second: 10447.92198

Timestep Collection Time: 3.73182
Timestep Consumption Time: 1.05879
PPO Batch Consumption Time: 0.10933
Total Iteration Time: 4.79062

Cumulative Model Updates: 6702
Cumulative Timesteps: 111852104

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 111852104...
Checkpoint 111852104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14780
Policy Entropy: 1.23126
Value Function Loss: 0.06758

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.06803

Collected Steps per Second: 13395.55868
Overall Steps per Second: 10451.66411

Timestep Collection Time: 3.73392
Timestep Consumption Time: 1.05173
PPO Batch Consumption Time: 0.11297
Total Iteration Time: 4.78565

Cumulative Model Updates: 6705
Cumulative Timesteps: 111902122

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09748
Policy Entropy: 1.22455
Value Function Loss: 0.07961

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.05980
Value Function Update Magnitude: 0.06379

Collected Steps per Second: 13692.27381
Overall Steps per Second: 10796.87957

Timestep Collection Time: 3.65242
Timestep Consumption Time: 0.97947
PPO Batch Consumption Time: 0.08091
Total Iteration Time: 4.63189

Cumulative Model Updates: 6708
Cumulative Timesteps: 111952132

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 111952132...
Checkpoint 111952132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02498
Policy Entropy: 1.22464
Value Function Loss: 0.08991

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.06291
Value Function Update Magnitude: 0.06009

Collected Steps per Second: 11229.20932
Overall Steps per Second: 8994.21687

Timestep Collection Time: 4.45356
Timestep Consumption Time: 1.10668
PPO Batch Consumption Time: 0.09183
Total Iteration Time: 5.56024

Cumulative Model Updates: 6711
Cumulative Timesteps: 112002142

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04213
Policy Entropy: 1.24283
Value Function Loss: 0.09704

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.06311
Value Function Update Magnitude: 0.06021

Collected Steps per Second: 11635.27326
Overall Steps per Second: 9278.02197

Timestep Collection Time: 4.30054
Timestep Consumption Time: 1.09263
PPO Batch Consumption Time: 0.09323
Total Iteration Time: 5.39318

Cumulative Model Updates: 6714
Cumulative Timesteps: 112052180

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 112052180...
Checkpoint 112052180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07380
Policy Entropy: 1.23905
Value Function Loss: 0.07781

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.06045

Collected Steps per Second: 11973.58856
Overall Steps per Second: 9314.66527

Timestep Collection Time: 4.17719
Timestep Consumption Time: 1.19240
PPO Batch Consumption Time: 0.12504
Total Iteration Time: 5.36960

Cumulative Model Updates: 6717
Cumulative Timesteps: 112102196

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01242
Policy Entropy: 1.23385
Value Function Loss: 0.07448

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07971
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.06954

Collected Steps per Second: 12058.49338
Overall Steps per Second: 9606.07984

Timestep Collection Time: 4.15010
Timestep Consumption Time: 1.05951
PPO Batch Consumption Time: 0.08517
Total Iteration Time: 5.20962

Cumulative Model Updates: 6720
Cumulative Timesteps: 112152240

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 112152240...
Checkpoint 112152240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02037
Policy Entropy: 1.22861
Value Function Loss: 0.07243

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.08475

Collected Steps per Second: 11831.38299
Overall Steps per Second: 9632.53172

Timestep Collection Time: 4.22757
Timestep Consumption Time: 0.96504
PPO Batch Consumption Time: 0.07925
Total Iteration Time: 5.19261

Cumulative Model Updates: 6723
Cumulative Timesteps: 112202258

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17951
Policy Entropy: 1.22977
Value Function Loss: 0.06773

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.06125
Value Function Update Magnitude: 0.08035

Collected Steps per Second: 11813.58215
Overall Steps per Second: 9497.37760

Timestep Collection Time: 4.23546
Timestep Consumption Time: 1.03294
PPO Batch Consumption Time: 0.07254
Total Iteration Time: 5.26840

Cumulative Model Updates: 6726
Cumulative Timesteps: 112252294

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 112252294...
Checkpoint 112252294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16674
Policy Entropy: 1.23793
Value Function Loss: 0.07609

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.06047
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 10035.92338
Overall Steps per Second: 8187.59606

Timestep Collection Time: 4.98350
Timestep Consumption Time: 1.12501
PPO Batch Consumption Time: 0.08649
Total Iteration Time: 6.10851

Cumulative Model Updates: 6729
Cumulative Timesteps: 112302308

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04444
Policy Entropy: 1.24201
Value Function Loss: 0.06657

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.05642
Value Function Update Magnitude: 0.06645

Collected Steps per Second: 12307.74361
Overall Steps per Second: 9885.87240

Timestep Collection Time: 4.06508
Timestep Consumption Time: 0.99588
PPO Batch Consumption Time: 0.06723
Total Iteration Time: 5.06096

Cumulative Model Updates: 6732
Cumulative Timesteps: 112352340

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 112352340...
Checkpoint 112352340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12823
Policy Entropy: 1.23851
Value Function Loss: 0.07682

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.08007

Collected Steps per Second: 10564.89014
Overall Steps per Second: 8482.38220

Timestep Collection Time: 4.73512
Timestep Consumption Time: 1.16252
PPO Batch Consumption Time: 0.10727
Total Iteration Time: 5.89764

Cumulative Model Updates: 6735
Cumulative Timesteps: 112402366

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09961
Policy Entropy: 1.23927
Value Function Loss: 0.05985

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.05581
Value Function Update Magnitude: 0.08042

Collected Steps per Second: 11955.70227
Overall Steps per Second: 9861.19166

Timestep Collection Time: 4.18478
Timestep Consumption Time: 0.88884
PPO Batch Consumption Time: 0.06765
Total Iteration Time: 5.07363

Cumulative Model Updates: 6738
Cumulative Timesteps: 112452398

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 112452398...
Checkpoint 112452398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03581
Policy Entropy: 1.23331
Value Function Loss: 0.06317

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.07315

Collected Steps per Second: 10796.63707
Overall Steps per Second: 8749.96196

Timestep Collection Time: 4.63385
Timestep Consumption Time: 1.08389
PPO Batch Consumption Time: 0.06095
Total Iteration Time: 5.71774

Cumulative Model Updates: 6741
Cumulative Timesteps: 112502428

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09586
Policy Entropy: 1.21768
Value Function Loss: 0.05481

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.05439
Value Function Update Magnitude: 0.07448

Collected Steps per Second: 12084.46906
Overall Steps per Second: 9660.86624

Timestep Collection Time: 4.14085
Timestep Consumption Time: 1.03881
PPO Batch Consumption Time: 0.08950
Total Iteration Time: 5.17966

Cumulative Model Updates: 6744
Cumulative Timesteps: 112552468

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 112552468...
Checkpoint 112552468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04436
Policy Entropy: 1.22216
Value Function Loss: 0.06426

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.05199
Value Function Update Magnitude: 0.06973

Collected Steps per Second: 11430.28469
Overall Steps per Second: 9287.24658

Timestep Collection Time: 4.37662
Timestep Consumption Time: 1.00991
PPO Batch Consumption Time: 0.07194
Total Iteration Time: 5.38653

Cumulative Model Updates: 6747
Cumulative Timesteps: 112602494

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11441
Policy Entropy: 1.21958
Value Function Loss: 0.06377

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.04987
Value Function Update Magnitude: 0.06515

Collected Steps per Second: 10623.80114
Overall Steps per Second: 8629.19045

Timestep Collection Time: 4.70792
Timestep Consumption Time: 1.08822
PPO Batch Consumption Time: 0.09410
Total Iteration Time: 5.79614

Cumulative Model Updates: 6750
Cumulative Timesteps: 112652510

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 112652510...
Checkpoint 112652510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14030
Policy Entropy: 1.22915
Value Function Loss: 0.06336

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05425
Policy Update Magnitude: 0.05345
Value Function Update Magnitude: 0.06946

Collected Steps per Second: 11761.88771
Overall Steps per Second: 9637.87775

Timestep Collection Time: 4.25187
Timestep Consumption Time: 0.93703
PPO Batch Consumption Time: 0.07426
Total Iteration Time: 5.18890

Cumulative Model Updates: 6753
Cumulative Timesteps: 112702520

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05872
Policy Entropy: 1.22578
Value Function Loss: 0.07219

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.06554

Collected Steps per Second: 12098.39248
Overall Steps per Second: 9635.49138

Timestep Collection Time: 4.13476
Timestep Consumption Time: 1.05688
PPO Batch Consumption Time: 0.08262
Total Iteration Time: 5.19164

Cumulative Model Updates: 6756
Cumulative Timesteps: 112752544

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 112752544...
Checkpoint 112752544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04523
Policy Entropy: 1.23227
Value Function Loss: 0.07687

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06064
Policy Update Magnitude: 0.07120
Value Function Update Magnitude: 0.06885

Collected Steps per Second: 11679.38988
Overall Steps per Second: 9495.63628

Timestep Collection Time: 4.28122
Timestep Consumption Time: 0.98457
PPO Batch Consumption Time: 0.07369
Total Iteration Time: 5.26579

Cumulative Model Updates: 6759
Cumulative Timesteps: 112802546

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18977
Policy Entropy: 1.22969
Value Function Loss: 0.08380

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06329
Policy Update Magnitude: 0.06306
Value Function Update Magnitude: 0.07487

Collected Steps per Second: 10465.19004
Overall Steps per Second: 8635.29533

Timestep Collection Time: 4.77813
Timestep Consumption Time: 1.01253
PPO Batch Consumption Time: 0.02992
Total Iteration Time: 5.79065

Cumulative Model Updates: 6762
Cumulative Timesteps: 112852550

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 112852550...
Checkpoint 112852550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15877
Policy Entropy: 1.21691
Value Function Loss: 0.06918

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.07927

Collected Steps per Second: 12940.13299
Overall Steps per Second: 10281.61618

Timestep Collection Time: 3.86688
Timestep Consumption Time: 0.99986
PPO Batch Consumption Time: 0.06855
Total Iteration Time: 4.86674

Cumulative Model Updates: 6765
Cumulative Timesteps: 112902588

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08709
Policy Entropy: 1.22054
Value Function Loss: 0.07054

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08183
Policy Update Magnitude: 0.06190
Value Function Update Magnitude: 0.07546

Collected Steps per Second: 11896.02776
Overall Steps per Second: 9566.97818

Timestep Collection Time: 4.20611
Timestep Consumption Time: 1.02396
PPO Batch Consumption Time: 0.09275
Total Iteration Time: 5.23007

Cumulative Model Updates: 6768
Cumulative Timesteps: 112952624

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 112952624...
Checkpoint 112952624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10327
Policy Entropy: 1.21955
Value Function Loss: 0.07676

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.05930
Value Function Update Magnitude: 0.07963

Collected Steps per Second: 13103.95289
Overall Steps per Second: 10381.59922

Timestep Collection Time: 3.81702
Timestep Consumption Time: 1.00093
PPO Batch Consumption Time: 0.06901
Total Iteration Time: 4.81795

Cumulative Model Updates: 6771
Cumulative Timesteps: 113002642

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06983
Policy Entropy: 1.22393
Value Function Loss: 0.08903

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06520
Policy Update Magnitude: 0.06124
Value Function Update Magnitude: 0.07599

Collected Steps per Second: 11280.32487
Overall Steps per Second: 9015.14430

Timestep Collection Time: 4.43321
Timestep Consumption Time: 1.11390
PPO Batch Consumption Time: 0.09850
Total Iteration Time: 5.54711

Cumulative Model Updates: 6774
Cumulative Timesteps: 113052650

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 113052650...
Checkpoint 113052650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03263
Policy Entropy: 1.21503
Value Function Loss: 0.08243

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.06035
Value Function Update Magnitude: 0.08052

Collected Steps per Second: 13285.45547
Overall Steps per Second: 10497.56860

Timestep Collection Time: 3.76547
Timestep Consumption Time: 1.00001
PPO Batch Consumption Time: 0.11206
Total Iteration Time: 4.76548

Cumulative Model Updates: 6777
Cumulative Timesteps: 113102676

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11942
Policy Entropy: 1.20627
Value Function Loss: 0.07474

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.08812

Collected Steps per Second: 13179.33462
Overall Steps per Second: 10435.16362

Timestep Collection Time: 3.79685
Timestep Consumption Time: 0.99847
PPO Batch Consumption Time: 0.08040
Total Iteration Time: 4.79532

Cumulative Model Updates: 6780
Cumulative Timesteps: 113152716

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 113152716...
Checkpoint 113152716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09867
Policy Entropy: 1.21118
Value Function Loss: 0.06509

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.07117
Value Function Update Magnitude: 0.08202

Collected Steps per Second: 13092.21099
Overall Steps per Second: 10410.54778

Timestep Collection Time: 3.82013
Timestep Consumption Time: 0.98403
PPO Batch Consumption Time: 0.08526
Total Iteration Time: 4.80417

Cumulative Model Updates: 6783
Cumulative Timesteps: 113202730

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20033
Policy Entropy: 1.20820
Value Function Loss: 0.06528

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.07219
Value Function Update Magnitude: 0.07978

Collected Steps per Second: 13728.65878
Overall Steps per Second: 10489.26076

Timestep Collection Time: 3.64406
Timestep Consumption Time: 1.12539
PPO Batch Consumption Time: 0.12121
Total Iteration Time: 4.76945

Cumulative Model Updates: 6786
Cumulative Timesteps: 113252758

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 113252758...
Checkpoint 113252758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00023
Policy Entropy: 1.21478
Value Function Loss: 0.07198

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.06470
Value Function Update Magnitude: 0.07621

Collected Steps per Second: 13278.99714
Overall Steps per Second: 10420.77468

Timestep Collection Time: 3.76836
Timestep Consumption Time: 1.03359
PPO Batch Consumption Time: 0.09533
Total Iteration Time: 4.80195

Cumulative Model Updates: 6789
Cumulative Timesteps: 113302798

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18424
Policy Entropy: 1.19123
Value Function Loss: 0.07686

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.06357
Value Function Update Magnitude: 0.08378

Collected Steps per Second: 13296.00800
Overall Steps per Second: 10867.73255

Timestep Collection Time: 3.76248
Timestep Consumption Time: 0.84069
PPO Batch Consumption Time: 0.06889
Total Iteration Time: 4.60317

Cumulative Model Updates: 6792
Cumulative Timesteps: 113352824

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 113352824...
Checkpoint 113352824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11786
Policy Entropy: 1.19933
Value Function Loss: 0.08497

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10567
Policy Update Magnitude: 0.06239
Value Function Update Magnitude: 0.08782

Collected Steps per Second: 13302.41526
Overall Steps per Second: 10704.04822

Timestep Collection Time: 3.76082
Timestep Consumption Time: 0.91292
PPO Batch Consumption Time: 0.06414
Total Iteration Time: 4.67375

Cumulative Model Updates: 6795
Cumulative Timesteps: 113402852

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05698
Policy Entropy: 1.19698
Value Function Loss: 0.09031

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 13036.80000
Overall Steps per Second: 10231.05086

Timestep Collection Time: 3.83806
Timestep Consumption Time: 1.05254
PPO Batch Consumption Time: 0.11054
Total Iteration Time: 4.89060

Cumulative Model Updates: 6798
Cumulative Timesteps: 113452888

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 113452888...
Checkpoint 113452888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01665
Policy Entropy: 1.20149
Value Function Loss: 0.09104

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12063
Policy Update Magnitude: 0.07011
Value Function Update Magnitude: 0.05520

Collected Steps per Second: 13291.77258
Overall Steps per Second: 10729.28618

Timestep Collection Time: 3.76188
Timestep Consumption Time: 0.89845
PPO Batch Consumption Time: 0.06277
Total Iteration Time: 4.66033

Cumulative Model Updates: 6801
Cumulative Timesteps: 113502890

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05358
Policy Entropy: 1.19882
Value Function Loss: 0.07641

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.06424

Collected Steps per Second: 12256.07296
Overall Steps per Second: 9762.25008

Timestep Collection Time: 4.07994
Timestep Consumption Time: 1.04224
PPO Batch Consumption Time: 0.09437
Total Iteration Time: 5.12218

Cumulative Model Updates: 6804
Cumulative Timesteps: 113552894

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 113552894...
Checkpoint 113552894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04406
Policy Entropy: 1.20783
Value Function Loss: 0.06370

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06483
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.07325

Collected Steps per Second: 12366.95060
Overall Steps per Second: 9682.95327

Timestep Collection Time: 4.04659
Timestep Consumption Time: 1.12167
PPO Batch Consumption Time: 0.11364
Total Iteration Time: 5.16826

Cumulative Model Updates: 6807
Cumulative Timesteps: 113602938

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07551
Policy Entropy: 1.19639
Value Function Loss: 0.05182

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08175
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.07124

Collected Steps per Second: 13631.90044
Overall Steps per Second: 10887.40722

Timestep Collection Time: 3.67095
Timestep Consumption Time: 0.92537
PPO Batch Consumption Time: 0.06497
Total Iteration Time: 4.59632

Cumulative Model Updates: 6810
Cumulative Timesteps: 113652980

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 113652980...
Checkpoint 113652980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01542
Policy Entropy: 1.19692
Value Function Loss: 0.05083

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.05770
Value Function Update Magnitude: 0.06742

Collected Steps per Second: 11150.79413
Overall Steps per Second: 8966.19325

Timestep Collection Time: 4.48578
Timestep Consumption Time: 1.09295
PPO Batch Consumption Time: 0.11066
Total Iteration Time: 5.57873

Cumulative Model Updates: 6813
Cumulative Timesteps: 113703000

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04578
Policy Entropy: 1.21350
Value Function Loss: 0.06382

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.05774
Value Function Update Magnitude: 0.05775

Collected Steps per Second: 13142.24521
Overall Steps per Second: 10648.97678

Timestep Collection Time: 3.80696
Timestep Consumption Time: 0.89133
PPO Batch Consumption Time: 0.06613
Total Iteration Time: 4.69829

Cumulative Model Updates: 6816
Cumulative Timesteps: 113753032

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 113753032...
Checkpoint 113753032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06142
Policy Entropy: 1.20600
Value Function Loss: 0.08978

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.05884
Value Function Update Magnitude: 0.05703

Collected Steps per Second: 10719.31266
Overall Steps per Second: 8520.15175

Timestep Collection Time: 4.66858
Timestep Consumption Time: 1.20502
PPO Batch Consumption Time: 0.11656
Total Iteration Time: 5.87360

Cumulative Model Updates: 6819
Cumulative Timesteps: 113803076

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03305
Policy Entropy: 1.20089
Value Function Loss: 0.08782

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.06197

Collected Steps per Second: 11639.67227
Overall Steps per Second: 9372.70354

Timestep Collection Time: 4.29961
Timestep Consumption Time: 1.03994
PPO Batch Consumption Time: 0.08115
Total Iteration Time: 5.33955

Cumulative Model Updates: 6822
Cumulative Timesteps: 113853122

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 113853122...
Checkpoint 113853122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03488
Policy Entropy: 1.19958
Value Function Loss: 0.07328

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.15789
Policy Update Magnitude: 0.06031
Value Function Update Magnitude: 0.06195

Collected Steps per Second: 11683.49826
Overall Steps per Second: 9186.37793

Timestep Collection Time: 4.27954
Timestep Consumption Time: 1.16330
PPO Batch Consumption Time: 0.11219
Total Iteration Time: 5.44284

Cumulative Model Updates: 6825
Cumulative Timesteps: 113903122

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11380
Policy Entropy: 1.21589
Value Function Loss: 0.05228

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.05336

Collected Steps per Second: 11890.24877
Overall Steps per Second: 9636.79055

Timestep Collection Time: 4.20614
Timestep Consumption Time: 0.98356
PPO Batch Consumption Time: 0.06392
Total Iteration Time: 5.18969

Cumulative Model Updates: 6828
Cumulative Timesteps: 113953134

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 113953134...
Checkpoint 113953134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10631
Policy Entropy: 1.20497
Value Function Loss: 0.05970

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.04798

Collected Steps per Second: 10531.10107
Overall Steps per Second: 8612.75749

Timestep Collection Time: 4.75050
Timestep Consumption Time: 1.05809
PPO Batch Consumption Time: 0.06976
Total Iteration Time: 5.80859

Cumulative Model Updates: 6831
Cumulative Timesteps: 114003162

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08082
Policy Entropy: 1.21552
Value Function Loss: 0.06272

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.05257
Value Function Update Magnitude: 0.04742

Collected Steps per Second: 12090.62932
Overall Steps per Second: 9571.24682

Timestep Collection Time: 4.13792
Timestep Consumption Time: 1.08920
PPO Batch Consumption Time: 0.06761
Total Iteration Time: 5.22711

Cumulative Model Updates: 6834
Cumulative Timesteps: 114053192

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 114053192...
Checkpoint 114053192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00267
Policy Entropy: 1.21711
Value Function Loss: 0.07592

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.04908

Collected Steps per Second: 10725.64374
Overall Steps per Second: 8705.23737

Timestep Collection Time: 4.66452
Timestep Consumption Time: 1.08259
PPO Batch Consumption Time: 0.08776
Total Iteration Time: 5.74711

Cumulative Model Updates: 6837
Cumulative Timesteps: 114103222

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09433
Policy Entropy: 1.21011
Value Function Loss: 0.06937

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07953
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.05637

Collected Steps per Second: 11784.62407
Overall Steps per Second: 9310.96113

Timestep Collection Time: 4.24383
Timestep Consumption Time: 1.12747
PPO Batch Consumption Time: 0.11919
Total Iteration Time: 5.37130

Cumulative Model Updates: 6840
Cumulative Timesteps: 114153234

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 114153234...
Checkpoint 114153234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09462
Policy Entropy: 1.20596
Value Function Loss: 0.07094

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.05379

Collected Steps per Second: 11950.18639
Overall Steps per Second: 9298.84518

Timestep Collection Time: 4.18554
Timestep Consumption Time: 1.19341
PPO Batch Consumption Time: 0.11761
Total Iteration Time: 5.37895

Cumulative Model Updates: 6843
Cumulative Timesteps: 114203252

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02082
Policy Entropy: 1.20415
Value Function Loss: 0.06334

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.05637

Collected Steps per Second: 11796.88009
Overall Steps per Second: 9280.72951

Timestep Collection Time: 4.24044
Timestep Consumption Time: 1.14965
PPO Batch Consumption Time: 0.11846
Total Iteration Time: 5.39009

Cumulative Model Updates: 6846
Cumulative Timesteps: 114253276

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 114253276...
Checkpoint 114253276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03158
Policy Entropy: 1.20378
Value Function Loss: 0.06152

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.04922
Value Function Update Magnitude: 0.05200

Collected Steps per Second: 11794.28431
Overall Steps per Second: 9284.44691

Timestep Collection Time: 4.23968
Timestep Consumption Time: 1.14610
PPO Batch Consumption Time: 0.10773
Total Iteration Time: 5.38578

Cumulative Model Updates: 6849
Cumulative Timesteps: 114303280

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19716
Policy Entropy: 1.20294
Value Function Loss: 0.06447

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.05063

Collected Steps per Second: 12141.84179
Overall Steps per Second: 9627.33349

Timestep Collection Time: 4.11931
Timestep Consumption Time: 1.07590
PPO Batch Consumption Time: 0.08448
Total Iteration Time: 5.19521

Cumulative Model Updates: 6852
Cumulative Timesteps: 114353296

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 114353296...
Checkpoint 114353296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07478
Policy Entropy: 1.19434
Value Function Loss: 0.07597

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.05193
Value Function Update Magnitude: 0.05030

Collected Steps per Second: 11689.74600
Overall Steps per Second: 9592.99071

Timestep Collection Time: 4.27742
Timestep Consumption Time: 0.93492
PPO Batch Consumption Time: 0.07964
Total Iteration Time: 5.21235

Cumulative Model Updates: 6855
Cumulative Timesteps: 114403298

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05710
Policy Entropy: 1.19164
Value Function Loss: 0.08694

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.04764

Collected Steps per Second: 11709.47915
Overall Steps per Second: 9399.39870

Timestep Collection Time: 4.27278
Timestep Consumption Time: 1.05012
PPO Batch Consumption Time: 0.07336
Total Iteration Time: 5.32289

Cumulative Model Updates: 6858
Cumulative Timesteps: 114453330

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 114453330...
Checkpoint 114453330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06453
Policy Entropy: 1.19111
Value Function Loss: 0.09046

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08609
Policy Update Magnitude: 0.06349
Value Function Update Magnitude: 0.05414

Collected Steps per Second: 11154.34745
Overall Steps per Second: 8901.66449

Timestep Collection Time: 4.48543
Timestep Consumption Time: 1.13510
PPO Batch Consumption Time: 0.10642
Total Iteration Time: 5.62052

Cumulative Model Updates: 6861
Cumulative Timesteps: 114503362

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10439
Policy Entropy: 1.20357
Value Function Loss: 0.09310

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06065
Policy Update Magnitude: 0.06276
Value Function Update Magnitude: 0.06819

Collected Steps per Second: 12033.49091
Overall Steps per Second: 9677.41649

Timestep Collection Time: 4.15873
Timestep Consumption Time: 1.01249
PPO Batch Consumption Time: 0.06734
Total Iteration Time: 5.17121

Cumulative Model Updates: 6864
Cumulative Timesteps: 114553406

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 114553406...
Checkpoint 114553406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04926
Policy Entropy: 1.20651
Value Function Loss: 0.09111

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06679
Policy Update Magnitude: 0.06246
Value Function Update Magnitude: 0.07373

Collected Steps per Second: 10505.15666
Overall Steps per Second: 8586.02780

Timestep Collection Time: 4.76052
Timestep Consumption Time: 1.06406
PPO Batch Consumption Time: 0.07245
Total Iteration Time: 5.82458

Cumulative Model Updates: 6867
Cumulative Timesteps: 114603416

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06791
Policy Entropy: 1.21157
Value Function Loss: 0.07029

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.06098
Value Function Update Magnitude: 0.07700

Collected Steps per Second: 11744.53876
Overall Steps per Second: 9612.55158

Timestep Collection Time: 4.25951
Timestep Consumption Time: 0.94473
PPO Batch Consumption Time: 0.07761
Total Iteration Time: 5.20424

Cumulative Model Updates: 6870
Cumulative Timesteps: 114653442

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 114653442...
Checkpoint 114653442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03362
Policy Entropy: 1.20387
Value Function Loss: 0.05529

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07804
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.07720

Collected Steps per Second: 13260.76516
Overall Steps per Second: 10731.72060

Timestep Collection Time: 3.77112
Timestep Consumption Time: 0.88871
PPO Batch Consumption Time: 0.06269
Total Iteration Time: 4.65983

Cumulative Model Updates: 6873
Cumulative Timesteps: 114703450

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04341
Policy Entropy: 1.19542
Value Function Loss: 0.05076

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.05828
Value Function Update Magnitude: 0.08015

Collected Steps per Second: 11967.52349
Overall Steps per Second: 9472.01366

Timestep Collection Time: 4.18215
Timestep Consumption Time: 1.10184
PPO Batch Consumption Time: 0.12237
Total Iteration Time: 5.28399

Cumulative Model Updates: 6876
Cumulative Timesteps: 114753500

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 114753500...
Checkpoint 114753500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10782
Policy Entropy: 1.20232
Value Function Loss: 0.06899

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06719
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.08007

Collected Steps per Second: 13547.05937
Overall Steps per Second: 10816.01047

Timestep Collection Time: 3.69305
Timestep Consumption Time: 0.93250
PPO Batch Consumption Time: 0.06479
Total Iteration Time: 4.62555

Cumulative Model Updates: 6879
Cumulative Timesteps: 114803530

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01267
Policy Entropy: 1.20810
Value Function Loss: 0.07479

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08065
Policy Update Magnitude: 0.06121
Value Function Update Magnitude: 0.08594

Collected Steps per Second: 11182.33652
Overall Steps per Second: 9014.40637

Timestep Collection Time: 4.47241
Timestep Consumption Time: 1.07560
PPO Batch Consumption Time: 0.11008
Total Iteration Time: 5.54801

Cumulative Model Updates: 6882
Cumulative Timesteps: 114853542

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 114853542...
Checkpoint 114853542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03893
Policy Entropy: 1.20763
Value Function Loss: 0.07914

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.10092

Collected Steps per Second: 13342.53636
Overall Steps per Second: 10769.48843

Timestep Collection Time: 3.74891
Timestep Consumption Time: 0.89569
PPO Batch Consumption Time: 0.06136
Total Iteration Time: 4.64460

Cumulative Model Updates: 6885
Cumulative Timesteps: 114903562

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03693
Policy Entropy: 1.20265
Value Function Loss: 0.07645

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.05679
Value Function Update Magnitude: 0.09118

Collected Steps per Second: 12320.75492
Overall Steps per Second: 9749.05376

Timestep Collection Time: 4.05836
Timestep Consumption Time: 1.07055
PPO Batch Consumption Time: 0.11026
Total Iteration Time: 5.12891

Cumulative Model Updates: 6888
Cumulative Timesteps: 114953564

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 114953564...
Checkpoint 114953564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01369
Policy Entropy: 1.21119
Value Function Loss: 0.07801

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.07940

Collected Steps per Second: 13455.26819
Overall Steps per Second: 10912.61306

Timestep Collection Time: 3.71735
Timestep Consumption Time: 0.86615
PPO Batch Consumption Time: 0.05940
Total Iteration Time: 4.58350

Cumulative Model Updates: 6891
Cumulative Timesteps: 115003582

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19312
Policy Entropy: 1.22164
Value Function Loss: 0.07265

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.08182

Collected Steps per Second: 12427.14511
Overall Steps per Second: 10000.40819

Timestep Collection Time: 4.02474
Timestep Consumption Time: 0.97666
PPO Batch Consumption Time: 0.10956
Total Iteration Time: 5.00140

Cumulative Model Updates: 6894
Cumulative Timesteps: 115053598

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 115053598...
Checkpoint 115053598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06865
Policy Entropy: 1.22020
Value Function Loss: 0.06227

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.05826
Value Function Update Magnitude: 0.08745

Collected Steps per Second: 13573.06060
Overall Steps per Second: 10938.02565

Timestep Collection Time: 3.68583
Timestep Consumption Time: 0.88794
PPO Batch Consumption Time: 0.05785
Total Iteration Time: 4.57377

Cumulative Model Updates: 6897
Cumulative Timesteps: 115103626

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15348
Policy Entropy: 1.22079
Value Function Loss: 0.06394

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.08106

Collected Steps per Second: 12060.36060
Overall Steps per Second: 9595.41799

Timestep Collection Time: 4.14813
Timestep Consumption Time: 1.06560
PPO Batch Consumption Time: 0.09866
Total Iteration Time: 5.21374

Cumulative Model Updates: 6900
Cumulative Timesteps: 115153654

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 115153654...
Checkpoint 115153654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04674
Policy Entropy: 1.22085
Value Function Loss: 0.06103

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.05833
Value Function Update Magnitude: 0.07901

Collected Steps per Second: 13347.50683
Overall Steps per Second: 10444.80032

Timestep Collection Time: 3.74647
Timestep Consumption Time: 1.04118
PPO Batch Consumption Time: 0.09879
Total Iteration Time: 4.78765

Cumulative Model Updates: 6903
Cumulative Timesteps: 115203660

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10543
Policy Entropy: 1.21792
Value Function Loss: 0.06319

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.08406

Collected Steps per Second: 13331.49972
Overall Steps per Second: 10472.56744

Timestep Collection Time: 3.75412
Timestep Consumption Time: 1.02485
PPO Batch Consumption Time: 0.09790
Total Iteration Time: 4.77896

Cumulative Model Updates: 6906
Cumulative Timesteps: 115253708

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 115253708...
Checkpoint 115253708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14258
Policy Entropy: 1.21996
Value Function Loss: 0.05355

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.07893

Collected Steps per Second: 13353.63055
Overall Steps per Second: 10860.93340

Timestep Collection Time: 3.74715
Timestep Consumption Time: 0.86001
PPO Batch Consumption Time: 0.06622
Total Iteration Time: 4.60715

Cumulative Model Updates: 6909
Cumulative Timesteps: 115303746

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02864
Policy Entropy: 1.22543
Value Function Loss: 0.05991

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06032
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.06816

Collected Steps per Second: 13346.85849
Overall Steps per Second: 10777.52300

Timestep Collection Time: 3.74890
Timestep Consumption Time: 0.89373
PPO Batch Consumption Time: 0.06577
Total Iteration Time: 4.64263

Cumulative Model Updates: 6912
Cumulative Timesteps: 115353782

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 115353782...
Checkpoint 115353782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02344
Policy Entropy: 1.21614
Value Function Loss: 0.06081

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07195
Policy Update Magnitude: 0.05554
Value Function Update Magnitude: 0.07815

Collected Steps per Second: 12072.13878
Overall Steps per Second: 9749.84026

Timestep Collection Time: 4.14558
Timestep Consumption Time: 0.98743
PPO Batch Consumption Time: 0.09180
Total Iteration Time: 5.13301

Cumulative Model Updates: 6915
Cumulative Timesteps: 115403828

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00588
Policy Entropy: 1.20577
Value Function Loss: 0.06372

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.05766
Value Function Update Magnitude: 0.07849

Collected Steps per Second: 13634.60647
Overall Steps per Second: 10489.37142

Timestep Collection Time: 3.67066
Timestep Consumption Time: 1.10065
PPO Batch Consumption Time: 0.12020
Total Iteration Time: 4.77131

Cumulative Model Updates: 6918
Cumulative Timesteps: 115453876

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 115453876...
Checkpoint 115453876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01550
Policy Entropy: 1.19859
Value Function Loss: 0.05729

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.07325

Collected Steps per Second: 11987.87124
Overall Steps per Second: 9605.58559

Timestep Collection Time: 4.17422
Timestep Consumption Time: 1.03525
PPO Batch Consumption Time: 0.08354
Total Iteration Time: 5.20947

Cumulative Model Updates: 6921
Cumulative Timesteps: 115503916

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01026
Policy Entropy: 1.20015
Value Function Loss: 0.05269

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06473
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.06889

Collected Steps per Second: 13281.78854
Overall Steps per Second: 10808.49091

Timestep Collection Time: 3.76756
Timestep Consumption Time: 0.86213
PPO Batch Consumption Time: 0.06048
Total Iteration Time: 4.62969

Cumulative Model Updates: 6924
Cumulative Timesteps: 115553956

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 115553956...
Checkpoint 115553956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01656
Policy Entropy: 1.20312
Value Function Loss: 0.04681

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06892
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.06756

Collected Steps per Second: 12617.58087
Overall Steps per Second: 10116.40356

Timestep Collection Time: 3.96415
Timestep Consumption Time: 0.98010
PPO Batch Consumption Time: 0.08158
Total Iteration Time: 4.94425

Cumulative Model Updates: 6927
Cumulative Timesteps: 115603974

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03583
Policy Entropy: 1.20673
Value Function Loss: 0.05186

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.06381

Collected Steps per Second: 13155.04241
Overall Steps per Second: 10627.23252

Timestep Collection Time: 3.80219
Timestep Consumption Time: 0.90440
PPO Batch Consumption Time: 0.06479
Total Iteration Time: 4.70659

Cumulative Model Updates: 6930
Cumulative Timesteps: 115653992

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 115653992...
Checkpoint 115653992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20633
Policy Entropy: 1.21247
Value Function Loss: 0.06674

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.05652
Value Function Update Magnitude: 0.06363

Collected Steps per Second: 12911.95593
Overall Steps per Second: 10324.58028

Timestep Collection Time: 3.87393
Timestep Consumption Time: 0.97082
PPO Batch Consumption Time: 0.10663
Total Iteration Time: 4.84475

Cumulative Model Updates: 6933
Cumulative Timesteps: 115704012

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03058
Policy Entropy: 1.20881
Value Function Loss: 0.06776

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.07306

Collected Steps per Second: 13426.26787
Overall Steps per Second: 10808.71202

Timestep Collection Time: 3.72732
Timestep Consumption Time: 0.90265
PPO Batch Consumption Time: 0.06043
Total Iteration Time: 4.62997

Cumulative Model Updates: 6936
Cumulative Timesteps: 115754056

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 115754056...
Checkpoint 115754056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07381
Policy Entropy: 1.20634
Value Function Loss: 0.05688

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.07925

Collected Steps per Second: 11835.27708
Overall Steps per Second: 9354.76910

Timestep Collection Time: 4.22533
Timestep Consumption Time: 1.12039
PPO Batch Consumption Time: 0.13268
Total Iteration Time: 5.34572

Cumulative Model Updates: 6939
Cumulative Timesteps: 115804064

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02195
Policy Entropy: 1.19585
Value Function Loss: 0.05404

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.05309
Value Function Update Magnitude: 0.07108

Collected Steps per Second: 12664.19861
Overall Steps per Second: 10260.61483

Timestep Collection Time: 3.94987
Timestep Consumption Time: 0.92527
PPO Batch Consumption Time: 0.06601
Total Iteration Time: 4.87515

Cumulative Model Updates: 6942
Cumulative Timesteps: 115854086

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 115854086...
Checkpoint 115854086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09128
Policy Entropy: 1.20596
Value Function Loss: 0.05839

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.06876

Collected Steps per Second: 11301.14056
Overall Steps per Second: 9033.41493

Timestep Collection Time: 4.42486
Timestep Consumption Time: 1.11081
PPO Batch Consumption Time: 0.09906
Total Iteration Time: 5.53567

Cumulative Model Updates: 6945
Cumulative Timesteps: 115904092

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03250
Policy Entropy: 1.20026
Value Function Loss: 0.06589

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.06690

Collected Steps per Second: 11591.09567
Overall Steps per Second: 9316.21126

Timestep Collection Time: 4.31521
Timestep Consumption Time: 1.05371
PPO Batch Consumption Time: 0.10550
Total Iteration Time: 5.36892

Cumulative Model Updates: 6948
Cumulative Timesteps: 115954110

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 115954110...
Checkpoint 115954110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11859
Policy Entropy: 1.20111
Value Function Loss: 0.05456

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.06649

Collected Steps per Second: 11364.34137
Overall Steps per Second: 8962.57354

Timestep Collection Time: 4.40413
Timestep Consumption Time: 1.18021
PPO Batch Consumption Time: 0.12192
Total Iteration Time: 5.58433

Cumulative Model Updates: 6951
Cumulative Timesteps: 116004160

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12511
Policy Entropy: 1.20260
Value Function Loss: 0.06006

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05323
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.06993

Collected Steps per Second: 12007.52377
Overall Steps per Second: 9607.32780

Timestep Collection Time: 4.16489
Timestep Consumption Time: 1.04051
PPO Batch Consumption Time: 0.08065
Total Iteration Time: 5.20540

Cumulative Model Updates: 6954
Cumulative Timesteps: 116054170

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 116054170...
Checkpoint 116054170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00107
Policy Entropy: 1.20225
Value Function Loss: 0.05671

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05553
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.07066

Collected Steps per Second: 12016.99527
Overall Steps per Second: 9900.58899

Timestep Collection Time: 4.16377
Timestep Consumption Time: 0.89007
PPO Batch Consumption Time: 0.06920
Total Iteration Time: 5.05384

Cumulative Model Updates: 6957
Cumulative Timesteps: 116104206

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14512
Policy Entropy: 1.20262
Value Function Loss: 0.07021

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06346
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.07442

Collected Steps per Second: 10528.12848
Overall Steps per Second: 8456.61132

Timestep Collection Time: 4.75032
Timestep Consumption Time: 1.16363
PPO Batch Consumption Time: 0.08377
Total Iteration Time: 5.91395

Cumulative Model Updates: 6960
Cumulative Timesteps: 116154218

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 116154218...
Checkpoint 116154218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03630
Policy Entropy: 1.20375
Value Function Loss: 0.06995

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06097
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.07383

Collected Steps per Second: 11862.54800
Overall Steps per Second: 9315.08467

Timestep Collection Time: 4.21764
Timestep Consumption Time: 1.15343
PPO Batch Consumption Time: 0.12194
Total Iteration Time: 5.37107

Cumulative Model Updates: 6963
Cumulative Timesteps: 116204250

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10344
Policy Entropy: 1.20698
Value Function Loss: 0.06535

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05874
Policy Update Magnitude: 0.05972
Value Function Update Magnitude: 0.07821

Collected Steps per Second: 12112.16119
Overall Steps per Second: 9593.86874

Timestep Collection Time: 4.12874
Timestep Consumption Time: 1.08375
PPO Batch Consumption Time: 0.09793
Total Iteration Time: 5.21250

Cumulative Model Updates: 6966
Cumulative Timesteps: 116254258

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 116254258...
Checkpoint 116254258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01622
Policy Entropy: 1.20154
Value Function Loss: 0.05740

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06458
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.07721

Collected Steps per Second: 11992.21103
Overall Steps per Second: 9632.85127

Timestep Collection Time: 4.17071
Timestep Consumption Time: 1.02153
PPO Batch Consumption Time: 0.07154
Total Iteration Time: 5.19223

Cumulative Model Updates: 6969
Cumulative Timesteps: 116304274

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11149
Policy Entropy: 1.20651
Value Function Loss: 0.05678

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.06224
Value Function Update Magnitude: 0.08200

Collected Steps per Second: 12095.02135
Overall Steps per Second: 9730.70204

Timestep Collection Time: 4.13575
Timestep Consumption Time: 1.00489
PPO Batch Consumption Time: 0.07166
Total Iteration Time: 5.14064

Cumulative Model Updates: 6972
Cumulative Timesteps: 116354296

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 116354296...
Checkpoint 116354296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02398
Policy Entropy: 1.21442
Value Function Loss: 0.05688

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.07942

Collected Steps per Second: 10571.56058
Overall Steps per Second: 8584.24386

Timestep Collection Time: 4.73289
Timestep Consumption Time: 1.09570
PPO Batch Consumption Time: 0.09385
Total Iteration Time: 5.82859

Cumulative Model Updates: 6975
Cumulative Timesteps: 116404330

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03977
Policy Entropy: 1.20291
Value Function Loss: 0.06686

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.06612
Value Function Update Magnitude: 0.07594

Collected Steps per Second: 11821.73526
Overall Steps per Second: 9587.98364

Timestep Collection Time: 4.22984
Timestep Consumption Time: 0.98544
PPO Batch Consumption Time: 0.06942
Total Iteration Time: 5.21528

Cumulative Model Updates: 6978
Cumulative Timesteps: 116454334

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 116454334...
Checkpoint 116454334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03786
Policy Entropy: 1.19327
Value Function Loss: 0.06425

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.06293
Value Function Update Magnitude: 0.07274

Collected Steps per Second: 10466.21471
Overall Steps per Second: 8410.43183

Timestep Collection Time: 4.77842
Timestep Consumption Time: 1.16800
PPO Batch Consumption Time: 0.11206
Total Iteration Time: 5.94642

Cumulative Model Updates: 6981
Cumulative Timesteps: 116504346

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00008
Policy Entropy: 1.19392
Value Function Loss: 0.07027

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 11720.20140
Overall Steps per Second: 9495.34520

Timestep Collection Time: 4.26870
Timestep Consumption Time: 1.00020
PPO Batch Consumption Time: 0.07350
Total Iteration Time: 5.26890

Cumulative Model Updates: 6984
Cumulative Timesteps: 116554376

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 116554376...
Checkpoint 116554376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12906
Policy Entropy: 1.20077
Value Function Loss: 0.05525

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06667
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.07020

Collected Steps per Second: 10668.00731
Overall Steps per Second: 8755.79709

Timestep Collection Time: 4.69085
Timestep Consumption Time: 1.02445
PPO Batch Consumption Time: 0.08504
Total Iteration Time: 5.71530

Cumulative Model Updates: 6987
Cumulative Timesteps: 116604418

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03641
Policy Entropy: 1.21264
Value Function Loss: 0.04999

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06671
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.07012

Collected Steps per Second: 10994.53539
Overall Steps per Second: 8911.43942

Timestep Collection Time: 4.54826
Timestep Consumption Time: 1.06318
PPO Batch Consumption Time: 0.07391
Total Iteration Time: 5.61144

Cumulative Model Updates: 6990
Cumulative Timesteps: 116654424

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 116654424...
Checkpoint 116654424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07123
Policy Entropy: 1.20911
Value Function Loss: 0.07128

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.06838

Collected Steps per Second: 11484.65545
Overall Steps per Second: 9299.05439

Timestep Collection Time: 4.35485
Timestep Consumption Time: 1.02354
PPO Batch Consumption Time: 0.07325
Total Iteration Time: 5.37840

Cumulative Model Updates: 6993
Cumulative Timesteps: 116704438

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07438
Policy Entropy: 1.20614
Value Function Loss: 0.07697

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.06529
Value Function Update Magnitude: 0.07443

Collected Steps per Second: 11988.01969
Overall Steps per Second: 9323.10359

Timestep Collection Time: 4.17183
Timestep Consumption Time: 1.19248
PPO Batch Consumption Time: 0.12056
Total Iteration Time: 5.36431

Cumulative Model Updates: 6996
Cumulative Timesteps: 116754450

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 116754450...
Checkpoint 116754450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08927
Policy Entropy: 1.20721
Value Function Loss: 0.08316

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.07082
Value Function Update Magnitude: 0.08556

Collected Steps per Second: 12807.49521
Overall Steps per Second: 10396.58245

Timestep Collection Time: 3.90443
Timestep Consumption Time: 0.90542
PPO Batch Consumption Time: 0.07082
Total Iteration Time: 4.80985

Cumulative Model Updates: 6999
Cumulative Timesteps: 116804456

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09763
Policy Entropy: 1.20649
Value Function Loss: 0.06806

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07123
Policy Update Magnitude: 0.06459
Value Function Update Magnitude: 0.08972

Collected Steps per Second: 13573.21894
Overall Steps per Second: 10903.68469

Timestep Collection Time: 3.68638
Timestep Consumption Time: 0.90253
PPO Batch Consumption Time: 0.07841
Total Iteration Time: 4.58891

Cumulative Model Updates: 7002
Cumulative Timesteps: 116854492

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 116854492...
Checkpoint 116854492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00867
Policy Entropy: 1.20319
Value Function Loss: 0.09092

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06772
Policy Update Magnitude: 0.06685
Value Function Update Magnitude: 0.09293

Collected Steps per Second: 13445.85787
Overall Steps per Second: 10817.29396

Timestep Collection Time: 3.72040
Timestep Consumption Time: 0.90404
PPO Batch Consumption Time: 0.06281
Total Iteration Time: 4.62445

Cumulative Model Updates: 7005
Cumulative Timesteps: 116904516

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04258
Policy Entropy: 1.20525
Value Function Loss: 0.08265

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.06769
Value Function Update Magnitude: 0.09096

Collected Steps per Second: 12369.23566
Overall Steps per Second: 9728.60896

Timestep Collection Time: 4.04552
Timestep Consumption Time: 1.09807
PPO Batch Consumption Time: 0.12497
Total Iteration Time: 5.14359

Cumulative Model Updates: 7008
Cumulative Timesteps: 116954556

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 116954556...
Checkpoint 116954556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00731
Policy Entropy: 1.20433
Value Function Loss: 0.06762

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.06956
Value Function Update Magnitude: 0.08574

Collected Steps per Second: 12614.96200
Overall Steps per Second: 9995.05868

Timestep Collection Time: 3.96672
Timestep Consumption Time: 1.03976
PPO Batch Consumption Time: 0.10039
Total Iteration Time: 5.00647

Cumulative Model Updates: 7011
Cumulative Timesteps: 117004596

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09052
Policy Entropy: 1.19934
Value Function Loss: 0.05389

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.06583
Value Function Update Magnitude: 0.08123

Collected Steps per Second: 13536.90353
Overall Steps per Second: 10902.21401

Timestep Collection Time: 3.69449
Timestep Consumption Time: 0.89283
PPO Batch Consumption Time: 0.05878
Total Iteration Time: 4.58733

Cumulative Model Updates: 7014
Cumulative Timesteps: 117054608

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 117054608...
Checkpoint 117054608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14921
Policy Entropy: 1.19270
Value Function Loss: 0.05127

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.06462
Value Function Update Magnitude: 0.07871

Collected Steps per Second: 11884.19221
Overall Steps per Second: 9679.56867

Timestep Collection Time: 4.20761
Timestep Consumption Time: 0.95833
PPO Batch Consumption Time: 0.10050
Total Iteration Time: 5.16593

Cumulative Model Updates: 7017
Cumulative Timesteps: 117104612

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04729
Policy Entropy: 1.20055
Value Function Loss: 0.06262

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.06799
Value Function Update Magnitude: 0.07681

Collected Steps per Second: 12968.46963
Overall Steps per Second: 10507.12675

Timestep Collection Time: 3.85766
Timestep Consumption Time: 0.90368
PPO Batch Consumption Time: 0.06499
Total Iteration Time: 4.76134

Cumulative Model Updates: 7020
Cumulative Timesteps: 117154640

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 117154640...
Checkpoint 117154640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06470
Policy Entropy: 1.20080
Value Function Loss: 0.06759

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.06479
Value Function Update Magnitude: 0.08121

Collected Steps per Second: 12362.51971
Overall Steps per Second: 9939.30546

Timestep Collection Time: 4.04756
Timestep Consumption Time: 0.98680
PPO Batch Consumption Time: 0.08137
Total Iteration Time: 5.03436

Cumulative Model Updates: 7023
Cumulative Timesteps: 117204678

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12342
Policy Entropy: 1.20492
Value Function Loss: 0.07138

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.06525
Value Function Update Magnitude: 0.08271

Collected Steps per Second: 13579.34448
Overall Steps per Second: 10490.05478

Timestep Collection Time: 3.68442
Timestep Consumption Time: 1.08505
PPO Batch Consumption Time: 0.10916
Total Iteration Time: 4.76947

Cumulative Model Updates: 7026
Cumulative Timesteps: 117254710

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 117254710...
Checkpoint 117254710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10807
Policy Entropy: 1.19591
Value Function Loss: 0.06400

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.06452
Value Function Update Magnitude: 0.08288

Collected Steps per Second: 13070.86581
Overall Steps per Second: 10425.58220

Timestep Collection Time: 3.82806
Timestep Consumption Time: 0.97129
PPO Batch Consumption Time: 0.08124
Total Iteration Time: 4.79935

Cumulative Model Updates: 7029
Cumulative Timesteps: 117304746

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04205
Policy Entropy: 1.19700
Value Function Loss: 0.05921

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05315
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.08067

Collected Steps per Second: 13328.34026
Overall Steps per Second: 10442.76699

Timestep Collection Time: 3.75201
Timestep Consumption Time: 1.03676
PPO Batch Consumption Time: 0.12913
Total Iteration Time: 4.78877

Cumulative Model Updates: 7032
Cumulative Timesteps: 117354754

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 117354754...
Checkpoint 117354754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13807
Policy Entropy: 1.18291
Value Function Loss: 0.05727

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.07668

Collected Steps per Second: 13149.57107
Overall Steps per Second: 10470.03308

Timestep Collection Time: 3.80256
Timestep Consumption Time: 0.97317
PPO Batch Consumption Time: 0.08400
Total Iteration Time: 4.77573

Cumulative Model Updates: 7035
Cumulative Timesteps: 117404756

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03408
Policy Entropy: 1.19368
Value Function Loss: 0.06074

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.07450

Collected Steps per Second: 13557.57944
Overall Steps per Second: 10839.27430

Timestep Collection Time: 3.68901
Timestep Consumption Time: 0.92514
PPO Batch Consumption Time: 0.06945
Total Iteration Time: 4.61415

Cumulative Model Updates: 7038
Cumulative Timesteps: 117454770

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 117454770...
Checkpoint 117454770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06750
Policy Entropy: 1.20078
Value Function Loss: 0.05056

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.06675
Value Function Update Magnitude: 0.07438

Collected Steps per Second: 12924.65997
Overall Steps per Second: 10414.04887

Timestep Collection Time: 3.87229
Timestep Consumption Time: 0.93353
PPO Batch Consumption Time: 0.06675
Total Iteration Time: 4.80582

Cumulative Model Updates: 7041
Cumulative Timesteps: 117504818

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09153
Policy Entropy: 1.20438
Value Function Loss: 0.05154

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.07071
Value Function Update Magnitude: 0.06834

Collected Steps per Second: 10471.53686
Overall Steps per Second: 8403.68805

Timestep Collection Time: 4.77676
Timestep Consumption Time: 1.17539
PPO Batch Consumption Time: 0.10596
Total Iteration Time: 5.95215

Cumulative Model Updates: 7044
Cumulative Timesteps: 117554838

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 117554838...
Checkpoint 117554838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00234
Policy Entropy: 1.20033
Value Function Loss: 0.05088

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06964
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.07073

Collected Steps per Second: 11420.97810
Overall Steps per Second: 9284.86848

Timestep Collection Time: 4.38229
Timestep Consumption Time: 1.00820
PPO Batch Consumption Time: 0.07181
Total Iteration Time: 5.39049

Cumulative Model Updates: 7047
Cumulative Timesteps: 117604888

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11324
Policy Entropy: 1.20851
Value Function Loss: 0.05978

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.06899
Value Function Update Magnitude: 0.08254

Collected Steps per Second: 11834.48870
Overall Steps per Second: 9328.16568

Timestep Collection Time: 4.22764
Timestep Consumption Time: 1.13590
PPO Batch Consumption Time: 0.11405
Total Iteration Time: 5.36354

Cumulative Model Updates: 7050
Cumulative Timesteps: 117654920

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 117654920...
Checkpoint 117654920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05936
Policy Entropy: 1.21091
Value Function Loss: 0.05483

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.06826
Value Function Update Magnitude: 0.07738

Collected Steps per Second: 11940.38758
Overall Steps per Second: 9612.05959

Timestep Collection Time: 4.18797
Timestep Consumption Time: 1.01445
PPO Batch Consumption Time: 0.06902
Total Iteration Time: 5.20242

Cumulative Model Updates: 7053
Cumulative Timesteps: 117704926

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14716
Policy Entropy: 1.20493
Value Function Loss: 0.04492

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.05988
Value Function Update Magnitude: 0.07005

Collected Steps per Second: 10614.05320
Overall Steps per Second: 8647.92329

Timestep Collection Time: 4.71356
Timestep Consumption Time: 1.07164
PPO Batch Consumption Time: 0.10960
Total Iteration Time: 5.78520

Cumulative Model Updates: 7056
Cumulative Timesteps: 117754956

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 117754956...
Checkpoint 117754956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14366
Policy Entropy: 1.19756
Value Function Loss: 0.04586

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.06544

Collected Steps per Second: 11864.45780
Overall Steps per Second: 9292.68850

Timestep Collection Time: 4.21764
Timestep Consumption Time: 1.16724
PPO Batch Consumption Time: 0.11413
Total Iteration Time: 5.38488

Cumulative Model Updates: 7059
Cumulative Timesteps: 117804996

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11198
Policy Entropy: 1.20268
Value Function Loss: 0.04891

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.06053

Collected Steps per Second: 11165.49325
Overall Steps per Second: 8924.54758

Timestep Collection Time: 4.48149
Timestep Consumption Time: 1.12530
PPO Batch Consumption Time: 0.09675
Total Iteration Time: 5.60678

Cumulative Model Updates: 7062
Cumulative Timesteps: 117855034

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 117855034...
Checkpoint 117855034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12898
Policy Entropy: 1.20364
Value Function Loss: 0.05427

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.06318

Collected Steps per Second: 12163.26350
Overall Steps per Second: 9770.78975

Timestep Collection Time: 4.11074
Timestep Consumption Time: 1.00655
PPO Batch Consumption Time: 0.07417
Total Iteration Time: 5.11729

Cumulative Model Updates: 7065
Cumulative Timesteps: 117905034

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03352
Policy Entropy: 1.21216
Value Function Loss: 0.05191

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.06795

Collected Steps per Second: 11220.97600
Overall Steps per Second: 8882.89973

Timestep Collection Time: 4.46057
Timestep Consumption Time: 1.17407
PPO Batch Consumption Time: 0.11420
Total Iteration Time: 5.63465

Cumulative Model Updates: 7068
Cumulative Timesteps: 117955086

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 117955086...
Checkpoint 117955086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12556
Policy Entropy: 1.21316
Value Function Loss: 0.05938

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.05253
Value Function Update Magnitude: 0.07685

Collected Steps per Second: 10369.37989
Overall Steps per Second: 8490.88176

Timestep Collection Time: 4.82594
Timestep Consumption Time: 1.06768
PPO Batch Consumption Time: 0.06904
Total Iteration Time: 5.89362

Cumulative Model Updates: 7071
Cumulative Timesteps: 118005128

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07483
Policy Entropy: 1.22051
Value Function Loss: 0.06212

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.06934

Collected Steps per Second: 10725.73293
Overall Steps per Second: 8513.60928

Timestep Collection Time: 4.66597
Timestep Consumption Time: 1.21238
PPO Batch Consumption Time: 0.10331
Total Iteration Time: 5.87835

Cumulative Model Updates: 7074
Cumulative Timesteps: 118055174

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 118055174...
Checkpoint 118055174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01277
Policy Entropy: 1.21700
Value Function Loss: 0.07669

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.06619

Collected Steps per Second: 11240.52560
Overall Steps per Second: 8940.96888

Timestep Collection Time: 4.44926
Timestep Consumption Time: 1.14432
PPO Batch Consumption Time: 0.09821
Total Iteration Time: 5.59358

Cumulative Model Updates: 7077
Cumulative Timesteps: 118105186

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13814
Policy Entropy: 1.22287
Value Function Loss: 0.07357

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05595
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.06633

Collected Steps per Second: 11678.08803
Overall Steps per Second: 9441.41786

Timestep Collection Time: 4.28443
Timestep Consumption Time: 1.01498
PPO Batch Consumption Time: 0.07446
Total Iteration Time: 5.29942

Cumulative Model Updates: 7080
Cumulative Timesteps: 118155220

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 118155220...
Checkpoint 118155220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07345
Policy Entropy: 1.21604
Value Function Loss: 0.06690

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05295
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.06277

Collected Steps per Second: 10644.24484
Overall Steps per Second: 8508.07083

Timestep Collection Time: 4.70019
Timestep Consumption Time: 1.18011
PPO Batch Consumption Time: 0.09974
Total Iteration Time: 5.88030

Cumulative Model Updates: 7083
Cumulative Timesteps: 118205250

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14365
Policy Entropy: 1.21066
Value Function Loss: 0.05592

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07403
Policy Update Magnitude: 0.05820
Value Function Update Magnitude: 0.05588

Collected Steps per Second: 11739.85250
Overall Steps per Second: 9298.91265

Timestep Collection Time: 4.25968
Timestep Consumption Time: 1.11815
PPO Batch Consumption Time: 0.10982
Total Iteration Time: 5.37783

Cumulative Model Updates: 7086
Cumulative Timesteps: 118255258

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 118255258...
Checkpoint 118255258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08357
Policy Entropy: 1.20725
Value Function Loss: 0.06012

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.05884

Collected Steps per Second: 12010.24471
Overall Steps per Second: 9305.62534

Timestep Collection Time: 4.16428
Timestep Consumption Time: 1.21032
PPO Batch Consumption Time: 0.12329
Total Iteration Time: 5.37460

Cumulative Model Updates: 7089
Cumulative Timesteps: 118305272

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07632
Policy Entropy: 1.21560
Value Function Loss: 0.07050

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.05965

Collected Steps per Second: 11831.65595
Overall Steps per Second: 9262.60310

Timestep Collection Time: 4.23035
Timestep Consumption Time: 1.17332
PPO Batch Consumption Time: 0.10711
Total Iteration Time: 5.40366

Cumulative Model Updates: 7092
Cumulative Timesteps: 118355324

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 118355324...
Checkpoint 118355324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09321
Policy Entropy: 1.23383
Value Function Loss: 0.08116

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06529
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.06318

Collected Steps per Second: 11478.84717
Overall Steps per Second: 9242.90524

Timestep Collection Time: 4.35619
Timestep Consumption Time: 1.05380
PPO Batch Consumption Time: 0.08158
Total Iteration Time: 5.40999

Cumulative Model Updates: 7095
Cumulative Timesteps: 118405328

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02615
Policy Entropy: 1.22218
Value Function Loss: 0.07370

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07874
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.05459

Collected Steps per Second: 12716.10022
Overall Steps per Second: 10034.41787

Timestep Collection Time: 3.93407
Timestep Consumption Time: 1.05137
PPO Batch Consumption Time: 0.07188
Total Iteration Time: 4.98544

Cumulative Model Updates: 7098
Cumulative Timesteps: 118455354

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 118455354...
Checkpoint 118455354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05064
Policy Entropy: 1.22685
Value Function Loss: 0.06196

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05291
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.05280

Collected Steps per Second: 12544.30696
Overall Steps per Second: 10204.79627

Timestep Collection Time: 3.98794
Timestep Consumption Time: 0.91426
PPO Batch Consumption Time: 0.06917
Total Iteration Time: 4.90220

Cumulative Model Updates: 7101
Cumulative Timesteps: 118505380

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12655
Policy Entropy: 1.21590
Value Function Loss: 0.06286

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.06970
Value Function Update Magnitude: 0.05692

Collected Steps per Second: 12951.73542
Overall Steps per Second: 10247.08757

Timestep Collection Time: 3.86141
Timestep Consumption Time: 1.01919
PPO Batch Consumption Time: 0.08391
Total Iteration Time: 4.88061

Cumulative Model Updates: 7104
Cumulative Timesteps: 118555392

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 118555392...
Checkpoint 118555392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01580
Policy Entropy: 1.21879
Value Function Loss: 0.07244

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.07147
Value Function Update Magnitude: 0.05515

Collected Steps per Second: 12612.30550
Overall Steps per Second: 10200.06815

Timestep Collection Time: 3.96597
Timestep Consumption Time: 0.93792
PPO Batch Consumption Time: 0.06662
Total Iteration Time: 4.90389

Cumulative Model Updates: 7107
Cumulative Timesteps: 118605412

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03851
Policy Entropy: 1.22026
Value Function Loss: 0.06798

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.07061
Value Function Update Magnitude: 0.05825

Collected Steps per Second: 12972.88001
Overall Steps per Second: 10326.94475

Timestep Collection Time: 3.85651
Timestep Consumption Time: 0.98810
PPO Batch Consumption Time: 0.10898
Total Iteration Time: 4.84461

Cumulative Model Updates: 7110
Cumulative Timesteps: 118655442

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 118655442...
Checkpoint 118655442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00536
Policy Entropy: 1.21646
Value Function Loss: 0.05288

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.06715
Value Function Update Magnitude: 0.05937

Collected Steps per Second: 13439.95059
Overall Steps per Second: 10456.68780

Timestep Collection Time: 3.72159
Timestep Consumption Time: 1.06176
PPO Batch Consumption Time: 0.10612
Total Iteration Time: 4.78335

Cumulative Model Updates: 7113
Cumulative Timesteps: 118705460

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00492
Policy Entropy: 1.21880
Value Function Loss: 0.05205

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09557
Policy Update Magnitude: 0.06114
Value Function Update Magnitude: 0.05212

Collected Steps per Second: 13441.12766
Overall Steps per Second: 10442.79975

Timestep Collection Time: 3.72260
Timestep Consumption Time: 1.06883
PPO Batch Consumption Time: 0.12056
Total Iteration Time: 4.79144

Cumulative Model Updates: 7116
Cumulative Timesteps: 118755496

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 118755496...
Checkpoint 118755496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03545
Policy Entropy: 1.22189
Value Function Loss: 0.06052

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.05855
Value Function Update Magnitude: 0.05375

Collected Steps per Second: 12797.57899
Overall Steps per Second: 10017.28968

Timestep Collection Time: 3.90761
Timestep Consumption Time: 1.08455
PPO Batch Consumption Time: 0.11138
Total Iteration Time: 4.99217

Cumulative Model Updates: 7119
Cumulative Timesteps: 118805504

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22897
Policy Entropy: 1.22540
Value Function Loss: 0.06052

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10566
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.05847

Collected Steps per Second: 12676.45984
Overall Steps per Second: 10257.77877

Timestep Collection Time: 3.94558
Timestep Consumption Time: 0.93033
PPO Batch Consumption Time: 0.06639
Total Iteration Time: 4.87591

Cumulative Model Updates: 7122
Cumulative Timesteps: 118855520

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 118855520...
Checkpoint 118855520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00985
Policy Entropy: 1.22280
Value Function Loss: 0.05575

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.05785

Collected Steps per Second: 12350.00653
Overall Steps per Second: 10175.94370

Timestep Collection Time: 4.04874
Timestep Consumption Time: 0.86500
PPO Batch Consumption Time: 0.06600
Total Iteration Time: 4.91375

Cumulative Model Updates: 7125
Cumulative Timesteps: 118905522

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04636
Policy Entropy: 1.21764
Value Function Loss: 0.06479

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.11045
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.05051

Collected Steps per Second: 13196.65628
Overall Steps per Second: 10643.32645

Timestep Collection Time: 3.79126
Timestep Consumption Time: 0.90952
PPO Batch Consumption Time: 0.06781
Total Iteration Time: 4.70079

Cumulative Model Updates: 7128
Cumulative Timesteps: 118955554

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 118955554...
Checkpoint 118955554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06288
Policy Entropy: 1.21001
Value Function Loss: 0.06106

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.05743
Value Function Update Magnitude: 0.04762

Collected Steps per Second: 13179.50667
Overall Steps per Second: 10291.39870

Timestep Collection Time: 3.79513
Timestep Consumption Time: 1.06504
PPO Batch Consumption Time: 0.11416
Total Iteration Time: 4.86018

Cumulative Model Updates: 7131
Cumulative Timesteps: 119005572

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03244
Policy Entropy: 1.20597
Value Function Loss: 0.06203

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.05657

Collected Steps per Second: 13446.55918
Overall Steps per Second: 10877.65049

Timestep Collection Time: 3.71961
Timestep Consumption Time: 0.87844
PPO Batch Consumption Time: 0.05833
Total Iteration Time: 4.59805

Cumulative Model Updates: 7134
Cumulative Timesteps: 119055588

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 119055588...
Checkpoint 119055588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05298
Policy Entropy: 1.21128
Value Function Loss: 0.05464

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.06358

Collected Steps per Second: 12565.02410
Overall Steps per Second: 10008.93450

Timestep Collection Time: 3.98248
Timestep Consumption Time: 1.01705
PPO Batch Consumption Time: 0.08696
Total Iteration Time: 4.99953

Cumulative Model Updates: 7137
Cumulative Timesteps: 119105628

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12336
Policy Entropy: 1.20948
Value Function Loss: 0.06407

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.07256

Collected Steps per Second: 12609.27427
Overall Steps per Second: 10326.85023

Timestep Collection Time: 3.96613
Timestep Consumption Time: 0.87659
PPO Batch Consumption Time: 0.06643
Total Iteration Time: 4.84272

Cumulative Model Updates: 7140
Cumulative Timesteps: 119155638

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 119155638...
Checkpoint 119155638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00918
Policy Entropy: 1.21166
Value Function Loss: 0.06227

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.07253

Collected Steps per Second: 11367.89606
Overall Steps per Second: 9065.74787

Timestep Collection Time: 4.39941
Timestep Consumption Time: 1.11718
PPO Batch Consumption Time: 0.09636
Total Iteration Time: 5.51659

Cumulative Model Updates: 7143
Cumulative Timesteps: 119205650

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03237
Policy Entropy: 1.21457
Value Function Loss: 0.05744

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.07259

Collected Steps per Second: 11307.37779
Overall Steps per Second: 8954.34470

Timestep Collection Time: 4.42419
Timestep Consumption Time: 1.16259
PPO Batch Consumption Time: 0.11896
Total Iteration Time: 5.58679

Cumulative Model Updates: 7146
Cumulative Timesteps: 119255676

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 119255676...
Checkpoint 119255676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10258
Policy Entropy: 1.21395
Value Function Loss: 0.05224

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06777
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.06680

Collected Steps per Second: 11953.95901
Overall Steps per Second: 9611.30045

Timestep Collection Time: 4.18589
Timestep Consumption Time: 1.02027
PPO Batch Consumption Time: 0.06486
Total Iteration Time: 5.20616

Cumulative Model Updates: 7149
Cumulative Timesteps: 119305714

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06484
Policy Entropy: 1.21861
Value Function Loss: 0.06663

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07394
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.07178

Collected Steps per Second: 10312.59321
Overall Steps per Second: 8357.72931

Timestep Collection Time: 4.84922
Timestep Consumption Time: 1.13423
PPO Batch Consumption Time: 0.08552
Total Iteration Time: 5.98344

Cumulative Model Updates: 7152
Cumulative Timesteps: 119355722

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 119355722...
Checkpoint 119355722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02655
Policy Entropy: 1.21817
Value Function Loss: 0.06275

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.06402
Value Function Update Magnitude: 0.07523

Collected Steps per Second: 11032.77923
Overall Steps per Second: 8976.72762

Timestep Collection Time: 4.53394
Timestep Consumption Time: 1.03847
PPO Batch Consumption Time: 0.10925
Total Iteration Time: 5.57241

Cumulative Model Updates: 7155
Cumulative Timesteps: 119405744

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10563
Policy Entropy: 1.22389
Value Function Loss: 0.06218

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.06133
Value Function Update Magnitude: 0.07539

Collected Steps per Second: 12175.14277
Overall Steps per Second: 9777.42599

Timestep Collection Time: 4.10919
Timestep Consumption Time: 1.00770
PPO Batch Consumption Time: 0.07398
Total Iteration Time: 5.11689

Cumulative Model Updates: 7158
Cumulative Timesteps: 119455774

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 119455774...
Checkpoint 119455774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04675
Policy Entropy: 1.22343
Value Function Loss: 0.04826

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06742
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.06933

Collected Steps per Second: 9891.86768
Overall Steps per Second: 7991.15711

Timestep Collection Time: 5.05688
Timestep Consumption Time: 1.20279
PPO Batch Consumption Time: 0.13392
Total Iteration Time: 6.25967

Cumulative Model Updates: 7161
Cumulative Timesteps: 119505796

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06452
Policy Entropy: 1.23259
Value Function Loss: 0.05359

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05650
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.07005

Collected Steps per Second: 12108.13941
Overall Steps per Second: 9711.82680

Timestep Collection Time: 4.13061
Timestep Consumption Time: 1.01919
PPO Batch Consumption Time: 0.07421
Total Iteration Time: 5.14980

Cumulative Model Updates: 7164
Cumulative Timesteps: 119555810

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 119555810...
Checkpoint 119555810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07922
Policy Entropy: 1.22507
Value Function Loss: 0.07110

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05705
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.06939

Collected Steps per Second: 11469.92115
Overall Steps per Second: 9228.62869

Timestep Collection Time: 4.36219
Timestep Consumption Time: 1.05942
PPO Batch Consumption Time: 0.08320
Total Iteration Time: 5.42161

Cumulative Model Updates: 7167
Cumulative Timesteps: 119605844

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00923
Policy Entropy: 1.22671
Value Function Loss: 0.07228

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.08309

Collected Steps per Second: 11853.99882
Overall Steps per Second: 9601.24300

Timestep Collection Time: 4.21849
Timestep Consumption Time: 0.98979
PPO Batch Consumption Time: 0.09053
Total Iteration Time: 5.20828

Cumulative Model Updates: 7170
Cumulative Timesteps: 119655850

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 119655850...
Checkpoint 119655850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03845
Policy Entropy: 1.22838
Value Function Loss: 0.07452

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.08268

Collected Steps per Second: 11892.62499
Overall Steps per Second: 9326.99987

Timestep Collection Time: 4.20530
Timestep Consumption Time: 1.15677
PPO Batch Consumption Time: 0.12279
Total Iteration Time: 5.36207

Cumulative Model Updates: 7173
Cumulative Timesteps: 119705862

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02636
Policy Entropy: 1.24001
Value Function Loss: 0.06225

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08251
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.08538

Collected Steps per Second: 11831.93314
Overall Steps per Second: 9632.75361

Timestep Collection Time: 4.22687
Timestep Consumption Time: 0.96500
PPO Batch Consumption Time: 0.06964
Total Iteration Time: 5.19187

Cumulative Model Updates: 7176
Cumulative Timesteps: 119755874

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 119755874...
Checkpoint 119755874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19196
Policy Entropy: 1.22837
Value Function Loss: 0.05438

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.05783
Value Function Update Magnitude: 0.07640

Collected Steps per Second: 11114.22055
Overall Steps per Second: 8927.41070

Timestep Collection Time: 4.50162
Timestep Consumption Time: 1.10269
PPO Batch Consumption Time: 0.09505
Total Iteration Time: 5.60431

Cumulative Model Updates: 7179
Cumulative Timesteps: 119805906

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06590
Policy Entropy: 1.23104
Value Function Loss: 0.05274

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.07024

Collected Steps per Second: 11243.64548
Overall Steps per Second: 8958.38080

Timestep Collection Time: 4.44749
Timestep Consumption Time: 1.13455
PPO Batch Consumption Time: 0.09090
Total Iteration Time: 5.58204

Cumulative Model Updates: 7182
Cumulative Timesteps: 119855912

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 119855912...
Checkpoint 119855912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14674
Policy Entropy: 1.23233
Value Function Loss: 0.04385

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.06739

Collected Steps per Second: 11581.92468
Overall Steps per Second: 9314.82301

Timestep Collection Time: 4.32173
Timestep Consumption Time: 1.05185
PPO Batch Consumption Time: 0.11320
Total Iteration Time: 5.37359

Cumulative Model Updates: 7185
Cumulative Timesteps: 119905966

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08216
Policy Entropy: 1.23821
Value Function Loss: 0.04952

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04170
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.06406

Collected Steps per Second: 12102.38130
Overall Steps per Second: 9578.61136

Timestep Collection Time: 4.13191
Timestep Consumption Time: 1.08868
PPO Batch Consumption Time: 0.08513
Total Iteration Time: 5.22059

Cumulative Model Updates: 7188
Cumulative Timesteps: 119955972

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 119955972...
Checkpoint 119955972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11610
Policy Entropy: 1.22023
Value Function Loss: 0.04530

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07111
Policy Update Magnitude: 0.05091
Value Function Update Magnitude: 0.06672

Collected Steps per Second: 11650.84320
Overall Steps per Second: 9330.69867

Timestep Collection Time: 4.29394
Timestep Consumption Time: 1.06772
PPO Batch Consumption Time: 0.10217
Total Iteration Time: 5.36166

Cumulative Model Updates: 7191
Cumulative Timesteps: 120006000

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10454
Policy Entropy: 1.21885
Value Function Loss: 0.04479

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06682
Policy Update Magnitude: 0.05367
Value Function Update Magnitude: 0.06986

Collected Steps per Second: 11826.74704
Overall Steps per Second: 9274.58833

Timestep Collection Time: 4.22889
Timestep Consumption Time: 1.16370
PPO Batch Consumption Time: 0.12664
Total Iteration Time: 5.39258

Cumulative Model Updates: 7194
Cumulative Timesteps: 120056014

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 120056014...
Checkpoint 120056014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05387
Policy Entropy: 1.22140
Value Function Loss: 0.05755

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.05459
Value Function Update Magnitude: 0.06520

Collected Steps per Second: 11960.56564
Overall Steps per Second: 9737.74597

Timestep Collection Time: 4.18191
Timestep Consumption Time: 0.95460
PPO Batch Consumption Time: 0.07080
Total Iteration Time: 5.13651

Cumulative Model Updates: 7197
Cumulative Timesteps: 120106032

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13406
Policy Entropy: 1.22796
Value Function Loss: 0.06826

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.06621

Collected Steps per Second: 13202.12287
Overall Steps per Second: 10739.74557

Timestep Collection Time: 3.78894
Timestep Consumption Time: 0.86872
PPO Batch Consumption Time: 0.07389
Total Iteration Time: 4.65765

Cumulative Model Updates: 7200
Cumulative Timesteps: 120156054

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 120156054...
Checkpoint 120156054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09266
Policy Entropy: 1.22222
Value Function Loss: 0.06019

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.05555
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 12958.69886
Overall Steps per Second: 10103.75341

Timestep Collection Time: 3.86088
Timestep Consumption Time: 1.09094
PPO Batch Consumption Time: 0.11899
Total Iteration Time: 4.95182

Cumulative Model Updates: 7203
Cumulative Timesteps: 120206086

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03642
Policy Entropy: 1.21531
Value Function Loss: 0.05416

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.07378

Collected Steps per Second: 13217.38067
Overall Steps per Second: 10717.26337

Timestep Collection Time: 3.78517
Timestep Consumption Time: 0.88300
PPO Batch Consumption Time: 0.06631
Total Iteration Time: 4.66817

Cumulative Model Updates: 7206
Cumulative Timesteps: 120256116

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 120256116...
Checkpoint 120256116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02570
Policy Entropy: 1.22161
Value Function Loss: 0.05257

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.05469
Value Function Update Magnitude: 0.07736

Collected Steps per Second: 12275.17586
Overall Steps per Second: 9753.94314

Timestep Collection Time: 4.07489
Timestep Consumption Time: 1.05329
PPO Batch Consumption Time: 0.09935
Total Iteration Time: 5.12818

Cumulative Model Updates: 7209
Cumulative Timesteps: 120306136

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10497
Policy Entropy: 1.21812
Value Function Loss: 0.06738

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.05585
Value Function Update Magnitude: 0.07208

Collected Steps per Second: 13316.35138
Overall Steps per Second: 10562.63068

Timestep Collection Time: 3.75478
Timestep Consumption Time: 0.97889
PPO Batch Consumption Time: 0.06814
Total Iteration Time: 4.73367

Cumulative Model Updates: 7212
Cumulative Timesteps: 120356136

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 120356136...
Checkpoint 120356136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06280
Policy Entropy: 1.21505
Value Function Loss: 0.08332

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.06785

Collected Steps per Second: 12968.40459
Overall Steps per Second: 10363.39774

Timestep Collection Time: 3.85876
Timestep Consumption Time: 0.96996
PPO Batch Consumption Time: 0.10143
Total Iteration Time: 4.82873

Cumulative Model Updates: 7215
Cumulative Timesteps: 120406178

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14022
Policy Entropy: 1.21352
Value Function Loss: 0.08470

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.06835

Collected Steps per Second: 13295.05280
Overall Steps per Second: 10721.83970

Timestep Collection Time: 3.76140
Timestep Consumption Time: 0.90273
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 4.66412

Cumulative Model Updates: 7218
Cumulative Timesteps: 120456186

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 120456186...
Checkpoint 120456186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12031
Policy Entropy: 1.21566
Value Function Loss: 0.08611

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.07574

Collected Steps per Second: 12448.65527
Overall Steps per Second: 9806.71915

Timestep Collection Time: 4.02084
Timestep Consumption Time: 1.08322
PPO Batch Consumption Time: 0.12191
Total Iteration Time: 5.10405

Cumulative Model Updates: 7221
Cumulative Timesteps: 120506240

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14249
Policy Entropy: 1.22523
Value Function Loss: 0.07682

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.06216
Value Function Update Magnitude: 0.08271

Collected Steps per Second: 13619.84987
Overall Steps per Second: 10825.34503

Timestep Collection Time: 3.67229
Timestep Consumption Time: 0.94798
PPO Batch Consumption Time: 0.07415
Total Iteration Time: 4.62027

Cumulative Model Updates: 7224
Cumulative Timesteps: 120556256

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 120556256...
Checkpoint 120556256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05589
Policy Entropy: 1.21697
Value Function Loss: 0.06457

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.05859
Value Function Update Magnitude: 0.07311

Collected Steps per Second: 13316.24141
Overall Steps per Second: 10732.33085

Timestep Collection Time: 3.75797
Timestep Consumption Time: 0.90477
PPO Batch Consumption Time: 0.06472
Total Iteration Time: 4.66273

Cumulative Model Updates: 7227
Cumulative Timesteps: 120606298

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12979
Policy Entropy: 1.21041
Value Function Loss: 0.06023

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.07372

Collected Steps per Second: 12548.50643
Overall Steps per Second: 10184.70344

Timestep Collection Time: 3.98693
Timestep Consumption Time: 0.92534
PPO Batch Consumption Time: 0.09163
Total Iteration Time: 4.91227

Cumulative Model Updates: 7230
Cumulative Timesteps: 120656328

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 120656328...
Checkpoint 120656328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09905
Policy Entropy: 1.21293
Value Function Loss: 0.06385

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.06946

Collected Steps per Second: 11170.44496
Overall Steps per Second: 8945.86970

Timestep Collection Time: 4.47681
Timestep Consumption Time: 1.11325
PPO Batch Consumption Time: 0.07619
Total Iteration Time: 5.59007

Cumulative Model Updates: 7233
Cumulative Timesteps: 120706336

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09233
Policy Entropy: 1.22230
Value Function Loss: 0.07313

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07278
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.06906

Collected Steps per Second: 11118.78623
Overall Steps per Second: 8953.30168

Timestep Collection Time: 4.50121
Timestep Consumption Time: 1.08868
PPO Batch Consumption Time: 0.09444
Total Iteration Time: 5.58989

Cumulative Model Updates: 7236
Cumulative Timesteps: 120756384

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 120756384...
Checkpoint 120756384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03537
Policy Entropy: 1.22381
Value Function Loss: 0.07199

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.07392

Collected Steps per Second: 12154.34823
Overall Steps per Second: 9598.64771

Timestep Collection Time: 4.11770
Timestep Consumption Time: 1.09636
PPO Batch Consumption Time: 0.07166
Total Iteration Time: 5.21407

Cumulative Model Updates: 7239
Cumulative Timesteps: 120806432

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03895
Policy Entropy: 1.22449
Value Function Loss: 0.06540

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08017
Policy Update Magnitude: 0.06309
Value Function Update Magnitude: 0.07583

Collected Steps per Second: 10416.01345
Overall Steps per Second: 8385.19464

Timestep Collection Time: 4.80203
Timestep Consumption Time: 1.16301
PPO Batch Consumption Time: 0.08196
Total Iteration Time: 5.96504

Cumulative Model Updates: 7242
Cumulative Timesteps: 120856450

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 120856450...
Checkpoint 120856450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05237
Policy Entropy: 1.22769
Value Function Loss: 0.05760

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.06981

Collected Steps per Second: 12040.92340
Overall Steps per Second: 9642.66208

Timestep Collection Time: 4.15317
Timestep Consumption Time: 1.03295
PPO Batch Consumption Time: 0.08283
Total Iteration Time: 5.18612

Cumulative Model Updates: 7245
Cumulative Timesteps: 120906458

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12660
Policy Entropy: 1.22911
Value Function Loss: 0.04572

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.06740

Collected Steps per Second: 12059.68267
Overall Steps per Second: 9641.65491

Timestep Collection Time: 4.14870
Timestep Consumption Time: 1.04045
PPO Batch Consumption Time: 0.07828
Total Iteration Time: 5.18915

Cumulative Model Updates: 7248
Cumulative Timesteps: 120956490

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 120956490...
Checkpoint 120956490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00042
Policy Entropy: 1.22571
Value Function Loss: 0.04109

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07490
Policy Update Magnitude: 0.05213
Value Function Update Magnitude: 0.06085

Collected Steps per Second: 11234.28885
Overall Steps per Second: 9067.40584

Timestep Collection Time: 4.45066
Timestep Consumption Time: 1.06360
PPO Batch Consumption Time: 0.07804
Total Iteration Time: 5.51426

Cumulative Model Updates: 7251
Cumulative Timesteps: 121006490

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06193
Policy Entropy: 1.23210
Value Function Loss: 0.05513

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.05067
Value Function Update Magnitude: 0.06129

Collected Steps per Second: 11597.45417
Overall Steps per Second: 9486.53616

Timestep Collection Time: 4.31146
Timestep Consumption Time: 0.95938
PPO Batch Consumption Time: 0.07251
Total Iteration Time: 5.27084

Cumulative Model Updates: 7254
Cumulative Timesteps: 121056492

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 121056492...
Checkpoint 121056492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03684
Policy Entropy: 1.23715
Value Function Loss: 0.05222

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07444
Policy Update Magnitude: 0.04983
Value Function Update Magnitude: 0.06016

Collected Steps per Second: 11779.00173
Overall Steps per Second: 9476.95316

Timestep Collection Time: 4.24722
Timestep Consumption Time: 1.03169
PPO Batch Consumption Time: 0.07568
Total Iteration Time: 5.27891

Cumulative Model Updates: 7257
Cumulative Timesteps: 121106520

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14502
Policy Entropy: 1.22172
Value Function Loss: 0.05214

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.05126

Collected Steps per Second: 11218.40409
Overall Steps per Second: 9118.92981

Timestep Collection Time: 4.45821
Timestep Consumption Time: 1.02642
PPO Batch Consumption Time: 0.09026
Total Iteration Time: 5.48463

Cumulative Model Updates: 7260
Cumulative Timesteps: 121156534

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 121156534...
Checkpoint 121156534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00700
Policy Entropy: 1.22281
Value Function Loss: 0.03824

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.04917
Value Function Update Magnitude: 0.05190

Collected Steps per Second: 11683.66092
Overall Steps per Second: 9404.82659

Timestep Collection Time: 4.28119
Timestep Consumption Time: 1.03735
PPO Batch Consumption Time: 0.07625
Total Iteration Time: 5.31855

Cumulative Model Updates: 7263
Cumulative Timesteps: 121206554

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09927
Policy Entropy: 1.22803
Value Function Loss: 0.04237

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05789
Policy Update Magnitude: 0.05137
Value Function Update Magnitude: 0.05694

Collected Steps per Second: 11391.02412
Overall Steps per Second: 9148.94077

Timestep Collection Time: 4.39153
Timestep Consumption Time: 1.07621
PPO Batch Consumption Time: 0.07961
Total Iteration Time: 5.46774

Cumulative Model Updates: 7266
Cumulative Timesteps: 121256578

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 121256578...
Checkpoint 121256578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06140
Policy Entropy: 1.23328
Value Function Loss: 0.04640

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05879
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.05353

Collected Steps per Second: 11543.79436
Overall Steps per Second: 9387.59299

Timestep Collection Time: 4.33220
Timestep Consumption Time: 0.99505
PPO Batch Consumption Time: 0.06641
Total Iteration Time: 5.32724

Cumulative Model Updates: 7269
Cumulative Timesteps: 121306588

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02779
Policy Entropy: 1.22770
Value Function Loss: 0.05221

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.05224
Value Function Update Magnitude: 0.05241

Collected Steps per Second: 11191.94944
Overall Steps per Second: 8882.17868

Timestep Collection Time: 4.47161
Timestep Consumption Time: 1.16282
PPO Batch Consumption Time: 0.10417
Total Iteration Time: 5.63443

Cumulative Model Updates: 7272
Cumulative Timesteps: 121356634

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 121356634...
Checkpoint 121356634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07018
Policy Entropy: 1.22877
Value Function Loss: 0.06216

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06506
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.05463

Collected Steps per Second: 11840.58568
Overall Steps per Second: 9644.83825

Timestep Collection Time: 4.22682
Timestep Consumption Time: 0.96228
PPO Batch Consumption Time: 0.08938
Total Iteration Time: 5.18910

Cumulative Model Updates: 7275
Cumulative Timesteps: 121406682

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00011
Policy Entropy: 1.23363
Value Function Loss: 0.05979

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06834
Policy Update Magnitude: 0.05409
Value Function Update Magnitude: 0.06057

Collected Steps per Second: 11618.92672
Overall Steps per Second: 9375.56140

Timestep Collection Time: 4.30711
Timestep Consumption Time: 1.03060
PPO Batch Consumption Time: 0.06974
Total Iteration Time: 5.33771

Cumulative Model Updates: 7278
Cumulative Timesteps: 121456726

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 121456726...
Checkpoint 121456726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14481
Policy Entropy: 1.21917
Value Function Loss: 0.05202

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.06886

Collected Steps per Second: 11875.47745
Overall Steps per Second: 9281.84199

Timestep Collection Time: 4.21154
Timestep Consumption Time: 1.17683
PPO Batch Consumption Time: 0.12782
Total Iteration Time: 5.38837

Cumulative Model Updates: 7281
Cumulative Timesteps: 121506740

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01137
Policy Entropy: 1.22007
Value Function Loss: 0.04265

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.04789
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 11541.67210
Overall Steps per Second: 9539.84375

Timestep Collection Time: 4.33369
Timestep Consumption Time: 0.90938
PPO Batch Consumption Time: 0.06708
Total Iteration Time: 5.24306

Cumulative Model Updates: 7284
Cumulative Timesteps: 121556758

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 121556758...
Checkpoint 121556758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10711
Policy Entropy: 1.22828
Value Function Loss: 0.04874

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.04816

Collected Steps per Second: 10711.51158
Overall Steps per Second: 8418.45112

Timestep Collection Time: 4.66937
Timestep Consumption Time: 1.27187
PPO Batch Consumption Time: 0.11107
Total Iteration Time: 5.94124

Cumulative Model Updates: 7287
Cumulative Timesteps: 121606774

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04103
Policy Entropy: 1.22330
Value Function Loss: 0.06322

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.06055
Value Function Update Magnitude: 0.04971

Collected Steps per Second: 13047.85729
Overall Steps per Second: 10402.99030

Timestep Collection Time: 3.83327
Timestep Consumption Time: 0.97458
PPO Batch Consumption Time: 0.08257
Total Iteration Time: 4.80785

Cumulative Model Updates: 7290
Cumulative Timesteps: 121656790

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 121656790...
Checkpoint 121656790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05093
Policy Entropy: 1.23015
Value Function Loss: 0.06304

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.05811

Collected Steps per Second: 12481.49160
Overall Steps per Second: 10013.79388

Timestep Collection Time: 4.00866
Timestep Consumption Time: 0.98785
PPO Batch Consumption Time: 0.07839
Total Iteration Time: 4.99651

Cumulative Model Updates: 7293
Cumulative Timesteps: 121706824

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07558
Policy Entropy: 1.22901
Value Function Loss: 0.05876

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11254
Policy Update Magnitude: 0.05600
Value Function Update Magnitude: 0.05564

Collected Steps per Second: 13342.83094
Overall Steps per Second: 10740.27213

Timestep Collection Time: 3.74973
Timestep Consumption Time: 0.90863
PPO Batch Consumption Time: 0.06613
Total Iteration Time: 4.65835

Cumulative Model Updates: 7296
Cumulative Timesteps: 121756856

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 121756856...
Checkpoint 121756856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03183
Policy Entropy: 1.23518
Value Function Loss: 0.04917

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07883
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.04801

Collected Steps per Second: 12019.71858
Overall Steps per Second: 9827.33451

Timestep Collection Time: 4.16233
Timestep Consumption Time: 0.92858
PPO Batch Consumption Time: 0.08522
Total Iteration Time: 5.09090

Cumulative Model Updates: 7299
Cumulative Timesteps: 121806886

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07116
Policy Entropy: 1.22427
Value Function Loss: 0.05677

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.11257
Policy Update Magnitude: 0.05473
Value Function Update Magnitude: 0.05062

Collected Steps per Second: 13433.48397
Overall Steps per Second: 10787.55198

Timestep Collection Time: 3.72249
Timestep Consumption Time: 0.91304
PPO Batch Consumption Time: 0.06266
Total Iteration Time: 4.63553

Cumulative Model Updates: 7302
Cumulative Timesteps: 121856892

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 121856892...
Checkpoint 121856892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10014
Policy Entropy: 1.23118
Value Function Loss: 0.06582

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.05673

Collected Steps per Second: 12056.73741
Overall Steps per Second: 9738.37753

Timestep Collection Time: 4.15004
Timestep Consumption Time: 0.98798
PPO Batch Consumption Time: 0.08126
Total Iteration Time: 5.13802

Cumulative Model Updates: 7305
Cumulative Timesteps: 121906928

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16907
Policy Entropy: 1.23047
Value Function Loss: 0.06948

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.05906

Collected Steps per Second: 12518.96722
Overall Steps per Second: 9650.72804

Timestep Collection Time: 3.99666
Timestep Consumption Time: 1.18782
PPO Batch Consumption Time: 0.12496
Total Iteration Time: 5.18448

Cumulative Model Updates: 7308
Cumulative Timesteps: 121956962

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 121956962...
Checkpoint 121956962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10224
Policy Entropy: 1.23211
Value Function Loss: 0.06081

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.04736
Value Function Update Magnitude: 0.05645

Collected Steps per Second: 13572.48548
Overall Steps per Second: 10885.07520

Timestep Collection Time: 3.68510
Timestep Consumption Time: 0.90981
PPO Batch Consumption Time: 0.06429
Total Iteration Time: 4.59492

Cumulative Model Updates: 7311
Cumulative Timesteps: 122006978

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04469
Policy Entropy: 1.21974
Value Function Loss: 0.05047

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.04800
Value Function Update Magnitude: 0.05697

Collected Steps per Second: 12078.63701
Overall Steps per Second: 9632.15174

Timestep Collection Time: 4.14136
Timestep Consumption Time: 1.05187
PPO Batch Consumption Time: 0.12343
Total Iteration Time: 5.19323

Cumulative Model Updates: 7314
Cumulative Timesteps: 122057000

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 122057000...
Checkpoint 122057000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06186
Policy Entropy: 1.22750
Value Function Loss: 0.04409

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.06261

Collected Steps per Second: 12972.78785
Overall Steps per Second: 10405.38253

Timestep Collection Time: 3.85623
Timestep Consumption Time: 0.95148
PPO Batch Consumption Time: 0.07560
Total Iteration Time: 4.80770

Cumulative Model Updates: 7317
Cumulative Timesteps: 122107026

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18453
Policy Entropy: 1.22998
Value Function Loss: 0.04652

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07643
Policy Update Magnitude: 0.04467
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 13113.28464
Overall Steps per Second: 10475.96708

Timestep Collection Time: 3.81689
Timestep Consumption Time: 0.96090
PPO Batch Consumption Time: 0.08270
Total Iteration Time: 4.77779

Cumulative Model Updates: 7320
Cumulative Timesteps: 122157078

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 122157078...
Checkpoint 122157078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09386
Policy Entropy: 1.22098
Value Function Loss: 0.05316

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05795
Policy Update Magnitude: 0.04525
Value Function Update Magnitude: 0.06450

Collected Steps per Second: 13735.08791
Overall Steps per Second: 10877.27937

Timestep Collection Time: 3.64031
Timestep Consumption Time: 0.95643
PPO Batch Consumption Time: 0.07330
Total Iteration Time: 4.59674

Cumulative Model Updates: 7323
Cumulative Timesteps: 122207078

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02392
Policy Entropy: 1.21524
Value Function Loss: 0.05989

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.06277

Collected Steps per Second: 13170.80438
Overall Steps per Second: 10410.43531

Timestep Collection Time: 3.79658
Timestep Consumption Time: 1.00668
PPO Batch Consumption Time: 0.06586
Total Iteration Time: 4.80326

Cumulative Model Updates: 7326
Cumulative Timesteps: 122257082

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 122257082...
Checkpoint 122257082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02852
Policy Entropy: 1.20980
Value Function Loss: 0.05510

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06827
Policy Update Magnitude: 0.04503
Value Function Update Magnitude: 0.07098

Collected Steps per Second: 11196.50798
Overall Steps per Second: 9302.23003

Timestep Collection Time: 4.46675
Timestep Consumption Time: 0.90960
PPO Batch Consumption Time: 0.08810
Total Iteration Time: 5.37635

Cumulative Model Updates: 7329
Cumulative Timesteps: 122307094

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11224
Policy Entropy: 1.20635
Value Function Loss: 0.04458

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05748
Policy Update Magnitude: 0.04647
Value Function Update Magnitude: 0.07040

Collected Steps per Second: 13314.51539
Overall Steps per Second: 10777.72109

Timestep Collection Time: 3.75560
Timestep Consumption Time: 0.88397
PPO Batch Consumption Time: 0.06366
Total Iteration Time: 4.63957

Cumulative Model Updates: 7332
Cumulative Timesteps: 122357098

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 122357098...
Checkpoint 122357098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00171
Policy Entropy: 1.20061
Value Function Loss: 0.04903

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.05981
Policy Update Magnitude: 0.04971
Value Function Update Magnitude: 0.06842

Collected Steps per Second: 11731.78549
Overall Steps per Second: 9410.38777

Timestep Collection Time: 4.26482
Timestep Consumption Time: 1.05207
PPO Batch Consumption Time: 0.08531
Total Iteration Time: 5.31689

Cumulative Model Updates: 7335
Cumulative Timesteps: 122407132

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14542
Policy Entropy: 1.20835
Value Function Loss: 0.05471

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.06757

Collected Steps per Second: 11555.90194
Overall Steps per Second: 9327.86776

Timestep Collection Time: 4.32749
Timestep Consumption Time: 1.03365
PPO Batch Consumption Time: 0.07183
Total Iteration Time: 5.36114

Cumulative Model Updates: 7338
Cumulative Timesteps: 122457140

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 122457140...
Checkpoint 122457140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13458
Policy Entropy: 1.22075
Value Function Loss: 0.05801

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05053
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.07219

Collected Steps per Second: 11162.23581
Overall Steps per Second: 8883.20115

Timestep Collection Time: 4.48011
Timestep Consumption Time: 1.14940
PPO Batch Consumption Time: 0.09958
Total Iteration Time: 5.62950

Cumulative Model Updates: 7341
Cumulative Timesteps: 122507148

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16533
Policy Entropy: 1.21346
Value Function Loss: 0.05723

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06766
Policy Update Magnitude: 0.04883
Value Function Update Magnitude: 0.07530

Collected Steps per Second: 11853.71943
Overall Steps per Second: 9616.15786

Timestep Collection Time: 4.22028
Timestep Consumption Time: 0.98201
PPO Batch Consumption Time: 0.07899
Total Iteration Time: 5.20229

Cumulative Model Updates: 7344
Cumulative Timesteps: 122557174

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 122557174...
Checkpoint 122557174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09795
Policy Entropy: 1.21356
Value Function Loss: 0.05667

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.07660

Collected Steps per Second: 11804.32910
Overall Steps per Second: 9589.83877

Timestep Collection Time: 4.23895
Timestep Consumption Time: 0.97886
PPO Batch Consumption Time: 0.06991
Total Iteration Time: 5.21781

Cumulative Model Updates: 7347
Cumulative Timesteps: 122607212

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03580
Policy Entropy: 1.21476
Value Function Loss: 0.06840

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06781
Policy Update Magnitude: 0.04950
Value Function Update Magnitude: 0.08622

Collected Steps per Second: 10611.15208
Overall Steps per Second: 8691.73461

Timestep Collection Time: 4.71240
Timestep Consumption Time: 1.04065
PPO Batch Consumption Time: 0.08762
Total Iteration Time: 5.75305

Cumulative Model Updates: 7350
Cumulative Timesteps: 122657216

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 122657216...
Checkpoint 122657216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06152
Policy Entropy: 1.22502
Value Function Loss: 0.06147

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06249
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.09139

Collected Steps per Second: 11885.67496
Overall Steps per Second: 9315.46574

Timestep Collection Time: 4.20725
Timestep Consumption Time: 1.16081
PPO Batch Consumption Time: 0.10190
Total Iteration Time: 5.36806

Cumulative Model Updates: 7353
Cumulative Timesteps: 122707222

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01810
Policy Entropy: 1.21665
Value Function Loss: 0.05369

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.05317
Value Function Update Magnitude: 0.08216

Collected Steps per Second: 11560.72715
Overall Steps per Second: 9254.89675

Timestep Collection Time: 4.32654
Timestep Consumption Time: 1.07795
PPO Batch Consumption Time: 0.08068
Total Iteration Time: 5.40449

Cumulative Model Updates: 7356
Cumulative Timesteps: 122757240

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 122757240...
Checkpoint 122757240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02826
Policy Entropy: 1.20961
Value Function Loss: 0.04033

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.07667

Collected Steps per Second: 11715.13881
Overall Steps per Second: 9311.31244

Timestep Collection Time: 4.27140
Timestep Consumption Time: 1.10271
PPO Batch Consumption Time: 0.11724
Total Iteration Time: 5.37411

Cumulative Model Updates: 7359
Cumulative Timesteps: 122807280

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02761
Policy Entropy: 1.20577
Value Function Loss: 0.04904

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07305
Policy Update Magnitude: 0.04725
Value Function Update Magnitude: 0.06963

Collected Steps per Second: 11757.80703
Overall Steps per Second: 9385.97596

Timestep Collection Time: 4.25419
Timestep Consumption Time: 1.07503
PPO Batch Consumption Time: 0.07293
Total Iteration Time: 5.32923

Cumulative Model Updates: 7362
Cumulative Timesteps: 122857300

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 122857300...
Checkpoint 122857300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06395
Policy Entropy: 1.21166
Value Function Loss: 0.05882

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.06703

Collected Steps per Second: 11697.93342
Overall Steps per Second: 9193.92518

Timestep Collection Time: 4.27494
Timestep Consumption Time: 1.16430
PPO Batch Consumption Time: 0.12854
Total Iteration Time: 5.43924

Cumulative Model Updates: 7365
Cumulative Timesteps: 122907308

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15184
Policy Entropy: 1.20992
Value Function Loss: 0.05551

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06850
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.07232

Collected Steps per Second: 11846.48636
Overall Steps per Second: 9592.37901

Timestep Collection Time: 4.22066
Timestep Consumption Time: 0.99181
PPO Batch Consumption Time: 0.06912
Total Iteration Time: 5.21247

Cumulative Model Updates: 7368
Cumulative Timesteps: 122957308

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 122957308...
Checkpoint 122957308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11731
Policy Entropy: 1.21882
Value Function Loss: 0.06399

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06362
Policy Update Magnitude: 0.04886
Value Function Update Magnitude: 0.07261

Collected Steps per Second: 10540.08045
Overall Steps per Second: 8370.00256

Timestep Collection Time: 4.74456
Timestep Consumption Time: 1.23011
PPO Batch Consumption Time: 0.13172
Total Iteration Time: 5.97467

Cumulative Model Updates: 7371
Cumulative Timesteps: 123007316

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08016
Policy Entropy: 1.21052
Value Function Loss: 0.06470

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.05096
Value Function Update Magnitude: 0.07153

Collected Steps per Second: 11859.49641
Overall Steps per Second: 9727.19776

Timestep Collection Time: 4.21873
Timestep Consumption Time: 0.92479
PPO Batch Consumption Time: 0.07425
Total Iteration Time: 5.14352

Cumulative Model Updates: 7374
Cumulative Timesteps: 123057348

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 123057348...
Checkpoint 123057348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.23786
Policy Entropy: 1.20906
Value Function Loss: 0.06671

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06115
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.07555

Collected Steps per Second: 11555.84321
Overall Steps per Second: 9210.37093

Timestep Collection Time: 4.33028
Timestep Consumption Time: 1.10273
PPO Batch Consumption Time: 0.08418
Total Iteration Time: 5.43301

Cumulative Model Updates: 7377
Cumulative Timesteps: 123107388

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.24357
Policy Entropy: 1.20783
Value Function Loss: 0.07196

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.05861
Value Function Update Magnitude: 0.07948

Collected Steps per Second: 11937.47000
Overall Steps per Second: 9610.70350

Timestep Collection Time: 4.18966
Timestep Consumption Time: 1.01432
PPO Batch Consumption Time: 0.07767
Total Iteration Time: 5.20399

Cumulative Model Updates: 7380
Cumulative Timesteps: 123157402

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 123157402...
Checkpoint 123157402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01132
Policy Entropy: 1.20608
Value Function Loss: 0.06290

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.07697

Collected Steps per Second: 12122.94343
Overall Steps per Second: 9652.61803

Timestep Collection Time: 4.12672
Timestep Consumption Time: 1.05612
PPO Batch Consumption Time: 0.08695
Total Iteration Time: 5.18284

Cumulative Model Updates: 7383
Cumulative Timesteps: 123207430

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00424
Policy Entropy: 1.20930
Value Function Loss: 0.06982

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06753
Policy Update Magnitude: 0.05613
Value Function Update Magnitude: 0.07785

Collected Steps per Second: 11510.41042
Overall Steps per Second: 9326.14817

Timestep Collection Time: 4.34424
Timestep Consumption Time: 1.01746
PPO Batch Consumption Time: 0.07231
Total Iteration Time: 5.36170

Cumulative Model Updates: 7386
Cumulative Timesteps: 123257434

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 123257434...
Checkpoint 123257434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12992
Policy Entropy: 1.21017
Value Function Loss: 0.06322

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06332
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.07302

Collected Steps per Second: 10637.66956
Overall Steps per Second: 8631.51690

Timestep Collection Time: 4.70216
Timestep Consumption Time: 1.09288
PPO Batch Consumption Time: 0.10114
Total Iteration Time: 5.79504

Cumulative Model Updates: 7389
Cumulative Timesteps: 123307454

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02918
Policy Entropy: 1.21208
Value Function Loss: 0.06401

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07115
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.08235

Collected Steps per Second: 11693.93682
Overall Steps per Second: 9276.11738

Timestep Collection Time: 4.27760
Timestep Consumption Time: 1.11496
PPO Batch Consumption Time: 0.10364
Total Iteration Time: 5.39256

Cumulative Model Updates: 7392
Cumulative Timesteps: 123357476

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 123357476...
Checkpoint 123357476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02713
Policy Entropy: 1.20769
Value Function Loss: 0.05965

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.07422

Collected Steps per Second: 12494.39856
Overall Steps per Second: 10031.76083

Timestep Collection Time: 4.00563
Timestep Consumption Time: 0.98332
PPO Batch Consumption Time: 0.09163
Total Iteration Time: 4.98895

Cumulative Model Updates: 7395
Cumulative Timesteps: 123407524

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03306
Policy Entropy: 1.21722
Value Function Loss: 0.05104

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.07075

Collected Steps per Second: 13945.47632
Overall Steps per Second: 11164.71767

Timestep Collection Time: 3.58640
Timestep Consumption Time: 0.89325
PPO Batch Consumption Time: 0.06245
Total Iteration Time: 4.47965

Cumulative Model Updates: 7398
Cumulative Timesteps: 123457538

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 123457538...
Checkpoint 123457538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01645
Policy Entropy: 1.22451
Value Function Loss: 0.04262

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.05089
Value Function Update Magnitude: 0.06747

Collected Steps per Second: 12432.65933
Overall Steps per Second: 9787.49136

Timestep Collection Time: 4.02327
Timestep Consumption Time: 1.08733
PPO Batch Consumption Time: 0.09445
Total Iteration Time: 5.11060

Cumulative Model Updates: 7401
Cumulative Timesteps: 123507558

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09369
Policy Entropy: 1.23578
Value Function Loss: 0.05249

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.07568

Collected Steps per Second: 12838.99861
Overall Steps per Second: 10563.96155

Timestep Collection Time: 3.89750
Timestep Consumption Time: 0.83936
PPO Batch Consumption Time: 0.06359
Total Iteration Time: 4.73686

Cumulative Model Updates: 7404
Cumulative Timesteps: 123557598

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 123557598...
Checkpoint 123557598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02194
Policy Entropy: 1.22232
Value Function Loss: 0.05212

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.04864
Value Function Update Magnitude: 0.07702

Collected Steps per Second: 13281.32440
Overall Steps per Second: 10382.13778

Timestep Collection Time: 3.76634
Timestep Consumption Time: 1.05174
PPO Batch Consumption Time: 0.11027
Total Iteration Time: 4.81808

Cumulative Model Updates: 7407
Cumulative Timesteps: 123607620

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14476
Policy Entropy: 1.22544
Value Function Loss: 0.05447

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.04769
Value Function Update Magnitude: 0.07811

Collected Steps per Second: 13165.86036
Overall Steps per Second: 10710.57077

Timestep Collection Time: 3.79785
Timestep Consumption Time: 0.87062
PPO Batch Consumption Time: 0.06241
Total Iteration Time: 4.66847

Cumulative Model Updates: 7410
Cumulative Timesteps: 123657622

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 123657622...
Checkpoint 123657622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20285
Policy Entropy: 1.22225
Value Function Loss: 0.05131

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.07615

Collected Steps per Second: 12586.72665
Overall Steps per Second: 10154.22624

Timestep Collection Time: 3.97435
Timestep Consumption Time: 0.95208
PPO Batch Consumption Time: 0.06889
Total Iteration Time: 4.92642

Cumulative Model Updates: 7413
Cumulative Timesteps: 123707646

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04090
Policy Entropy: 1.22171
Value Function Loss: 0.05508

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07195
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.06391

Collected Steps per Second: 13454.85393
Overall Steps per Second: 10816.48459

Timestep Collection Time: 3.71613
Timestep Consumption Time: 0.90644
PPO Batch Consumption Time: 0.06235
Total Iteration Time: 4.62257

Cumulative Model Updates: 7416
Cumulative Timesteps: 123757646

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 123757646...
Checkpoint 123757646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04769
Policy Entropy: 1.21236
Value Function Loss: 0.05671

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.06852

Collected Steps per Second: 12122.02324
Overall Steps per Second: 9746.62187

Timestep Collection Time: 4.12670
Timestep Consumption Time: 1.00574
PPO Batch Consumption Time: 0.11860
Total Iteration Time: 5.13244

Cumulative Model Updates: 7419
Cumulative Timesteps: 123807670

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15737
Policy Entropy: 1.21156
Value Function Loss: 0.05489

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.06654

Collected Steps per Second: 12640.50483
Overall Steps per Second: 10289.65336

Timestep Collection Time: 3.95807
Timestep Consumption Time: 0.90429
PPO Batch Consumption Time: 0.06518
Total Iteration Time: 4.86236

Cumulative Model Updates: 7422
Cumulative Timesteps: 123857702

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 123857702...
Checkpoint 123857702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05798
Policy Entropy: 1.22580
Value Function Loss: 0.05189

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.06003
Value Function Update Magnitude: 0.07228

Collected Steps per Second: 11623.49910
Overall Steps per Second: 9404.82938

Timestep Collection Time: 4.30232
Timestep Consumption Time: 1.01495
PPO Batch Consumption Time: 0.09890
Total Iteration Time: 5.31727

Cumulative Model Updates: 7425
Cumulative Timesteps: 123907710

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12921
Policy Entropy: 1.21607
Value Function Loss: 0.05503

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.07108
Value Function Update Magnitude: 0.06710

Collected Steps per Second: 13711.96418
Overall Steps per Second: 10977.14113

Timestep Collection Time: 3.64966
Timestep Consumption Time: 0.90927
PPO Batch Consumption Time: 0.06277
Total Iteration Time: 4.55893

Cumulative Model Updates: 7428
Cumulative Timesteps: 123957754

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 123957754...
Checkpoint 123957754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01045
Policy Entropy: 1.22608
Value Function Loss: 0.05022

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.06351
Value Function Update Magnitude: 0.06675

Collected Steps per Second: 13053.73051
Overall Steps per Second: 10357.65683

Timestep Collection Time: 3.83339
Timestep Consumption Time: 0.99782
PPO Batch Consumption Time: 0.09148
Total Iteration Time: 4.83121

Cumulative Model Updates: 7431
Cumulative Timesteps: 124007794

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22391
Policy Entropy: 1.23349
Value Function Loss: 0.04847

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.06657

Collected Steps per Second: 13025.33245
Overall Steps per Second: 10766.92545

Timestep Collection Time: 3.83990
Timestep Consumption Time: 0.80544
PPO Batch Consumption Time: 0.06265
Total Iteration Time: 4.64534

Cumulative Model Updates: 7434
Cumulative Timesteps: 124057810

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 124057810...
Checkpoint 124057810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22803
Policy Entropy: 1.23101
Value Function Loss: 0.04816

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.06435
Value Function Update Magnitude: 0.06555

Collected Steps per Second: 12249.96188
Overall Steps per Second: 9745.02379

Timestep Collection Time: 4.08426
Timestep Consumption Time: 1.04985
PPO Batch Consumption Time: 0.09836
Total Iteration Time: 5.13411

Cumulative Model Updates: 7437
Cumulative Timesteps: 124107842

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18585
Policy Entropy: 1.22142
Value Function Loss: 0.05687

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07343
Policy Update Magnitude: 0.06442
Value Function Update Magnitude: 0.06340

Collected Steps per Second: 13193.46381
Overall Steps per Second: 10711.42249

Timestep Collection Time: 3.79021
Timestep Consumption Time: 0.87826
PPO Batch Consumption Time: 0.06243
Total Iteration Time: 4.66847

Cumulative Model Updates: 7440
Cumulative Timesteps: 124157848

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 124157848...
Checkpoint 124157848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10436
Policy Entropy: 1.22610
Value Function Loss: 0.06124

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05968
Policy Update Magnitude: 0.05938
Value Function Update Magnitude: 0.06149

Collected Steps per Second: 11578.30702
Overall Steps per Second: 9403.81312

Timestep Collection Time: 4.32084
Timestep Consumption Time: 0.99913
PPO Batch Consumption Time: 0.07257
Total Iteration Time: 5.31997

Cumulative Model Updates: 7443
Cumulative Timesteps: 124207876

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07439
Policy Entropy: 1.23051
Value Function Loss: 0.06308

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05204
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.06692

Collected Steps per Second: 13157.88300
Overall Steps per Second: 10607.24741

Timestep Collection Time: 3.80365
Timestep Consumption Time: 0.91463
PPO Batch Consumption Time: 0.06574
Total Iteration Time: 4.71828

Cumulative Model Updates: 7446
Cumulative Timesteps: 124257924

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 124257924...
Checkpoint 124257924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12147
Policy Entropy: 1.22654
Value Function Loss: 0.05160

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05941
Policy Update Magnitude: 0.05920
Value Function Update Magnitude: 0.06784

Collected Steps per Second: 13309.44835
Overall Steps per Second: 10759.29894

Timestep Collection Time: 3.75974
Timestep Consumption Time: 0.89113
PPO Batch Consumption Time: 0.07558
Total Iteration Time: 4.65086

Cumulative Model Updates: 7449
Cumulative Timesteps: 124307964

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03980
Policy Entropy: 1.22697
Value Function Loss: 0.05156

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.06754
Value Function Update Magnitude: 0.06900

Collected Steps per Second: 12925.07979
Overall Steps per Second: 10064.57702

Timestep Collection Time: 3.87170
Timestep Consumption Time: 1.10039
PPO Batch Consumption Time: 0.12075
Total Iteration Time: 4.97209

Cumulative Model Updates: 7452
Cumulative Timesteps: 124358006

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 124358006...
Checkpoint 124358006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04391
Policy Entropy: 1.22691
Value Function Loss: 0.05240

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06496
Policy Update Magnitude: 0.06291
Value Function Update Magnitude: 0.07205

Collected Steps per Second: 13291.16788
Overall Steps per Second: 10765.45013

Timestep Collection Time: 3.76430
Timestep Consumption Time: 0.88316
PPO Batch Consumption Time: 0.06246
Total Iteration Time: 4.64746

Cumulative Model Updates: 7455
Cumulative Timesteps: 124408038

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00259
Policy Entropy: 1.22945
Value Function Loss: 0.05431

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07151
Policy Update Magnitude: 0.06189
Value Function Update Magnitude: 0.07594

Collected Steps per Second: 12450.58867
Overall Steps per Second: 9755.25414

Timestep Collection Time: 4.01941
Timestep Consumption Time: 1.11055
PPO Batch Consumption Time: 0.11980
Total Iteration Time: 5.12995

Cumulative Model Updates: 7458
Cumulative Timesteps: 124458082

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 124458082...
Checkpoint 124458082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08724
Policy Entropy: 1.23178
Value Function Loss: 0.05396

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.06746

Collected Steps per Second: 13669.04196
Overall Steps per Second: 10986.96120

Timestep Collection Time: 3.65805
Timestep Consumption Time: 0.89298
PPO Batch Consumption Time: 0.06177
Total Iteration Time: 4.55103

Cumulative Model Updates: 7461
Cumulative Timesteps: 124508084

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07072
Policy Entropy: 1.22730
Value Function Loss: 0.05607

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.06084
Value Function Update Magnitude: 0.06414

Collected Steps per Second: 11713.29812
Overall Steps per Second: 9519.02532

Timestep Collection Time: 4.27104
Timestep Consumption Time: 0.98454
PPO Batch Consumption Time: 0.09096
Total Iteration Time: 5.25558

Cumulative Model Updates: 7464
Cumulative Timesteps: 124558112

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 124558112...
Checkpoint 124558112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06360
Policy Entropy: 1.22628
Value Function Loss: 0.05211

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10582
Policy Update Magnitude: 0.05531
Value Function Update Magnitude: 0.06975

Collected Steps per Second: 13411.87568
Overall Steps per Second: 10493.41286

Timestep Collection Time: 3.72998
Timestep Consumption Time: 1.03739
PPO Batch Consumption Time: 0.09839
Total Iteration Time: 4.76737

Cumulative Model Updates: 7467
Cumulative Timesteps: 124608138

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18265
Policy Entropy: 1.22282
Value Function Loss: 0.05785

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.05087
Value Function Update Magnitude: 0.06697

Collected Steps per Second: 13349.24833
Overall Steps per Second: 10428.98575

Timestep Collection Time: 3.74838
Timestep Consumption Time: 1.04960
PPO Batch Consumption Time: 0.07308
Total Iteration Time: 4.79797

Cumulative Model Updates: 7470
Cumulative Timesteps: 124658176

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 124658176...
Checkpoint 124658176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05986
Policy Entropy: 1.22537
Value Function Loss: 0.05067

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05066
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.06530

Collected Steps per Second: 13104.94528
Overall Steps per Second: 10480.02636

Timestep Collection Time: 3.81612
Timestep Consumption Time: 0.95582
PPO Batch Consumption Time: 0.10078
Total Iteration Time: 4.77193

Cumulative Model Updates: 7473
Cumulative Timesteps: 124708186

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06969
Policy Entropy: 1.22284
Value Function Loss: 0.06074

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 13098.67806
Overall Steps per Second: 10442.51028

Timestep Collection Time: 3.81810
Timestep Consumption Time: 0.97117
PPO Batch Consumption Time: 0.08178
Total Iteration Time: 4.78927

Cumulative Model Updates: 7476
Cumulative Timesteps: 124758198

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 124758198...
Checkpoint 124758198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08732
Policy Entropy: 1.21814
Value Function Loss: 0.05561

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.05381
Value Function Update Magnitude: 0.06033

Collected Steps per Second: 13203.17240
Overall Steps per Second: 10438.81764

Timestep Collection Time: 3.78985
Timestep Consumption Time: 1.00361
PPO Batch Consumption Time: 0.09980
Total Iteration Time: 4.79345

Cumulative Model Updates: 7479
Cumulative Timesteps: 124808236

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02687
Policy Entropy: 1.22073
Value Function Loss: 0.05473

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.06725

Collected Steps per Second: 13391.04336
Overall Steps per Second: 10434.37038

Timestep Collection Time: 3.73757
Timestep Consumption Time: 1.05907
PPO Batch Consumption Time: 0.10060
Total Iteration Time: 4.79665

Cumulative Model Updates: 7482
Cumulative Timesteps: 124858286

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 124858286...
Checkpoint 124858286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01063
Policy Entropy: 1.22211
Value Function Loss: 0.05113

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06087
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 12250.32529
Overall Steps per Second: 9695.79309

Timestep Collection Time: 4.08479
Timestep Consumption Time: 1.07621
PPO Batch Consumption Time: 0.11091
Total Iteration Time: 5.16100

Cumulative Model Updates: 7485
Cumulative Timesteps: 124908326

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02488
Policy Entropy: 1.22259
Value Function Loss: 0.05868

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05827
Policy Update Magnitude: 0.05446
Value Function Update Magnitude: 0.06564

Collected Steps per Second: 13328.71476
Overall Steps per Second: 10964.34745

Timestep Collection Time: 3.75265
Timestep Consumption Time: 0.80923
PPO Batch Consumption Time: 0.06307
Total Iteration Time: 4.56188

Cumulative Model Updates: 7488
Cumulative Timesteps: 124958344

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 124958344...
Checkpoint 124958344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07171
Policy Entropy: 1.22814
Value Function Loss: 0.05696

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.05061
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 12709.18846
Overall Steps per Second: 9968.83538

Timestep Collection Time: 3.93668
Timestep Consumption Time: 1.08216
PPO Batch Consumption Time: 0.11170
Total Iteration Time: 5.01884

Cumulative Model Updates: 7491
Cumulative Timesteps: 125008376

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10916
Policy Entropy: 1.22967
Value Function Loss: 0.06665

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.07144

Collected Steps per Second: 12120.45638
Overall Steps per Second: 9827.40084

Timestep Collection Time: 4.12641
Timestep Consumption Time: 0.96283
PPO Batch Consumption Time: 0.06952
Total Iteration Time: 5.08924

Cumulative Model Updates: 7494
Cumulative Timesteps: 125058390

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 125058390...
Checkpoint 125058390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02408
Policy Entropy: 1.23508
Value Function Loss: 0.06273

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06745
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.07373

Collected Steps per Second: 10247.85786
Overall Steps per Second: 8208.00835

Timestep Collection Time: 4.88219
Timestep Consumption Time: 1.21332
PPO Batch Consumption Time: 0.13399
Total Iteration Time: 6.09551

Cumulative Model Updates: 7497
Cumulative Timesteps: 125108422

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12300
Policy Entropy: 1.23286
Value Function Loss: 0.07078

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.08137

Collected Steps per Second: 11829.84166
Overall Steps per Second: 9621.23694

Timestep Collection Time: 4.22778
Timestep Consumption Time: 0.97051
PPO Batch Consumption Time: 0.06634
Total Iteration Time: 5.19829

Cumulative Model Updates: 7500
Cumulative Timesteps: 125158436

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 125158436...
Checkpoint 125158436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00350
Policy Entropy: 1.22976
Value Function Loss: 0.06646

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.05881
Value Function Update Magnitude: 0.07070

Collected Steps per Second: 10318.60568
Overall Steps per Second: 8364.80161

Timestep Collection Time: 4.84814
Timestep Consumption Time: 1.13240
PPO Batch Consumption Time: 0.10478
Total Iteration Time: 5.98054

Cumulative Model Updates: 7503
Cumulative Timesteps: 125208462

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01055
Policy Entropy: 1.23599
Value Function Loss: 0.06423

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.06776

Collected Steps per Second: 11453.50683
Overall Steps per Second: 9238.81260

Timestep Collection Time: 4.36862
Timestep Consumption Time: 1.04723
PPO Batch Consumption Time: 0.07257
Total Iteration Time: 5.41585

Cumulative Model Updates: 7506
Cumulative Timesteps: 125258498

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 125258498...
Checkpoint 125258498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07037
Policy Entropy: 1.24272
Value Function Loss: 0.06108

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06449
Policy Update Magnitude: 0.05691
Value Function Update Magnitude: 0.06912

Collected Steps per Second: 11798.80410
Overall Steps per Second: 9352.04723

Timestep Collection Time: 4.23857
Timestep Consumption Time: 1.10893
PPO Batch Consumption Time: 0.10537
Total Iteration Time: 5.34749

Cumulative Model Updates: 7509
Cumulative Timesteps: 125308508

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00524
Policy Entropy: 1.24440
Value Function Loss: 0.06045

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.07134

Collected Steps per Second: 12103.72709
Overall Steps per Second: 9585.07145

Timestep Collection Time: 4.13096
Timestep Consumption Time: 1.08549
PPO Batch Consumption Time: 0.08459
Total Iteration Time: 5.21645

Cumulative Model Updates: 7512
Cumulative Timesteps: 125358508

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 125358508...
Checkpoint 125358508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14716
Policy Entropy: 1.24364
Value Function Loss: 0.06903

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.07209

Collected Steps per Second: 11648.67630
Overall Steps per Second: 9313.57304

Timestep Collection Time: 4.29388
Timestep Consumption Time: 1.07656
PPO Batch Consumption Time: 0.07750
Total Iteration Time: 5.37044

Cumulative Model Updates: 7515
Cumulative Timesteps: 125408526

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09898
Policy Entropy: 1.24469
Value Function Loss: 0.07929

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.05542
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 12150.88407
Overall Steps per Second: 9868.93263

Timestep Collection Time: 4.11904
Timestep Consumption Time: 0.95243
PPO Batch Consumption Time: 0.07112
Total Iteration Time: 5.07147

Cumulative Model Updates: 7518
Cumulative Timesteps: 125458576

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 125458576...
Checkpoint 125458576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03516
Policy Entropy: 1.24514
Value Function Loss: 0.07703

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05893
Policy Update Magnitude: 0.05647
Value Function Update Magnitude: 0.08518

Collected Steps per Second: 11163.26942
Overall Steps per Second: 8811.09733

Timestep Collection Time: 4.48184
Timestep Consumption Time: 1.19645
PPO Batch Consumption Time: 0.12334
Total Iteration Time: 5.67829

Cumulative Model Updates: 7521
Cumulative Timesteps: 125508608

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05738
Policy Entropy: 1.24638
Value Function Loss: 0.08468

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.09105

Collected Steps per Second: 11591.77607
Overall Steps per Second: 9352.42928

Timestep Collection Time: 4.31547
Timestep Consumption Time: 1.03330
PPO Batch Consumption Time: 0.07552
Total Iteration Time: 5.34877

Cumulative Model Updates: 7524
Cumulative Timesteps: 125558632

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 125558632...
Checkpoint 125558632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11680
Policy Entropy: 1.24618
Value Function Loss: 0.07471

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.05779
Value Function Update Magnitude: 0.09366

Collected Steps per Second: 11592.24349
Overall Steps per Second: 9530.63809

Timestep Collection Time: 4.31547
Timestep Consumption Time: 0.93349
PPO Batch Consumption Time: 0.06868
Total Iteration Time: 5.24897

Cumulative Model Updates: 7527
Cumulative Timesteps: 125608658

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02919
Policy Entropy: 1.24981
Value Function Loss: 0.07020

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.05604
Value Function Update Magnitude: 0.09225

Collected Steps per Second: 12087.62262
Overall Steps per Second: 9713.48564

Timestep Collection Time: 4.13878
Timestep Consumption Time: 1.01159
PPO Batch Consumption Time: 0.06995
Total Iteration Time: 5.15037

Cumulative Model Updates: 7530
Cumulative Timesteps: 125658686

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 125658686...
Checkpoint 125658686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08678
Policy Entropy: 1.25706
Value Function Loss: 0.05140

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.08622

Collected Steps per Second: 10981.34772
Overall Steps per Second: 8896.26365

Timestep Collection Time: 4.55591
Timestep Consumption Time: 1.06780
PPO Batch Consumption Time: 0.08316
Total Iteration Time: 5.62371

Cumulative Model Updates: 7533
Cumulative Timesteps: 125708716

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01060
Policy Entropy: 1.25588
Value Function Loss: 0.06151

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.05264
Value Function Update Magnitude: 0.07829

Collected Steps per Second: 12140.69860
Overall Steps per Second: 9736.51260

Timestep Collection Time: 4.12151
Timestep Consumption Time: 1.01770
PPO Batch Consumption Time: 0.07430
Total Iteration Time: 5.13921

Cumulative Model Updates: 7536
Cumulative Timesteps: 125758754

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 125758754...
Checkpoint 125758754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14588
Policy Entropy: 1.24954
Value Function Loss: 0.06031

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.05194
Value Function Update Magnitude: 0.07481

Collected Steps per Second: 11785.88272
Overall Steps per Second: 9544.66264

Timestep Collection Time: 4.24627
Timestep Consumption Time: 0.99708
PPO Batch Consumption Time: 0.07089
Total Iteration Time: 5.24335

Cumulative Model Updates: 7539
Cumulative Timesteps: 125808800

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09252
Policy Entropy: 1.25240
Value Function Loss: 0.05920

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.07565

Collected Steps per Second: 11458.73093
Overall Steps per Second: 9298.99675

Timestep Collection Time: 4.36663
Timestep Consumption Time: 1.01417
PPO Batch Consumption Time: 0.10535
Total Iteration Time: 5.38080

Cumulative Model Updates: 7542
Cumulative Timesteps: 125858836

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 125858836...
Checkpoint 125858836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07200
Policy Entropy: 1.25307
Value Function Loss: 0.05504

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.07557

Collected Steps per Second: 11696.67307
Overall Steps per Second: 9282.16147

Timestep Collection Time: 4.27917
Timestep Consumption Time: 1.11311
PPO Batch Consumption Time: 0.10599
Total Iteration Time: 5.39228

Cumulative Model Updates: 7545
Cumulative Timesteps: 125908888

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00224
Policy Entropy: 1.25243
Value Function Loss: 0.05373

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05341
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.06792

Collected Steps per Second: 12002.44571
Overall Steps per Second: 9854.48704

Timestep Collection Time: 4.16632
Timestep Consumption Time: 0.90812
PPO Batch Consumption Time: 0.06775
Total Iteration Time: 5.07444

Cumulative Model Updates: 7548
Cumulative Timesteps: 125958894

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 125958894...
Checkpoint 125958894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05510
Policy Entropy: 1.24727
Value Function Loss: 0.05731

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.07141

Collected Steps per Second: 12141.52569
Overall Steps per Second: 9793.22992

Timestep Collection Time: 4.11876
Timestep Consumption Time: 0.98763
PPO Batch Consumption Time: 0.07752
Total Iteration Time: 5.10638

Cumulative Model Updates: 7551
Cumulative Timesteps: 126008902

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04743
Policy Entropy: 1.24689
Value Function Loss: 0.05359

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.06695

Collected Steps per Second: 13090.68435
Overall Steps per Second: 10567.04979

Timestep Collection Time: 3.82104
Timestep Consumption Time: 0.91254
PPO Batch Consumption Time: 0.06485
Total Iteration Time: 4.73358

Cumulative Model Updates: 7554
Cumulative Timesteps: 126058922

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 126058922...
Checkpoint 126058922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12115
Policy Entropy: 1.25283
Value Function Loss: 0.05817

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.06879

Collected Steps per Second: 13042.69756
Overall Steps per Second: 10389.52052

Timestep Collection Time: 3.83402
Timestep Consumption Time: 0.97910
PPO Batch Consumption Time: 0.10910
Total Iteration Time: 4.81312

Cumulative Model Updates: 7557
Cumulative Timesteps: 126108928

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02552
Policy Entropy: 1.25948
Value Function Loss: 0.05148

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06879
Policy Update Magnitude: 0.04862
Value Function Update Magnitude: 0.07412

Collected Steps per Second: 13491.62829
Overall Steps per Second: 10890.03990

Timestep Collection Time: 3.70837
Timestep Consumption Time: 0.88592
PPO Batch Consumption Time: 0.05961
Total Iteration Time: 4.59429

Cumulative Model Updates: 7560
Cumulative Timesteps: 126158960

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 126158960...
Checkpoint 126158960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03102
Policy Entropy: 1.25533
Value Function Loss: 0.04631

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06506
Policy Update Magnitude: 0.04548
Value Function Update Magnitude: 0.06984

Collected Steps per Second: 12251.64674
Overall Steps per Second: 9992.08195

Timestep Collection Time: 4.08255
Timestep Consumption Time: 0.92321
PPO Batch Consumption Time: 0.07087
Total Iteration Time: 5.00576

Cumulative Model Updates: 7563
Cumulative Timesteps: 126208978

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09795
Policy Entropy: 1.25292
Value Function Loss: 0.04138

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06755
Policy Update Magnitude: 0.04459
Value Function Update Magnitude: 0.06793

Collected Steps per Second: 13797.53564
Overall Steps per Second: 11106.20057

Timestep Collection Time: 3.62586
Timestep Consumption Time: 0.87865
PPO Batch Consumption Time: 0.06176
Total Iteration Time: 4.50451

Cumulative Model Updates: 7566
Cumulative Timesteps: 126259006

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 126259006...
Checkpoint 126259006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12510
Policy Entropy: 1.26366
Value Function Loss: 0.05103

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06067
Policy Update Magnitude: 0.04497
Value Function Update Magnitude: 0.06561

Collected Steps per Second: 13363.25871
Overall Steps per Second: 10709.38923

Timestep Collection Time: 3.74504
Timestep Consumption Time: 0.92805
PPO Batch Consumption Time: 0.06603
Total Iteration Time: 4.67310

Cumulative Model Updates: 7569
Cumulative Timesteps: 126309052

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08173
Policy Entropy: 1.25566
Value Function Loss: 0.05940

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05536
Policy Update Magnitude: 0.05185
Value Function Update Magnitude: 0.06526

Collected Steps per Second: 13289.79867
Overall Steps per Second: 10442.86660

Timestep Collection Time: 3.76439
Timestep Consumption Time: 1.02625
PPO Batch Consumption Time: 0.09726
Total Iteration Time: 4.79064

Cumulative Model Updates: 7572
Cumulative Timesteps: 126359080

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 126359080...
Checkpoint 126359080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12250
Policy Entropy: 1.25273
Value Function Loss: 0.06611

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05792
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.07101

Collected Steps per Second: 13550.43205
Overall Steps per Second: 10491.09033

Timestep Collection Time: 3.69140
Timestep Consumption Time: 1.07646
PPO Batch Consumption Time: 0.11332
Total Iteration Time: 4.76786

Cumulative Model Updates: 7575
Cumulative Timesteps: 126409100

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02664
Policy Entropy: 1.26085
Value Function Loss: 0.05480

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.07856

Collected Steps per Second: 13651.30437
Overall Steps per Second: 10818.66996

Timestep Collection Time: 3.66485
Timestep Consumption Time: 0.95956
PPO Batch Consumption Time: 0.07289
Total Iteration Time: 4.62441

Cumulative Model Updates: 7578
Cumulative Timesteps: 126459130

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 126459130...
Checkpoint 126459130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00924
Policy Entropy: 1.25776
Value Function Loss: 0.05220

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.08030

Collected Steps per Second: 11343.96440
Overall Steps per Second: 9282.34932

Timestep Collection Time: 4.40851
Timestep Consumption Time: 0.97913
PPO Batch Consumption Time: 0.07569
Total Iteration Time: 5.38764

Cumulative Model Updates: 7581
Cumulative Timesteps: 126509140

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12467
Policy Entropy: 1.25947
Value Function Loss: 0.05310

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.06907

Collected Steps per Second: 11079.38833
Overall Steps per Second: 8952.65223

Timestep Collection Time: 4.51307
Timestep Consumption Time: 1.07210
PPO Batch Consumption Time: 0.07238
Total Iteration Time: 5.58516

Cumulative Model Updates: 7584
Cumulative Timesteps: 126559142

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 126559142...
Checkpoint 126559142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05888
Policy Entropy: 1.27292
Value Function Loss: 0.06061

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.04663
Value Function Update Magnitude: 0.06439

Collected Steps per Second: 11670.51142
Overall Steps per Second: 9329.39658

Timestep Collection Time: 4.28739
Timestep Consumption Time: 1.07588
PPO Batch Consumption Time: 0.08304
Total Iteration Time: 5.36326

Cumulative Model Updates: 7587
Cumulative Timesteps: 126609178

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00909
Policy Entropy: 1.27456
Value Function Loss: 0.06536

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.04810
Value Function Update Magnitude: 0.06971

Collected Steps per Second: 12473.53081
Overall Steps per Second: 9643.83591

Timestep Collection Time: 4.00929
Timestep Consumption Time: 1.17641
PPO Batch Consumption Time: 0.11399
Total Iteration Time: 5.18570

Cumulative Model Updates: 7590
Cumulative Timesteps: 126659188

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 126659188...
Checkpoint 126659188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01930
Policy Entropy: 1.26831
Value Function Loss: 0.05733

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.05432
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.07470

Collected Steps per Second: 12014.47469
Overall Steps per Second: 9664.79122

Timestep Collection Time: 4.16364
Timestep Consumption Time: 1.01226
PPO Batch Consumption Time: 0.06955
Total Iteration Time: 5.17590

Cumulative Model Updates: 7593
Cumulative Timesteps: 126709212

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03695
Policy Entropy: 1.26717
Value Function Loss: 0.06008

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.05821
Policy Update Magnitude: 0.05125
Value Function Update Magnitude: 0.07150

Collected Steps per Second: 11036.08138
Overall Steps per Second: 8926.12570

Timestep Collection Time: 4.53186
Timestep Consumption Time: 1.07124
PPO Batch Consumption Time: 0.11088
Total Iteration Time: 5.60310

Cumulative Model Updates: 7596
Cumulative Timesteps: 126759226

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 126759226...
Checkpoint 126759226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10934
Policy Entropy: 1.26081
Value Function Loss: 0.04882

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04689
Policy Update Magnitude: 0.04893
Value Function Update Magnitude: 0.07054

Collected Steps per Second: 11394.83989
Overall Steps per Second: 9174.27202

Timestep Collection Time: 4.38795
Timestep Consumption Time: 1.06207
PPO Batch Consumption Time: 0.07822
Total Iteration Time: 5.45002

Cumulative Model Updates: 7599
Cumulative Timesteps: 126809226

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10785
Policy Entropy: 1.26199
Value Function Loss: 0.05632

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.04845
Value Function Update Magnitude: 0.07713

Collected Steps per Second: 10859.30249
Overall Steps per Second: 8728.15623

Timestep Collection Time: 4.60472
Timestep Consumption Time: 1.12433
PPO Batch Consumption Time: 0.11503
Total Iteration Time: 5.72905

Cumulative Model Updates: 7602
Cumulative Timesteps: 126859230

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 126859230...
Checkpoint 126859230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03777
Policy Entropy: 1.25966
Value Function Loss: 0.04993

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.08248

Collected Steps per Second: 12065.82917
Overall Steps per Second: 9715.03714

Timestep Collection Time: 4.14592
Timestep Consumption Time: 1.00321
PPO Batch Consumption Time: 0.07205
Total Iteration Time: 5.14913

Cumulative Model Updates: 7605
Cumulative Timesteps: 126909254

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08871
Policy Entropy: 1.27127
Value Function Loss: 0.05812

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.05322
Value Function Update Magnitude: 0.07960

Collected Steps per Second: 11458.62954
Overall Steps per Second: 9186.87237

Timestep Collection Time: 4.36614
Timestep Consumption Time: 1.07967
PPO Batch Consumption Time: 0.07889
Total Iteration Time: 5.44581

Cumulative Model Updates: 7608
Cumulative Timesteps: 126959284

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 126959284...
Checkpoint 126959284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09832
Policy Entropy: 1.27476
Value Function Loss: 0.05239

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06199
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.07622

Collected Steps per Second: 11989.32928
Overall Steps per Second: 9673.04256

Timestep Collection Time: 4.17204
Timestep Consumption Time: 0.99903
PPO Batch Consumption Time: 0.08691
Total Iteration Time: 5.17107

Cumulative Model Updates: 7611
Cumulative Timesteps: 127009304

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09580
Policy Entropy: 1.27056
Value Function Loss: 0.05470

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.06942

Collected Steps per Second: 12040.59052
Overall Steps per Second: 9602.40533

Timestep Collection Time: 4.15412
Timestep Consumption Time: 1.05479
PPO Batch Consumption Time: 0.09098
Total Iteration Time: 5.20890

Cumulative Model Updates: 7614
Cumulative Timesteps: 127059322

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 127059322...
Checkpoint 127059322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13090
Policy Entropy: 1.27041
Value Function Loss: 0.04827

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06978
Policy Update Magnitude: 0.05108
Value Function Update Magnitude: 0.06979

Collected Steps per Second: 11739.06058
Overall Steps per Second: 9384.47924

Timestep Collection Time: 4.26150
Timestep Consumption Time: 1.06922
PPO Batch Consumption Time: 0.07719
Total Iteration Time: 5.33072

Cumulative Model Updates: 7617
Cumulative Timesteps: 127109348

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05258
Policy Entropy: 1.26995
Value Function Loss: 0.04422

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.04677
Value Function Update Magnitude: 0.07763

Collected Steps per Second: 11245.91981
Overall Steps per Second: 8911.62071

Timestep Collection Time: 4.44890
Timestep Consumption Time: 1.16534
PPO Batch Consumption Time: 0.10356
Total Iteration Time: 5.61424

Cumulative Model Updates: 7620
Cumulative Timesteps: 127159380

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 127159380...
Checkpoint 127159380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01713
Policy Entropy: 1.27412
Value Function Loss: 0.04678

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 12013.67717
Overall Steps per Second: 9708.21144

Timestep Collection Time: 4.16575
Timestep Consumption Time: 0.98927
PPO Batch Consumption Time: 0.06951
Total Iteration Time: 5.15502

Cumulative Model Updates: 7623
Cumulative Timesteps: 127209426

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00009
Policy Entropy: 1.27377
Value Function Loss: 0.04743

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.05374
Value Function Update Magnitude: 0.08231

Collected Steps per Second: 11855.46678
Overall Steps per Second: 9540.36192

Timestep Collection Time: 4.22033
Timestep Consumption Time: 1.02412
PPO Batch Consumption Time: 0.09455
Total Iteration Time: 5.24446

Cumulative Model Updates: 7626
Cumulative Timesteps: 127259460

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 127259460...
Checkpoint 127259460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01920
Policy Entropy: 1.28303
Value Function Loss: 0.04633

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.09019

Collected Steps per Second: 11622.30618
Overall Steps per Second: 9313.06803

Timestep Collection Time: 4.30569
Timestep Consumption Time: 1.06762
PPO Batch Consumption Time: 0.07951
Total Iteration Time: 5.37331

Cumulative Model Updates: 7629
Cumulative Timesteps: 127309502

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07359
Policy Entropy: 1.28951
Value Function Loss: 0.03898

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.08541

Collected Steps per Second: 11921.28449
Overall Steps per Second: 9289.57068

Timestep Collection Time: 4.19485
Timestep Consumption Time: 1.18839
PPO Batch Consumption Time: 0.10482
Total Iteration Time: 5.38324

Cumulative Model Updates: 7632
Cumulative Timesteps: 127359510

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 127359510...
Checkpoint 127359510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02665
Policy Entropy: 1.28666
Value Function Loss: 0.03713

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06316
Policy Update Magnitude: 0.04455
Value Function Update Magnitude: 0.07083

Collected Steps per Second: 12526.49278
Overall Steps per Second: 10054.49101

Timestep Collection Time: 3.99170
Timestep Consumption Time: 0.98140
PPO Batch Consumption Time: 0.08239
Total Iteration Time: 4.97310

Cumulative Model Updates: 7635
Cumulative Timesteps: 127409512

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10696
Policy Entropy: 1.29198
Value Function Loss: 0.04296

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.05337
Policy Update Magnitude: 0.04255
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 12409.61650
Overall Steps per Second: 10093.92419

Timestep Collection Time: 4.03316
Timestep Consumption Time: 0.92527
PPO Batch Consumption Time: 0.07032
Total Iteration Time: 4.95843

Cumulative Model Updates: 7638
Cumulative Timesteps: 127459562

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 127459562...
Checkpoint 127459562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09209
Policy Entropy: 1.29233
Value Function Loss: 0.04772

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.04819
Policy Update Magnitude: 0.04306
Value Function Update Magnitude: 0.06538

Collected Steps per Second: 13294.52422
Overall Steps per Second: 10785.50274

Timestep Collection Time: 3.76365
Timestep Consumption Time: 0.87554
PPO Batch Consumption Time: 0.07164
Total Iteration Time: 4.63919

Cumulative Model Updates: 7641
Cumulative Timesteps: 127509598

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02603
Policy Entropy: 1.29672
Value Function Loss: 0.06108

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04081
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.06831

Collected Steps per Second: 13200.06880
Overall Steps per Second: 10422.13547

Timestep Collection Time: 3.78998
Timestep Consumption Time: 1.01019
PPO Batch Consumption Time: 0.06417
Total Iteration Time: 4.80017

Cumulative Model Updates: 7644
Cumulative Timesteps: 127559626

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 127559626...
Checkpoint 127559626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07176
Policy Entropy: 1.30148
Value Function Loss: 0.06565

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05163
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.07224

Collected Steps per Second: 12197.62682
Overall Steps per Second: 9703.50117

Timestep Collection Time: 4.10359
Timestep Consumption Time: 1.05476
PPO Batch Consumption Time: 0.10807
Total Iteration Time: 5.15834

Cumulative Model Updates: 7647
Cumulative Timesteps: 127609680

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18418
Policy Entropy: 1.30336
Value Function Loss: 0.06630

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05518
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.06970

Collected Steps per Second: 13684.21644
Overall Steps per Second: 10842.93971

Timestep Collection Time: 3.65764
Timestep Consumption Time: 0.95845
PPO Batch Consumption Time: 0.07572
Total Iteration Time: 4.61609

Cumulative Model Updates: 7650
Cumulative Timesteps: 127659732

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 127659732...
Checkpoint 127659732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02942
Policy Entropy: 1.30491
Value Function Loss: 0.06205

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.05534
Policy Update Magnitude: 0.04765
Value Function Update Magnitude: 0.07113

Collected Steps per Second: 13231.89581
Overall Steps per Second: 10629.81525

Timestep Collection Time: 3.78056
Timestep Consumption Time: 0.92545
PPO Batch Consumption Time: 0.06841
Total Iteration Time: 4.70601

Cumulative Model Updates: 7653
Cumulative Timesteps: 127709756

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04707
Policy Entropy: 1.31315
Value Function Loss: 0.06348

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06715
Policy Update Magnitude: 0.04868
Value Function Update Magnitude: 0.07034

Collected Steps per Second: 12814.70145
Overall Steps per Second: 10295.68593

Timestep Collection Time: 3.90629
Timestep Consumption Time: 0.95574
PPO Batch Consumption Time: 0.09990
Total Iteration Time: 4.86204

Cumulative Model Updates: 7656
Cumulative Timesteps: 127759814

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 127759814...
Checkpoint 127759814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.21452
Policy Entropy: 1.30962
Value Function Loss: 0.06661

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06307
Policy Update Magnitude: 0.04570
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 12550.07291
Overall Steps per Second: 10187.46151

Timestep Collection Time: 3.98420
Timestep Consumption Time: 0.92399
PPO Batch Consumption Time: 0.07070
Total Iteration Time: 4.90819

Cumulative Model Updates: 7659
Cumulative Timesteps: 127809816

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14898
Policy Entropy: 1.30902
Value Function Loss: 0.05991

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.06881
Policy Update Magnitude: 0.04392
Value Function Update Magnitude: 0.07009

Collected Steps per Second: 13066.58396
Overall Steps per Second: 10296.64298

Timestep Collection Time: 3.82870
Timestep Consumption Time: 1.02997
PPO Batch Consumption Time: 0.10091
Total Iteration Time: 4.85867

Cumulative Model Updates: 7662
Cumulative Timesteps: 127859844

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 127859844...
Checkpoint 127859844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06799
Policy Entropy: 1.31105
Value Function Loss: 0.05468

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.05696
Policy Update Magnitude: 0.04352
Value Function Update Magnitude: 0.06692

Collected Steps per Second: 13864.60277
Overall Steps per Second: 10876.21957

Timestep Collection Time: 3.60804
Timestep Consumption Time: 0.99136
PPO Batch Consumption Time: 0.08529
Total Iteration Time: 4.59939

Cumulative Model Updates: 7665
Cumulative Timesteps: 127909868

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01064
Policy Entropy: 1.31389
Value Function Loss: 0.04996

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06433
Policy Update Magnitude: 0.04051
Value Function Update Magnitude: 0.06576

Collected Steps per Second: 12900.70296
Overall Steps per Second: 10502.88439

Timestep Collection Time: 3.87684
Timestep Consumption Time: 0.88509
PPO Batch Consumption Time: 0.06196
Total Iteration Time: 4.76193

Cumulative Model Updates: 7668
Cumulative Timesteps: 127959882

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 127959882...
Checkpoint 127959882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10496
Policy Entropy: 1.30551
Value Function Loss: 0.05327

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06519
Policy Update Magnitude: 0.03959
Value Function Update Magnitude: 0.05115

Collected Steps per Second: 12584.24120
Overall Steps per Second: 10031.59017

Timestep Collection Time: 3.97497
Timestep Consumption Time: 1.01148
PPO Batch Consumption Time: 0.11525
Total Iteration Time: 4.98645

Cumulative Model Updates: 7671
Cumulative Timesteps: 128009904

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08294
Policy Entropy: 1.30669
Value Function Loss: 0.06899

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.04063
Value Function Update Magnitude: 0.05084

Collected Steps per Second: 13058.03347
Overall Steps per Second: 10398.30566

Timestep Collection Time: 3.83289
Timestep Consumption Time: 0.98039
PPO Batch Consumption Time: 0.08534
Total Iteration Time: 4.81328

Cumulative Model Updates: 7674
Cumulative Timesteps: 128059954

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 128059954...
Checkpoint 128059954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03085
Policy Entropy: 1.30382
Value Function Loss: 0.07585

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06477
Policy Update Magnitude: 0.04416
Value Function Update Magnitude: 0.05221

Collected Steps per Second: 13259.36049
Overall Steps per Second: 10473.17853

Timestep Collection Time: 3.77122
Timestep Consumption Time: 1.00326
PPO Batch Consumption Time: 0.08406
Total Iteration Time: 4.77448

Cumulative Model Updates: 7677
Cumulative Timesteps: 128109958

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12142
Policy Entropy: 1.29481
Value Function Loss: 0.08194

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.05078
Value Function Update Magnitude: 0.05386

Collected Steps per Second: 10846.63285
Overall Steps per Second: 8628.41204

Timestep Collection Time: 4.61120
Timestep Consumption Time: 1.18546
PPO Batch Consumption Time: 0.09399
Total Iteration Time: 5.79666

Cumulative Model Updates: 7680
Cumulative Timesteps: 128159974

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 128159974...
Checkpoint 128159974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02116
Policy Entropy: 1.29292
Value Function Loss: 0.08501

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.05921

Collected Steps per Second: 11804.17544
Overall Steps per Second: 9313.57434

Timestep Collection Time: 4.23748
Timestep Consumption Time: 1.13317
PPO Batch Consumption Time: 0.11582
Total Iteration Time: 5.37066

Cumulative Model Updates: 7683
Cumulative Timesteps: 128209994

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07922
Policy Entropy: 1.29373
Value Function Loss: 0.07184

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.06291

Collected Steps per Second: 11807.51144
Overall Steps per Second: 9695.06831

Timestep Collection Time: 4.23595
Timestep Consumption Time: 0.92296
PPO Batch Consumption Time: 0.07332
Total Iteration Time: 5.15891

Cumulative Model Updates: 7686
Cumulative Timesteps: 128260010

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 128260010...
Checkpoint 128260010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12848
Policy Entropy: 1.30129
Value Function Loss: 0.07336

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03679
Policy Update Magnitude: 0.05020
Value Function Update Magnitude: 0.06042

Collected Steps per Second: 11804.73898
Overall Steps per Second: 9226.40935

Timestep Collection Time: 4.23626
Timestep Consumption Time: 1.18383
PPO Batch Consumption Time: 0.12055
Total Iteration Time: 5.42009

Cumulative Model Updates: 7689
Cumulative Timesteps: 128310018

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02273
Policy Entropy: 1.30276
Value Function Loss: 0.06172

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03721
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.05915

Collected Steps per Second: 11890.50983
Overall Steps per Second: 9620.17281

Timestep Collection Time: 4.20857
Timestep Consumption Time: 0.99321
PPO Batch Consumption Time: 0.06821
Total Iteration Time: 5.20178

Cumulative Model Updates: 7692
Cumulative Timesteps: 128360060

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 128360060...
Checkpoint 128360060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00694
Policy Entropy: 1.29973
Value Function Loss: 0.05874

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06489
Policy Update Magnitude: 0.04923
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 10830.80701
Overall Steps per Second: 8642.51994

Timestep Collection Time: 4.61775
Timestep Consumption Time: 1.16922
PPO Batch Consumption Time: 0.10682
Total Iteration Time: 5.78697

Cumulative Model Updates: 7695
Cumulative Timesteps: 128410074

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09411
Policy Entropy: 1.29746
Value Function Loss: 0.05122

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06605
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.05625

Collected Steps per Second: 11771.42746
Overall Steps per Second: 9299.97134

Timestep Collection Time: 4.24825
Timestep Consumption Time: 1.12897
PPO Batch Consumption Time: 0.10427
Total Iteration Time: 5.37722

Cumulative Model Updates: 7698
Cumulative Timesteps: 128460082

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 128460082...
Checkpoint 128460082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17777
Policy Entropy: 1.29555
Value Function Loss: 0.04810

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05290
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.06175

Collected Steps per Second: 11834.48114
Overall Steps per Second: 9711.50802

Timestep Collection Time: 4.22545
Timestep Consumption Time: 0.92370
PPO Batch Consumption Time: 0.07325
Total Iteration Time: 5.14915

Cumulative Model Updates: 7701
Cumulative Timesteps: 128510088

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11461
Policy Entropy: 1.29746
Value Function Loss: 0.05339

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.04985
Policy Update Magnitude: 0.05148
Value Function Update Magnitude: 0.06420

Collected Steps per Second: 11718.65614
Overall Steps per Second: 9193.76579

Timestep Collection Time: 4.26704
Timestep Consumption Time: 1.17186
PPO Batch Consumption Time: 0.10097
Total Iteration Time: 5.43890

Cumulative Model Updates: 7704
Cumulative Timesteps: 128560092

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 128560092...
Checkpoint 128560092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00843
Policy Entropy: 1.29304
Value Function Loss: 0.05643

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07188
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.06514

Collected Steps per Second: 12053.80952
Overall Steps per Second: 9736.25637

Timestep Collection Time: 4.14906
Timestep Consumption Time: 0.98761
PPO Batch Consumption Time: 0.07266
Total Iteration Time: 5.13668

Cumulative Model Updates: 7707
Cumulative Timesteps: 128610104

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01578
Policy Entropy: 1.29478
Value Function Loss: 0.05875

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06100
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.05957

Collected Steps per Second: 11150.83243
Overall Steps per Second: 8869.82351

Timestep Collection Time: 4.48720
Timestep Consumption Time: 1.15395
PPO Batch Consumption Time: 0.11193
Total Iteration Time: 5.64115

Cumulative Model Updates: 7710
Cumulative Timesteps: 128660140

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 128660140...
Checkpoint 128660140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02512
Policy Entropy: 1.29267
Value Function Loss: 0.05979

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04736
Policy Update Magnitude: 0.04723
Value Function Update Magnitude: 0.06557

Collected Steps per Second: 11666.38373
Overall Steps per Second: 9445.79964

Timestep Collection Time: 4.28873
Timestep Consumption Time: 1.00823
PPO Batch Consumption Time: 0.07289
Total Iteration Time: 5.29696

Cumulative Model Updates: 7713
Cumulative Timesteps: 128710174

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06411
Policy Entropy: 1.28849
Value Function Loss: 0.06206

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.06061

Collected Steps per Second: 11688.72228
Overall Steps per Second: 9481.00621

Timestep Collection Time: 4.27951
Timestep Consumption Time: 0.99651
PPO Batch Consumption Time: 0.09164
Total Iteration Time: 5.27602

Cumulative Model Updates: 7716
Cumulative Timesteps: 128760196

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 128760196...
Checkpoint 128760196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00665
Policy Entropy: 1.28814
Value Function Loss: 0.07194

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06715
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.05439

Collected Steps per Second: 11788.63797
Overall Steps per Second: 9238.97912

Timestep Collection Time: 4.24222
Timestep Consumption Time: 1.17072
PPO Batch Consumption Time: 0.10016
Total Iteration Time: 5.41294

Cumulative Model Updates: 7719
Cumulative Timesteps: 128810206

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01647
Policy Entropy: 1.28679
Value Function Loss: 0.06512

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.05976
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.05768

Collected Steps per Second: 11137.22727
Overall Steps per Second: 8979.45892

Timestep Collection Time: 4.49160
Timestep Consumption Time: 1.07933
PPO Batch Consumption Time: 0.09006
Total Iteration Time: 5.57094

Cumulative Model Updates: 7722
Cumulative Timesteps: 128860230

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 128860230...
Checkpoint 128860230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09809
Policy Entropy: 1.28467
Value Function Loss: 0.07029

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.05570
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.06006

Collected Steps per Second: 11958.82868
Overall Steps per Second: 9602.35412

Timestep Collection Time: 4.18252
Timestep Consumption Time: 1.02641
PPO Batch Consumption Time: 0.06917
Total Iteration Time: 5.20893

Cumulative Model Updates: 7725
Cumulative Timesteps: 128910248

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07740
Policy Entropy: 1.29202
Value Function Loss: 0.07485

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06415
Policy Update Magnitude: 0.05556
Value Function Update Magnitude: 0.06433

Collected Steps per Second: 10705.49903
Overall Steps per Second: 8672.99259

Timestep Collection Time: 4.67274
Timestep Consumption Time: 1.09505
PPO Batch Consumption Time: 0.07504
Total Iteration Time: 5.76779

Cumulative Model Updates: 7728
Cumulative Timesteps: 128960272

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 128960272...
Checkpoint 128960272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06354
Policy Entropy: 1.29333
Value Function Loss: 0.08097

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.06237
Value Function Update Magnitude: 0.05804

Collected Steps per Second: 11880.41767
Overall Steps per Second: 9746.19862

Timestep Collection Time: 4.21046
Timestep Consumption Time: 0.92200
PPO Batch Consumption Time: 0.06595
Total Iteration Time: 5.13246

Cumulative Model Updates: 7731
Cumulative Timesteps: 129010294

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08645
Policy Entropy: 1.28354
Value Function Loss: 0.07901

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.06226
Value Function Update Magnitude: 0.05208

Collected Steps per Second: 12422.06966
Overall Steps per Second: 9919.06053

Timestep Collection Time: 4.02799
Timestep Consumption Time: 1.01644
PPO Batch Consumption Time: 0.09454
Total Iteration Time: 5.04443

Cumulative Model Updates: 7734
Cumulative Timesteps: 129060330

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 129060330...
Checkpoint 129060330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08984
Policy Entropy: 1.28050
Value Function Loss: 0.06247

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.05550
Value Function Update Magnitude: 0.05320

Collected Steps per Second: 12916.53439
Overall Steps per Second: 10495.03821

Timestep Collection Time: 3.87271
Timestep Consumption Time: 0.89354
PPO Batch Consumption Time: 0.06245
Total Iteration Time: 4.76625

Cumulative Model Updates: 7737
Cumulative Timesteps: 129110352

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13558
Policy Entropy: 1.28414
Value Function Loss: 0.06517

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06311
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 12170.76780
Overall Steps per Second: 9991.99042

Timestep Collection Time: 4.11166
Timestep Consumption Time: 0.89656
PPO Batch Consumption Time: 0.07590
Total Iteration Time: 5.00821

Cumulative Model Updates: 7740
Cumulative Timesteps: 129160394

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 129160394...
Checkpoint 129160394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02741
Policy Entropy: 1.28196
Value Function Loss: 0.05526

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.05777
Policy Update Magnitude: 0.05210
Value Function Update Magnitude: 0.07006

Collected Steps per Second: 13352.71229
Overall Steps per Second: 10469.78512

Timestep Collection Time: 3.74591
Timestep Consumption Time: 1.03146
PPO Batch Consumption Time: 0.09737
Total Iteration Time: 4.77737

Cumulative Model Updates: 7743
Cumulative Timesteps: 129210412

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04153
Policy Entropy: 1.27730
Value Function Loss: 0.05547

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.04833
Value Function Update Magnitude: 0.06486

Collected Steps per Second: 13499.21977
Overall Steps per Second: 10837.01794

Timestep Collection Time: 3.70555
Timestep Consumption Time: 0.91030
PPO Batch Consumption Time: 0.06924
Total Iteration Time: 4.61585

Cumulative Model Updates: 7746
Cumulative Timesteps: 129260434

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 129260434...
Checkpoint 129260434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09748
Policy Entropy: 1.27433
Value Function Loss: 0.05057

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.04943
Value Function Update Magnitude: 0.06585

Collected Steps per Second: 13416.18511
Overall Steps per Second: 10526.20088

Timestep Collection Time: 3.72744
Timestep Consumption Time: 1.02337
PPO Batch Consumption Time: 0.10338
Total Iteration Time: 4.75081

Cumulative Model Updates: 7749
Cumulative Timesteps: 129310442

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01368
Policy Entropy: 1.27809
Value Function Loss: 0.06127

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.07029

Collected Steps per Second: 12875.33707
Overall Steps per Second: 10002.01412

Timestep Collection Time: 3.88510
Timestep Consumption Time: 1.11609
PPO Batch Consumption Time: 0.06695
Total Iteration Time: 5.00119

Cumulative Model Updates: 7752
Cumulative Timesteps: 129360464

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 129360464...
Checkpoint 129360464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02282
Policy Entropy: 1.27912
Value Function Loss: 0.05610

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.07879

Collected Steps per Second: 10245.44366
Overall Steps per Second: 8386.79754

Timestep Collection Time: 4.88432
Timestep Consumption Time: 1.08244
PPO Batch Consumption Time: 0.08451
Total Iteration Time: 5.96676

Cumulative Model Updates: 7755
Cumulative Timesteps: 129410506

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06368
Policy Entropy: 1.27367
Value Function Loss: 0.05515

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.08425

Collected Steps per Second: 12260.71179
Overall Steps per Second: 9602.80274

Timestep Collection Time: 4.07970
Timestep Consumption Time: 1.12920
PPO Batch Consumption Time: 0.09719
Total Iteration Time: 5.20890

Cumulative Model Updates: 7758
Cumulative Timesteps: 129460526

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 129460526...
Checkpoint 129460526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14770
Policy Entropy: 1.27213
Value Function Loss: 0.04997

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.07805

Collected Steps per Second: 11377.64095
Overall Steps per Second: 9006.56067

Timestep Collection Time: 4.39810
Timestep Consumption Time: 1.15785
PPO Batch Consumption Time: 0.12223
Total Iteration Time: 5.55595

Cumulative Model Updates: 7761
Cumulative Timesteps: 129510566

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16563
Policy Entropy: 1.26669
Value Function Loss: 0.06715

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08345
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.06724

Collected Steps per Second: 12141.48532
Overall Steps per Second: 9614.59033

Timestep Collection Time: 4.12124
Timestep Consumption Time: 1.08314
PPO Batch Consumption Time: 0.08451
Total Iteration Time: 5.20438

Cumulative Model Updates: 7764
Cumulative Timesteps: 129560604

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 129560604...
Checkpoint 129560604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05738
Policy Entropy: 1.26235
Value Function Loss: 0.05949

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.06068
Value Function Update Magnitude: 0.06155

Collected Steps per Second: 12020.24453
Overall Steps per Second: 9616.94699

Timestep Collection Time: 4.16115
Timestep Consumption Time: 1.03988
PPO Batch Consumption Time: 0.09616
Total Iteration Time: 5.20103

Cumulative Model Updates: 7767
Cumulative Timesteps: 129610622

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05382
Policy Entropy: 1.25871
Value Function Loss: 0.05204

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.05887

Collected Steps per Second: 11973.39291
Overall Steps per Second: 9951.63832

Timestep Collection Time: 4.17793
Timestep Consumption Time: 0.84878
PPO Batch Consumption Time: 0.06772
Total Iteration Time: 5.02671

Cumulative Model Updates: 7770
Cumulative Timesteps: 129660646

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 129660646...
Checkpoint 129660646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08025
Policy Entropy: 1.26757
Value Function Loss: 0.04674

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.05301
Value Function Update Magnitude: 0.05167

Collected Steps per Second: 10287.63138
Overall Steps per Second: 8403.37842

Timestep Collection Time: 4.86021
Timestep Consumption Time: 1.08978
PPO Batch Consumption Time: 0.09490
Total Iteration Time: 5.94999

Cumulative Model Updates: 7773
Cumulative Timesteps: 129710646

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06343
Policy Entropy: 1.26367
Value Function Loss: 0.05368

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.05122

Collected Steps per Second: 12193.77609
Overall Steps per Second: 9842.59117

Timestep Collection Time: 4.10406
Timestep Consumption Time: 0.98037
PPO Batch Consumption Time: 0.07065
Total Iteration Time: 5.08443

Cumulative Model Updates: 7776
Cumulative Timesteps: 129760690

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 129760690...
Checkpoint 129760690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01149
Policy Entropy: 1.26185
Value Function Loss: 0.06639

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.05524

Collected Steps per Second: 11983.14628
Overall Steps per Second: 9471.72653

Timestep Collection Time: 4.17470
Timestep Consumption Time: 1.10692
PPO Batch Consumption Time: 0.10328
Total Iteration Time: 5.28161

Cumulative Model Updates: 7779
Cumulative Timesteps: 129810716

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08977
Policy Entropy: 1.25977
Value Function Loss: 0.07285

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.06028
Value Function Update Magnitude: 0.05830

Collected Steps per Second: 11980.00927
Overall Steps per Second: 9627.51688

Timestep Collection Time: 4.17546
Timestep Consumption Time: 1.02028
PPO Batch Consumption Time: 0.07423
Total Iteration Time: 5.19573

Cumulative Model Updates: 7782
Cumulative Timesteps: 129860738

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 129860738...
Checkpoint 129860738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14627
Policy Entropy: 1.26096
Value Function Loss: 0.06558

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07804
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.05927

Collected Steps per Second: 12060.27631
Overall Steps per Second: 9919.23164

Timestep Collection Time: 4.14717
Timestep Consumption Time: 0.89516
PPO Batch Consumption Time: 0.07275
Total Iteration Time: 5.04233

Cumulative Model Updates: 7785
Cumulative Timesteps: 129910754

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09690
Policy Entropy: 1.26556
Value Function Loss: 0.06271

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04628
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.05965

Collected Steps per Second: 10588.48278
Overall Steps per Second: 8447.38031

Timestep Collection Time: 4.72476
Timestep Consumption Time: 1.19755
PPO Batch Consumption Time: 0.10183
Total Iteration Time: 5.92231

Cumulative Model Updates: 7788
Cumulative Timesteps: 129960782

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 129960782...
Checkpoint 129960782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17246
Policy Entropy: 1.25873
Value Function Loss: 0.05938

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.05584

Collected Steps per Second: 10519.72940
Overall Steps per Second: 8625.49534

Timestep Collection Time: 4.75564
Timestep Consumption Time: 1.04438
PPO Batch Consumption Time: 0.08337
Total Iteration Time: 5.80001

Cumulative Model Updates: 7791
Cumulative Timesteps: 130010810

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03668
Policy Entropy: 1.25264
Value Function Loss: 0.06702

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.05233

Collected Steps per Second: 12132.60496
Overall Steps per Second: 9663.84516

Timestep Collection Time: 4.12212
Timestep Consumption Time: 1.05305
PPO Batch Consumption Time: 0.09044
Total Iteration Time: 5.17517

Cumulative Model Updates: 7794
Cumulative Timesteps: 130060822

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 130060822...
Checkpoint 130060822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15452
Policy Entropy: 1.25948
Value Function Loss: 0.06080

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07245
Policy Update Magnitude: 0.05824
Value Function Update Magnitude: 0.05791

Collected Steps per Second: 12125.26426
Overall Steps per Second: 9731.40540

Timestep Collection Time: 4.12511
Timestep Consumption Time: 1.01475
PPO Batch Consumption Time: 0.07503
Total Iteration Time: 5.13985

Cumulative Model Updates: 7797
Cumulative Timesteps: 130110840

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03208
Policy Entropy: 1.27037
Value Function Loss: 0.06700

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05064
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.06581

Collected Steps per Second: 11524.22329
Overall Steps per Second: 9177.67222

Timestep Collection Time: 4.33973
Timestep Consumption Time: 1.10958
PPO Batch Consumption Time: 0.10600
Total Iteration Time: 5.44931

Cumulative Model Updates: 7800
Cumulative Timesteps: 130160852

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 130160852...
Checkpoint 130160852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06050
Policy Entropy: 1.26052
Value Function Loss: 0.06888

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.05803

Collected Steps per Second: 11870.09019
Overall Steps per Second: 9304.50223

Timestep Collection Time: 4.21294
Timestep Consumption Time: 1.16166
PPO Batch Consumption Time: 0.08913
Total Iteration Time: 5.37460

Cumulative Model Updates: 7803
Cumulative Timesteps: 130210860

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06335
Policy Entropy: 1.25356
Value Function Loss: 0.06211

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.05629

Collected Steps per Second: 11319.77300
Overall Steps per Second: 8962.17546

Timestep Collection Time: 4.42094
Timestep Consumption Time: 1.16298
PPO Batch Consumption Time: 0.11837
Total Iteration Time: 5.58391

Cumulative Model Updates: 7806
Cumulative Timesteps: 130260904

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 130260904...
Checkpoint 130260904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08717
Policy Entropy: 1.26222
Value Function Loss: 0.05372

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06067
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.05742

Collected Steps per Second: 12621.75930
Overall Steps per Second: 10426.21877

Timestep Collection Time: 3.96173
Timestep Consumption Time: 0.83426
PPO Batch Consumption Time: 0.06260
Total Iteration Time: 4.79599

Cumulative Model Updates: 7809
Cumulative Timesteps: 130310908

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02042
Policy Entropy: 1.26226
Value Function Loss: 0.04700

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.05748
Policy Update Magnitude: 0.06100
Value Function Update Magnitude: 0.05039

Collected Steps per Second: 12265.00330
Overall Steps per Second: 9654.96653

Timestep Collection Time: 4.07925
Timestep Consumption Time: 1.10275
PPO Batch Consumption Time: 0.12100
Total Iteration Time: 5.18200

Cumulative Model Updates: 7812
Cumulative Timesteps: 130360940

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 130360940...
Checkpoint 130360940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02566
Policy Entropy: 1.26311
Value Function Loss: 0.05116

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.05390

Collected Steps per Second: 13129.05755
Overall Steps per Second: 10436.48391

Timestep Collection Time: 3.80850
Timestep Consumption Time: 0.98258
PPO Batch Consumption Time: 0.08610
Total Iteration Time: 4.79108

Cumulative Model Updates: 7815
Cumulative Timesteps: 130410942

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06140
Policy Entropy: 1.25796
Value Function Loss: 0.05652

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.05429

Collected Steps per Second: 13581.43899
Overall Steps per Second: 10460.34191

Timestep Collection Time: 3.68444
Timestep Consumption Time: 1.09934
PPO Batch Consumption Time: 0.12498
Total Iteration Time: 4.78378

Cumulative Model Updates: 7818
Cumulative Timesteps: 130460982

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 130460982...
Checkpoint 130460982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07917
Policy Entropy: 1.25599
Value Function Loss: 0.05973

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06815
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.05578

Collected Steps per Second: 13219.41290
Overall Steps per Second: 10427.20523

Timestep Collection Time: 3.78322
Timestep Consumption Time: 1.01308
PPO Batch Consumption Time: 0.09923
Total Iteration Time: 4.79630

Cumulative Model Updates: 7821
Cumulative Timesteps: 130510994

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05484
Policy Entropy: 1.25315
Value Function Loss: 0.07052

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06002
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.06434

Collected Steps per Second: 13229.36979
Overall Steps per Second: 10460.95742

Timestep Collection Time: 3.78143
Timestep Consumption Time: 1.00073
PPO Batch Consumption Time: 0.11613
Total Iteration Time: 4.78216

Cumulative Model Updates: 7824
Cumulative Timesteps: 130561020

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 130561020...
Checkpoint 130561020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08703
Policy Entropy: 1.25193
Value Function Loss: 0.06604

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07325
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.08295

Collected Steps per Second: 13350.64883
Overall Steps per Second: 10436.23600

Timestep Collection Time: 3.74723
Timestep Consumption Time: 1.04645
PPO Batch Consumption Time: 0.09289
Total Iteration Time: 4.79368

Cumulative Model Updates: 7827
Cumulative Timesteps: 130611048

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11566
Policy Entropy: 1.24336
Value Function Loss: 0.06664

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.07656

Collected Steps per Second: 11817.24150
Overall Steps per Second: 9623.41943

Timestep Collection Time: 4.23483
Timestep Consumption Time: 0.96540
PPO Batch Consumption Time: 0.07093
Total Iteration Time: 5.20023

Cumulative Model Updates: 7830
Cumulative Timesteps: 130661092

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 130661092...
Checkpoint 130661092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15925
Policy Entropy: 1.24143
Value Function Loss: 0.05805

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.07377

Collected Steps per Second: 12931.15863
Overall Steps per Second: 10306.94006

Timestep Collection Time: 3.86879
Timestep Consumption Time: 0.98502
PPO Batch Consumption Time: 0.07007
Total Iteration Time: 4.85382

Cumulative Model Updates: 7833
Cumulative Timesteps: 130711120

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14076
Policy Entropy: 1.24212
Value Function Loss: 0.05900

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06146
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.08490

Collected Steps per Second: 12045.55016
Overall Steps per Second: 9741.43663

Timestep Collection Time: 4.15091
Timestep Consumption Time: 0.98180
PPO Batch Consumption Time: 0.08196
Total Iteration Time: 5.13271

Cumulative Model Updates: 7836
Cumulative Timesteps: 130761120

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 130761120...
Checkpoint 130761120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08266
Policy Entropy: 1.24340
Value Function Loss: 0.05554

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04542
Policy Update Magnitude: 0.05990
Value Function Update Magnitude: 0.07604

Collected Steps per Second: 13148.51233
Overall Steps per Second: 10835.96922

Timestep Collection Time: 3.80530
Timestep Consumption Time: 0.81210
PPO Batch Consumption Time: 0.05925
Total Iteration Time: 4.61740

Cumulative Model Updates: 7839
Cumulative Timesteps: 130811154

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05981
Policy Entropy: 1.23627
Value Function Loss: 0.04738

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05970
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.07285

Collected Steps per Second: 11334.91779
Overall Steps per Second: 9042.06877

Timestep Collection Time: 4.41521
Timestep Consumption Time: 1.11959
PPO Batch Consumption Time: 0.10198
Total Iteration Time: 5.53480

Cumulative Model Updates: 7842
Cumulative Timesteps: 130861200

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 130861200...
Checkpoint 130861200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07973
Policy Entropy: 1.24176
Value Function Loss: 0.04671

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 11435.09206
Overall Steps per Second: 9278.53131

Timestep Collection Time: 4.37618
Timestep Consumption Time: 1.01713
PPO Batch Consumption Time: 0.07060
Total Iteration Time: 5.39331

Cumulative Model Updates: 7845
Cumulative Timesteps: 130911242

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08329
Policy Entropy: 1.24342
Value Function Loss: 0.05164

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.05634
Value Function Update Magnitude: 0.06284

Collected Steps per Second: 11059.54543
Overall Steps per Second: 8948.69911

Timestep Collection Time: 4.52387
Timestep Consumption Time: 1.06711
PPO Batch Consumption Time: 0.08119
Total Iteration Time: 5.59098

Cumulative Model Updates: 7848
Cumulative Timesteps: 130961274

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 130961274...
Checkpoint 130961274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11642
Policy Entropy: 1.24404
Value Function Loss: 0.05541

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06718
Policy Update Magnitude: 0.05495
Value Function Update Magnitude: 0.06263

Collected Steps per Second: 11046.34634
Overall Steps per Second: 8927.24527

Timestep Collection Time: 4.52892
Timestep Consumption Time: 1.07505
PPO Batch Consumption Time: 0.07423
Total Iteration Time: 5.60397

Cumulative Model Updates: 7851
Cumulative Timesteps: 131011302

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03952
Policy Entropy: 1.23676
Value Function Loss: 0.06665

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.06793

Collected Steps per Second: 11868.91039
Overall Steps per Second: 9311.56610

Timestep Collection Time: 4.21370
Timestep Consumption Time: 1.15726
PPO Batch Consumption Time: 0.10277
Total Iteration Time: 5.37095

Cumulative Model Updates: 7854
Cumulative Timesteps: 131061314

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 131061314...
Checkpoint 131061314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00185
Policy Entropy: 1.24419
Value Function Loss: 0.06536

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.05966
Value Function Update Magnitude: 0.07707

Collected Steps per Second: 12155.63114
Overall Steps per Second: 9650.18719

Timestep Collection Time: 4.11480
Timestep Consumption Time: 1.06831
PPO Batch Consumption Time: 0.08672
Total Iteration Time: 5.18311

Cumulative Model Updates: 7857
Cumulative Timesteps: 131111332

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02198
Policy Entropy: 1.25429
Value Function Loss: 0.07284

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06021
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 11959.67169
Overall Steps per Second: 9609.62899

Timestep Collection Time: 4.18189
Timestep Consumption Time: 1.02268
PPO Batch Consumption Time: 0.08406
Total Iteration Time: 5.20457

Cumulative Model Updates: 7860
Cumulative Timesteps: 131161346

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 131161346...
Checkpoint 131161346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12534
Policy Entropy: 1.25299
Value Function Loss: 0.06735

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05965
Policy Update Magnitude: 0.06088
Value Function Update Magnitude: 0.07200

Collected Steps per Second: 11862.65104
Overall Steps per Second: 9717.67632

Timestep Collection Time: 4.21727
Timestep Consumption Time: 0.93087
PPO Batch Consumption Time: 0.06902
Total Iteration Time: 5.14814

Cumulative Model Updates: 7863
Cumulative Timesteps: 131211374

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04609
Policy Entropy: 1.24944
Value Function Loss: 0.06154

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.07966

Collected Steps per Second: 11079.81578
Overall Steps per Second: 8882.52573

Timestep Collection Time: 4.51433
Timestep Consumption Time: 1.11672
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 5.63106

Cumulative Model Updates: 7866
Cumulative Timesteps: 131261392

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 131261392...
Checkpoint 131261392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14991
Policy Entropy: 1.25167
Value Function Loss: 0.05374

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09023
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.07903

Collected Steps per Second: 12059.28413
Overall Steps per Second: 9755.88820

Timestep Collection Time: 4.14933
Timestep Consumption Time: 0.97967
PPO Batch Consumption Time: 0.07071
Total Iteration Time: 5.12901

Cumulative Model Updates: 7869
Cumulative Timesteps: 131311430

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05137
Policy Entropy: 1.25018
Value Function Loss: 0.04584

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06482
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.07771

Collected Steps per Second: 11718.91053
Overall Steps per Second: 9199.81770

Timestep Collection Time: 4.26985
Timestep Consumption Time: 1.16917
PPO Batch Consumption Time: 0.11694
Total Iteration Time: 5.43902

Cumulative Model Updates: 7872
Cumulative Timesteps: 131361468

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 131361468...
Checkpoint 131361468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07227
Policy Entropy: 1.24599
Value Function Loss: 0.05092

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.05452
Value Function Update Magnitude: 0.07061

Collected Steps per Second: 11843.11294
Overall Steps per Second: 9311.81685

Timestep Collection Time: 4.22355
Timestep Consumption Time: 1.14812
PPO Batch Consumption Time: 0.10940
Total Iteration Time: 5.37167

Cumulative Model Updates: 7875
Cumulative Timesteps: 131411488

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10708
Policy Entropy: 1.24687
Value Function Loss: 0.05301

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.05191
Value Function Update Magnitude: 0.06940

Collected Steps per Second: 12062.80389
Overall Steps per Second: 9634.67915

Timestep Collection Time: 4.14796
Timestep Consumption Time: 1.04537
PPO Batch Consumption Time: 0.10351
Total Iteration Time: 5.19332

Cumulative Model Updates: 7878
Cumulative Timesteps: 131461524

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 131461524...
Checkpoint 131461524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09023
Policy Entropy: 1.24684
Value Function Loss: 0.05844

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06231
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.06427

Collected Steps per Second: 11891.66552
Overall Steps per Second: 9672.10677

Timestep Collection Time: 4.20681
Timestep Consumption Time: 0.96538
PPO Batch Consumption Time: 0.06851
Total Iteration Time: 5.17219

Cumulative Model Updates: 7881
Cumulative Timesteps: 131511550

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05024
Policy Entropy: 1.24677
Value Function Loss: 0.05571

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04815
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.06488

Collected Steps per Second: 11203.88295
Overall Steps per Second: 8920.19311

Timestep Collection Time: 4.46345
Timestep Consumption Time: 1.14270
PPO Batch Consumption Time: 0.11543
Total Iteration Time: 5.60616

Cumulative Model Updates: 7884
Cumulative Timesteps: 131561558

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 131561558...
Checkpoint 131561558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08440
Policy Entropy: 1.22938
Value Function Loss: 0.06524

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08773
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.06963

Collected Steps per Second: 12188.67576
Overall Steps per Second: 9790.01971

Timestep Collection Time: 4.10430
Timestep Consumption Time: 1.00560
PPO Batch Consumption Time: 0.06951
Total Iteration Time: 5.10990

Cumulative Model Updates: 7887
Cumulative Timesteps: 131611584

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04499
Policy Entropy: 1.22754
Value Function Loss: 0.05511

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07883
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.07162

Collected Steps per Second: 11381.16710
Overall Steps per Second: 8803.78798

Timestep Collection Time: 4.39551
Timestep Consumption Time: 1.28682
PPO Batch Consumption Time: 0.12654
Total Iteration Time: 5.68233

Cumulative Model Updates: 7890
Cumulative Timesteps: 131661610

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 131661610...
Checkpoint 131661610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03315
Policy Entropy: 1.22737
Value Function Loss: 0.05304

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07245
Policy Update Magnitude: 0.05401
Value Function Update Magnitude: 0.06469

Collected Steps per Second: 11746.71363
Overall Steps per Second: 9684.00759

Timestep Collection Time: 4.26009
Timestep Consumption Time: 0.90740
PPO Batch Consumption Time: 0.06637
Total Iteration Time: 5.16749

Cumulative Model Updates: 7893
Cumulative Timesteps: 131711652

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06076
Policy Entropy: 1.22196
Value Function Loss: 0.04002

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07773
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.06893

Collected Steps per Second: 11059.31390
Overall Steps per Second: 8946.76561

Timestep Collection Time: 4.52524
Timestep Consumption Time: 1.06852
PPO Batch Consumption Time: 0.10633
Total Iteration Time: 5.59375

Cumulative Model Updates: 7896
Cumulative Timesteps: 131761698

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 131761698...
Checkpoint 131761698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12666
Policy Entropy: 1.22316
Value Function Loss: 0.04936

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.05566
Value Function Update Magnitude: 0.06560

Collected Steps per Second: 13282.35471
Overall Steps per Second: 10702.85672

Timestep Collection Time: 3.76710
Timestep Consumption Time: 0.90791
PPO Batch Consumption Time: 0.06398
Total Iteration Time: 4.67501

Cumulative Model Updates: 7899
Cumulative Timesteps: 131811734

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03829
Policy Entropy: 1.22605
Value Function Loss: 0.04946

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.05804
Value Function Update Magnitude: 0.06789

Collected Steps per Second: 12861.57394
Overall Steps per Second: 10182.68177

Timestep Collection Time: 3.88755
Timestep Consumption Time: 1.02275
PPO Batch Consumption Time: 0.09119
Total Iteration Time: 4.91030

Cumulative Model Updates: 7902
Cumulative Timesteps: 131861734

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 131861734...
Checkpoint 131861734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07437
Policy Entropy: 1.22876
Value Function Loss: 0.07491

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.07723

Collected Steps per Second: 13493.99875
Overall Steps per Second: 10861.53369

Timestep Collection Time: 3.70757
Timestep Consumption Time: 0.89859
PPO Batch Consumption Time: 0.06060
Total Iteration Time: 4.60616

Cumulative Model Updates: 7905
Cumulative Timesteps: 131911764

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12086
Policy Entropy: 1.22423
Value Function Loss: 0.06403

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.06591
Value Function Update Magnitude: 0.07871

Collected Steps per Second: 12357.72711
Overall Steps per Second: 9705.29471

Timestep Collection Time: 4.05042
Timestep Consumption Time: 1.10697
PPO Batch Consumption Time: 0.12765
Total Iteration Time: 5.15739

Cumulative Model Updates: 7908
Cumulative Timesteps: 131961818

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 131961818...
Checkpoint 131961818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06998
Policy Entropy: 1.22052
Value Function Loss: 0.06861

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.07543

Collected Steps per Second: 13407.78165
Overall Steps per Second: 10439.71028

Timestep Collection Time: 3.73052
Timestep Consumption Time: 1.06061
PPO Batch Consumption Time: 0.10750
Total Iteration Time: 4.79113

Cumulative Model Updates: 7911
Cumulative Timesteps: 132011836

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07266
Policy Entropy: 1.22714
Value Function Loss: 0.05006

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.07175

Collected Steps per Second: 13662.07910
Overall Steps per Second: 10449.62018

Timestep Collection Time: 3.66006
Timestep Consumption Time: 1.12519
PPO Batch Consumption Time: 0.12557
Total Iteration Time: 4.78525

Cumulative Model Updates: 7914
Cumulative Timesteps: 132061840

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 132061840...
Checkpoint 132061840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09883
Policy Entropy: 1.22337
Value Function Loss: 0.05446

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.05617
Value Function Update Magnitude: 0.07041

Collected Steps per Second: 13430.38931
Overall Steps per Second: 10849.49818

Timestep Collection Time: 3.72305
Timestep Consumption Time: 0.88564
PPO Batch Consumption Time: 0.08142
Total Iteration Time: 4.60869

Cumulative Model Updates: 7917
Cumulative Timesteps: 132111842

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00871
Policy Entropy: 1.22735
Value Function Loss: 0.04747

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07483
Policy Update Magnitude: 0.05390
Value Function Update Magnitude: 0.07207

Collected Steps per Second: 13452.35154
Overall Steps per Second: 10855.84060

Timestep Collection Time: 3.71890
Timestep Consumption Time: 0.88949
PPO Batch Consumption Time: 0.06131
Total Iteration Time: 4.60839

Cumulative Model Updates: 7920
Cumulative Timesteps: 132161870

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 132161870...
Checkpoint 132161870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05140
Policy Entropy: 1.23107
Value Function Loss: 0.05507

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07331
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.07747

Collected Steps per Second: 12253.87371
Overall Steps per Second: 9664.62714

Timestep Collection Time: 4.08100
Timestep Consumption Time: 1.09334
PPO Batch Consumption Time: 0.10133
Total Iteration Time: 5.17433

Cumulative Model Updates: 7923
Cumulative Timesteps: 132211878

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10792
Policy Entropy: 1.23617
Value Function Loss: 0.05062

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06214
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.08053

Collected Steps per Second: 11273.57094
Overall Steps per Second: 8937.40052

Timestep Collection Time: 4.43764
Timestep Consumption Time: 1.15997
PPO Batch Consumption Time: 0.07383
Total Iteration Time: 5.59760

Cumulative Model Updates: 7926
Cumulative Timesteps: 132261906

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 132261906...
Checkpoint 132261906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00014
Policy Entropy: 1.22386
Value Function Loss: 0.05326

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.06277
Value Function Update Magnitude: 0.08928

Collected Steps per Second: 11689.60319
Overall Steps per Second: 9459.10579

Timestep Collection Time: 4.27936
Timestep Consumption Time: 1.00909
PPO Batch Consumption Time: 0.08174
Total Iteration Time: 5.28845

Cumulative Model Updates: 7929
Cumulative Timesteps: 132311930

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00809
Policy Entropy: 1.22005
Value Function Loss: 0.04323

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.05827
Value Function Update Magnitude: 0.07452

Collected Steps per Second: 11125.12666
Overall Steps per Second: 9155.78405

Timestep Collection Time: 4.49775
Timestep Consumption Time: 0.96743
PPO Batch Consumption Time: 0.08290
Total Iteration Time: 5.46518

Cumulative Model Updates: 7932
Cumulative Timesteps: 132361968

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 132361968...
Checkpoint 132361968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09080
Policy Entropy: 1.23359
Value Function Loss: 0.05411

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10247
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.07638

Collected Steps per Second: 12010.29211
Overall Steps per Second: 9685.01875

Timestep Collection Time: 4.16526
Timestep Consumption Time: 1.00004
PPO Batch Consumption Time: 0.07040
Total Iteration Time: 5.16530

Cumulative Model Updates: 7935
Cumulative Timesteps: 132411994

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06748
Policy Entropy: 1.23502
Value Function Loss: 0.05585

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.09027

Collected Steps per Second: 10680.44701
Overall Steps per Second: 8609.46110

Timestep Collection Time: 4.68351
Timestep Consumption Time: 1.12661
PPO Batch Consumption Time: 0.11372
Total Iteration Time: 5.81012

Cumulative Model Updates: 7938
Cumulative Timesteps: 132462016

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 132462016...
Checkpoint 132462016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00127
Policy Entropy: 1.21737
Value Function Loss: 0.05540

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.08601

Collected Steps per Second: 12027.47565
Overall Steps per Second: 9678.12550

Timestep Collection Time: 4.15981
Timestep Consumption Time: 1.00979
PPO Batch Consumption Time: 0.06964
Total Iteration Time: 5.16960

Cumulative Model Updates: 7941
Cumulative Timesteps: 132512048

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08144
Policy Entropy: 1.21093
Value Function Loss: 0.04083

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10081
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.07751

Collected Steps per Second: 10292.18325
Overall Steps per Second: 8330.06889

Timestep Collection Time: 4.86116
Timestep Consumption Time: 1.14503
PPO Batch Consumption Time: 0.10660
Total Iteration Time: 6.00619

Cumulative Model Updates: 7944
Cumulative Timesteps: 132562080

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 132562080...
Checkpoint 132562080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03642
Policy Entropy: 1.21018
Value Function Loss: 0.03727

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.05252
Value Function Update Magnitude: 0.06775

Collected Steps per Second: 11940.05351
Overall Steps per Second: 9732.76013

Timestep Collection Time: 4.18893
Timestep Consumption Time: 0.95001
PPO Batch Consumption Time: 0.07349
Total Iteration Time: 5.13893

Cumulative Model Updates: 7947
Cumulative Timesteps: 132612096

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11812
Policy Entropy: 1.21564
Value Function Loss: 0.04211

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.06290

Collected Steps per Second: 11686.15835
Overall Steps per Second: 9203.54560

Timestep Collection Time: 4.28028
Timestep Consumption Time: 1.15458
PPO Batch Consumption Time: 0.11271
Total Iteration Time: 5.43486

Cumulative Model Updates: 7950
Cumulative Timesteps: 132662116

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 132662116...
Checkpoint 132662116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08618
Policy Entropy: 1.21828
Value Function Loss: 0.04511

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.06534

Collected Steps per Second: 11546.68835
Overall Steps per Second: 9258.83643

Timestep Collection Time: 4.33077
Timestep Consumption Time: 1.07013
PPO Batch Consumption Time: 0.07871
Total Iteration Time: 5.40089

Cumulative Model Updates: 7953
Cumulative Timesteps: 132712122

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16846
Policy Entropy: 1.21889
Value Function Loss: 0.04773

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05765
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.07040

Collected Steps per Second: 12270.32099
Overall Steps per Second: 9643.19761

Timestep Collection Time: 4.07715
Timestep Consumption Time: 1.11075
PPO Batch Consumption Time: 0.09858
Total Iteration Time: 5.18791

Cumulative Model Updates: 7956
Cumulative Timesteps: 132762150

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 132762150...
Checkpoint 132762150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00875
Policy Entropy: 1.21029
Value Function Loss: 0.04327

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 11719.66845
Overall Steps per Second: 9298.55778

Timestep Collection Time: 4.26684
Timestep Consumption Time: 1.11098
PPO Batch Consumption Time: 0.09903
Total Iteration Time: 5.37782

Cumulative Model Updates: 7959
Cumulative Timesteps: 132812156

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01434
Policy Entropy: 1.21216
Value Function Loss: 0.05030

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.06666

Collected Steps per Second: 11320.45551
Overall Steps per Second: 9263.40652

Timestep Collection Time: 4.41714
Timestep Consumption Time: 0.98088
PPO Batch Consumption Time: 0.07937
Total Iteration Time: 5.39801

Cumulative Model Updates: 7962
Cumulative Timesteps: 132862160

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 132862160...
Checkpoint 132862160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09125
Policy Entropy: 1.20680
Value Function Loss: 0.05077

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.06266

Collected Steps per Second: 11498.65720
Overall Steps per Second: 9281.65845

Timestep Collection Time: 4.34868
Timestep Consumption Time: 1.03872
PPO Batch Consumption Time: 0.07147
Total Iteration Time: 5.38740

Cumulative Model Updates: 7965
Cumulative Timesteps: 132912164

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01606
Policy Entropy: 1.21615
Value Function Loss: 0.05809

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05705
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.06234

Collected Steps per Second: 11691.73345
Overall Steps per Second: 9316.22942

Timestep Collection Time: 4.27960
Timestep Consumption Time: 1.09124
PPO Batch Consumption Time: 0.10842
Total Iteration Time: 5.37084

Cumulative Model Updates: 7968
Cumulative Timesteps: 132962200

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 132962200...
Checkpoint 132962200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07499
Policy Entropy: 1.20978
Value Function Loss: 0.05369

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.06345
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.06486

Collected Steps per Second: 12010.30752
Overall Steps per Second: 9720.65305

Timestep Collection Time: 4.16492
Timestep Consumption Time: 0.98103
PPO Batch Consumption Time: 0.06737
Total Iteration Time: 5.14595

Cumulative Model Updates: 7971
Cumulative Timesteps: 133012222

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10594
Policy Entropy: 1.21711
Value Function Loss: 0.06832

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.07288

Collected Steps per Second: 11754.83545
Overall Steps per Second: 9235.93536

Timestep Collection Time: 4.25595
Timestep Consumption Time: 1.16072
PPO Batch Consumption Time: 0.11522
Total Iteration Time: 5.41667

Cumulative Model Updates: 7974
Cumulative Timesteps: 133062250

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 133062250...
Checkpoint 133062250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04624
Policy Entropy: 1.20623
Value Function Loss: 0.07272

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.06765

Collected Steps per Second: 11324.11290
Overall Steps per Second: 9345.56505

Timestep Collection Time: 4.41748
Timestep Consumption Time: 0.93522
PPO Batch Consumption Time: 0.07225
Total Iteration Time: 5.35270

Cumulative Model Updates: 7977
Cumulative Timesteps: 133112274

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01770
Policy Entropy: 1.20154
Value Function Loss: 0.07191

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.06137
Value Function Update Magnitude: 0.06015

Collected Steps per Second: 13195.77517
Overall Steps per Second: 10302.65419

Timestep Collection Time: 3.78939
Timestep Consumption Time: 1.06411
PPO Batch Consumption Time: 0.08015
Total Iteration Time: 4.85351

Cumulative Model Updates: 7980
Cumulative Timesteps: 133162278

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 133162278...
Checkpoint 133162278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00157
Policy Entropy: 1.19323
Value Function Loss: 0.05691

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.17316
Policy Update Magnitude: 0.05858
Value Function Update Magnitude: 0.05788

Collected Steps per Second: 12449.74117
Overall Steps per Second: 10197.20699

Timestep Collection Time: 4.01727
Timestep Consumption Time: 0.88740
PPO Batch Consumption Time: 0.06659
Total Iteration Time: 4.90468

Cumulative Model Updates: 7983
Cumulative Timesteps: 133212292

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17337
Policy Entropy: 1.20171
Value Function Loss: 0.05448

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.06086
Value Function Update Magnitude: 0.05580

Collected Steps per Second: 13486.91572
Overall Steps per Second: 10738.19312

Timestep Collection Time: 3.70937
Timestep Consumption Time: 0.94951
PPO Batch Consumption Time: 0.08177
Total Iteration Time: 4.65888

Cumulative Model Updates: 7986
Cumulative Timesteps: 133262320

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 133262320...
Checkpoint 133262320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.25187
Policy Entropy: 1.21273
Value Function Loss: 0.04941

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.05014

Collected Steps per Second: 12927.78561
Overall Steps per Second: 10461.66105

Timestep Collection Time: 3.86996
Timestep Consumption Time: 0.91226
PPO Batch Consumption Time: 0.06267
Total Iteration Time: 4.78222

Cumulative Model Updates: 7989
Cumulative Timesteps: 133312350

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05121
Policy Entropy: 1.20504
Value Function Loss: 0.06568

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.05395

Collected Steps per Second: 10885.77210
Overall Steps per Second: 8988.95810

Timestep Collection Time: 4.59701
Timestep Consumption Time: 0.97004
PPO Batch Consumption Time: 0.10261
Total Iteration Time: 5.56705

Cumulative Model Updates: 7992
Cumulative Timesteps: 133362392

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 133362392...
Checkpoint 133362392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01165
Policy Entropy: 1.20346
Value Function Loss: 0.05985

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.05899
Value Function Update Magnitude: 0.06442

Collected Steps per Second: 13305.53550
Overall Steps per Second: 10779.37934

Timestep Collection Time: 3.76009
Timestep Consumption Time: 0.88118
PPO Batch Consumption Time: 0.06140
Total Iteration Time: 4.64127

Cumulative Model Updates: 7995
Cumulative Timesteps: 133412422

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00136
Policy Entropy: 1.20937
Value Function Loss: 0.06649

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.05889
Value Function Update Magnitude: 0.06195

Collected Steps per Second: 11905.88980
Overall Steps per Second: 9702.03198

Timestep Collection Time: 4.20011
Timestep Consumption Time: 0.95407
PPO Batch Consumption Time: 0.06746
Total Iteration Time: 5.15418

Cumulative Model Updates: 7998
Cumulative Timesteps: 133462428

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 133462428...
Checkpoint 133462428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00913
Policy Entropy: 1.21320
Value Function Loss: 0.05510

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06612
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.05321

Collected Steps per Second: 12118.89184
Overall Steps per Second: 9672.86501

Timestep Collection Time: 4.12744
Timestep Consumption Time: 1.04373
PPO Batch Consumption Time: 0.10980
Total Iteration Time: 5.17117

Cumulative Model Updates: 8001
Cumulative Timesteps: 133512448

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06112
Policy Entropy: 1.20158
Value Function Loss: 0.05733

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.05287

Collected Steps per Second: 13275.69589
Overall Steps per Second: 10723.67927

Timestep Collection Time: 3.77005
Timestep Consumption Time: 0.89719
PPO Batch Consumption Time: 0.06434
Total Iteration Time: 4.66724

Cumulative Model Updates: 8004
Cumulative Timesteps: 133562498

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 133562498...
Checkpoint 133562498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02421
Policy Entropy: 1.20261
Value Function Loss: 0.05652

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07436
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.04776

Collected Steps per Second: 12118.36458
Overall Steps per Second: 9791.80008

Timestep Collection Time: 4.12679
Timestep Consumption Time: 0.98054
PPO Batch Consumption Time: 0.11026
Total Iteration Time: 5.10733

Cumulative Model Updates: 8007
Cumulative Timesteps: 133612508

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04125
Policy Entropy: 1.20507
Value Function Loss: 0.06301

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06951
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.05100

Collected Steps per Second: 13473.70695
Overall Steps per Second: 10447.78054

Timestep Collection Time: 3.71331
Timestep Consumption Time: 1.07546
PPO Batch Consumption Time: 0.11613
Total Iteration Time: 4.78877

Cumulative Model Updates: 8010
Cumulative Timesteps: 133662540

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 133662540...
Checkpoint 133662540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08892
Policy Entropy: 1.20330
Value Function Loss: 0.05906

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.06569
Value Function Update Magnitude: 0.05707

Collected Steps per Second: 12793.88971
Overall Steps per Second: 10036.19032

Timestep Collection Time: 3.91046
Timestep Consumption Time: 1.07450
PPO Batch Consumption Time: 0.11685
Total Iteration Time: 4.98496

Cumulative Model Updates: 8013
Cumulative Timesteps: 133712570

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06212
Policy Entropy: 1.19816
Value Function Loss: 0.05592

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.06460
Value Function Update Magnitude: 0.06583

Collected Steps per Second: 13191.24137
Overall Steps per Second: 10696.86696

Timestep Collection Time: 3.79403
Timestep Consumption Time: 0.88472
PPO Batch Consumption Time: 0.06516
Total Iteration Time: 4.67875

Cumulative Model Updates: 8016
Cumulative Timesteps: 133762618

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 133762618...
Checkpoint 133762618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12654
Policy Entropy: 1.20220
Value Function Loss: 0.04876

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.06023
Value Function Update Magnitude: 0.07406

Collected Steps per Second: 11967.32021
Overall Steps per Second: 9770.13751

Timestep Collection Time: 4.17988
Timestep Consumption Time: 0.94000
PPO Batch Consumption Time: 0.06615
Total Iteration Time: 5.11989

Cumulative Model Updates: 8019
Cumulative Timesteps: 133812640

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00780
Policy Entropy: 1.21181
Value Function Loss: 0.04552

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.06011
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 12554.14014
Overall Steps per Second: 10433.05761

Timestep Collection Time: 3.98562
Timestep Consumption Time: 0.81029
PPO Batch Consumption Time: 0.06338
Total Iteration Time: 4.79591

Cumulative Model Updates: 8022
Cumulative Timesteps: 133862676

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 133862676...
Checkpoint 133862676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07939
Policy Entropy: 1.20078
Value Function Loss: 0.05225

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.05548
Value Function Update Magnitude: 0.06050

Collected Steps per Second: 11159.49186
Overall Steps per Second: 8991.49671

Timestep Collection Time: 4.48121
Timestep Consumption Time: 1.08049
PPO Batch Consumption Time: 0.11760
Total Iteration Time: 5.56170

Cumulative Model Updates: 8025
Cumulative Timesteps: 133912684

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10041
Policy Entropy: 1.19783
Value Function Loss: 0.04742

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.05315

Collected Steps per Second: 13521.57008
Overall Steps per Second: 10436.30045

Timestep Collection Time: 3.70090
Timestep Consumption Time: 1.09409
PPO Batch Consumption Time: 0.12203
Total Iteration Time: 4.79499

Cumulative Model Updates: 8028
Cumulative Timesteps: 133962726

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 133962726...
Checkpoint 133962726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07796
Policy Entropy: 1.20592
Value Function Loss: 0.05393

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05921
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.05366

Collected Steps per Second: 13181.71429
Overall Steps per Second: 10463.71172

Timestep Collection Time: 3.79495
Timestep Consumption Time: 0.98576
PPO Batch Consumption Time: 0.11717
Total Iteration Time: 4.78071

Cumulative Model Updates: 8031
Cumulative Timesteps: 134012750

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06695
Policy Entropy: 1.22044
Value Function Loss: 0.04809

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.05650
Value Function Update Magnitude: 0.05651

Collected Steps per Second: 13386.83976
Overall Steps per Second: 10406.87235

Timestep Collection Time: 3.73516
Timestep Consumption Time: 1.06955
PPO Batch Consumption Time: 0.11399
Total Iteration Time: 4.80471

Cumulative Model Updates: 8034
Cumulative Timesteps: 134062752

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 134062752...
Checkpoint 134062752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15567
Policy Entropy: 1.19988
Value Function Loss: 0.05889

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.05648

Collected Steps per Second: 13200.60971
Overall Steps per Second: 10436.15139

Timestep Collection Time: 3.78770
Timestep Consumption Time: 1.00333
PPO Batch Consumption Time: 0.09718
Total Iteration Time: 4.79104

Cumulative Model Updates: 8037
Cumulative Timesteps: 134112752

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14190
Policy Entropy: 1.20725
Value Function Loss: 0.05962

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.05167
Value Function Update Magnitude: 0.06132

Collected Steps per Second: 11902.18306
Overall Steps per Second: 9270.69249

Timestep Collection Time: 4.20427
Timestep Consumption Time: 1.19338
PPO Batch Consumption Time: 0.09169
Total Iteration Time: 5.39766

Cumulative Model Updates: 8040
Cumulative Timesteps: 134162792

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 134162792...
Checkpoint 134162792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06838
Policy Entropy: 1.22694
Value Function Loss: 0.06652

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.05512
Value Function Update Magnitude: 0.05912

Collected Steps per Second: 11435.20233
Overall Steps per Second: 8994.45222

Timestep Collection Time: 4.37421
Timestep Consumption Time: 1.18699
PPO Batch Consumption Time: 0.10042
Total Iteration Time: 5.56121

Cumulative Model Updates: 8043
Cumulative Timesteps: 134212812

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16211
Policy Entropy: 1.21144
Value Function Loss: 0.06462

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.05964

Collected Steps per Second: 11699.16786
Overall Steps per Second: 9658.09243

Timestep Collection Time: 4.27689
Timestep Consumption Time: 0.90385
PPO Batch Consumption Time: 0.06890
Total Iteration Time: 5.18073

Cumulative Model Updates: 8046
Cumulative Timesteps: 134262848

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 134262848...
Checkpoint 134262848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20340
Policy Entropy: 1.21955
Value Function Loss: 0.05618

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.05316
Value Function Update Magnitude: 0.05479

Collected Steps per Second: 10785.66425
Overall Steps per Second: 8632.49423

Timestep Collection Time: 4.63708
Timestep Consumption Time: 1.15661
PPO Batch Consumption Time: 0.10207
Total Iteration Time: 5.79369

Cumulative Model Updates: 8049
Cumulative Timesteps: 134312862

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00212
Policy Entropy: 1.23450
Value Function Loss: 0.05267

Mean KL Divergence: 0.01993
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.05230
Value Function Update Magnitude: 0.05485

Collected Steps per Second: 11781.07885
Overall Steps per Second: 9596.33233

Timestep Collection Time: 4.24613
Timestep Consumption Time: 0.96669
PPO Batch Consumption Time: 0.06672
Total Iteration Time: 5.21282

Cumulative Model Updates: 8052
Cumulative Timesteps: 134362886

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 134362886...
Checkpoint 134362886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00292
Policy Entropy: 1.22890
Value Function Loss: 0.05211

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.05511
Value Function Update Magnitude: 0.05321

Collected Steps per Second: 10769.54404
Overall Steps per Second: 8641.90327

Timestep Collection Time: 4.64662
Timestep Consumption Time: 1.14400
PPO Batch Consumption Time: 0.09384
Total Iteration Time: 5.79062

Cumulative Model Updates: 8055
Cumulative Timesteps: 134412928

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06332
Policy Entropy: 1.23108
Value Function Loss: 0.04833

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.05149

Collected Steps per Second: 11968.84989
Overall Steps per Second: 9582.67679

Timestep Collection Time: 4.18002
Timestep Consumption Time: 1.04086
PPO Batch Consumption Time: 0.07451
Total Iteration Time: 5.22088

Cumulative Model Updates: 8058
Cumulative Timesteps: 134462958

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 134462958...
Checkpoint 134462958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05842
Policy Entropy: 1.22988
Value Function Loss: 0.03932

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.05352
Value Function Update Magnitude: 0.05214

Collected Steps per Second: 11530.61421
Overall Steps per Second: 9380.37962

Timestep Collection Time: 4.34010
Timestep Consumption Time: 0.99487
PPO Batch Consumption Time: 0.10444
Total Iteration Time: 5.33497

Cumulative Model Updates: 8061
Cumulative Timesteps: 134513002

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10280
Policy Entropy: 1.23051
Value Function Loss: 0.03327

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.05711

Collected Steps per Second: 11913.40182
Overall Steps per Second: 9593.11903

Timestep Collection Time: 4.20031
Timestep Consumption Time: 1.01593
PPO Batch Consumption Time: 0.06558
Total Iteration Time: 5.21624

Cumulative Model Updates: 8064
Cumulative Timesteps: 134563042

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 134563042...
Checkpoint 134563042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14502
Policy Entropy: 1.23093
Value Function Loss: 0.03473

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07047
Policy Update Magnitude: 0.05198
Value Function Update Magnitude: 0.06001

Collected Steps per Second: 10506.41717
Overall Steps per Second: 8394.07659

Timestep Collection Time: 4.76014
Timestep Consumption Time: 1.19787
PPO Batch Consumption Time: 0.11764
Total Iteration Time: 5.95801

Cumulative Model Updates: 8067
Cumulative Timesteps: 134613054

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06710
Policy Entropy: 1.23992
Value Function Loss: 0.04980

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.05349
Value Function Update Magnitude: 0.05749

Collected Steps per Second: 12254.58042
Overall Steps per Second: 9800.41893

Timestep Collection Time: 4.08027
Timestep Consumption Time: 1.02176
PPO Batch Consumption Time: 0.07392
Total Iteration Time: 5.10203

Cumulative Model Updates: 8070
Cumulative Timesteps: 134663056

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 134663056...
Checkpoint 134663056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11067
Policy Entropy: 1.23877
Value Function Loss: 0.06929

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.06491

Collected Steps per Second: 10931.91865
Overall Steps per Second: 8782.65974

Timestep Collection Time: 4.57577
Timestep Consumption Time: 1.11977
PPO Batch Consumption Time: 0.09180
Total Iteration Time: 5.69554

Cumulative Model Updates: 8073
Cumulative Timesteps: 134713078

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09823
Policy Entropy: 1.22957
Value Function Loss: 0.06892

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07518
Policy Update Magnitude: 0.05854
Value Function Update Magnitude: 0.07444

Collected Steps per Second: 11671.44069
Overall Steps per Second: 9432.25612

Timestep Collection Time: 4.28636
Timestep Consumption Time: 1.01757
PPO Batch Consumption Time: 0.07484
Total Iteration Time: 5.30393

Cumulative Model Updates: 8076
Cumulative Timesteps: 134763106

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 134763106...
Checkpoint 134763106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10204
Policy Entropy: 1.22536
Value Function Loss: 0.05691

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.07494

Collected Steps per Second: 11369.29639
Overall Steps per Second: 9105.23420

Timestep Collection Time: 4.40010
Timestep Consumption Time: 1.09411
PPO Batch Consumption Time: 0.07623
Total Iteration Time: 5.49420

Cumulative Model Updates: 8079
Cumulative Timesteps: 134813132

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10294
Policy Entropy: 1.22649
Value Function Loss: 0.04723

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.07337

Collected Steps per Second: 11590.07575
Overall Steps per Second: 9399.03144

Timestep Collection Time: 4.31662
Timestep Consumption Time: 1.00626
PPO Batch Consumption Time: 0.07708
Total Iteration Time: 5.32289

Cumulative Model Updates: 8082
Cumulative Timesteps: 134863162

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 134863162...
Checkpoint 134863162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05600
Policy Entropy: 1.23150
Value Function Loss: 0.05014

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06743
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.06838

Collected Steps per Second: 11315.97473
Overall Steps per Second: 9205.35270

Timestep Collection Time: 4.42136
Timestep Consumption Time: 1.01374
PPO Batch Consumption Time: 0.08842
Total Iteration Time: 5.43510

Cumulative Model Updates: 8085
Cumulative Timesteps: 134913194

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02543
Policy Entropy: 1.23028
Value Function Loss: 0.05991

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05374
Policy Update Magnitude: 0.05256
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 12048.19057
Overall Steps per Second: 9733.45862

Timestep Collection Time: 4.15116
Timestep Consumption Time: 0.98720
PPO Batch Consumption Time: 0.06960
Total Iteration Time: 5.13836

Cumulative Model Updates: 8088
Cumulative Timesteps: 134963208

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 134963208...
Checkpoint 134963208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18790
Policy Entropy: 1.22554
Value Function Loss: 0.05628

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07231
Policy Update Magnitude: 0.05412
Value Function Update Magnitude: 0.07193

Collected Steps per Second: 11838.10761
Overall Steps per Second: 9559.62811

Timestep Collection Time: 4.22804
Timestep Consumption Time: 1.00773
PPO Batch Consumption Time: 0.07497
Total Iteration Time: 5.23577

Cumulative Model Updates: 8091
Cumulative Timesteps: 135013260

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01165
Policy Entropy: 1.22243
Value Function Loss: 0.06022

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06386
Policy Update Magnitude: 0.05332
Value Function Update Magnitude: 0.06961

Collected Steps per Second: 13481.77352
Overall Steps per Second: 10563.24623

Timestep Collection Time: 3.71108
Timestep Consumption Time: 1.02534
PPO Batch Consumption Time: 0.06684
Total Iteration Time: 4.73642

Cumulative Model Updates: 8094
Cumulative Timesteps: 135063292

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 135063292...
Checkpoint 135063292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01479
Policy Entropy: 1.23396
Value Function Loss: 0.07031

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06639
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.07190

Collected Steps per Second: 12610.96521
Overall Steps per Second: 9937.78596

Timestep Collection Time: 3.96845
Timestep Consumption Time: 1.06748
PPO Batch Consumption Time: 0.10366
Total Iteration Time: 5.03593

Cumulative Model Updates: 8097
Cumulative Timesteps: 135113338

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05298
Policy Entropy: 1.23753
Value Function Loss: 0.07276

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05124
Policy Update Magnitude: 0.05738
Value Function Update Magnitude: 0.07510

Collected Steps per Second: 13446.23845
Overall Steps per Second: 10888.00994

Timestep Collection Time: 3.72164
Timestep Consumption Time: 0.87443
PPO Batch Consumption Time: 0.07479
Total Iteration Time: 4.59606

Cumulative Model Updates: 8100
Cumulative Timesteps: 135163380

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 135163380...
Checkpoint 135163380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05875
Policy Entropy: 1.23489
Value Function Loss: 0.06350

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07284
Policy Update Magnitude: 0.05558
Value Function Update Magnitude: 0.07631

Collected Steps per Second: 13059.07669
Overall Steps per Second: 10509.31442

Timestep Collection Time: 3.82952
Timestep Consumption Time: 0.92912
PPO Batch Consumption Time: 0.06009
Total Iteration Time: 4.75864

Cumulative Model Updates: 8103
Cumulative Timesteps: 135213390

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13327
Policy Entropy: 1.23696
Value Function Loss: 0.05704

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07584
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.07930

Collected Steps per Second: 12175.46112
Overall Steps per Second: 9626.94982

Timestep Collection Time: 4.10711
Timestep Consumption Time: 1.08726
PPO Batch Consumption Time: 0.12472
Total Iteration Time: 5.19438

Cumulative Model Updates: 8106
Cumulative Timesteps: 135263396

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 135263396...
Checkpoint 135263396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11347
Policy Entropy: 1.23471
Value Function Loss: 0.05288

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.04863
Policy Update Magnitude: 0.06027
Value Function Update Magnitude: 0.08470

Collected Steps per Second: 13480.90744
Overall Steps per Second: 10869.00600

Timestep Collection Time: 3.71236
Timestep Consumption Time: 0.89211
PPO Batch Consumption Time: 0.05977
Total Iteration Time: 4.60447

Cumulative Model Updates: 8109
Cumulative Timesteps: 135313442

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04923
Policy Entropy: 1.23594
Value Function Loss: 0.05458

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.05964
Value Function Update Magnitude: 0.08392

Collected Steps per Second: 11986.47409
Overall Steps per Second: 9644.04936

Timestep Collection Time: 4.17420
Timestep Consumption Time: 1.01386
PPO Batch Consumption Time: 0.09390
Total Iteration Time: 5.18807

Cumulative Model Updates: 8112
Cumulative Timesteps: 135363476

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 135363476...
Checkpoint 135363476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01631
Policy Entropy: 1.23003
Value Function Loss: 0.05208

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.05694
Value Function Update Magnitude: 0.07971

Collected Steps per Second: 13233.89690
Overall Steps per Second: 10908.33574

Timestep Collection Time: 3.77893
Timestep Consumption Time: 0.80564
PPO Batch Consumption Time: 0.05814
Total Iteration Time: 4.58457

Cumulative Model Updates: 8115
Cumulative Timesteps: 135413486

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11754
Policy Entropy: 1.23154
Value Function Loss: 0.05159

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.05161
Value Function Update Magnitude: 0.08340

Collected Steps per Second: 12262.92688
Overall Steps per Second: 9667.66313

Timestep Collection Time: 4.07994
Timestep Consumption Time: 1.09525
PPO Batch Consumption Time: 0.12034
Total Iteration Time: 5.17519

Cumulative Model Updates: 8118
Cumulative Timesteps: 135463518

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 135463518...
Checkpoint 135463518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02140
Policy Entropy: 1.23385
Value Function Loss: 0.04449

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06982
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.08110

Collected Steps per Second: 12432.13853
Overall Steps per Second: 9997.77658

Timestep Collection Time: 4.02280
Timestep Consumption Time: 0.97951
PPO Batch Consumption Time: 0.07756
Total Iteration Time: 5.00231

Cumulative Model Updates: 8121
Cumulative Timesteps: 135513530

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09557
Policy Entropy: 1.23287
Value Function Loss: 0.04309

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.07094

Collected Steps per Second: 12764.90977
Overall Steps per Second: 10515.90009

Timestep Collection Time: 3.91746
Timestep Consumption Time: 0.83782
PPO Batch Consumption Time: 0.06250
Total Iteration Time: 4.75528

Cumulative Model Updates: 8124
Cumulative Timesteps: 135563536

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 135563536...
Checkpoint 135563536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22354
Policy Entropy: 1.23704
Value Function Loss: 0.04477

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.05007
Value Function Update Magnitude: 0.07433

Collected Steps per Second: 12474.34920
Overall Steps per Second: 9950.18377

Timestep Collection Time: 4.00887
Timestep Consumption Time: 1.01697
PPO Batch Consumption Time: 0.09422
Total Iteration Time: 5.02584

Cumulative Model Updates: 8127
Cumulative Timesteps: 135613544

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06129
Policy Entropy: 1.24133
Value Function Loss: 0.06073

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.07534

Collected Steps per Second: 13163.37422
Overall Steps per Second: 10704.56975

Timestep Collection Time: 3.80206
Timestep Consumption Time: 0.87332
PPO Batch Consumption Time: 0.06379
Total Iteration Time: 4.67539

Cumulative Model Updates: 8130
Cumulative Timesteps: 135663592

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 135663592...
Checkpoint 135663592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07591
Policy Entropy: 1.23926
Value Function Loss: 0.06498

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.05777
Value Function Update Magnitude: 0.07721

Collected Steps per Second: 12427.09896
Overall Steps per Second: 9836.44359

Timestep Collection Time: 4.02475
Timestep Consumption Time: 1.06001
PPO Batch Consumption Time: 0.09963
Total Iteration Time: 5.08476

Cumulative Model Updates: 8133
Cumulative Timesteps: 135713608

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14583
Policy Entropy: 1.24567
Value Function Loss: 0.06313

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.06038
Value Function Update Magnitude: 0.07194

Collected Steps per Second: 13409.50799
Overall Steps per Second: 10447.84381

Timestep Collection Time: 3.73064
Timestep Consumption Time: 1.05753
PPO Batch Consumption Time: 0.10262
Total Iteration Time: 4.78816

Cumulative Model Updates: 8136
Cumulative Timesteps: 135763634

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 135763634...
Checkpoint 135763634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07323
Policy Entropy: 1.23532
Value Function Loss: 0.05644

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.06790

Collected Steps per Second: 12999.93322
Overall Steps per Second: 10428.58070

Timestep Collection Time: 3.84725
Timestep Consumption Time: 0.94861
PPO Batch Consumption Time: 0.10284
Total Iteration Time: 4.79586

Cumulative Model Updates: 8139
Cumulative Timesteps: 135813648

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03608
Policy Entropy: 1.23659
Value Function Loss: 0.05405

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 12175.74260
Overall Steps per Second: 9661.34446

Timestep Collection Time: 4.10965
Timestep Consumption Time: 1.06955
PPO Batch Consumption Time: 0.11689
Total Iteration Time: 5.17920

Cumulative Model Updates: 8142
Cumulative Timesteps: 135863686

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 135863686...
Checkpoint 135863686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10237
Policy Entropy: 1.24178
Value Function Loss: 0.04750

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08102
Policy Update Magnitude: 0.05702
Value Function Update Magnitude: 0.07095

Collected Steps per Second: 13207.41905
Overall Steps per Second: 10718.78096

Timestep Collection Time: 3.78757
Timestep Consumption Time: 0.87938
PPO Batch Consumption Time: 0.06480
Total Iteration Time: 4.66695

Cumulative Model Updates: 8145
Cumulative Timesteps: 135913710

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05476
Policy Entropy: 1.24720
Value Function Loss: 0.05078

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.06804

Collected Steps per Second: 12230.22746
Overall Steps per Second: 9745.20201

Timestep Collection Time: 4.09003
Timestep Consumption Time: 1.04296
PPO Batch Consumption Time: 0.10125
Total Iteration Time: 5.13299

Cumulative Model Updates: 8148
Cumulative Timesteps: 135963732

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 135963732...
Checkpoint 135963732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01102
Policy Entropy: 1.24007
Value Function Loss: 0.05231

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.05510
Value Function Update Magnitude: 0.07455

Collected Steps per Second: 13168.57151
Overall Steps per Second: 10452.85634

Timestep Collection Time: 3.79996
Timestep Consumption Time: 0.98725
PPO Batch Consumption Time: 0.08299
Total Iteration Time: 4.78721

Cumulative Model Updates: 8151
Cumulative Timesteps: 136013772

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09123
Policy Entropy: 1.23599
Value Function Loss: 0.05812

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 12658.24180
Overall Steps per Second: 10068.99079

Timestep Collection Time: 3.95047
Timestep Consumption Time: 1.01587
PPO Batch Consumption Time: 0.12485
Total Iteration Time: 4.96634

Cumulative Model Updates: 8154
Cumulative Timesteps: 136063778

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 136063778...
Checkpoint 136063778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07796
Policy Entropy: 1.22944
Value Function Loss: 0.06151

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.05342
Value Function Update Magnitude: 0.07875

Collected Steps per Second: 12944.40579
Overall Steps per Second: 10463.62136

Timestep Collection Time: 3.86283
Timestep Consumption Time: 0.91582
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 4.77865

Cumulative Model Updates: 8157
Cumulative Timesteps: 136113780

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06376
Policy Entropy: 1.22966
Value Function Loss: 0.05981

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.07795

Collected Steps per Second: 11634.66112
Overall Steps per Second: 9256.94955

Timestep Collection Time: 4.29974
Timestep Consumption Time: 1.10442
PPO Batch Consumption Time: 0.10083
Total Iteration Time: 5.40416

Cumulative Model Updates: 8160
Cumulative Timesteps: 136163806

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 136163806...
Checkpoint 136163806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04801
Policy Entropy: 1.23201
Value Function Loss: 0.07307

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08881
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.07931

Collected Steps per Second: 13637.94114
Overall Steps per Second: 10979.03145

Timestep Collection Time: 3.67006
Timestep Consumption Time: 0.88882
PPO Batch Consumption Time: 0.06193
Total Iteration Time: 4.55887

Cumulative Model Updates: 8163
Cumulative Timesteps: 136213858

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01504
Policy Entropy: 1.23996
Value Function Loss: 0.05830

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.07863

Collected Steps per Second: 11983.45061
Overall Steps per Second: 9562.95665

Timestep Collection Time: 4.17543
Timestep Consumption Time: 1.05685
PPO Batch Consumption Time: 0.09974
Total Iteration Time: 5.23227

Cumulative Model Updates: 8166
Cumulative Timesteps: 136263894

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 136263894...
Checkpoint 136263894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19175
Policy Entropy: 1.23710
Value Function Loss: 0.04528

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.07677

Collected Steps per Second: 12118.26440
Overall Steps per Second: 9845.91516

Timestep Collection Time: 4.13013
Timestep Consumption Time: 0.95320
PPO Batch Consumption Time: 0.06703
Total Iteration Time: 5.08333

Cumulative Model Updates: 8169
Cumulative Timesteps: 136313944

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15829
Policy Entropy: 1.23403
Value Function Loss: 0.03903

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.05574
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 13170.79683
Overall Steps per Second: 10263.23169

Timestep Collection Time: 3.79780
Timestep Consumption Time: 1.07591
PPO Batch Consumption Time: 0.11442
Total Iteration Time: 4.87371

Cumulative Model Updates: 8172
Cumulative Timesteps: 136363964

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 136363964...
Checkpoint 136363964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02751
Policy Entropy: 1.24314
Value Function Loss: 0.04583

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.08598

Collected Steps per Second: 13330.78460
Overall Steps per Second: 10721.36935

Timestep Collection Time: 3.75147
Timestep Consumption Time: 0.91305
PPO Batch Consumption Time: 0.06376
Total Iteration Time: 4.66452

Cumulative Model Updates: 8175
Cumulative Timesteps: 136413974

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03069
Policy Entropy: 1.23624
Value Function Loss: 0.06878

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07117
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.08390

Collected Steps per Second: 11987.86605
Overall Steps per Second: 9747.87867

Timestep Collection Time: 4.17155
Timestep Consumption Time: 0.95859
PPO Batch Consumption Time: 0.09694
Total Iteration Time: 5.13014

Cumulative Model Updates: 8178
Cumulative Timesteps: 136463982

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 136463982...
Checkpoint 136463982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10309
Policy Entropy: 1.24344
Value Function Loss: 0.06457

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06383
Policy Update Magnitude: 0.05906
Value Function Update Magnitude: 0.07960

Collected Steps per Second: 12435.24821
Overall Steps per Second: 9997.77489

Timestep Collection Time: 4.02372
Timestep Consumption Time: 0.98099
PPO Batch Consumption Time: 0.06988
Total Iteration Time: 5.00471

Cumulative Model Updates: 8181
Cumulative Timesteps: 136514018

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01758
Policy Entropy: 1.23974
Value Function Loss: 0.06922

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.05716
Value Function Update Magnitude: 0.08299

Collected Steps per Second: 11922.99460
Overall Steps per Second: 9650.44550

Timestep Collection Time: 4.19643
Timestep Consumption Time: 0.98820
PPO Batch Consumption Time: 0.06571
Total Iteration Time: 5.18463

Cumulative Model Updates: 8184
Cumulative Timesteps: 136564052

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 136564052...
Checkpoint 136564052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04569
Policy Entropy: 1.24157
Value Function Loss: 0.06218

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.08073

Collected Steps per Second: 13673.69737
Overall Steps per Second: 11038.64886

Timestep Collection Time: 3.66002
Timestep Consumption Time: 0.87369
PPO Batch Consumption Time: 0.05924
Total Iteration Time: 4.53371

Cumulative Model Updates: 8187
Cumulative Timesteps: 136614098

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02402
Policy Entropy: 1.24119
Value Function Loss: 0.07795

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06195
Policy Update Magnitude: 0.05840
Value Function Update Magnitude: 0.08402

Collected Steps per Second: 12783.41150
Overall Steps per Second: 9971.22866

Timestep Collection Time: 3.91226
Timestep Consumption Time: 1.10337
PPO Batch Consumption Time: 0.12249
Total Iteration Time: 5.01563

Cumulative Model Updates: 8190
Cumulative Timesteps: 136664110

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 136664110...
Checkpoint 136664110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05840
Policy Entropy: 1.23642
Value Function Loss: 0.07452

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06644
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.09082

Collected Steps per Second: 12368.80231
Overall Steps per Second: 9905.91002

Timestep Collection Time: 4.04405
Timestep Consumption Time: 1.00547
PPO Batch Consumption Time: 0.06832
Total Iteration Time: 5.04951

Cumulative Model Updates: 8193
Cumulative Timesteps: 136714130

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01568
Policy Entropy: 1.23608
Value Function Loss: 0.06467

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.08906

Collected Steps per Second: 10212.58739
Overall Steps per Second: 8525.24707

Timestep Collection Time: 4.89729
Timestep Consumption Time: 0.96929
PPO Batch Consumption Time: 0.02901
Total Iteration Time: 5.86657

Cumulative Model Updates: 8196
Cumulative Timesteps: 136764144

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 136764144...
Checkpoint 136764144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03238
Policy Entropy: 1.23916
Value Function Loss: 0.05726

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.05805
Value Function Update Magnitude: 0.08232

Collected Steps per Second: 11982.03861
Overall Steps per Second: 9508.32577

Timestep Collection Time: 4.17291
Timestep Consumption Time: 1.08564
PPO Batch Consumption Time: 0.09884
Total Iteration Time: 5.25855

Cumulative Model Updates: 8199
Cumulative Timesteps: 136814144

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03781
Policy Entropy: 1.23613
Value Function Loss: 0.04464

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.07478

Collected Steps per Second: 11248.67326
Overall Steps per Second: 8969.05554

Timestep Collection Time: 4.44710
Timestep Consumption Time: 1.13030
PPO Batch Consumption Time: 0.10265
Total Iteration Time: 5.57740

Cumulative Model Updates: 8202
Cumulative Timesteps: 136864168

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 136864168...
Checkpoint 136864168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03013
Policy Entropy: 1.24188
Value Function Loss: 0.04271

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.06935

Collected Steps per Second: 11849.90819
Overall Steps per Second: 9279.71693

Timestep Collection Time: 4.22231
Timestep Consumption Time: 1.16945
PPO Batch Consumption Time: 0.11669
Total Iteration Time: 5.39176

Cumulative Model Updates: 8205
Cumulative Timesteps: 136914202

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13429
Policy Entropy: 1.23828
Value Function Loss: 0.04220

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.06670

Collected Steps per Second: 11914.53670
Overall Steps per Second: 9609.64542

Timestep Collection Time: 4.19941
Timestep Consumption Time: 1.00724
PPO Batch Consumption Time: 0.09228
Total Iteration Time: 5.20664

Cumulative Model Updates: 8208
Cumulative Timesteps: 136964236

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 136964236...
Checkpoint 136964236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04893
Policy Entropy: 1.24188
Value Function Loss: 0.05580

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.06708

Collected Steps per Second: 12048.11047
Overall Steps per Second: 9634.12939

Timestep Collection Time: 4.15235
Timestep Consumption Time: 1.04044
PPO Batch Consumption Time: 0.07781
Total Iteration Time: 5.19279

Cumulative Model Updates: 8211
Cumulative Timesteps: 137014264

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06749
Policy Entropy: 1.24667
Value Function Loss: 0.04813

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.06474

Collected Steps per Second: 11700.80040
Overall Steps per Second: 9510.64706

Timestep Collection Time: 4.27424
Timestep Consumption Time: 0.98429
PPO Batch Consumption Time: 0.07549
Total Iteration Time: 5.25853

Cumulative Model Updates: 8214
Cumulative Timesteps: 137064276

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 137064276...
Checkpoint 137064276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05860
Policy Entropy: 1.24789
Value Function Loss: 0.05083

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.05649
Value Function Update Magnitude: 0.06805

Collected Steps per Second: 10574.32445
Overall Steps per Second: 8480.42418

Timestep Collection Time: 4.73260
Timestep Consumption Time: 1.16852
PPO Batch Consumption Time: 0.10012
Total Iteration Time: 5.90112

Cumulative Model Updates: 8217
Cumulative Timesteps: 137114320

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03673
Policy Entropy: 1.25398
Value Function Loss: 0.05108

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 11751.06226
Overall Steps per Second: 9280.07693

Timestep Collection Time: 4.25596
Timestep Consumption Time: 1.13322
PPO Batch Consumption Time: 0.11287
Total Iteration Time: 5.38918

Cumulative Model Updates: 8220
Cumulative Timesteps: 137164332

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 137164332...
Checkpoint 137164332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12499
Policy Entropy: 1.26060
Value Function Loss: 0.05815

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.05846
Policy Update Magnitude: 0.05319
Value Function Update Magnitude: 0.07147

Collected Steps per Second: 11026.42458
Overall Steps per Second: 8934.98947

Timestep Collection Time: 4.53946
Timestep Consumption Time: 1.06256
PPO Batch Consumption Time: 0.08499
Total Iteration Time: 5.60202

Cumulative Model Updates: 8223
Cumulative Timesteps: 137214386

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18661
Policy Entropy: 1.25538
Value Function Loss: 0.05384

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.06731

Collected Steps per Second: 11994.34733
Overall Steps per Second: 9680.26150

Timestep Collection Time: 4.16963
Timestep Consumption Time: 0.99676
PPO Batch Consumption Time: 0.06658
Total Iteration Time: 5.16639

Cumulative Model Updates: 8226
Cumulative Timesteps: 137264398

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 137264398...
Checkpoint 137264398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17642
Policy Entropy: 1.25656
Value Function Loss: 0.05896

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05851
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.06966

Collected Steps per Second: 10372.04893
Overall Steps per Second: 8350.63702

Timestep Collection Time: 4.82238
Timestep Consumption Time: 1.16734
PPO Batch Consumption Time: 0.08633
Total Iteration Time: 5.98972

Cumulative Model Updates: 8229
Cumulative Timesteps: 137314416

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03394
Policy Entropy: 1.25286
Value Function Loss: 0.05757

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.05809
Value Function Update Magnitude: 0.07649

Collected Steps per Second: 11164.82908
Overall Steps per Second: 8971.71749

Timestep Collection Time: 4.47907
Timestep Consumption Time: 1.09490
PPO Batch Consumption Time: 0.10681
Total Iteration Time: 5.57396

Cumulative Model Updates: 8232
Cumulative Timesteps: 137364424

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 137364424...
Checkpoint 137364424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.29993
Policy Entropy: 1.25331
Value Function Loss: 0.05546

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.05984
Value Function Update Magnitude: 0.08115

Collected Steps per Second: 11804.33742
Overall Steps per Second: 9585.80784

Timestep Collection Time: 4.23709
Timestep Consumption Time: 0.98063
PPO Batch Consumption Time: 0.06964
Total Iteration Time: 5.21771

Cumulative Model Updates: 8235
Cumulative Timesteps: 137414440

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08674
Policy Entropy: 1.24655
Value Function Loss: 0.04857

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 10627.58656
Overall Steps per Second: 8811.25048

Timestep Collection Time: 4.70662
Timestep Consumption Time: 0.97021
PPO Batch Consumption Time: 0.02560
Total Iteration Time: 5.67683

Cumulative Model Updates: 8238
Cumulative Timesteps: 137464460

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 137464460...
Checkpoint 137464460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14329
Policy Entropy: 1.24670
Value Function Loss: 0.05069

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07994
Policy Update Magnitude: 0.05321
Value Function Update Magnitude: 0.07056

Collected Steps per Second: 12087.37957
Overall Steps per Second: 9693.32518

Timestep Collection Time: 4.13737
Timestep Consumption Time: 1.02185
PPO Batch Consumption Time: 0.07860
Total Iteration Time: 5.15922

Cumulative Model Updates: 8241
Cumulative Timesteps: 137514470

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00789
Policy Entropy: 1.25100
Value Function Loss: 0.05573

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06571
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.06935

Collected Steps per Second: 10554.22304
Overall Steps per Second: 8468.91262

Timestep Collection Time: 4.74104
Timestep Consumption Time: 1.16739
PPO Batch Consumption Time: 0.09093
Total Iteration Time: 5.90843

Cumulative Model Updates: 8244
Cumulative Timesteps: 137564508

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 137564508...
Checkpoint 137564508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04767
Policy Entropy: 1.25443
Value Function Loss: 0.05355

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06773
Policy Update Magnitude: 0.05311
Value Function Update Magnitude: 0.07787

Collected Steps per Second: 12770.66143
Overall Steps per Second: 10455.45520

Timestep Collection Time: 3.91757
Timestep Consumption Time: 0.86749
PPO Batch Consumption Time: 0.07425
Total Iteration Time: 4.78506

Cumulative Model Updates: 8247
Cumulative Timesteps: 137614538

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02036
Policy Entropy: 1.25360
Value Function Loss: 0.05094

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06204
Policy Update Magnitude: 0.05000
Value Function Update Magnitude: 0.08414

Collected Steps per Second: 13265.47735
Overall Steps per Second: 10459.59284

Timestep Collection Time: 3.77114
Timestep Consumption Time: 1.01164
PPO Batch Consumption Time: 0.09765
Total Iteration Time: 4.78279

Cumulative Model Updates: 8250
Cumulative Timesteps: 137664564

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 137664564...
Checkpoint 137664564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05889
Policy Entropy: 1.25000
Value Function Loss: 0.04278

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06263
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.08831

Collected Steps per Second: 13279.77428
Overall Steps per Second: 10463.94589

Timestep Collection Time: 3.76784
Timestep Consumption Time: 1.01392
PPO Batch Consumption Time: 0.09877
Total Iteration Time: 4.78175

Cumulative Model Updates: 8253
Cumulative Timesteps: 137714600

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01240
Policy Entropy: 1.25091
Value Function Loss: 0.04396

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05575
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 13635.63264
Overall Steps per Second: 10866.53416

Timestep Collection Time: 3.66818
Timestep Consumption Time: 0.93476
PPO Batch Consumption Time: 0.07360
Total Iteration Time: 4.60294

Cumulative Model Updates: 8256
Cumulative Timesteps: 137764618

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 137764618...
Checkpoint 137764618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01292
Policy Entropy: 1.24401
Value Function Loss: 0.03682

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.04890
Policy Update Magnitude: 0.04836
Value Function Update Magnitude: 0.07909

Collected Steps per Second: 13274.73086
Overall Steps per Second: 10731.06926

Timestep Collection Time: 3.76671
Timestep Consumption Time: 0.89285
PPO Batch Consumption Time: 0.06668
Total Iteration Time: 4.65955

Cumulative Model Updates: 8259
Cumulative Timesteps: 137814620

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05385
Policy Entropy: 1.24588
Value Function Loss: 0.04894

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06199
Policy Update Magnitude: 0.04880
Value Function Update Magnitude: 0.08383

Collected Steps per Second: 12160.94683
Overall Steps per Second: 9764.88804

Timestep Collection Time: 4.11432
Timestep Consumption Time: 1.00955
PPO Batch Consumption Time: 0.07757
Total Iteration Time: 5.12387

Cumulative Model Updates: 8262
Cumulative Timesteps: 137864654

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 137864654...
Checkpoint 137864654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09580
Policy Entropy: 1.24394
Value Function Loss: 0.04903

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06601
Policy Update Magnitude: 0.05049
Value Function Update Magnitude: 0.07492

Collected Steps per Second: 13205.14904
Overall Steps per Second: 10481.24893

Timestep Collection Time: 3.78883
Timestep Consumption Time: 0.98465
PPO Batch Consumption Time: 0.08212
Total Iteration Time: 4.77348

Cumulative Model Updates: 8265
Cumulative Timesteps: 137914686

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08962
Policy Entropy: 1.25732
Value Function Loss: 0.05757

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.07579

Collected Steps per Second: 13212.51193
Overall Steps per Second: 10426.47344

Timestep Collection Time: 3.78762
Timestep Consumption Time: 1.01208
PPO Batch Consumption Time: 0.09379
Total Iteration Time: 4.79971

Cumulative Model Updates: 8268
Cumulative Timesteps: 137964730

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 137964730...
Checkpoint 137964730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04135
Policy Entropy: 1.24593
Value Function Loss: 0.05039

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07269
Policy Update Magnitude: 0.04687
Value Function Update Magnitude: 0.07314

Collected Steps per Second: 13448.42426
Overall Steps per Second: 10917.48096

Timestep Collection Time: 3.71984
Timestep Consumption Time: 0.86235
PPO Batch Consumption Time: 0.07054
Total Iteration Time: 4.58219

Cumulative Model Updates: 8271
Cumulative Timesteps: 138014756

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04861
Policy Entropy: 1.24925
Value Function Loss: 0.05851

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.04892
Value Function Update Magnitude: 0.07524

Collected Steps per Second: 13380.71666
Overall Steps per Second: 10787.54961

Timestep Collection Time: 3.73866
Timestep Consumption Time: 0.89872
PPO Batch Consumption Time: 0.06597
Total Iteration Time: 4.63738

Cumulative Model Updates: 8274
Cumulative Timesteps: 138064782

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 138064782...
Checkpoint 138064782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05290
Policy Entropy: 1.24599
Value Function Loss: 0.05737

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.07122

Collected Steps per Second: 12217.52641
Overall Steps per Second: 9782.90313

Timestep Collection Time: 4.09543
Timestep Consumption Time: 1.01921
PPO Batch Consumption Time: 0.10039
Total Iteration Time: 5.11464

Cumulative Model Updates: 8277
Cumulative Timesteps: 138114818

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02560
Policy Entropy: 1.25655
Value Function Loss: 0.05642

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.05448
Value Function Update Magnitude: 0.07464

Collected Steps per Second: 13560.37108
Overall Steps per Second: 10427.49565

Timestep Collection Time: 3.69075
Timestep Consumption Time: 1.10886
PPO Batch Consumption Time: 0.12263
Total Iteration Time: 4.79962

Cumulative Model Updates: 8280
Cumulative Timesteps: 138164866

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 138164866...
Checkpoint 138164866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04104
Policy Entropy: 1.25055
Value Function Loss: 0.05179

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.05413
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 13242.26219
Overall Steps per Second: 10431.11157

Timestep Collection Time: 3.77639
Timestep Consumption Time: 1.01773
PPO Batch Consumption Time: 0.09601
Total Iteration Time: 4.79412

Cumulative Model Updates: 8283
Cumulative Timesteps: 138214874

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04551
Policy Entropy: 1.25116
Value Function Loss: 0.05120

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06450
Policy Update Magnitude: 0.05200
Value Function Update Magnitude: 0.06653

Collected Steps per Second: 12543.88597
Overall Steps per Second: 10038.23682

Timestep Collection Time: 3.98728
Timestep Consumption Time: 0.99527
PPO Batch Consumption Time: 0.10639
Total Iteration Time: 4.98255

Cumulative Model Updates: 8286
Cumulative Timesteps: 138264890

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 138264890...
Checkpoint 138264890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07961
Policy Entropy: 1.25625
Value Function Loss: 0.04851

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07117
Policy Update Magnitude: 0.05221
Value Function Update Magnitude: 0.06575

Collected Steps per Second: 12538.44357
Overall Steps per Second: 10139.76935

Timestep Collection Time: 3.98790
Timestep Consumption Time: 0.94338
PPO Batch Consumption Time: 0.06867
Total Iteration Time: 4.93128

Cumulative Model Updates: 8289
Cumulative Timesteps: 138314892

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02629
Policy Entropy: 1.26133
Value Function Loss: 0.05778

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.06007

Collected Steps per Second: 12610.37261
Overall Steps per Second: 9914.88690

Timestep Collection Time: 3.96610
Timestep Consumption Time: 1.07823
PPO Batch Consumption Time: 0.11778
Total Iteration Time: 5.04433

Cumulative Model Updates: 8292
Cumulative Timesteps: 138364906

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 138364906...
Checkpoint 138364906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02657
Policy Entropy: 1.25706
Value Function Loss: 0.05442

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.05659
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.06685

Collected Steps per Second: 13387.77053
Overall Steps per Second: 10431.33874

Timestep Collection Time: 3.73505
Timestep Consumption Time: 1.05858
PPO Batch Consumption Time: 0.11398
Total Iteration Time: 4.79363

Cumulative Model Updates: 8295
Cumulative Timesteps: 138414910

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00021
Policy Entropy: 1.25784
Value Function Loss: 0.05848

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.04943
Policy Update Magnitude: 0.05514
Value Function Update Magnitude: 0.07517

Collected Steps per Second: 13474.82385
Overall Steps per Second: 10465.59361

Timestep Collection Time: 3.71077
Timestep Consumption Time: 1.06698
PPO Batch Consumption Time: 0.10986
Total Iteration Time: 4.77775

Cumulative Model Updates: 8298
Cumulative Timesteps: 138464912

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 138464912...
Checkpoint 138464912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08238
Policy Entropy: 1.26073
Value Function Loss: 0.05526

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05030
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.07537

Collected Steps per Second: 12467.80256
Overall Steps per Second: 9976.21419

Timestep Collection Time: 4.01097
Timestep Consumption Time: 1.00175
PPO Batch Consumption Time: 0.08004
Total Iteration Time: 5.01272

Cumulative Model Updates: 8301
Cumulative Timesteps: 138514920

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06193
Policy Entropy: 1.26316
Value Function Loss: 0.05543

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06241
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.07592

Collected Steps per Second: 13442.80117
Overall Steps per Second: 10816.86185

Timestep Collection Time: 3.72140
Timestep Consumption Time: 0.90342
PPO Batch Consumption Time: 0.06391
Total Iteration Time: 4.62482

Cumulative Model Updates: 8304
Cumulative Timesteps: 138564946

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 138564946...
Checkpoint 138564946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08432
Policy Entropy: 1.26523
Value Function Loss: 0.05018

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06086
Policy Update Magnitude: 0.05069
Value Function Update Magnitude: 0.07138

Collected Steps per Second: 11920.49362
Overall Steps per Second: 9700.79575

Timestep Collection Time: 4.19513
Timestep Consumption Time: 0.95991
PPO Batch Consumption Time: 0.07057
Total Iteration Time: 5.15504

Cumulative Model Updates: 8307
Cumulative Timesteps: 138614954

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11126
Policy Entropy: 1.26593
Value Function Loss: 0.04363

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06624
Policy Update Magnitude: 0.04999
Value Function Update Magnitude: 0.06494

Collected Steps per Second: 12693.38898
Overall Steps per Second: 10330.05151

Timestep Collection Time: 3.94252
Timestep Consumption Time: 0.90198
PPO Batch Consumption Time: 0.06770
Total Iteration Time: 4.84451

Cumulative Model Updates: 8310
Cumulative Timesteps: 138664998

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 138664998...
Checkpoint 138664998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08009
Policy Entropy: 1.26366
Value Function Loss: 0.04936

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.05917
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.06481

Collected Steps per Second: 12175.25717
Overall Steps per Second: 9742.26607

Timestep Collection Time: 4.10669
Timestep Consumption Time: 1.02559
PPO Batch Consumption Time: 0.09712
Total Iteration Time: 5.13228

Cumulative Model Updates: 8313
Cumulative Timesteps: 138714998

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06341
Policy Entropy: 1.27290
Value Function Loss: 0.05633

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.04492
Value Function Update Magnitude: 0.06150

Collected Steps per Second: 13271.23984
Overall Steps per Second: 10738.42437

Timestep Collection Time: 3.77116
Timestep Consumption Time: 0.88948
PPO Batch Consumption Time: 0.06543
Total Iteration Time: 4.66065

Cumulative Model Updates: 8316
Cumulative Timesteps: 138765046

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 138765046...
Checkpoint 138765046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01057
Policy Entropy: 1.26723
Value Function Loss: 0.05603

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06403
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.06067

Collected Steps per Second: 11700.30695
Overall Steps per Second: 9419.99256

Timestep Collection Time: 4.27356
Timestep Consumption Time: 1.03451
PPO Batch Consumption Time: 0.08323
Total Iteration Time: 5.30807

Cumulative Model Updates: 8319
Cumulative Timesteps: 138815048

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03798
Policy Entropy: 1.28960
Value Function Loss: 0.05414

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.05283
Value Function Update Magnitude: 0.06511

Collected Steps per Second: 12054.35850
Overall Steps per Second: 9638.70228

Timestep Collection Time: 4.15136
Timestep Consumption Time: 1.04042
PPO Batch Consumption Time: 0.09182
Total Iteration Time: 5.19178

Cumulative Model Updates: 8322
Cumulative Timesteps: 138865090

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 138865090...
Checkpoint 138865090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12090
Policy Entropy: 1.28063
Value Function Loss: 0.05079

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.05646
Value Function Update Magnitude: 0.06756

Collected Steps per Second: 13090.60700
Overall Steps per Second: 10619.43539

Timestep Collection Time: 3.82091
Timestep Consumption Time: 0.88914
PPO Batch Consumption Time: 0.06505
Total Iteration Time: 4.71004

Cumulative Model Updates: 8325
Cumulative Timesteps: 138915108

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.25283
Policy Entropy: 1.28493
Value Function Loss: 0.05187

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07158
Policy Update Magnitude: 0.05178
Value Function Update Magnitude: 0.07094

Collected Steps per Second: 13580.52980
Overall Steps per Second: 10718.32842

Timestep Collection Time: 3.68277
Timestep Consumption Time: 0.98344
PPO Batch Consumption Time: 0.08221
Total Iteration Time: 4.66621

Cumulative Model Updates: 8328
Cumulative Timesteps: 138965122

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 138965122...
Checkpoint 138965122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09995
Policy Entropy: 1.27457
Value Function Loss: 0.05037

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.05493
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.06981

Collected Steps per Second: 12098.44778
Overall Steps per Second: 9982.53449

Timestep Collection Time: 4.13276
Timestep Consumption Time: 0.87599
PPO Batch Consumption Time: 0.06460
Total Iteration Time: 5.00875

Cumulative Model Updates: 8331
Cumulative Timesteps: 139015122

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01580
Policy Entropy: 1.26324
Value Function Loss: 0.05101

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04069
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.06566

Collected Steps per Second: 12250.02707
Overall Steps per Second: 10041.97389

Timestep Collection Time: 4.08489
Timestep Consumption Time: 0.89820
PPO Batch Consumption Time: 0.08258
Total Iteration Time: 4.98308

Cumulative Model Updates: 8334
Cumulative Timesteps: 139065162

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 139065162...
Checkpoint 139065162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01962
Policy Entropy: 1.26576
Value Function Loss: 0.04556

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.05761
Policy Update Magnitude: 0.04752
Value Function Update Magnitude: 0.06343

Collected Steps per Second: 13297.79732
Overall Steps per Second: 10491.16434

Timestep Collection Time: 3.76107
Timestep Consumption Time: 1.00618
PPO Batch Consumption Time: 0.08864
Total Iteration Time: 4.76725

Cumulative Model Updates: 8337
Cumulative Timesteps: 139115176

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03609
Policy Entropy: 1.27295
Value Function Loss: 0.03989

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.06759

Collected Steps per Second: 13298.05131
Overall Steps per Second: 10448.82547

Timestep Collection Time: 3.76236
Timestep Consumption Time: 1.02593
PPO Batch Consumption Time: 0.10149
Total Iteration Time: 4.78829

Cumulative Model Updates: 8340
Cumulative Timesteps: 139165208

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 139165208...
Checkpoint 139165208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10041
Policy Entropy: 1.28640
Value Function Loss: 0.03560

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04710
Policy Update Magnitude: 0.04673
Value Function Update Magnitude: 0.06833

Collected Steps per Second: 13625.28654
Overall Steps per Second: 10456.12239

Timestep Collection Time: 3.67038
Timestep Consumption Time: 1.11246
PPO Batch Consumption Time: 0.12154
Total Iteration Time: 4.78284

Cumulative Model Updates: 8343
Cumulative Timesteps: 139215218

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15915
Policy Entropy: 1.29278
Value Function Loss: 0.04627

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04169
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.06299

Collected Steps per Second: 12422.65345
Overall Steps per Second: 9639.39610

Timestep Collection Time: 4.02668
Timestep Consumption Time: 1.16265
PPO Batch Consumption Time: 0.12040
Total Iteration Time: 5.18933

Cumulative Model Updates: 8346
Cumulative Timesteps: 139265240

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 139265240...
Checkpoint 139265240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04521
Policy Entropy: 1.29435
Value Function Loss: 0.04790

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05523
Policy Update Magnitude: 0.05060
Value Function Update Magnitude: 0.06479

Collected Steps per Second: 13098.35936
Overall Steps per Second: 10584.80065

Timestep Collection Time: 3.82033
Timestep Consumption Time: 0.90721
PPO Batch Consumption Time: 0.06768
Total Iteration Time: 4.72753

Cumulative Model Updates: 8349
Cumulative Timesteps: 139315280

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08952
Policy Entropy: 1.29112
Value Function Loss: 0.05298

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.05854
Policy Update Magnitude: 0.04778
Value Function Update Magnitude: 0.07457

Collected Steps per Second: 12795.57002
Overall Steps per Second: 10246.84774

Timestep Collection Time: 3.90838
Timestep Consumption Time: 0.97214
PPO Batch Consumption Time: 0.07656
Total Iteration Time: 4.88053

Cumulative Model Updates: 8352
Cumulative Timesteps: 139365290

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 139365290...
Checkpoint 139365290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03825
Policy Entropy: 1.28171
Value Function Loss: 0.05350

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06687
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.08330

Collected Steps per Second: 13441.52380
Overall Steps per Second: 10878.47114

Timestep Collection Time: 3.71997
Timestep Consumption Time: 0.87645
PPO Batch Consumption Time: 0.06146
Total Iteration Time: 4.59642

Cumulative Model Updates: 8355
Cumulative Timesteps: 139415292

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00558
Policy Entropy: 1.27306
Value Function Loss: 0.05890

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06281
Policy Update Magnitude: 0.04556
Value Function Update Magnitude: 0.08527

Collected Steps per Second: 12448.49616
Overall Steps per Second: 10035.03591

Timestep Collection Time: 4.01719
Timestep Consumption Time: 0.96615
PPO Batch Consumption Time: 0.07809
Total Iteration Time: 4.98334

Cumulative Model Updates: 8358
Cumulative Timesteps: 139465300

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 139465300...
Checkpoint 139465300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04239
Policy Entropy: 1.27649
Value Function Loss: 0.05684

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06277
Policy Update Magnitude: 0.04936
Value Function Update Magnitude: 0.07079

Collected Steps per Second: 13193.49167
Overall Steps per Second: 10565.88623

Timestep Collection Time: 3.79141
Timestep Consumption Time: 0.94288
PPO Batch Consumption Time: 0.06397
Total Iteration Time: 4.73429

Cumulative Model Updates: 8361
Cumulative Timesteps: 139515322

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05595
Policy Entropy: 1.27382
Value Function Loss: 0.05787

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05123
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.07110

Collected Steps per Second: 12002.02864
Overall Steps per Second: 9922.52860

Timestep Collection Time: 4.16896
Timestep Consumption Time: 0.87370
PPO Batch Consumption Time: 0.07645
Total Iteration Time: 5.04267

Cumulative Model Updates: 8364
Cumulative Timesteps: 139565358

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 139565358...
Checkpoint 139565358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03005
Policy Entropy: 1.27050
Value Function Loss: 0.05511

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.05791
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.06841

Collected Steps per Second: 13462.34633
Overall Steps per Second: 10506.54281

Timestep Collection Time: 3.71793
Timestep Consumption Time: 1.04596
PPO Batch Consumption Time: 0.10552
Total Iteration Time: 4.76389

Cumulative Model Updates: 8367
Cumulative Timesteps: 139615410

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07590
Policy Entropy: 1.26134
Value Function Loss: 0.04989

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.05924

Collected Steps per Second: 12387.94739
Overall Steps per Second: 9636.61283

Timestep Collection Time: 4.03650
Timestep Consumption Time: 1.15246
PPO Batch Consumption Time: 0.08340
Total Iteration Time: 5.18896

Cumulative Model Updates: 8370
Cumulative Timesteps: 139665414

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 139665414...
Checkpoint 139665414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09289
Policy Entropy: 1.25755
Value Function Loss: 0.05222

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.06309

Collected Steps per Second: 11692.32859
Overall Steps per Second: 9268.52538

Timestep Collection Time: 4.27716
Timestep Consumption Time: 1.11852
PPO Batch Consumption Time: 0.08410
Total Iteration Time: 5.39568

Cumulative Model Updates: 8373
Cumulative Timesteps: 139715424

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05994
Policy Entropy: 1.26659
Value Function Loss: 0.05169

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.06768

Collected Steps per Second: 11678.23575
Overall Steps per Second: 9289.60124

Timestep Collection Time: 4.28387
Timestep Consumption Time: 1.10151
PPO Batch Consumption Time: 0.11470
Total Iteration Time: 5.38538

Cumulative Model Updates: 8376
Cumulative Timesteps: 139765452

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 139765452...
Checkpoint 139765452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15327
Policy Entropy: 1.27109
Value Function Loss: 0.04890

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06124
Policy Update Magnitude: 0.04705
Value Function Update Magnitude: 0.06702

Collected Steps per Second: 11340.20831
Overall Steps per Second: 9349.44529

Timestep Collection Time: 4.41226
Timestep Consumption Time: 0.93950
PPO Batch Consumption Time: 0.07127
Total Iteration Time: 5.35176

Cumulative Model Updates: 8379
Cumulative Timesteps: 139815488

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09622
Policy Entropy: 1.27453
Value Function Loss: 0.05269

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05230
Policy Update Magnitude: 0.04668
Value Function Update Magnitude: 0.07863

Collected Steps per Second: 11675.62696
Overall Steps per Second: 9204.64367

Timestep Collection Time: 4.28380
Timestep Consumption Time: 1.14998
PPO Batch Consumption Time: 0.10960
Total Iteration Time: 5.43378

Cumulative Model Updates: 8382
Cumulative Timesteps: 139865504

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 139865504...
Checkpoint 139865504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09195
Policy Entropy: 1.27214
Value Function Loss: 0.05133

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06546
Policy Update Magnitude: 0.04889
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 11869.81541
Overall Steps per Second: 9329.99689

Timestep Collection Time: 4.21456
Timestep Consumption Time: 1.14729
PPO Batch Consumption Time: 0.12167
Total Iteration Time: 5.36185

Cumulative Model Updates: 8385
Cumulative Timesteps: 139915530

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09933
Policy Entropy: 1.27127
Value Function Loss: 0.05412

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.07301

Collected Steps per Second: 11981.08832
Overall Steps per Second: 9544.36418

Timestep Collection Time: 4.17441
Timestep Consumption Time: 1.06575
PPO Batch Consumption Time: 0.07671
Total Iteration Time: 5.24016

Cumulative Model Updates: 8388
Cumulative Timesteps: 139965544

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 139965544...
Checkpoint 139965544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02883
Policy Entropy: 1.27041
Value Function Loss: 0.04556

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06440
Policy Update Magnitude: 0.04877
Value Function Update Magnitude: 0.07098

Collected Steps per Second: 10210.89248
Overall Steps per Second: 8163.55964

Timestep Collection Time: 4.89791
Timestep Consumption Time: 1.22834
PPO Batch Consumption Time: 0.13370
Total Iteration Time: 6.12625

Cumulative Model Updates: 8391
Cumulative Timesteps: 140015556

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02704
Policy Entropy: 1.26838
Value Function Loss: 0.03938

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.06772

Collected Steps per Second: 11648.15772
Overall Steps per Second: 9434.85725

Timestep Collection Time: 4.29441
Timestep Consumption Time: 1.00742
PPO Batch Consumption Time: 0.07495
Total Iteration Time: 5.30183

Cumulative Model Updates: 8394
Cumulative Timesteps: 140065578

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 140065578...
Checkpoint 140065578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18011
Policy Entropy: 1.26776
Value Function Loss: 0.03864

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07731
Policy Update Magnitude: 0.04611
Value Function Update Magnitude: 0.06452

Collected Steps per Second: 10968.61228
Overall Steps per Second: 8789.35302

Timestep Collection Time: 4.56047
Timestep Consumption Time: 1.13074
PPO Batch Consumption Time: 0.10196
Total Iteration Time: 5.69120

Cumulative Model Updates: 8397
Cumulative Timesteps: 140115600

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06097
Policy Entropy: 1.27260
Value Function Loss: 0.04261

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.04418
Value Function Update Magnitude: 0.06060

Collected Steps per Second: 12079.82106
Overall Steps per Second: 9639.82460

Timestep Collection Time: 4.14046
Timestep Consumption Time: 1.04802
PPO Batch Consumption Time: 0.08370
Total Iteration Time: 5.18848

Cumulative Model Updates: 8400
Cumulative Timesteps: 140165616

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 140165616...
Checkpoint 140165616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19980
Policy Entropy: 1.27298
Value Function Loss: 0.04526

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.06115

Collected Steps per Second: 11494.24949
Overall Steps per Second: 9299.12049

Timestep Collection Time: 4.35052
Timestep Consumption Time: 1.02697
PPO Batch Consumption Time: 0.10828
Total Iteration Time: 5.37750

Cumulative Model Updates: 8403
Cumulative Timesteps: 140215622

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06896
Policy Entropy: 1.26768
Value Function Loss: 0.04210

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.06077

Collected Steps per Second: 11661.63958
Overall Steps per Second: 9367.31620

Timestep Collection Time: 4.29065
Timestep Consumption Time: 1.05090
PPO Batch Consumption Time: 0.07694
Total Iteration Time: 5.34155

Cumulative Model Updates: 8406
Cumulative Timesteps: 140265658

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 140265658...
Checkpoint 140265658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02693
Policy Entropy: 1.26429
Value Function Loss: 0.05114

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 10881.64212
Overall Steps per Second: 8836.06414

Timestep Collection Time: 4.59618
Timestep Consumption Time: 1.06403
PPO Batch Consumption Time: 0.08525
Total Iteration Time: 5.66021

Cumulative Model Updates: 8409
Cumulative Timesteps: 140315672

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06455
Policy Entropy: 1.26483
Value Function Loss: 0.04900

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.06415

Collected Steps per Second: 11792.34263
Overall Steps per Second: 9312.87559

Timestep Collection Time: 4.24140
Timestep Consumption Time: 1.12923
PPO Batch Consumption Time: 0.10505
Total Iteration Time: 5.37063

Cumulative Model Updates: 8412
Cumulative Timesteps: 140365688

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 140365688...
Checkpoint 140365688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06228
Policy Entropy: 1.26471
Value Function Loss: 0.05444

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07041
Policy Update Magnitude: 0.04638
Value Function Update Magnitude: 0.06831

Collected Steps per Second: 11796.49722
Overall Steps per Second: 9276.97191

Timestep Collection Time: 4.24211
Timestep Consumption Time: 1.15211
PPO Batch Consumption Time: 0.09867
Total Iteration Time: 5.39422

Cumulative Model Updates: 8415
Cumulative Timesteps: 140415730

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01555
Policy Entropy: 1.26143
Value Function Loss: 0.04936

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.04635
Value Function Update Magnitude: 0.07023

Collected Steps per Second: 11797.58347
Overall Steps per Second: 9615.53296

Timestep Collection Time: 4.24138
Timestep Consumption Time: 0.96249
PPO Batch Consumption Time: 0.06985
Total Iteration Time: 5.20387

Cumulative Model Updates: 8418
Cumulative Timesteps: 140465768

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 140465768...
Checkpoint 140465768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04356
Policy Entropy: 1.26036
Value Function Loss: 0.05496

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.05013
Value Function Update Magnitude: 0.07688

Collected Steps per Second: 11717.96012
Overall Steps per Second: 9298.29009

Timestep Collection Time: 4.26730
Timestep Consumption Time: 1.11047
PPO Batch Consumption Time: 0.08021
Total Iteration Time: 5.37776

Cumulative Model Updates: 8421
Cumulative Timesteps: 140515772

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05186
Policy Entropy: 1.26738
Value Function Loss: 0.05234

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.04925
Value Function Update Magnitude: 0.07112

Collected Steps per Second: 11572.21403
Overall Steps per Second: 9289.73476

Timestep Collection Time: 4.32311
Timestep Consumption Time: 1.06219
PPO Batch Consumption Time: 0.09274
Total Iteration Time: 5.38530

Cumulative Model Updates: 8424
Cumulative Timesteps: 140565800

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 140565800...
Checkpoint 140565800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14744
Policy Entropy: 1.26572
Value Function Loss: 0.05956

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.04866
Value Function Update Magnitude: 0.07269

Collected Steps per Second: 11805.25273
Overall Steps per Second: 9277.25772

Timestep Collection Time: 4.23642
Timestep Consumption Time: 1.15440
PPO Batch Consumption Time: 0.10532
Total Iteration Time: 5.39082

Cumulative Model Updates: 8427
Cumulative Timesteps: 140615812

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06191
Policy Entropy: 1.27212
Value Function Loss: 0.05787

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.07464

Collected Steps per Second: 12903.65450
Overall Steps per Second: 10478.07239

Timestep Collection Time: 3.87503
Timestep Consumption Time: 0.89703
PPO Batch Consumption Time: 0.06085
Total Iteration Time: 4.77206

Cumulative Model Updates: 8430
Cumulative Timesteps: 140665814

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 140665814...
Checkpoint 140665814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08187
Policy Entropy: 1.26000
Value Function Loss: 0.04716

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.08005

Collected Steps per Second: 11977.12551
Overall Steps per Second: 9648.36946

Timestep Collection Time: 4.17479
Timestep Consumption Time: 1.00764
PPO Batch Consumption Time: 0.11870
Total Iteration Time: 5.18243

Cumulative Model Updates: 8433
Cumulative Timesteps: 140715816

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05457
Policy Entropy: 1.26176
Value Function Loss: 0.03881

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.06699
Value Function Update Magnitude: 0.07308

Collected Steps per Second: 12948.07564
Overall Steps per Second: 10469.22060

Timestep Collection Time: 3.86173
Timestep Consumption Time: 0.91436
PPO Batch Consumption Time: 0.06275
Total Iteration Time: 4.77610

Cumulative Model Updates: 8436
Cumulative Timesteps: 140765818

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 140765818...
Checkpoint 140765818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16879
Policy Entropy: 1.25936
Value Function Loss: 0.03842

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.06273
Value Function Update Magnitude: 0.06509

Collected Steps per Second: 12100.02113
Overall Steps per Second: 9606.77452

Timestep Collection Time: 4.13619
Timestep Consumption Time: 1.07347
PPO Batch Consumption Time: 0.11640
Total Iteration Time: 5.20966

Cumulative Model Updates: 8439
Cumulative Timesteps: 140815866

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09255
Policy Entropy: 1.26822
Value Function Loss: 0.04572

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.06793

Collected Steps per Second: 13263.66668
Overall Steps per Second: 10442.80089

Timestep Collection Time: 3.77301
Timestep Consumption Time: 1.01919
PPO Batch Consumption Time: 0.12193
Total Iteration Time: 4.79220

Cumulative Model Updates: 8442
Cumulative Timesteps: 140865910

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 140865910...
Checkpoint 140865910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07722
Policy Entropy: 1.26460
Value Function Loss: 0.05506

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.06315

Collected Steps per Second: 13306.63940
Overall Steps per Second: 10452.35309

Timestep Collection Time: 3.75948
Timestep Consumption Time: 1.02662
PPO Batch Consumption Time: 0.10290
Total Iteration Time: 4.78610

Cumulative Model Updates: 8445
Cumulative Timesteps: 140915936

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01868
Policy Entropy: 1.25963
Value Function Loss: 0.06267

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.06680

Collected Steps per Second: 13407.70468
Overall Steps per Second: 10445.06266

Timestep Collection Time: 3.72935
Timestep Consumption Time: 1.05779
PPO Batch Consumption Time: 0.11424
Total Iteration Time: 4.78714

Cumulative Model Updates: 8448
Cumulative Timesteps: 140965938

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 140965938...
Checkpoint 140965938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02652
Policy Entropy: 1.25577
Value Function Loss: 0.06558

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.06659
Value Function Update Magnitude: 0.07365

Collected Steps per Second: 13467.10336
Overall Steps per Second: 10467.08911

Timestep Collection Time: 3.71587
Timestep Consumption Time: 1.06502
PPO Batch Consumption Time: 0.10994
Total Iteration Time: 4.78089

Cumulative Model Updates: 8451
Cumulative Timesteps: 141015980

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08441
Policy Entropy: 1.24578
Value Function Loss: 0.07593

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.07386
Value Function Update Magnitude: 0.07315

Collected Steps per Second: 13686.42685
Overall Steps per Second: 10836.80570

Timestep Collection Time: 3.65603
Timestep Consumption Time: 0.96138
PPO Batch Consumption Time: 0.07255
Total Iteration Time: 4.61741

Cumulative Model Updates: 8454
Cumulative Timesteps: 141066018

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 141066018...
Checkpoint 141066018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03693
Policy Entropy: 1.24714
Value Function Loss: 0.06585

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.07427
Value Function Update Magnitude: 0.07865

Collected Steps per Second: 13298.84137
Overall Steps per Second: 11002.24752

Timestep Collection Time: 3.76093
Timestep Consumption Time: 0.78505
PPO Batch Consumption Time: 0.05871
Total Iteration Time: 4.54598

Cumulative Model Updates: 8457
Cumulative Timesteps: 141116034

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02754
Policy Entropy: 1.25317
Value Function Loss: 0.06287

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.06922
Value Function Update Magnitude: 0.07969

Collected Steps per Second: 12573.30879
Overall Steps per Second: 9938.53152

Timestep Collection Time: 3.97986
Timestep Consumption Time: 1.05509
PPO Batch Consumption Time: 0.09915
Total Iteration Time: 5.03495

Cumulative Model Updates: 8460
Cumulative Timesteps: 141166074

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 141166074...
Checkpoint 141166074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12191
Policy Entropy: 1.26325
Value Function Loss: 0.04913

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05274
Policy Update Magnitude: 0.06630
Value Function Update Magnitude: 0.07059

Collected Steps per Second: 13239.10387
Overall Steps per Second: 10697.24528

Timestep Collection Time: 3.77820
Timestep Consumption Time: 0.89777
PPO Batch Consumption Time: 0.06456
Total Iteration Time: 4.67597

Cumulative Model Updates: 8463
Cumulative Timesteps: 141216094

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02625
Policy Entropy: 1.26597
Value Function Loss: 0.05517

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06037
Policy Update Magnitude: 0.06888
Value Function Update Magnitude: 0.07143

Collected Steps per Second: 13571.47946
Overall Steps per Second: 10716.77382

Timestep Collection Time: 3.68567
Timestep Consumption Time: 0.98178
PPO Batch Consumption Time: 0.08263
Total Iteration Time: 4.66745

Cumulative Model Updates: 8466
Cumulative Timesteps: 141266114

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 141266114...
Checkpoint 141266114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13575
Policy Entropy: 1.25505
Value Function Loss: 0.05334

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.06662
Value Function Update Magnitude: 0.07381

Collected Steps per Second: 13351.70110
Overall Steps per Second: 10671.10795

Timestep Collection Time: 3.74649
Timestep Consumption Time: 0.94112
PPO Batch Consumption Time: 0.06768
Total Iteration Time: 4.68761

Cumulative Model Updates: 8469
Cumulative Timesteps: 141316136

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08258
Policy Entropy: 1.25022
Value Function Loss: 0.05200

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08717
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.06820

Collected Steps per Second: 12330.07157
Overall Steps per Second: 9838.91710

Timestep Collection Time: 4.05821
Timestep Consumption Time: 1.02751
PPO Batch Consumption Time: 0.12210
Total Iteration Time: 5.08572

Cumulative Model Updates: 8472
Cumulative Timesteps: 141366174

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 141366174...
Checkpoint 141366174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15123
Policy Entropy: 1.26144
Value Function Loss: 0.05205

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06602
Policy Update Magnitude: 0.06608
Value Function Update Magnitude: 0.06881

Collected Steps per Second: 13212.66784
Overall Steps per Second: 10485.44071

Timestep Collection Time: 3.78773
Timestep Consumption Time: 0.98518
PPO Batch Consumption Time: 0.06208
Total Iteration Time: 4.77290

Cumulative Model Updates: 8475
Cumulative Timesteps: 141416220

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01625
Policy Entropy: 1.25612
Value Function Loss: 0.04802

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.06486
Value Function Update Magnitude: 0.07203

Collected Steps per Second: 11940.39530
Overall Steps per Second: 9579.89412

Timestep Collection Time: 4.18797
Timestep Consumption Time: 1.03192
PPO Batch Consumption Time: 0.10174
Total Iteration Time: 5.21989

Cumulative Model Updates: 8478
Cumulative Timesteps: 141466226

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 141466226...
Checkpoint 141466226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06306
Policy Entropy: 1.25368
Value Function Loss: 0.04232

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.07333

Collected Steps per Second: 13685.88853
Overall Steps per Second: 11022.44200

Timestep Collection Time: 3.65661
Timestep Consumption Time: 0.88358
PPO Batch Consumption Time: 0.06103
Total Iteration Time: 4.54019

Cumulative Model Updates: 8481
Cumulative Timesteps: 141516270

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11053
Policy Entropy: 1.25572
Value Function Loss: 0.04036

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.07095

Collected Steps per Second: 12219.56767
Overall Steps per Second: 9927.96469

Timestep Collection Time: 4.09458
Timestep Consumption Time: 0.94512
PPO Batch Consumption Time: 0.06875
Total Iteration Time: 5.03970

Cumulative Model Updates: 8484
Cumulative Timesteps: 141566304

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 141566304...
Checkpoint 141566304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05279
Policy Entropy: 1.25605
Value Function Loss: 0.04683

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.05255
Value Function Update Magnitude: 0.06793

Collected Steps per Second: 13123.00561
Overall Steps per Second: 10670.44596

Timestep Collection Time: 3.81300
Timestep Consumption Time: 0.87640
PPO Batch Consumption Time: 0.06707
Total Iteration Time: 4.68940

Cumulative Model Updates: 8487
Cumulative Timesteps: 141616342

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03054
Policy Entropy: 1.25614
Value Function Loss: 0.04977

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07001
Policy Update Magnitude: 0.05229
Value Function Update Magnitude: 0.06649

Collected Steps per Second: 13022.22871
Overall Steps per Second: 10259.14931

Timestep Collection Time: 3.84020
Timestep Consumption Time: 1.03428
PPO Batch Consumption Time: 0.09785
Total Iteration Time: 4.87448

Cumulative Model Updates: 8490
Cumulative Timesteps: 141666350

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 141666350...
Checkpoint 141666350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08330
Policy Entropy: 1.26057
Value Function Loss: 0.04191

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.05033
Value Function Update Magnitude: 0.06339

Collected Steps per Second: 13161.12256
Overall Steps per Second: 10651.21119

Timestep Collection Time: 3.80089
Timestep Consumption Time: 0.89566
PPO Batch Consumption Time: 0.06495
Total Iteration Time: 4.69656

Cumulative Model Updates: 8493
Cumulative Timesteps: 141716374

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10363
Policy Entropy: 1.26059
Value Function Loss: 0.03503

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05593
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.06415

Collected Steps per Second: 12022.67561
Overall Steps per Second: 9823.94782

Timestep Collection Time: 4.16247
Timestep Consumption Time: 0.93161
PPO Batch Consumption Time: 0.08778
Total Iteration Time: 5.09408

Cumulative Model Updates: 8496
Cumulative Timesteps: 141766418

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 141766418...
Checkpoint 141766418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15509
Policy Entropy: 1.26080
Value Function Loss: 0.03707

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05770
Policy Update Magnitude: 0.04759
Value Function Update Magnitude: 0.06667

Collected Steps per Second: 12940.87543
Overall Steps per Second: 10545.13015

Timestep Collection Time: 3.86512
Timestep Consumption Time: 0.87811
PPO Batch Consumption Time: 0.06184
Total Iteration Time: 4.74323

Cumulative Model Updates: 8499
Cumulative Timesteps: 141816436

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07627
Policy Entropy: 1.26348
Value Function Loss: 0.03922

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06338
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.07010

Collected Steps per Second: 12553.60729
Overall Steps per Second: 9974.33978

Timestep Collection Time: 3.98451
Timestep Consumption Time: 1.03036
PPO Batch Consumption Time: 0.10583
Total Iteration Time: 5.01487

Cumulative Model Updates: 8502
Cumulative Timesteps: 141866456

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 141866456...
Checkpoint 141866456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08999
Policy Entropy: 1.27218
Value Function Loss: 0.05078

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.07018

Collected Steps per Second: 13508.22689
Overall Steps per Second: 10465.48470

Timestep Collection Time: 3.70189
Timestep Consumption Time: 1.07629
PPO Batch Consumption Time: 0.11665
Total Iteration Time: 4.77818

Cumulative Model Updates: 8505
Cumulative Timesteps: 141916462

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02971
Policy Entropy: 1.27255
Value Function Loss: 0.05492

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.05331
Value Function Update Magnitude: 0.06941

Collected Steps per Second: 13272.33386
Overall Steps per Second: 10415.04797

Timestep Collection Time: 3.77040
Timestep Consumption Time: 1.03438
PPO Batch Consumption Time: 0.09994
Total Iteration Time: 4.80478

Cumulative Model Updates: 8508
Cumulative Timesteps: 141966504

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 141966504...
Checkpoint 141966504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02582
Policy Entropy: 1.27542
Value Function Loss: 0.05924

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.05289
Value Function Update Magnitude: 0.06827

Collected Steps per Second: 13226.09595
Overall Steps per Second: 10481.80398

Timestep Collection Time: 3.78313
Timestep Consumption Time: 0.99048
PPO Batch Consumption Time: 0.11615
Total Iteration Time: 4.77361

Cumulative Model Updates: 8511
Cumulative Timesteps: 142016540

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00036
Policy Entropy: 1.25956
Value Function Loss: 0.04688

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.05008
Value Function Update Magnitude: 0.06973

Collected Steps per Second: 13358.25182
Overall Steps per Second: 10415.89969

Timestep Collection Time: 3.74375
Timestep Consumption Time: 1.05756
PPO Batch Consumption Time: 0.10629
Total Iteration Time: 4.80131

Cumulative Model Updates: 8514
Cumulative Timesteps: 142066550

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 142066550...
Checkpoint 142066550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09781
Policy Entropy: 1.26620
Value Function Loss: 0.04013

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.04772
Value Function Update Magnitude: 0.06944

Collected Steps per Second: 12338.59462
Overall Steps per Second: 9671.77263

Timestep Collection Time: 4.05443
Timestep Consumption Time: 1.11794
PPO Batch Consumption Time: 0.11741
Total Iteration Time: 5.17237

Cumulative Model Updates: 8517
Cumulative Timesteps: 142116576

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00981
Policy Entropy: 1.27784
Value Function Loss: 0.03563

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.06818

Collected Steps per Second: 13554.31763
Overall Steps per Second: 10929.90019

Timestep Collection Time: 3.68975
Timestep Consumption Time: 0.88596
PPO Batch Consumption Time: 0.06069
Total Iteration Time: 4.57571

Cumulative Model Updates: 8520
Cumulative Timesteps: 142166588

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 142166588...
Checkpoint 142166588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02980
Policy Entropy: 1.27560
Value Function Loss: 0.04318

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07112
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.06229

Collected Steps per Second: 12787.97740
Overall Steps per Second: 9944.98857

Timestep Collection Time: 3.91133
Timestep Consumption Time: 1.11814
PPO Batch Consumption Time: 0.10062
Total Iteration Time: 5.02947

Cumulative Model Updates: 8523
Cumulative Timesteps: 142216606

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05336
Policy Entropy: 1.26661
Value Function Loss: 0.05086

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.04498
Value Function Update Magnitude: 0.06200

Collected Steps per Second: 12989.55924
Overall Steps per Second: 10735.85398

Timestep Collection Time: 3.85017
Timestep Consumption Time: 0.80824
PPO Batch Consumption Time: 0.06224
Total Iteration Time: 4.65841

Cumulative Model Updates: 8526
Cumulative Timesteps: 142266618

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 142266618...
Checkpoint 142266618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00411
Policy Entropy: 1.26235
Value Function Loss: 0.04233

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.06571

Collected Steps per Second: 11507.67336
Overall Steps per Second: 9399.34559

Timestep Collection Time: 4.34736
Timestep Consumption Time: 0.97514
PPO Batch Consumption Time: 0.07963
Total Iteration Time: 5.32250

Cumulative Model Updates: 8529
Cumulative Timesteps: 142316646

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03930
Policy Entropy: 1.26813
Value Function Loss: 0.04407

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05055
Policy Update Magnitude: 0.04837
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 13047.61977
Overall Steps per Second: 10592.35677

Timestep Collection Time: 3.83580
Timestep Consumption Time: 0.88912
PPO Batch Consumption Time: 0.06791
Total Iteration Time: 4.72492

Cumulative Model Updates: 8532
Cumulative Timesteps: 142366694

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 142366694...
Checkpoint 142366694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06107
Policy Entropy: 1.26417
Value Function Loss: 0.04426

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.06880

Collected Steps per Second: 13068.89023
Overall Steps per Second: 10348.68970

Timestep Collection Time: 3.82986
Timestep Consumption Time: 1.00670
PPO Batch Consumption Time: 0.08031
Total Iteration Time: 4.83655

Cumulative Model Updates: 8535
Cumulative Timesteps: 142416746

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14513
Policy Entropy: 1.26267
Value Function Loss: 0.05994

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.05752
Value Function Update Magnitude: 0.07471

Collected Steps per Second: 12615.71213
Overall Steps per Second: 10287.91162

Timestep Collection Time: 3.96585
Timestep Consumption Time: 0.89734
PPO Batch Consumption Time: 0.06661
Total Iteration Time: 4.86318

Cumulative Model Updates: 8538
Cumulative Timesteps: 142466778

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 142466778...
Checkpoint 142466778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11544
Policy Entropy: 1.25995
Value Function Loss: 0.06512

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07118
Policy Update Magnitude: 0.06062
Value Function Update Magnitude: 0.08818

Collected Steps per Second: 12198.60512
Overall Steps per Second: 9764.61508

Timestep Collection Time: 4.10063
Timestep Consumption Time: 1.02215
PPO Batch Consumption Time: 0.09875
Total Iteration Time: 5.12278

Cumulative Model Updates: 8541
Cumulative Timesteps: 142516800

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03266
Policy Entropy: 1.26167
Value Function Loss: 0.06094

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.05833
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.09044

Collected Steps per Second: 13460.10049
Overall Steps per Second: 10475.90796

Timestep Collection Time: 3.71869
Timestep Consumption Time: 1.05932
PPO Batch Consumption Time: 0.10327
Total Iteration Time: 4.77801

Cumulative Model Updates: 8544
Cumulative Timesteps: 142566854

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 142566854...
Checkpoint 142566854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01835
Policy Entropy: 1.26037
Value Function Loss: 0.05424

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06101
Policy Update Magnitude: 0.05497
Value Function Update Magnitude: 0.07674

Collected Steps per Second: 13023.99450
Overall Steps per Second: 10393.56725

Timestep Collection Time: 3.84183
Timestep Consumption Time: 0.97230
PPO Batch Consumption Time: 0.07736
Total Iteration Time: 4.81413

Cumulative Model Updates: 8547
Cumulative Timesteps: 142616890

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14375
Policy Entropy: 1.26218
Value Function Loss: 0.05828

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06218
Policy Update Magnitude: 0.05416
Value Function Update Magnitude: 0.07693

Collected Steps per Second: 11898.19321
Overall Steps per Second: 9632.82772

Timestep Collection Time: 4.20400
Timestep Consumption Time: 0.98866
PPO Batch Consumption Time: 0.08131
Total Iteration Time: 5.19266

Cumulative Model Updates: 8550
Cumulative Timesteps: 142666910

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 142666910...
Checkpoint 142666910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09246
Policy Entropy: 1.26164
Value Function Loss: 0.05897

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05118
Policy Update Magnitude: 0.05243
Value Function Update Magnitude: 0.07512

Collected Steps per Second: 11339.97605
Overall Steps per Second: 8991.59291

Timestep Collection Time: 4.40989
Timestep Consumption Time: 1.15175
PPO Batch Consumption Time: 0.09821
Total Iteration Time: 5.56164

Cumulative Model Updates: 8553
Cumulative Timesteps: 142716918

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07883
Policy Entropy: 1.25815
Value Function Loss: 0.05508

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06506
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.07736

Collected Steps per Second: 11647.90418
Overall Steps per Second: 9246.72198

Timestep Collection Time: 4.29296
Timestep Consumption Time: 1.11479
PPO Batch Consumption Time: 0.08976
Total Iteration Time: 5.40775

Cumulative Model Updates: 8556
Cumulative Timesteps: 142766922

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 142766922...
Checkpoint 142766922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05933
Policy Entropy: 1.26269
Value Function Loss: 0.05501

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.05062
Value Function Update Magnitude: 0.08244

Collected Steps per Second: 11583.95139
Overall Steps per Second: 9295.90980

Timestep Collection Time: 4.31822
Timestep Consumption Time: 1.06286
PPO Batch Consumption Time: 0.07504
Total Iteration Time: 5.38108

Cumulative Model Updates: 8559
Cumulative Timesteps: 142816944

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.21362
Policy Entropy: 1.27398
Value Function Loss: 0.05241

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.05744
Policy Update Magnitude: 0.04954
Value Function Update Magnitude: 0.07568

Collected Steps per Second: 11847.15891
Overall Steps per Second: 9308.08651

Timestep Collection Time: 4.22397
Timestep Consumption Time: 1.15222
PPO Batch Consumption Time: 0.11909
Total Iteration Time: 5.37619

Cumulative Model Updates: 8562
Cumulative Timesteps: 142866986

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 142866986...
Checkpoint 142866986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13862
Policy Entropy: 1.27468
Value Function Loss: 0.05637

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05531
Policy Update Magnitude: 0.05145
Value Function Update Magnitude: 0.07630

Collected Steps per Second: 11791.46371
Overall Steps per Second: 9622.41631

Timestep Collection Time: 4.24205
Timestep Consumption Time: 0.95623
PPO Batch Consumption Time: 0.07781
Total Iteration Time: 5.19828

Cumulative Model Updates: 8565
Cumulative Timesteps: 142917006

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17293
Policy Entropy: 1.27421
Value Function Loss: 0.05586

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06533
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.06729

Collected Steps per Second: 11275.56176
Overall Steps per Second: 8963.79352

Timestep Collection Time: 4.43597
Timestep Consumption Time: 1.14404
PPO Batch Consumption Time: 0.09146
Total Iteration Time: 5.58000

Cumulative Model Updates: 8568
Cumulative Timesteps: 142967024

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 142967024...
Checkpoint 142967024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03916
Policy Entropy: 1.26895
Value Function Loss: 0.05305

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.05379
Value Function Update Magnitude: 0.07315

Collected Steps per Second: 11912.70547
Overall Steps per Second: 9315.78577

Timestep Collection Time: 4.19972
Timestep Consumption Time: 1.17074
PPO Batch Consumption Time: 0.12507
Total Iteration Time: 5.37045

Cumulative Model Updates: 8571
Cumulative Timesteps: 143017054

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11397
Policy Entropy: 1.27240
Value Function Loss: 0.04378

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.05508
Value Function Update Magnitude: 0.08461

Collected Steps per Second: 11881.76013
Overall Steps per Second: 9263.29674

Timestep Collection Time: 4.20897
Timestep Consumption Time: 1.18975
PPO Batch Consumption Time: 0.11731
Total Iteration Time: 5.39873

Cumulative Model Updates: 8574
Cumulative Timesteps: 143067064

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 143067064...
Checkpoint 143067064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01338
Policy Entropy: 1.26052
Value Function Loss: 0.03748

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.08173
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.07931

Collected Steps per Second: 11913.32508
Overall Steps per Second: 9286.24503

Timestep Collection Time: 4.19984
Timestep Consumption Time: 1.18813
PPO Batch Consumption Time: 0.11157
Total Iteration Time: 5.38797

Cumulative Model Updates: 8577
Cumulative Timesteps: 143117098

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01009
Policy Entropy: 1.25688
Value Function Loss: 0.04198

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.04785
Value Function Update Magnitude: 0.07325

Collected Steps per Second: 11582.53035
Overall Steps per Second: 9285.08179

Timestep Collection Time: 4.32116
Timestep Consumption Time: 1.06920
PPO Batch Consumption Time: 0.11077
Total Iteration Time: 5.39037

Cumulative Model Updates: 8580
Cumulative Timesteps: 143167148

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 143167148...
Checkpoint 143167148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15795
Policy Entropy: 1.25726
Value Function Loss: 0.05071

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.07945

Collected Steps per Second: 11695.17723
Overall Steps per Second: 9247.05641

Timestep Collection Time: 4.27920
Timestep Consumption Time: 1.13290
PPO Batch Consumption Time: 0.07638
Total Iteration Time: 5.41210

Cumulative Model Updates: 8583
Cumulative Timesteps: 143217194

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03744
Policy Entropy: 1.26431
Value Function Loss: 0.04732

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.09156

Collected Steps per Second: 11808.27349
Overall Steps per Second: 9319.99893

Timestep Collection Time: 4.23449
Timestep Consumption Time: 1.13053
PPO Batch Consumption Time: 0.10059
Total Iteration Time: 5.36502

Cumulative Model Updates: 8586
Cumulative Timesteps: 143267196

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 143267196...
Checkpoint 143267196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01538
Policy Entropy: 1.26156
Value Function Loss: 0.03838

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.08684

Collected Steps per Second: 12083.21906
Overall Steps per Second: 9284.70609

Timestep Collection Time: 4.14078
Timestep Consumption Time: 1.24808
PPO Batch Consumption Time: 0.13086
Total Iteration Time: 5.38886

Cumulative Model Updates: 8589
Cumulative Timesteps: 143317230

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07899
Policy Entropy: 1.26033
Value Function Loss: 0.03576

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06083
Policy Update Magnitude: 0.04575
Value Function Update Magnitude: 0.07619

Collected Steps per Second: 11767.36545
Overall Steps per Second: 9291.49597

Timestep Collection Time: 4.25091
Timestep Consumption Time: 1.13272
PPO Batch Consumption Time: 0.10469
Total Iteration Time: 5.38363

Cumulative Model Updates: 8592
Cumulative Timesteps: 143367252

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 143367252...
Checkpoint 143367252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05047
Policy Entropy: 1.25829
Value Function Loss: 0.04440

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06567
Policy Update Magnitude: 0.04704
Value Function Update Magnitude: 0.07045

Collected Steps per Second: 11867.69115
Overall Steps per Second: 9636.36465

Timestep Collection Time: 4.21447
Timestep Consumption Time: 0.97587
PPO Batch Consumption Time: 0.08966
Total Iteration Time: 5.19034

Cumulative Model Updates: 8595
Cumulative Timesteps: 143417268

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02535
Policy Entropy: 1.26567
Value Function Loss: 0.04968

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.05197
Policy Update Magnitude: 0.04519
Value Function Update Magnitude: 0.07331

Collected Steps per Second: 12108.52551
Overall Steps per Second: 9615.25370

Timestep Collection Time: 4.13147
Timestep Consumption Time: 1.07131
PPO Batch Consumption Time: 0.08303
Total Iteration Time: 5.20277

Cumulative Model Updates: 8598
Cumulative Timesteps: 143467294

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 143467294...
Checkpoint 143467294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07960
Policy Entropy: 1.26021
Value Function Loss: 0.06192

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05523
Policy Update Magnitude: 0.04520
Value Function Update Magnitude: 0.06933

Collected Steps per Second: 11676.87731
Overall Steps per Second: 9380.91066

Timestep Collection Time: 4.28385
Timestep Consumption Time: 1.04847
PPO Batch Consumption Time: 0.07469
Total Iteration Time: 5.33232

Cumulative Model Updates: 8601
Cumulative Timesteps: 143517316

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10774
Policy Entropy: 1.25163
Value Function Loss: 0.05712

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.04799
Value Function Update Magnitude: 0.07425

Collected Steps per Second: 11506.25854
Overall Steps per Second: 9205.22938

Timestep Collection Time: 4.34598
Timestep Consumption Time: 1.08636
PPO Batch Consumption Time: 0.11938
Total Iteration Time: 5.43235

Cumulative Model Updates: 8604
Cumulative Timesteps: 143567322

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 143567322...
Checkpoint 143567322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01742
Policy Entropy: 1.25463
Value Function Loss: 0.04508

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.07595

Collected Steps per Second: 13493.80533
Overall Steps per Second: 10926.42301

Timestep Collection Time: 3.70792
Timestep Consumption Time: 0.87125
PPO Batch Consumption Time: 0.05720
Total Iteration Time: 4.57917

Cumulative Model Updates: 8607
Cumulative Timesteps: 143617356

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06541
Policy Entropy: 1.25829
Value Function Loss: 0.03747

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.07123

Collected Steps per Second: 11739.70146
Overall Steps per Second: 9624.19567

Timestep Collection Time: 4.26229
Timestep Consumption Time: 0.93690
PPO Batch Consumption Time: 0.08987
Total Iteration Time: 5.19919

Cumulative Model Updates: 8610
Cumulative Timesteps: 143667394

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 143667394...
Checkpoint 143667394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07949
Policy Entropy: 1.25834
Value Function Loss: 0.03982

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06084
Policy Update Magnitude: 0.04626
Value Function Update Magnitude: 0.07494

Collected Steps per Second: 12859.35902
Overall Steps per Second: 10453.21737

Timestep Collection Time: 3.89102
Timestep Consumption Time: 0.89564
PPO Batch Consumption Time: 0.06089
Total Iteration Time: 4.78666

Cumulative Model Updates: 8613
Cumulative Timesteps: 143717430

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11811
Policy Entropy: 1.25344
Value Function Loss: 0.04413

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.04872
Value Function Update Magnitude: 0.08019

Collected Steps per Second: 12384.15588
Overall Steps per Second: 9994.88746

Timestep Collection Time: 4.03742
Timestep Consumption Time: 0.96514
PPO Batch Consumption Time: 0.08285
Total Iteration Time: 5.00256

Cumulative Model Updates: 8616
Cumulative Timesteps: 143767430

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 143767430...
Checkpoint 143767430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15862
Policy Entropy: 1.26115
Value Function Loss: 0.03791

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.04482
Value Function Update Magnitude: 0.07340

Collected Steps per Second: 13432.82745
Overall Steps per Second: 10481.94066

Timestep Collection Time: 3.72222
Timestep Consumption Time: 1.04788
PPO Batch Consumption Time: 0.10342
Total Iteration Time: 4.77011

Cumulative Model Updates: 8619
Cumulative Timesteps: 143817430

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06029
Policy Entropy: 1.27130
Value Function Loss: 0.04202

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05230
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.06352

Collected Steps per Second: 12882.21163
Overall Steps per Second: 10387.85537

Timestep Collection Time: 3.88132
Timestep Consumption Time: 0.93199
PPO Batch Consumption Time: 0.06986
Total Iteration Time: 4.81331

Cumulative Model Updates: 8622
Cumulative Timesteps: 143867430

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 143867430...
Checkpoint 143867430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04720
Policy Entropy: 1.25996
Value Function Loss: 0.04510

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05832
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.07167

Collected Steps per Second: 12063.63035
Overall Steps per Second: 9693.21682

Timestep Collection Time: 4.14850
Timestep Consumption Time: 1.01449
PPO Batch Consumption Time: 0.10019
Total Iteration Time: 5.16299

Cumulative Model Updates: 8625
Cumulative Timesteps: 143917476

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14837
Policy Entropy: 1.26110
Value Function Loss: 0.04703

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.04490
Value Function Update Magnitude: 0.08052

Collected Steps per Second: 12875.88683
Overall Steps per Second: 10479.33436

Timestep Collection Time: 3.88447
Timestep Consumption Time: 0.88835
PPO Batch Consumption Time: 0.06253
Total Iteration Time: 4.77282

Cumulative Model Updates: 8628
Cumulative Timesteps: 143967492

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 143967492...
Checkpoint 143967492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01479
Policy Entropy: 1.26275
Value Function Loss: 0.04653

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.06391
Policy Update Magnitude: 0.04436
Value Function Update Magnitude: 0.07848

Collected Steps per Second: 12200.48178
Overall Steps per Second: 9616.71075

Timestep Collection Time: 4.10115
Timestep Consumption Time: 1.10188
PPO Batch Consumption Time: 0.12084
Total Iteration Time: 5.20303

Cumulative Model Updates: 8631
Cumulative Timesteps: 144017528

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11326
Policy Entropy: 1.26391
Value Function Loss: 0.05042

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.05787
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.08213

Collected Steps per Second: 13463.53899
Overall Steps per Second: 10817.28661

Timestep Collection Time: 3.71507
Timestep Consumption Time: 0.90882
PPO Batch Consumption Time: 0.06072
Total Iteration Time: 4.62390

Cumulative Model Updates: 8634
Cumulative Timesteps: 144067546

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 144067546...
Checkpoint 144067546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10801
Policy Entropy: 1.25722
Value Function Loss: 0.04774

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04681
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.08329

Collected Steps per Second: 12050.13084
Overall Steps per Second: 9683.77732

Timestep Collection Time: 4.15232
Timestep Consumption Time: 1.01467
PPO Batch Consumption Time: 0.09531
Total Iteration Time: 5.16699

Cumulative Model Updates: 8637
Cumulative Timesteps: 144117582

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14430
Policy Entropy: 1.25482
Value Function Loss: 0.04857

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04757
Policy Update Magnitude: 0.04608
Value Function Update Magnitude: 0.08641

Collected Steps per Second: 13238.43416
Overall Steps per Second: 10932.55726

Timestep Collection Time: 3.77733
Timestep Consumption Time: 0.79671
PPO Batch Consumption Time: 0.05838
Total Iteration Time: 4.57404

Cumulative Model Updates: 8640
Cumulative Timesteps: 144167588

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 144167588...
Checkpoint 144167588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20978
Policy Entropy: 1.24790
Value Function Loss: 0.04408

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05401
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.07434

Collected Steps per Second: 12533.12781
Overall Steps per Second: 9982.20846

Timestep Collection Time: 3.99007
Timestep Consumption Time: 1.01965
PPO Batch Consumption Time: 0.09069
Total Iteration Time: 5.00971

Cumulative Model Updates: 8643
Cumulative Timesteps: 144217596

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02015
Policy Entropy: 1.24713
Value Function Loss: 0.04776

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.04806
Value Function Update Magnitude: 0.07006

Collected Steps per Second: 13240.24649
Overall Steps per Second: 10767.27732

Timestep Collection Time: 3.77923
Timestep Consumption Time: 0.86799
PPO Batch Consumption Time: 0.06281
Total Iteration Time: 4.64723

Cumulative Model Updates: 8646
Cumulative Timesteps: 144267634

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 144267634...
Checkpoint 144267634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00990
Policy Entropy: 1.24606
Value Function Loss: 0.05022

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.05192
Value Function Update Magnitude: 0.06278

Collected Steps per Second: 12383.72867
Overall Steps per Second: 9783.50085

Timestep Collection Time: 4.03820
Timestep Consumption Time: 1.07326
PPO Batch Consumption Time: 0.11654
Total Iteration Time: 5.11146

Cumulative Model Updates: 8649
Cumulative Timesteps: 144317642

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00865
Policy Entropy: 1.24677
Value Function Loss: 0.05142

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.05945

Collected Steps per Second: 13000.27397
Overall Steps per Second: 10041.98745

Timestep Collection Time: 3.84792
Timestep Consumption Time: 1.13357
PPO Batch Consumption Time: 0.12389
Total Iteration Time: 4.98148

Cumulative Model Updates: 8652
Cumulative Timesteps: 144367666

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 144367666...
Checkpoint 144367666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00062
Policy Entropy: 1.24684
Value Function Loss: 0.05400

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.05888

Collected Steps per Second: 13048.89795
Overall Steps per Second: 10755.39761

Timestep Collection Time: 3.83481
Timestep Consumption Time: 0.81774
PPO Batch Consumption Time: 0.06398
Total Iteration Time: 4.65255

Cumulative Model Updates: 8655
Cumulative Timesteps: 144417706

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09253
Policy Entropy: 1.24796
Value Function Loss: 0.04975

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07689
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.05927

Collected Steps per Second: 12311.49920
Overall Steps per Second: 9746.51126

Timestep Collection Time: 4.06417
Timestep Consumption Time: 1.06957
PPO Batch Consumption Time: 0.11221
Total Iteration Time: 5.13373

Cumulative Model Updates: 8658
Cumulative Timesteps: 144467742

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 144467742...
Checkpoint 144467742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00615
Policy Entropy: 1.25024
Value Function Loss: 0.05926

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08379
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.06168

Collected Steps per Second: 13556.93131
Overall Steps per Second: 10948.70877

Timestep Collection Time: 3.69184
Timestep Consumption Time: 0.87948
PPO Batch Consumption Time: 0.06006
Total Iteration Time: 4.57132

Cumulative Model Updates: 8661
Cumulative Timesteps: 144517792

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01211
Policy Entropy: 1.25110
Value Function Loss: 0.04971

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.06514

Collected Steps per Second: 12779.71950
Overall Steps per Second: 9996.04286

Timestep Collection Time: 3.91448
Timestep Consumption Time: 1.09010
PPO Batch Consumption Time: 0.11012
Total Iteration Time: 5.00458

Cumulative Model Updates: 8664
Cumulative Timesteps: 144567818

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 144567818...
Checkpoint 144567818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00954
Policy Entropy: 1.25476
Value Function Loss: 0.05329

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06011
Policy Update Magnitude: 0.05598
Value Function Update Magnitude: 0.06588

Collected Steps per Second: 12994.10118
Overall Steps per Second: 10542.33124

Timestep Collection Time: 3.85052
Timestep Consumption Time: 0.89549
PPO Batch Consumption Time: 0.06277
Total Iteration Time: 4.74601

Cumulative Model Updates: 8667
Cumulative Timesteps: 144617852

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04335
Policy Entropy: 1.26324
Value Function Loss: 0.04751

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06104
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 12783.56577
Overall Steps per Second: 10314.25249

Timestep Collection Time: 3.91362
Timestep Consumption Time: 0.93695
PPO Batch Consumption Time: 0.09366
Total Iteration Time: 4.85057

Cumulative Model Updates: 8670
Cumulative Timesteps: 144667882

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 144667882...
Checkpoint 144667882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01801
Policy Entropy: 1.25096
Value Function Loss: 0.05256

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.05658
Value Function Update Magnitude: 0.07105

Collected Steps per Second: 13307.17532
Overall Steps per Second: 10743.04311

Timestep Collection Time: 3.76038
Timestep Consumption Time: 0.89752
PPO Batch Consumption Time: 0.06261
Total Iteration Time: 4.65790

Cumulative Model Updates: 8673
Cumulative Timesteps: 144717922

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00736
Policy Entropy: 1.24568
Value Function Loss: 0.04804

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.07497

Collected Steps per Second: 12239.39674
Overall Steps per Second: 9789.45235

Timestep Collection Time: 4.08909
Timestep Consumption Time: 1.02335
PPO Batch Consumption Time: 0.10038
Total Iteration Time: 5.11244

Cumulative Model Updates: 8676
Cumulative Timesteps: 144767970

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 144767970...
Checkpoint 144767970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00324
Policy Entropy: 1.25217
Value Function Loss: 0.04546

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.05112
Value Function Update Magnitude: 0.06956

Collected Steps per Second: 13672.89983
Overall Steps per Second: 10496.85023

Timestep Collection Time: 3.65979
Timestep Consumption Time: 1.10735
PPO Batch Consumption Time: 0.12094
Total Iteration Time: 4.76714

Cumulative Model Updates: 8679
Cumulative Timesteps: 144818010

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09482
Policy Entropy: 1.25272
Value Function Loss: 0.03683

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.06604

Collected Steps per Second: 13567.48179
Overall Steps per Second: 10441.26859

Timestep Collection Time: 3.68543
Timestep Consumption Time: 1.10345
PPO Batch Consumption Time: 0.12079
Total Iteration Time: 4.78888

Cumulative Model Updates: 8682
Cumulative Timesteps: 144868012

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 144868012...
Checkpoint 144868012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04546
Policy Entropy: 1.25023
Value Function Loss: 0.04124

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.04770
Value Function Update Magnitude: 0.06408

Collected Steps per Second: 13269.86518
Overall Steps per Second: 10432.91011

Timestep Collection Time: 3.76824
Timestep Consumption Time: 1.02467
PPO Batch Consumption Time: 0.10121
Total Iteration Time: 4.79291

Cumulative Model Updates: 8685
Cumulative Timesteps: 144918016

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03611
Policy Entropy: 1.25188
Value Function Loss: 0.04279

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.06467

Collected Steps per Second: 13586.57643
Overall Steps per Second: 10439.21781

Timestep Collection Time: 3.68202
Timestep Consumption Time: 1.11010
PPO Batch Consumption Time: 0.12410
Total Iteration Time: 4.79212

Cumulative Model Updates: 8688
Cumulative Timesteps: 144968042

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 144968042...
Checkpoint 144968042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07627
Policy Entropy: 1.25952
Value Function Loss: 0.04774

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.06659

Collected Steps per Second: 13054.58927
Overall Steps per Second: 10393.37786

Timestep Collection Time: 3.83145
Timestep Consumption Time: 0.98104
PPO Batch Consumption Time: 0.09016
Total Iteration Time: 4.81249

Cumulative Model Updates: 8691
Cumulative Timesteps: 145018060

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01698
Policy Entropy: 1.26057
Value Function Loss: 0.05694

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.05418
Value Function Update Magnitude: 0.06745

Collected Steps per Second: 13064.84001
Overall Steps per Second: 10461.95260

Timestep Collection Time: 3.82951
Timestep Consumption Time: 0.95277
PPO Batch Consumption Time: 0.10157
Total Iteration Time: 4.78228

Cumulative Model Updates: 8694
Cumulative Timesteps: 145068092

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 145068092...
Checkpoint 145068092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03576
Policy Entropy: 1.26036
Value Function Loss: 0.06326

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05619
Policy Update Magnitude: 0.05294
Value Function Update Magnitude: 0.07429

Collected Steps per Second: 13266.38018
Overall Steps per Second: 10473.81646

Timestep Collection Time: 3.77089
Timestep Consumption Time: 1.00541
PPO Batch Consumption Time: 0.09355
Total Iteration Time: 4.77629

Cumulative Model Updates: 8697
Cumulative Timesteps: 145118118

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11955
Policy Entropy: 1.26445
Value Function Loss: 0.06924

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05469
Policy Update Magnitude: 0.05011
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 13041.01737
Overall Steps per Second: 10435.07310

Timestep Collection Time: 3.83651
Timestep Consumption Time: 0.95809
PPO Batch Consumption Time: 0.07467
Total Iteration Time: 4.79460

Cumulative Model Updates: 8700
Cumulative Timesteps: 145168150

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 145168150...
Checkpoint 145168150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10238
Policy Entropy: 1.26500
Value Function Loss: 0.05081

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04613
Policy Update Magnitude: 0.04976
Value Function Update Magnitude: 0.06947

Collected Steps per Second: 12001.44321
Overall Steps per Second: 9645.70902

Timestep Collection Time: 4.16967
Timestep Consumption Time: 1.01834
PPO Batch Consumption Time: 0.07271
Total Iteration Time: 5.18801

Cumulative Model Updates: 8703
Cumulative Timesteps: 145218192

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08977
Policy Entropy: 1.25618
Value Function Loss: 0.03867

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04455
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 12999.93946
Overall Steps per Second: 10558.42803

Timestep Collection Time: 3.84694
Timestep Consumption Time: 0.88956
PPO Batch Consumption Time: 0.06572
Total Iteration Time: 4.73650

Cumulative Model Updates: 8706
Cumulative Timesteps: 145268202

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 145268202...
Checkpoint 145268202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10426
Policy Entropy: 1.25850
Value Function Loss: 0.04046

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06066
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.07275

Collected Steps per Second: 12947.95096
Overall Steps per Second: 10382.18867

Timestep Collection Time: 3.86362
Timestep Consumption Time: 0.95482
PPO Batch Consumption Time: 0.09859
Total Iteration Time: 4.81844

Cumulative Model Updates: 8709
Cumulative Timesteps: 145318228

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06153
Policy Entropy: 1.25446
Value Function Loss: 0.05139

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06381
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 13511.22002
Overall Steps per Second: 10901.08480

Timestep Collection Time: 3.70196
Timestep Consumption Time: 0.88639
PPO Batch Consumption Time: 0.06040
Total Iteration Time: 4.58835

Cumulative Model Updates: 8712
Cumulative Timesteps: 145368246

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 145368246...
Checkpoint 145368246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03458
Policy Entropy: 1.26254
Value Function Loss: 0.05246

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07084
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.07218

Collected Steps per Second: 11758.14726
Overall Steps per Second: 9586.44036

Timestep Collection Time: 4.25390
Timestep Consumption Time: 0.96368
PPO Batch Consumption Time: 0.08332
Total Iteration Time: 5.21758

Cumulative Model Updates: 8715
Cumulative Timesteps: 145418264

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02921
Policy Entropy: 1.25709
Value Function Loss: 0.04503

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.07658

Collected Steps per Second: 13721.07311
Overall Steps per Second: 10873.94418

Timestep Collection Time: 3.64505
Timestep Consumption Time: 0.95438
PPO Batch Consumption Time: 0.07750
Total Iteration Time: 4.59944

Cumulative Model Updates: 8718
Cumulative Timesteps: 145468278

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 145468278...
Checkpoint 145468278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06933
Policy Entropy: 1.25552
Value Function Loss: 0.03571

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06994
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 13262.80504
Overall Steps per Second: 10667.78522

Timestep Collection Time: 3.77009
Timestep Consumption Time: 0.91710
PPO Batch Consumption Time: 0.06347
Total Iteration Time: 4.68720

Cumulative Model Updates: 8721
Cumulative Timesteps: 145518280

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12383
Policy Entropy: 1.25330
Value Function Loss: 0.03407

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.05661
Policy Update Magnitude: 0.04441
Value Function Update Magnitude: 0.06157

Collected Steps per Second: 13288.94353
Overall Steps per Second: 10304.57999

Timestep Collection Time: 3.76373
Timestep Consumption Time: 1.09003
PPO Batch Consumption Time: 0.11926
Total Iteration Time: 4.85376

Cumulative Model Updates: 8724
Cumulative Timesteps: 145568296

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 145568296...
Checkpoint 145568296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04741
Policy Entropy: 1.25567
Value Function Loss: 0.04360

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04971
Policy Update Magnitude: 0.04386
Value Function Update Magnitude: 0.05960

Collected Steps per Second: 13621.54391
Overall Steps per Second: 10900.88983

Timestep Collection Time: 3.67095
Timestep Consumption Time: 0.91620
PPO Batch Consumption Time: 0.06304
Total Iteration Time: 4.58715

Cumulative Model Updates: 8727
Cumulative Timesteps: 145618300

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07869
Policy Entropy: 1.24892
Value Function Loss: 0.04203

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04656
Policy Update Magnitude: 0.04338
Value Function Update Magnitude: 0.05814

Collected Steps per Second: 10636.25914
Overall Steps per Second: 8592.75120

Timestep Collection Time: 4.70222
Timestep Consumption Time: 1.11827
PPO Batch Consumption Time: 0.08751
Total Iteration Time: 5.82049

Cumulative Model Updates: 8730
Cumulative Timesteps: 145668314

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 145668314...
Checkpoint 145668314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10951
Policy Entropy: 1.25179
Value Function Loss: 0.04748

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06030
Policy Update Magnitude: 0.04448
Value Function Update Magnitude: 0.05631

Collected Steps per Second: 11686.10180
Overall Steps per Second: 9347.47930

Timestep Collection Time: 4.28081
Timestep Consumption Time: 1.07101
PPO Batch Consumption Time: 0.12392
Total Iteration Time: 5.35182

Cumulative Model Updates: 8733
Cumulative Timesteps: 145718340

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00132
Policy Entropy: 1.25319
Value Function Loss: 0.03676

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06814
Policy Update Magnitude: 0.04450
Value Function Update Magnitude: 0.05921

Collected Steps per Second: 11795.96251
Overall Steps per Second: 9235.24039

Timestep Collection Time: 4.23976
Timestep Consumption Time: 1.17559
PPO Batch Consumption Time: 0.10251
Total Iteration Time: 5.41534

Cumulative Model Updates: 8736
Cumulative Timesteps: 145768352

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 145768352...
Checkpoint 145768352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06272
Policy Entropy: 1.25854
Value Function Loss: 0.04841

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.05745
Policy Update Magnitude: 0.04385
Value Function Update Magnitude: 0.06183

Collected Steps per Second: 11694.72506
Overall Steps per Second: 9321.04239

Timestep Collection Time: 4.27560
Timestep Consumption Time: 1.08882
PPO Batch Consumption Time: 0.09920
Total Iteration Time: 5.36442

Cumulative Model Updates: 8739
Cumulative Timesteps: 145818354

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.15640
Policy Entropy: 1.25192
Value Function Loss: 0.04324

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05355
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.06133

Collected Steps per Second: 11767.42213
Overall Steps per Second: 9266.64029

Timestep Collection Time: 4.25242
Timestep Consumption Time: 1.14760
PPO Batch Consumption Time: 0.10683
Total Iteration Time: 5.40002

Cumulative Model Updates: 8742
Cumulative Timesteps: 145868394

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 145868394...
Checkpoint 145868394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05695
Policy Entropy: 1.25332
Value Function Loss: 0.04886

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06491
Policy Update Magnitude: 0.04623
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 11829.98302
Overall Steps per Second: 9295.01345

Timestep Collection Time: 4.22723
Timestep Consumption Time: 1.15286
PPO Batch Consumption Time: 0.11598
Total Iteration Time: 5.38009

Cumulative Model Updates: 8745
Cumulative Timesteps: 145918402

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09610
Policy Entropy: 1.24838
Value Function Loss: 0.04813

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.05553
Value Function Update Magnitude: 0.06604

Collected Steps per Second: 11874.53661
Overall Steps per Second: 9606.97558

Timestep Collection Time: 4.21136
Timestep Consumption Time: 0.99402
PPO Batch Consumption Time: 0.09038
Total Iteration Time: 5.20538

Cumulative Model Updates: 8748
Cumulative Timesteps: 145968410

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 145968410...
Checkpoint 145968410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06039
Policy Entropy: 1.24946
Value Function Loss: 0.04865

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.06975

Collected Steps per Second: 11992.52734
Overall Steps per Second: 9339.56915

Timestep Collection Time: 4.17226
Timestep Consumption Time: 1.18516
PPO Batch Consumption Time: 0.12230
Total Iteration Time: 5.35742

Cumulative Model Updates: 8751
Cumulative Timesteps: 146018446

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03250
Policy Entropy: 1.25157
Value Function Loss: 0.05097

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.07826

Collected Steps per Second: 11753.72986
Overall Steps per Second: 9551.02638

Timestep Collection Time: 4.25567
Timestep Consumption Time: 0.98146
PPO Batch Consumption Time: 0.07154
Total Iteration Time: 5.23713

Cumulative Model Updates: 8754
Cumulative Timesteps: 146068466

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 146068466...
Checkpoint 146068466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03943
Policy Entropy: 1.26137
Value Function Loss: 0.04806

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.07087

Collected Steps per Second: 10963.92645
Overall Steps per Second: 8713.06210

Timestep Collection Time: 4.56150
Timestep Consumption Time: 1.17838
PPO Batch Consumption Time: 0.11994
Total Iteration Time: 5.73989

Cumulative Model Updates: 8757
Cumulative Timesteps: 146118478

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05169
Policy Entropy: 1.26482
Value Function Loss: 0.04818

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.06997

Collected Steps per Second: 11773.71942
Overall Steps per Second: 9243.56249

Timestep Collection Time: 4.24760
Timestep Consumption Time: 1.16266
PPO Batch Consumption Time: 0.10056
Total Iteration Time: 5.41025

Cumulative Model Updates: 8760
Cumulative Timesteps: 146168488

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 146168488...
Checkpoint 146168488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01645
Policy Entropy: 1.26301
Value Function Loss: 0.04833

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.08205

Collected Steps per Second: 11343.53343
Overall Steps per Second: 8977.02119

Timestep Collection Time: 4.40797
Timestep Consumption Time: 1.16203
PPO Batch Consumption Time: 0.10032
Total Iteration Time: 5.57000

Cumulative Model Updates: 8763
Cumulative Timesteps: 146218490

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04215
Policy Entropy: 1.26082
Value Function Loss: 0.05314

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07094
Policy Update Magnitude: 0.04721
Value Function Update Magnitude: 0.07753

Collected Steps per Second: 12254.02171
Overall Steps per Second: 9736.15744

Timestep Collection Time: 4.08160
Timestep Consumption Time: 1.05554
PPO Batch Consumption Time: 0.07471
Total Iteration Time: 5.13714

Cumulative Model Updates: 8766
Cumulative Timesteps: 146268506

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 146268506...
Checkpoint 146268506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03518
Policy Entropy: 1.26038
Value Function Loss: 0.05273

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06707
Policy Update Magnitude: 0.04729
Value Function Update Magnitude: 0.07317

Collected Steps per Second: 11211.99002
Overall Steps per Second: 8879.35314

Timestep Collection Time: 4.46183
Timestep Consumption Time: 1.17214
PPO Batch Consumption Time: 0.10979
Total Iteration Time: 5.63397

Cumulative Model Updates: 8769
Cumulative Timesteps: 146318532

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03485
Policy Entropy: 1.25302
Value Function Loss: 0.04320

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06624
Policy Update Magnitude: 0.05031
Value Function Update Magnitude: 0.06901

Collected Steps per Second: 11714.60327
Overall Steps per Second: 9669.22059

Timestep Collection Time: 4.27074
Timestep Consumption Time: 0.90341
PPO Batch Consumption Time: 0.06808
Total Iteration Time: 5.17415

Cumulative Model Updates: 8772
Cumulative Timesteps: 146368562

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 146368562...
Checkpoint 146368562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08358
Policy Entropy: 1.25720
Value Function Loss: 0.05006

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.04881
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.07002

Collected Steps per Second: 10977.25835
Overall Steps per Second: 8884.95761

Timestep Collection Time: 4.55688
Timestep Consumption Time: 1.07309
PPO Batch Consumption Time: 0.08264
Total Iteration Time: 5.62996

Cumulative Model Updates: 8775
Cumulative Timesteps: 146418584

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04429
Policy Entropy: 1.25496
Value Function Loss: 0.06525

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.05241
Value Function Update Magnitude: 0.06947

Collected Steps per Second: 11892.64071
Overall Steps per Second: 9632.27979

Timestep Collection Time: 4.20512
Timestep Consumption Time: 0.98680
PPO Batch Consumption Time: 0.06906
Total Iteration Time: 5.19192

Cumulative Model Updates: 8778
Cumulative Timesteps: 146468594

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 146468594...
Checkpoint 146468594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02698
Policy Entropy: 1.25488
Value Function Loss: 0.06953

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.07341

Collected Steps per Second: 10548.24824
Overall Steps per Second: 8412.59128

Timestep Collection Time: 4.74297
Timestep Consumption Time: 1.20407
PPO Batch Consumption Time: 0.11180
Total Iteration Time: 5.94704

Cumulative Model Updates: 8781
Cumulative Timesteps: 146518624

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05785
Policy Entropy: 1.24719
Value Function Loss: 0.06026

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.04788
Value Function Update Magnitude: 0.07804

Collected Steps per Second: 13350.80884
Overall Steps per Second: 10431.83749

Timestep Collection Time: 3.74689
Timestep Consumption Time: 1.04843
PPO Batch Consumption Time: 0.10118
Total Iteration Time: 4.79532

Cumulative Model Updates: 8784
Cumulative Timesteps: 146568648

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 146568648...
Checkpoint 146568648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04984
Policy Entropy: 1.24680
Value Function Loss: 0.03751

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.07973

Collected Steps per Second: 12353.34484
Overall Steps per Second: 10007.03871

Timestep Collection Time: 4.04975
Timestep Consumption Time: 0.94953
PPO Batch Consumption Time: 0.09992
Total Iteration Time: 4.99928

Cumulative Model Updates: 8787
Cumulative Timesteps: 146618676

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09321
Policy Entropy: 1.24777
Value Function Loss: 0.03584

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06082
Policy Update Magnitude: 0.04244
Value Function Update Magnitude: 0.07249

Collected Steps per Second: 13034.22501
Overall Steps per Second: 10538.03398

Timestep Collection Time: 3.83774
Timestep Consumption Time: 0.90906
PPO Batch Consumption Time: 0.06556
Total Iteration Time: 4.74681

Cumulative Model Updates: 8790
Cumulative Timesteps: 146668698

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 146668698...
Checkpoint 146668698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11737
Policy Entropy: 1.24649
Value Function Loss: 0.03085

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.04005
Value Function Update Magnitude: 0.07403

Collected Steps per Second: 13008.39269
Overall Steps per Second: 10375.77090

Timestep Collection Time: 3.84598
Timestep Consumption Time: 0.97583
PPO Batch Consumption Time: 0.08282
Total Iteration Time: 4.82181

Cumulative Model Updates: 8793
Cumulative Timesteps: 146718728

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01564
Policy Entropy: 1.24986
Value Function Loss: 0.04250

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.04208
Value Function Update Magnitude: 0.07201

Collected Steps per Second: 13703.38018
Overall Steps per Second: 11006.70096

Timestep Collection Time: 3.64903
Timestep Consumption Time: 0.89402
PPO Batch Consumption Time: 0.06353
Total Iteration Time: 4.54305

Cumulative Model Updates: 8796
Cumulative Timesteps: 146768732

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 146768732...
Checkpoint 146768732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12108
Policy Entropy: 1.25224
Value Function Loss: 0.04528

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06518
Policy Update Magnitude: 0.04383
Value Function Update Magnitude: 0.06974

Collected Steps per Second: 13225.70525
Overall Steps per Second: 10344.26251

Timestep Collection Time: 3.78309
Timestep Consumption Time: 1.05380
PPO Batch Consumption Time: 0.10338
Total Iteration Time: 4.83688

Cumulative Model Updates: 8799
Cumulative Timesteps: 146818766

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03658
Policy Entropy: 1.26061
Value Function Loss: 0.05436

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06012
Policy Update Magnitude: 0.04414
Value Function Update Magnitude: 0.06922

Collected Steps per Second: 13155.36543
Overall Steps per Second: 10451.20879

Timestep Collection Time: 3.80195
Timestep Consumption Time: 0.98372
PPO Batch Consumption Time: 0.11293
Total Iteration Time: 4.78567

Cumulative Model Updates: 8802
Cumulative Timesteps: 146868782

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 146868782...
Checkpoint 146868782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00727
Policy Entropy: 1.26105
Value Function Loss: 0.05535

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06057
Policy Update Magnitude: 0.04751
Value Function Update Magnitude: 0.07269

Collected Steps per Second: 13331.17885
Overall Steps per Second: 10423.78627

Timestep Collection Time: 3.75091
Timestep Consumption Time: 1.04620
PPO Batch Consumption Time: 0.10703
Total Iteration Time: 4.79711

Cumulative Model Updates: 8805
Cumulative Timesteps: 146918786

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10845
Policy Entropy: 1.25678
Value Function Loss: 0.06017

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04909
Policy Update Magnitude: 0.05214
Value Function Update Magnitude: 0.07720

Collected Steps per Second: 12991.97744
Overall Steps per Second: 10416.60651

Timestep Collection Time: 3.85192
Timestep Consumption Time: 0.95234
PPO Batch Consumption Time: 0.07347
Total Iteration Time: 4.80425

Cumulative Model Updates: 8808
Cumulative Timesteps: 146968830

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 146968830...
Checkpoint 146968830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07891
Policy Entropy: 1.25267
Value Function Loss: 0.06311

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04739
Policy Update Magnitude: 0.05453
Value Function Update Magnitude: 0.08121

Collected Steps per Second: 13617.07230
Overall Steps per Second: 10508.95671

Timestep Collection Time: 3.67392
Timestep Consumption Time: 1.08659
PPO Batch Consumption Time: 0.11355
Total Iteration Time: 4.76051

Cumulative Model Updates: 8811
Cumulative Timesteps: 147018858

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03060
Policy Entropy: 1.24792
Value Function Loss: 0.06910

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06512
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.08682

Collected Steps per Second: 13343.08078
Overall Steps per Second: 10404.75995

Timestep Collection Time: 3.75086
Timestep Consumption Time: 1.05925
PPO Batch Consumption Time: 0.10037
Total Iteration Time: 4.81011

Cumulative Model Updates: 8814
Cumulative Timesteps: 147068906

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 147068906...
Checkpoint 147068906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00720
Policy Entropy: 1.24868
Value Function Loss: 0.06221

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.05769
Value Function Update Magnitude: 0.08791

Collected Steps per Second: 13214.47105
Overall Steps per Second: 10494.00947

Timestep Collection Time: 3.78418
Timestep Consumption Time: 0.98101
PPO Batch Consumption Time: 0.11360
Total Iteration Time: 4.76519

Cumulative Model Updates: 8817
Cumulative Timesteps: 147118912

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22617
Policy Entropy: 1.24746
Value Function Loss: 0.05480

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06637
Policy Update Magnitude: 0.05708
Value Function Update Magnitude: 0.08374

Collected Steps per Second: 13475.28451
Overall Steps per Second: 10413.19001

Timestep Collection Time: 3.71139
Timestep Consumption Time: 1.09137
PPO Batch Consumption Time: 0.11667
Total Iteration Time: 4.80275

Cumulative Model Updates: 8820
Cumulative Timesteps: 147168924

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 147168924...
Checkpoint 147168924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01376
Policy Entropy: 1.25017
Value Function Loss: 0.04384

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.07951

Collected Steps per Second: 13534.12663
Overall Steps per Second: 10436.83642

Timestep Collection Time: 3.69643
Timestep Consumption Time: 1.09697
PPO Batch Consumption Time: 0.10221
Total Iteration Time: 4.79341

Cumulative Model Updates: 8823
Cumulative Timesteps: 147218952

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11017
Policy Entropy: 1.25249
Value Function Loss: 0.04122

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 0.05481
Value Function Update Magnitude: 0.07656

Collected Steps per Second: 13104.68542
Overall Steps per Second: 10452.27270

Timestep Collection Time: 3.81879
Timestep Consumption Time: 0.96907
PPO Batch Consumption Time: 0.08320
Total Iteration Time: 4.78786

Cumulative Model Updates: 8826
Cumulative Timesteps: 147268996

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 147268996...
Checkpoint 147268996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12418
Policy Entropy: 1.25495
Value Function Loss: 0.04544

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07435
Policy Update Magnitude: 0.05677
Value Function Update Magnitude: 0.07233

Collected Steps per Second: 12942.43824
Overall Steps per Second: 10070.58272

Timestep Collection Time: 3.86635
Timestep Consumption Time: 1.10258
PPO Batch Consumption Time: 0.11958
Total Iteration Time: 4.96893

Cumulative Model Updates: 8829
Cumulative Timesteps: 147319036

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06678
Policy Entropy: 1.25478
Value Function Loss: 0.04731

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.07492

Collected Steps per Second: 13432.08733
Overall Steps per Second: 10991.14662

Timestep Collection Time: 3.72451
Timestep Consumption Time: 0.82715
PPO Batch Consumption Time: 0.06766
Total Iteration Time: 4.55166

Cumulative Model Updates: 8832
Cumulative Timesteps: 147369064

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 147369064...
Checkpoint 147369064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04174
Policy Entropy: 1.24936
Value Function Loss: 0.04565

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.08261

Collected Steps per Second: 12496.60525
Overall Steps per Second: 9949.69938

Timestep Collection Time: 4.00381
Timestep Consumption Time: 1.02489
PPO Batch Consumption Time: 0.08278
Total Iteration Time: 5.02869

Cumulative Model Updates: 8835
Cumulative Timesteps: 147419098

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18151
Policy Entropy: 1.24815
Value Function Loss: 0.05162

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.05219
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 13384.42703
Overall Steps per Second: 10886.51001

Timestep Collection Time: 3.73927
Timestep Consumption Time: 0.85798
PPO Batch Consumption Time: 0.05702
Total Iteration Time: 4.59725

Cumulative Model Updates: 8838
Cumulative Timesteps: 147469146

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 147469146...
Checkpoint 147469146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03252
Policy Entropy: 1.25669
Value Function Loss: 0.05509

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06347
Policy Update Magnitude: 0.05202
Value Function Update Magnitude: 0.07117

Collected Steps per Second: 12316.38453
Overall Steps per Second: 9999.39040

Timestep Collection Time: 4.05980
Timestep Consumption Time: 0.94071
PPO Batch Consumption Time: 0.07640
Total Iteration Time: 5.00050

Cumulative Model Updates: 8841
Cumulative Timesteps: 147519148

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14720
Policy Entropy: 1.25743
Value Function Loss: 0.05775

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05010
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.07465

Collected Steps per Second: 13287.29320
Overall Steps per Second: 10742.64141

Timestep Collection Time: 3.76480
Timestep Consumption Time: 0.89178
PPO Batch Consumption Time: 0.06425
Total Iteration Time: 4.65658

Cumulative Model Updates: 8844
Cumulative Timesteps: 147569172

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 147569172...
Checkpoint 147569172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02026
Policy Entropy: 1.25721
Value Function Loss: 0.05232

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05310
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.07235

Collected Steps per Second: 12014.58415
Overall Steps per Second: 9762.96009

Timestep Collection Time: 4.16161
Timestep Consumption Time: 0.95979
PPO Batch Consumption Time: 0.09661
Total Iteration Time: 5.12140

Cumulative Model Updates: 8847
Cumulative Timesteps: 147619172

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20738
Policy Entropy: 1.25639
Value Function Loss: 0.05220

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06131
Policy Update Magnitude: 0.04908
Value Function Update Magnitude: 0.06815

Collected Steps per Second: 13250.96725
Overall Steps per Second: 10661.39944

Timestep Collection Time: 3.77542
Timestep Consumption Time: 0.91702
PPO Batch Consumption Time: 0.06740
Total Iteration Time: 4.69244

Cumulative Model Updates: 8850
Cumulative Timesteps: 147669200

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 147669200...
Checkpoint 147669200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01803
Policy Entropy: 1.25705
Value Function Loss: 0.04578

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06333
Policy Update Magnitude: 0.04992
Value Function Update Magnitude: 0.06932

Collected Steps per Second: 10446.12271
Overall Steps per Second: 8254.45658

Timestep Collection Time: 4.79010
Timestep Consumption Time: 1.27183
PPO Batch Consumption Time: 0.11855
Total Iteration Time: 6.06194

Cumulative Model Updates: 8853
Cumulative Timesteps: 147719238

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12171
Policy Entropy: 1.25822
Value Function Loss: 0.04528

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.06770

Collected Steps per Second: 11613.95992
Overall Steps per Second: 9618.73370

Timestep Collection Time: 4.30671
Timestep Consumption Time: 0.89335
PPO Batch Consumption Time: 0.06654
Total Iteration Time: 5.20006

Cumulative Model Updates: 8856
Cumulative Timesteps: 147769256

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 147769256...
Checkpoint 147769256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02968
Policy Entropy: 1.25668
Value Function Loss: 0.04903

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07781
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.06633

Collected Steps per Second: 10888.27020
Overall Steps per Second: 8656.67234

Timestep Collection Time: 4.59375
Timestep Consumption Time: 1.18422
PPO Batch Consumption Time: 0.11896
Total Iteration Time: 5.77797

Cumulative Model Updates: 8859
Cumulative Timesteps: 147819274

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05926
Policy Entropy: 1.25628
Value Function Loss: 0.06536

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.07472

Collected Steps per Second: 11787.08461
Overall Steps per Second: 9273.90723

Timestep Collection Time: 4.24380
Timestep Consumption Time: 1.15005
PPO Batch Consumption Time: 0.11064
Total Iteration Time: 5.39384

Cumulative Model Updates: 8862
Cumulative Timesteps: 147869296

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 147869296...
Checkpoint 147869296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10468
Policy Entropy: 1.25911
Value Function Loss: 0.05886

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05061
Policy Update Magnitude: 0.04918
Value Function Update Magnitude: 0.07383

Collected Steps per Second: 11734.88286
Overall Steps per Second: 9261.21670

Timestep Collection Time: 4.26506
Timestep Consumption Time: 1.13920
PPO Batch Consumption Time: 0.08434
Total Iteration Time: 5.40426

Cumulative Model Updates: 8865
Cumulative Timesteps: 147919346

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09995
Policy Entropy: 1.26035
Value Function Loss: 0.05006

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04275
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.06840

Collected Steps per Second: 11685.57614
Overall Steps per Second: 9303.15102

Timestep Collection Time: 4.28289
Timestep Consumption Time: 1.09680
PPO Batch Consumption Time: 0.08844
Total Iteration Time: 5.37968

Cumulative Model Updates: 8868
Cumulative Timesteps: 147969394

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 147969394...
Checkpoint 147969394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06242
Policy Entropy: 1.26221
Value Function Loss: 0.04089

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04361
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.06584

Collected Steps per Second: 11753.36137
Overall Steps per Second: 9319.20140

Timestep Collection Time: 4.25597
Timestep Consumption Time: 1.11165
PPO Batch Consumption Time: 0.11820
Total Iteration Time: 5.36763

Cumulative Model Updates: 8871
Cumulative Timesteps: 148019416

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08182
Policy Entropy: 1.25786
Value Function Loss: 0.04234

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.05901
Policy Update Magnitude: 0.04821
Value Function Update Magnitude: 0.06492

Collected Steps per Second: 11962.59012
Overall Steps per Second: 9572.63837

Timestep Collection Time: 4.18103
Timestep Consumption Time: 1.04386
PPO Batch Consumption Time: 0.07163
Total Iteration Time: 5.22489

Cumulative Model Updates: 8874
Cumulative Timesteps: 148069432

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 148069432...
Checkpoint 148069432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03371
Policy Entropy: 1.25450
Value Function Loss: 0.06166

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.05343
Value Function Update Magnitude: 0.06878

Collected Steps per Second: 11672.13758
Overall Steps per Second: 9324.00692

Timestep Collection Time: 4.28593
Timestep Consumption Time: 1.07936
PPO Batch Consumption Time: 0.10438
Total Iteration Time: 5.36529

Cumulative Model Updates: 8877
Cumulative Timesteps: 148119458

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03351
Policy Entropy: 1.26428
Value Function Loss: 0.06461

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.07640

Collected Steps per Second: 10719.70068
Overall Steps per Second: 8621.87530

Timestep Collection Time: 4.66767
Timestep Consumption Time: 1.13571
PPO Batch Consumption Time: 0.08628
Total Iteration Time: 5.80338

Cumulative Model Updates: 8880
Cumulative Timesteps: 148169494

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 148169494...
Checkpoint 148169494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06531
Policy Entropy: 1.26204
Value Function Loss: 0.06186

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.08874

Collected Steps per Second: 11638.91848
Overall Steps per Second: 9389.13205

Timestep Collection Time: 4.29679
Timestep Consumption Time: 1.02958
PPO Batch Consumption Time: 0.07499
Total Iteration Time: 5.32637

Cumulative Model Updates: 8883
Cumulative Timesteps: 148219504

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08815
Policy Entropy: 1.25845
Value Function Loss: 0.04643

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08607
Policy Update Magnitude: 0.05505
Value Function Update Magnitude: 0.08473

Collected Steps per Second: 11305.03283
Overall Steps per Second: 9187.44049

Timestep Collection Time: 4.42369
Timestep Consumption Time: 1.01961
PPO Batch Consumption Time: 0.09086
Total Iteration Time: 5.44330

Cumulative Model Updates: 8886
Cumulative Timesteps: 148269514

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 148269514...
Checkpoint 148269514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14568
Policy Entropy: 1.26275
Value Function Loss: 0.04661

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.08448

Collected Steps per Second: 11659.53381
Overall Steps per Second: 9403.60029

Timestep Collection Time: 4.28868
Timestep Consumption Time: 1.02886
PPO Batch Consumption Time: 0.07261
Total Iteration Time: 5.31754

Cumulative Model Updates: 8889
Cumulative Timesteps: 148319518

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01741
Policy Entropy: 1.26167
Value Function Loss: 0.04144

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.05338
Value Function Update Magnitude: 0.07947

Collected Steps per Second: 11821.37012
Overall Steps per Second: 9496.56795

Timestep Collection Time: 4.23234
Timestep Consumption Time: 1.03609
PPO Batch Consumption Time: 0.07258
Total Iteration Time: 5.26843

Cumulative Model Updates: 8892
Cumulative Timesteps: 148369550

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 148369550...
Checkpoint 148369550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13160
Policy Entropy: 1.26797
Value Function Loss: 0.04778

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.05165
Value Function Update Magnitude: 0.08254

Collected Steps per Second: 11850.18873
Overall Steps per Second: 9317.33319

Timestep Collection Time: 4.22120
Timestep Consumption Time: 1.14750
PPO Batch Consumption Time: 0.10181
Total Iteration Time: 5.36870

Cumulative Model Updates: 8895
Cumulative Timesteps: 148419572

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05471
Policy Entropy: 1.25360
Value Function Loss: 0.03695

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.07525

Collected Steps per Second: 9999.78430
Overall Steps per Second: 7881.85072

Timestep Collection Time: 5.00331
Timestep Consumption Time: 1.34444
PPO Batch Consumption Time: 0.16658
Total Iteration Time: 6.34775

Cumulative Model Updates: 8898
Cumulative Timesteps: 148469604

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 148469604...
Checkpoint 148469604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06761
Policy Entropy: 1.26472
Value Function Loss: 0.04408

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.06718

Collected Steps per Second: 11305.09043
Overall Steps per Second: 8954.88951

Timestep Collection Time: 4.42562
Timestep Consumption Time: 1.16150
PPO Batch Consumption Time: 0.14726
Total Iteration Time: 5.58712

Cumulative Model Updates: 8901
Cumulative Timesteps: 148519636

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10736
Policy Entropy: 1.27419
Value Function Loss: 0.04965

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06842
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.07222

Collected Steps per Second: 10358.31972
Overall Steps per Second: 8042.61484

Timestep Collection Time: 4.83167
Timestep Consumption Time: 1.39118
PPO Batch Consumption Time: 0.15340
Total Iteration Time: 6.22285

Cumulative Model Updates: 8904
Cumulative Timesteps: 148569684

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 148569684...
Checkpoint 148569684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03391
Policy Entropy: 1.26735
Value Function Loss: 0.05567

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.07224

Collected Steps per Second: 11728.52548
Overall Steps per Second: 9598.05771

Timestep Collection Time: 4.26652
Timestep Consumption Time: 0.94703
PPO Batch Consumption Time: 0.06971
Total Iteration Time: 5.21355

Cumulative Model Updates: 8907
Cumulative Timesteps: 148619724

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14920
Policy Entropy: 1.26365
Value Function Loss: 0.06093

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.05079
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 11350.22165
Overall Steps per Second: 8706.55902

Timestep Collection Time: 4.40908
Timestep Consumption Time: 1.33877
PPO Batch Consumption Time: 0.17626
Total Iteration Time: 5.74785

Cumulative Model Updates: 8910
Cumulative Timesteps: 148669768

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 148669768...
Checkpoint 148669768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00321
Policy Entropy: 1.27135
Value Function Loss: 0.06285

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.04839
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 13536.78419
Overall Steps per Second: 10935.05416

Timestep Collection Time: 3.69704
Timestep Consumption Time: 0.87962
PPO Batch Consumption Time: 0.06058
Total Iteration Time: 4.57666

Cumulative Model Updates: 8913
Cumulative Timesteps: 148719814

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00521
Policy Entropy: 1.27483
Value Function Loss: 0.05489

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06265
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.07263

Collected Steps per Second: 12609.47765
Overall Steps per Second: 9602.16139

Timestep Collection Time: 3.96781
Timestep Consumption Time: 1.24268
PPO Batch Consumption Time: 0.18455
Total Iteration Time: 5.21049

Cumulative Model Updates: 8916
Cumulative Timesteps: 148769846

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 148769846...
Checkpoint 148769846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00986
Policy Entropy: 1.26939
Value Function Loss: 0.03729

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05339
Policy Update Magnitude: 0.05014
Value Function Update Magnitude: 0.07010

Collected Steps per Second: 13662.00570
Overall Steps per Second: 10106.26522

Timestep Collection Time: 3.66271
Timestep Consumption Time: 1.28867
PPO Batch Consumption Time: 0.17551
Total Iteration Time: 4.95138

Cumulative Model Updates: 8919
Cumulative Timesteps: 148819886

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09673
Policy Entropy: 1.26105
Value Function Loss: 0.04176

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.07968

Collected Steps per Second: 13237.68183
Overall Steps per Second: 10782.39939

Timestep Collection Time: 3.77770
Timestep Consumption Time: 0.86023
PPO Batch Consumption Time: 0.06369
Total Iteration Time: 4.63793

Cumulative Model Updates: 8922
Cumulative Timesteps: 148869894

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 148869894...
Checkpoint 148869894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12378
Policy Entropy: 1.26525
Value Function Loss: 0.04760

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.04826
Value Function Update Magnitude: 0.07546

Collected Steps per Second: 12918.90138
Overall Steps per Second: 9703.77566

Timestep Collection Time: 3.87138
Timestep Consumption Time: 1.28269
PPO Batch Consumption Time: 0.17864
Total Iteration Time: 5.15408

Cumulative Model Updates: 8925
Cumulative Timesteps: 148919908

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06943
Policy Entropy: 1.26425
Value Function Loss: 0.05292

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.05001
Value Function Update Magnitude: 0.06779

Collected Steps per Second: 13789.60912
Overall Steps per Second: 11008.66044

Timestep Collection Time: 3.62983
Timestep Consumption Time: 0.91695
PPO Batch Consumption Time: 0.06594
Total Iteration Time: 4.54678

Cumulative Model Updates: 8928
Cumulative Timesteps: 148969962

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 148969962...
Checkpoint 148969962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08195
Policy Entropy: 1.26682
Value Function Loss: 0.04621

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.04805
Value Function Update Magnitude: 0.06458

Collected Steps per Second: 12967.81071
Overall Steps per Second: 9955.18525

Timestep Collection Time: 3.85632
Timestep Consumption Time: 1.16699
PPO Batch Consumption Time: 0.16115
Total Iteration Time: 5.02331

Cumulative Model Updates: 8931
Cumulative Timesteps: 149019970

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11987
Policy Entropy: 1.26615
Value Function Loss: 0.04461

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.04546
Value Function Update Magnitude: 0.06483

Collected Steps per Second: 13625.22461
Overall Steps per Second: 10953.01723

Timestep Collection Time: 3.67054
Timestep Consumption Time: 0.89550
PPO Batch Consumption Time: 0.06776
Total Iteration Time: 4.56605

Cumulative Model Updates: 8934
Cumulative Timesteps: 149069982

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 149069982...
Checkpoint 149069982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13084
Policy Entropy: 1.26683
Value Function Loss: 0.04249

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07997
Policy Update Magnitude: 0.04301
Value Function Update Magnitude: 0.06601

Collected Steps per Second: 13136.89285
Overall Steps per Second: 10006.80190

Timestep Collection Time: 3.80973
Timestep Consumption Time: 1.19167
PPO Batch Consumption Time: 0.13926
Total Iteration Time: 5.00140

Cumulative Model Updates: 8937
Cumulative Timesteps: 149120030

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10287
Policy Entropy: 1.26421
Value Function Loss: 0.04998

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06541
Policy Update Magnitude: 0.04491
Value Function Update Magnitude: 0.06820

Collected Steps per Second: 13711.96221
Overall Steps per Second: 11209.35071

Timestep Collection Time: 3.64703
Timestep Consumption Time: 0.81424
PPO Batch Consumption Time: 0.06542
Total Iteration Time: 4.46128

Cumulative Model Updates: 8940
Cumulative Timesteps: 149170038

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 149170038...
Checkpoint 149170038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04109
Policy Entropy: 1.25399
Value Function Loss: 0.04599

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.04746
Value Function Update Magnitude: 0.07101

Collected Steps per Second: 12003.93669
Overall Steps per Second: 9084.07416

Timestep Collection Time: 4.16863
Timestep Consumption Time: 1.33991
PPO Batch Consumption Time: 0.18775
Total Iteration Time: 5.50854

Cumulative Model Updates: 8943
Cumulative Timesteps: 149220078

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14537
Policy Entropy: 1.24753
Value Function Loss: 0.05265

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.04411
Value Function Update Magnitude: 0.07089

Collected Steps per Second: 13144.52472
Overall Steps per Second: 10862.04888

Timestep Collection Time: 3.80417
Timestep Consumption Time: 0.79938
PPO Batch Consumption Time: 0.06275
Total Iteration Time: 4.60355

Cumulative Model Updates: 8946
Cumulative Timesteps: 149270082

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 149270082...
Checkpoint 149270082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03711
Policy Entropy: 1.25435
Value Function Loss: 0.05210

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08763
Policy Update Magnitude: 0.04406
Value Function Update Magnitude: 0.06649

Collected Steps per Second: 12410.41660
Overall Steps per Second: 9302.60754

Timestep Collection Time: 4.03242
Timestep Consumption Time: 1.34715
PPO Batch Consumption Time: 0.18706
Total Iteration Time: 5.37957

Cumulative Model Updates: 8949
Cumulative Timesteps: 149320126

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07811
Policy Entropy: 1.25416
Value Function Loss: 0.05946

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 13145.22659
Overall Steps per Second: 9986.81050

Timestep Collection Time: 3.80397
Timestep Consumption Time: 1.20304
PPO Batch Consumption Time: 0.14935
Total Iteration Time: 5.00700

Cumulative Model Updates: 8952
Cumulative Timesteps: 149370130

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 149370130...
Checkpoint 149370130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.25199
Policy Entropy: 1.25856
Value Function Loss: 0.04311

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06473
Policy Update Magnitude: 0.04701
Value Function Update Magnitude: 0.07298

Collected Steps per Second: 13320.05880
Overall Steps per Second: 10528.46767

Timestep Collection Time: 3.75449
Timestep Consumption Time: 0.99549
PPO Batch Consumption Time: 0.06896
Total Iteration Time: 4.74998

Cumulative Model Updates: 8955
Cumulative Timesteps: 149420140

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08430
Policy Entropy: 1.25035
Value Function Loss: 0.04320

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07169
Policy Update Magnitude: 0.04618
Value Function Update Magnitude: 0.07396

Collected Steps per Second: 10161.98548
Overall Steps per Second: 7799.89563

Timestep Collection Time: 4.92286
Timestep Consumption Time: 1.49082
PPO Batch Consumption Time: 0.19000
Total Iteration Time: 6.41368

Cumulative Model Updates: 8958
Cumulative Timesteps: 149470166

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 149470166...
Checkpoint 149470166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00387
Policy Entropy: 1.25337
Value Function Loss: 0.04262

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06493
Policy Update Magnitude: 0.04846
Value Function Update Magnitude: 0.06759

Collected Steps per Second: 11593.33431
Overall Steps per Second: 8966.33099

Timestep Collection Time: 4.31455
Timestep Consumption Time: 1.26410
PPO Batch Consumption Time: 0.17043
Total Iteration Time: 5.57865

Cumulative Model Updates: 8961
Cumulative Timesteps: 149520186

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01479
Policy Entropy: 1.25542
Value Function Loss: 0.04965

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06016
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.07128

Collected Steps per Second: 11958.17714
Overall Steps per Second: 9668.53514

Timestep Collection Time: 4.18191
Timestep Consumption Time: 0.99033
PPO Batch Consumption Time: 0.07516
Total Iteration Time: 5.17224

Cumulative Model Updates: 8964
Cumulative Timesteps: 149570194

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 149570194...
Checkpoint 149570194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11242
Policy Entropy: 1.25149
Value Function Loss: 0.04420

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06568
Policy Update Magnitude: 0.04843
Value Function Update Magnitude: 0.07581

Collected Steps per Second: 11666.71779
Overall Steps per Second: 8925.19117

Timestep Collection Time: 4.28690
Timestep Consumption Time: 1.31679
PPO Batch Consumption Time: 0.16132
Total Iteration Time: 5.60369

Cumulative Model Updates: 8967
Cumulative Timesteps: 149620208

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09234
Policy Entropy: 1.24999
Value Function Loss: 0.04634

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06444
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.06683

Collected Steps per Second: 12347.32865
Overall Steps per Second: 10017.35021

Timestep Collection Time: 4.05205
Timestep Consumption Time: 0.94248
PPO Batch Consumption Time: 0.06945
Total Iteration Time: 4.99453

Cumulative Model Updates: 8970
Cumulative Timesteps: 149670240

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 149670240...
Checkpoint 149670240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05966
Policy Entropy: 1.24235
Value Function Loss: 0.04857

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.06903

Collected Steps per Second: 11017.70961
Overall Steps per Second: 8362.39261

Timestep Collection Time: 4.54069
Timestep Consumption Time: 1.44181
PPO Batch Consumption Time: 0.18790
Total Iteration Time: 5.98250

Cumulative Model Updates: 8973
Cumulative Timesteps: 149720268

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05246
Policy Entropy: 1.24843
Value Function Loss: 0.05315

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06287
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.07491

Collected Steps per Second: 12220.91662
Overall Steps per Second: 9452.32103

Timestep Collection Time: 4.09331
Timestep Consumption Time: 1.19894
PPO Batch Consumption Time: 0.16692
Total Iteration Time: 5.29225

Cumulative Model Updates: 8976
Cumulative Timesteps: 149770292

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 149770292...
Checkpoint 149770292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12427
Policy Entropy: 1.24908
Value Function Loss: 0.04538

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06152
Policy Update Magnitude: 0.05492
Value Function Update Magnitude: 0.07210

Collected Steps per Second: 12302.78825
Overall Steps per Second: 9516.97284

Timestep Collection Time: 4.06607
Timestep Consumption Time: 1.19022
PPO Batch Consumption Time: 0.13537
Total Iteration Time: 5.25629

Cumulative Model Updates: 8979
Cumulative Timesteps: 149820316

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07565
Policy Entropy: 1.24473
Value Function Loss: 0.04956

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05745
Policy Update Magnitude: 0.05271
Value Function Update Magnitude: 0.07384

Collected Steps per Second: 12279.82111
Overall Steps per Second: 9916.57632

Timestep Collection Time: 4.07514
Timestep Consumption Time: 0.97116
PPO Batch Consumption Time: 0.07129
Total Iteration Time: 5.04630

Cumulative Model Updates: 8982
Cumulative Timesteps: 149870358

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 149870358...
Checkpoint 149870358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.22517
Policy Entropy: 1.24394
Value Function Loss: 0.04674

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06637
Policy Update Magnitude: 0.05411
Value Function Update Magnitude: 0.07400

Collected Steps per Second: 11248.27709
Overall Steps per Second: 8688.32767

Timestep Collection Time: 4.44744
Timestep Consumption Time: 1.31040
PPO Batch Consumption Time: 0.17776
Total Iteration Time: 5.75784

Cumulative Model Updates: 8985
Cumulative Timesteps: 149920384

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14412
Policy Entropy: 1.24638
Value Function Loss: 0.05323

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.07546

Collected Steps per Second: 12332.48924
Overall Steps per Second: 9870.80833

Timestep Collection Time: 4.05595
Timestep Consumption Time: 1.01151
PPO Batch Consumption Time: 0.07355
Total Iteration Time: 5.06747

Cumulative Model Updates: 8988
Cumulative Timesteps: 149970404

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 149970404...
Checkpoint 149970404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11017
Policy Entropy: 1.25691
Value Function Loss: 0.04887

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.05119
Value Function Update Magnitude: 0.07402

Collected Steps per Second: 11459.53913
Overall Steps per Second: 8764.69722

Timestep Collection Time: 4.36789
Timestep Consumption Time: 1.34298
PPO Batch Consumption Time: 0.15641
Total Iteration Time: 5.71086

Cumulative Model Updates: 8991
Cumulative Timesteps: 150020458

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04700
Policy Entropy: 1.25724
Value Function Loss: 0.04598

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06656
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.06852

Collected Steps per Second: 12437.31044
Overall Steps per Second: 9983.72844

Timestep Collection Time: 4.02322
Timestep Consumption Time: 0.98874
PPO Batch Consumption Time: 0.06925
Total Iteration Time: 5.01196

Cumulative Model Updates: 8994
Cumulative Timesteps: 150070496

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 150070496...
Checkpoint 150070496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16399
Policy Entropy: 1.24504
Value Function Loss: 0.04007

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.04797
Value Function Update Magnitude: 0.06405

Collected Steps per Second: 11010.67475
Overall Steps per Second: 8392.76604

Timestep Collection Time: 4.54141
Timestep Consumption Time: 1.41658
PPO Batch Consumption Time: 0.18703
Total Iteration Time: 5.95799

Cumulative Model Updates: 8997
Cumulative Timesteps: 150120500

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04141
Policy Entropy: 1.24049
Value Function Loss: 0.03676

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08918
Policy Update Magnitude: 0.04581
Value Function Update Magnitude: 0.06203

Collected Steps per Second: 12262.81192
Overall Steps per Second: 10063.81986

Timestep Collection Time: 4.07851
Timestep Consumption Time: 0.89117
PPO Batch Consumption Time: 0.07143
Total Iteration Time: 4.96968

Cumulative Model Updates: 9000
Cumulative Timesteps: 150170514

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 150170514...
Checkpoint 150170514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09222
Policy Entropy: 1.24855
Value Function Loss: 0.04457

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07261
Policy Update Magnitude: 0.04730
Value Function Update Magnitude: 0.06207

Collected Steps per Second: 11484.88301
Overall Steps per Second: 8650.32584

Timestep Collection Time: 4.35477
Timestep Consumption Time: 1.42698
PPO Batch Consumption Time: 0.18685
Total Iteration Time: 5.78175

Cumulative Model Updates: 9003
Cumulative Timesteps: 150220528

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13748
Policy Entropy: 1.25587
Value Function Loss: 0.03724

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04638
Policy Update Magnitude: 0.04627
Value Function Update Magnitude: 0.06230

Collected Steps per Second: 11591.83851
Overall Steps per Second: 8939.00907

Timestep Collection Time: 4.31718
Timestep Consumption Time: 1.28121
PPO Batch Consumption Time: 0.16547
Total Iteration Time: 5.59838

Cumulative Model Updates: 9006
Cumulative Timesteps: 150270572

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 150270572...
Checkpoint 150270572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07408
Policy Entropy: 1.25390
Value Function Loss: 0.04295

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05301
Policy Update Magnitude: 0.04555
Value Function Update Magnitude: 0.07133

Collected Steps per Second: 12709.00755
Overall Steps per Second: 9622.29222

Timestep Collection Time: 3.93453
Timestep Consumption Time: 1.26215
PPO Batch Consumption Time: 0.16812
Total Iteration Time: 5.19668

Cumulative Model Updates: 9009
Cumulative Timesteps: 150320576

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02923
Policy Entropy: 1.24459
Value Function Loss: 0.04256

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06147
Policy Update Magnitude: 0.04601
Value Function Update Magnitude: 0.07034

Collected Steps per Second: 13847.73998
Overall Steps per Second: 11050.07840

Timestep Collection Time: 3.61460
Timestep Consumption Time: 0.91514
PPO Batch Consumption Time: 0.06609
Total Iteration Time: 4.52974

Cumulative Model Updates: 9012
Cumulative Timesteps: 150370630

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 150370630...
Checkpoint 150370630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01936
Policy Entropy: 1.24257
Value Function Loss: 0.05631

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07076
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.06790

Collected Steps per Second: 12873.34280
Overall Steps per Second: 9907.09404

Timestep Collection Time: 3.88803
Timestep Consumption Time: 1.16410
PPO Batch Consumption Time: 0.15715
Total Iteration Time: 5.05214

Cumulative Model Updates: 9015
Cumulative Timesteps: 150420682

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00464
Policy Entropy: 1.24279
Value Function Loss: 0.05093

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.06792
Policy Update Magnitude: 0.05326
Value Function Update Magnitude: 0.07542

Collected Steps per Second: 13932.41510
Overall Steps per Second: 11110.67403

Timestep Collection Time: 3.59105
Timestep Consumption Time: 0.91201
PPO Batch Consumption Time: 0.06531
Total Iteration Time: 4.50306

Cumulative Model Updates: 9018
Cumulative Timesteps: 150470714

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 150470714...
Checkpoint 150470714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14629
Policy Entropy: 1.24204
Value Function Loss: 0.04570

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06604
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.07398

Collected Steps per Second: 11780.18708
Overall Steps per Second: 9123.87519

Timestep Collection Time: 4.24713
Timestep Consumption Time: 1.23650
PPO Batch Consumption Time: 0.14556
Total Iteration Time: 5.48363

Cumulative Model Updates: 9021
Cumulative Timesteps: 150520746

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02398
Policy Entropy: 1.24060
Value Function Loss: 0.05035

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.06047
Policy Update Magnitude: 0.04957
Value Function Update Magnitude: 0.06832

Collected Steps per Second: 13464.92412
Overall Steps per Second: 10887.54412

Timestep Collection Time: 3.71335
Timestep Consumption Time: 0.87905
PPO Batch Consumption Time: 0.06234
Total Iteration Time: 4.59240

Cumulative Model Updates: 9024
Cumulative Timesteps: 150570746

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 150570746...
Checkpoint 150570746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00753
Policy Entropy: 1.24605
Value Function Loss: 0.05666

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.06438

Collected Steps per Second: 13185.79653
Overall Steps per Second: 10054.25445

Timestep Collection Time: 3.79575
Timestep Consumption Time: 1.18224
PPO Batch Consumption Time: 0.13729
Total Iteration Time: 4.97799

Cumulative Model Updates: 9027
Cumulative Timesteps: 150620796

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01787
Policy Entropy: 1.25504
Value Function Loss: 0.05311

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07759
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.07394

Collected Steps per Second: 13824.16341
Overall Steps per Second: 11126.11670

Timestep Collection Time: 3.61787
Timestep Consumption Time: 0.87732
PPO Batch Consumption Time: 0.06561
Total Iteration Time: 4.49519

Cumulative Model Updates: 9030
Cumulative Timesteps: 150670810

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 150670810...
Checkpoint 150670810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03807
Policy Entropy: 1.26382
Value Function Loss: 0.04698

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.07221

Collected Steps per Second: 13433.46179
Overall Steps per Second: 9852.15404

Timestep Collection Time: 3.72428
Timestep Consumption Time: 1.35380
PPO Batch Consumption Time: 0.19803
Total Iteration Time: 5.07808

Cumulative Model Updates: 9033
Cumulative Timesteps: 150720840

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05773
Policy Entropy: 1.25253
Value Function Loss: 0.05359

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.06779

Collected Steps per Second: 13369.97406
Overall Steps per Second: 10725.17096

Timestep Collection Time: 3.74017
Timestep Consumption Time: 0.92232
PPO Batch Consumption Time: 0.06972
Total Iteration Time: 4.66249

Cumulative Model Updates: 9036
Cumulative Timesteps: 150770846

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 150770846...
Checkpoint 150770846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10779
Policy Entropy: 1.24021
Value Function Loss: 0.05095

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.07008

Collected Steps per Second: 13134.75829
Overall Steps per Second: 10172.90224

Timestep Collection Time: 3.80791
Timestep Consumption Time: 1.10868
PPO Batch Consumption Time: 0.13389
Total Iteration Time: 4.91659

Cumulative Model Updates: 9039
Cumulative Timesteps: 150820862

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09748
Policy Entropy: 1.24352
Value Function Loss: 0.05336

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.04996
Value Function Update Magnitude: 0.07075

Collected Steps per Second: 13378.57541
Overall Steps per Second: 10733.50885

Timestep Collection Time: 3.73762
Timestep Consumption Time: 0.92106
PPO Batch Consumption Time: 0.06853
Total Iteration Time: 4.65868

Cumulative Model Updates: 9042
Cumulative Timesteps: 150870866

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 150870866...
Checkpoint 150870866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03993
Policy Entropy: 1.24541
Value Function Loss: 0.04288

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05827
Policy Update Magnitude: 0.04906
Value Function Update Magnitude: 0.06662

Collected Steps per Second: 12513.03115
Overall Steps per Second: 9400.38106

Timestep Collection Time: 3.99615
Timestep Consumption Time: 1.32320
PPO Batch Consumption Time: 0.18640
Total Iteration Time: 5.31936

Cumulative Model Updates: 9045
Cumulative Timesteps: 150920870

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00553
Policy Entropy: 1.23646
Value Function Loss: 0.04563

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.04784
Value Function Update Magnitude: 0.06587

Collected Steps per Second: 13537.38283
Overall Steps per Second: 10025.78540

Timestep Collection Time: 3.69732
Timestep Consumption Time: 1.29501
PPO Batch Consumption Time: 0.17444
Total Iteration Time: 4.99233

Cumulative Model Updates: 9048
Cumulative Timesteps: 150970922

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 150970922...
Checkpoint 150970922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14562
Policy Entropy: 1.23004
Value Function Loss: 0.03958

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.04887
Value Function Update Magnitude: 0.05784

Collected Steps per Second: 13192.43537
Overall Steps per Second: 10456.70337

Timestep Collection Time: 3.79035
Timestep Consumption Time: 0.99165
PPO Batch Consumption Time: 0.06550
Total Iteration Time: 4.78200

Cumulative Model Updates: 9051
Cumulative Timesteps: 151020926

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10478
Policy Entropy: 1.24077
Value Function Loss: 0.04037

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.05053
Value Function Update Magnitude: 0.05267

Collected Steps per Second: 12007.37153
Overall Steps per Second: 9241.64765

Timestep Collection Time: 4.16527
Timestep Consumption Time: 1.24653
PPO Batch Consumption Time: 0.18370
Total Iteration Time: 5.41181

Cumulative Model Updates: 9054
Cumulative Timesteps: 151070940

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 151070940...
Checkpoint 151070940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04157
Policy Entropy: 1.24615
Value Function Loss: 0.05080

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05669
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.05300

Collected Steps per Second: 13173.28902
Overall Steps per Second: 10618.78941

Timestep Collection Time: 3.79632
Timestep Consumption Time: 0.91326
PPO Batch Consumption Time: 0.06786
Total Iteration Time: 4.70958

Cumulative Model Updates: 9057
Cumulative Timesteps: 151120950

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02475
Policy Entropy: 1.23835
Value Function Loss: 0.05349

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.04978
Value Function Update Magnitude: 0.05118

Collected Steps per Second: 13094.48973
Overall Steps per Second: 9887.10794

Timestep Collection Time: 3.81932
Timestep Consumption Time: 1.23899
PPO Batch Consumption Time: 0.15794
Total Iteration Time: 5.05830

Cumulative Model Updates: 9060
Cumulative Timesteps: 151170962

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 151170962...
Checkpoint 151170962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01977
Policy Entropy: 1.22945
Value Function Loss: 0.06161

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.05194

Collected Steps per Second: 13700.59858
Overall Steps per Second: 11010.78478

Timestep Collection Time: 3.65167
Timestep Consumption Time: 0.89206
PPO Batch Consumption Time: 0.06487
Total Iteration Time: 4.54373

Cumulative Model Updates: 9063
Cumulative Timesteps: 151220992

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12704
Policy Entropy: 1.22788
Value Function Loss: 0.05145

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.05551

Collected Steps per Second: 13136.83166
Overall Steps per Second: 9959.12292

Timestep Collection Time: 3.80701
Timestep Consumption Time: 1.21472
PPO Batch Consumption Time: 0.15099
Total Iteration Time: 5.02173

Cumulative Model Updates: 9066
Cumulative Timesteps: 151271004

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 151271004...
Checkpoint 151271004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11041
Policy Entropy: 1.23424
Value Function Loss: 0.05456

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.05210

Collected Steps per Second: 13720.32806
Overall Steps per Second: 11004.50554

Timestep Collection Time: 3.64496
Timestep Consumption Time: 0.89955
PPO Batch Consumption Time: 0.06811
Total Iteration Time: 4.54450

Cumulative Model Updates: 9069
Cumulative Timesteps: 151321014

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05727
Policy Entropy: 1.24684
Value Function Loss: 0.05810

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.04933
Value Function Update Magnitude: 0.05237

Collected Steps per Second: 13372.37386
Overall Steps per Second: 9910.38768

Timestep Collection Time: 3.74130
Timestep Consumption Time: 1.30694
PPO Batch Consumption Time: 0.17186
Total Iteration Time: 5.04824

Cumulative Model Updates: 9072
Cumulative Timesteps: 151371044

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 151371044...
Checkpoint 151371044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01748
Policy Entropy: 1.24329
Value Function Loss: 0.05106

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.05151
Value Function Update Magnitude: 0.06072

Collected Steps per Second: 13240.92974
Overall Steps per Second: 10735.12490

Timestep Collection Time: 3.77828
Timestep Consumption Time: 0.88193
PPO Batch Consumption Time: 0.06738
Total Iteration Time: 4.66022

Cumulative Model Updates: 9075
Cumulative Timesteps: 151421072

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07688
Policy Entropy: 1.24018
Value Function Loss: 0.05093

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.04825
Value Function Update Magnitude: 0.06324

Collected Steps per Second: 12880.11900
Overall Steps per Second: 9799.16167

Timestep Collection Time: 3.88428
Timestep Consumption Time: 1.22126
PPO Batch Consumption Time: 0.17019
Total Iteration Time: 5.10554

Cumulative Model Updates: 9078
Cumulative Timesteps: 151471102

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 151471102...
Checkpoint 151471102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02274
Policy Entropy: 1.23688
Value Function Loss: 0.04822

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.05003
Value Function Update Magnitude: 0.06443

Collected Steps per Second: 13152.99052
Overall Steps per Second: 10035.06464

Timestep Collection Time: 3.80279
Timestep Consumption Time: 1.18154
PPO Batch Consumption Time: 0.13495
Total Iteration Time: 4.98432

Cumulative Model Updates: 9081
Cumulative Timesteps: 151521120

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08729
Policy Entropy: 1.23622
Value Function Loss: 0.05259

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06426
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.05387

Collected Steps per Second: 13486.88753
Overall Steps per Second: 10936.83973

Timestep Collection Time: 3.70775
Timestep Consumption Time: 0.86450
PPO Batch Consumption Time: 0.06401
Total Iteration Time: 4.57225

Cumulative Model Updates: 9084
Cumulative Timesteps: 151571126

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 151571126...
Checkpoint 151571126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16741
Policy Entropy: 1.22935
Value Function Loss: 0.04853

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.05706

Collected Steps per Second: 12530.33753
Overall Steps per Second: 9619.87354

Timestep Collection Time: 3.99048
Timestep Consumption Time: 1.20731
PPO Batch Consumption Time: 0.14708
Total Iteration Time: 5.19778

Cumulative Model Updates: 9087
Cumulative Timesteps: 151621128

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06275
Policy Entropy: 1.22866
Value Function Loss: 0.04181

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.06047

Collected Steps per Second: 13588.31615
Overall Steps per Second: 10913.58316

Timestep Collection Time: 3.68213
Timestep Consumption Time: 0.90243
PPO Batch Consumption Time: 0.06335
Total Iteration Time: 4.58456

Cumulative Model Updates: 9090
Cumulative Timesteps: 151671162

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 151671162...
Checkpoint 151671162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08657
Policy Entropy: 1.23129
Value Function Loss: 0.04274

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.04767
Value Function Update Magnitude: 0.05925

Collected Steps per Second: 12899.34076
Overall Steps per Second: 10009.57678

Timestep Collection Time: 3.87818
Timestep Consumption Time: 1.11963
PPO Batch Consumption Time: 0.14035
Total Iteration Time: 4.99781

Cumulative Model Updates: 9093
Cumulative Timesteps: 151721188

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03759
Policy Entropy: 1.23639
Value Function Loss: 0.05213

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06913
Policy Update Magnitude: 0.05124
Value Function Update Magnitude: 0.05783

Collected Steps per Second: 13588.37958
Overall Steps per Second: 10256.94425

Timestep Collection Time: 3.68212
Timestep Consumption Time: 1.19594
PPO Batch Consumption Time: 0.16362
Total Iteration Time: 4.87806

Cumulative Model Updates: 9096
Cumulative Timesteps: 151771222

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 151771222...
Checkpoint 151771222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08867
Policy Entropy: 1.23123
Value Function Loss: 0.05889

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.05831
Value Function Update Magnitude: 0.06103

Collected Steps per Second: 13639.17246
Overall Steps per Second: 10194.22841

Timestep Collection Time: 3.66826
Timestep Consumption Time: 1.23962
PPO Batch Consumption Time: 0.16472
Total Iteration Time: 4.90788

Cumulative Model Updates: 9099
Cumulative Timesteps: 151821254

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05780
Policy Entropy: 1.22567
Value Function Loss: 0.05983

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.05602
Value Function Update Magnitude: 0.06355

Collected Steps per Second: 12821.19261
Overall Steps per Second: 9669.51074

Timestep Collection Time: 3.90073
Timestep Consumption Time: 1.27140
PPO Batch Consumption Time: 0.15947
Total Iteration Time: 5.17213

Cumulative Model Updates: 9102
Cumulative Timesteps: 151871266

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 151871266...
Checkpoint 151871266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09753
Policy Entropy: 1.22887
Value Function Loss: 0.04976

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.05307
Value Function Update Magnitude: 0.05933

Collected Steps per Second: 13449.94384
Overall Steps per Second: 10857.00771

Timestep Collection Time: 3.71838
Timestep Consumption Time: 0.88805
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 4.60643

Cumulative Model Updates: 9105
Cumulative Timesteps: 151921278

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08571
Policy Entropy: 1.22763
Value Function Loss: 0.03974

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.04972
Value Function Update Magnitude: 0.05911

Collected Steps per Second: 12734.58081
Overall Steps per Second: 9631.10501

Timestep Collection Time: 3.92695
Timestep Consumption Time: 1.26540
PPO Batch Consumption Time: 0.19113
Total Iteration Time: 5.19234

Cumulative Model Updates: 9108
Cumulative Timesteps: 151971286

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 151971286...
Checkpoint 151971286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02708
Policy Entropy: 1.23029
Value Function Loss: 0.03458

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.04434
Value Function Update Magnitude: 0.05451

Collected Steps per Second: 13039.85538
Overall Steps per Second: 9734.46239

Timestep Collection Time: 3.83777
Timestep Consumption Time: 1.30314
PPO Batch Consumption Time: 0.18319
Total Iteration Time: 5.14091

Cumulative Model Updates: 9111
Cumulative Timesteps: 152021330

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04333
Policy Entropy: 1.22618
Value Function Loss: 0.03689

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.04310
Value Function Update Magnitude: 0.05348

Collected Steps per Second: 13520.03234
Overall Steps per Second: 10948.60702

Timestep Collection Time: 3.69955
Timestep Consumption Time: 0.86889
PPO Batch Consumption Time: 0.06789
Total Iteration Time: 4.56844

Cumulative Model Updates: 9114
Cumulative Timesteps: 152071348

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 152071348...
Checkpoint 152071348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05029
Policy Entropy: 1.23137
Value Function Loss: 0.04128

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04892
Policy Update Magnitude: 0.04651
Value Function Update Magnitude: 0.05656

Collected Steps per Second: 13833.30549
Overall Steps per Second: 10361.07706

Timestep Collection Time: 3.61490
Timestep Consumption Time: 1.21143
PPO Batch Consumption Time: 0.15349
Total Iteration Time: 4.82633

Cumulative Model Updates: 9117
Cumulative Timesteps: 152121354

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05032
Policy Entropy: 1.22931
Value Function Loss: 0.04835

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.04962
Value Function Update Magnitude: 0.05933

Collected Steps per Second: 13573.04444
Overall Steps per Second: 10959.29184

Timestep Collection Time: 3.68451
Timestep Consumption Time: 0.87874
PPO Batch Consumption Time: 0.06534
Total Iteration Time: 4.56325

Cumulative Model Updates: 9120
Cumulative Timesteps: 152171364

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 152171364...
Checkpoint 152171364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08674
Policy Entropy: 1.22650
Value Function Loss: 0.04833

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.04997
Value Function Update Magnitude: 0.05873

Collected Steps per Second: 13064.79961
Overall Steps per Second: 9972.61733

Timestep Collection Time: 3.82891
Timestep Consumption Time: 1.18722
PPO Batch Consumption Time: 0.14507
Total Iteration Time: 5.01614

Cumulative Model Updates: 9123
Cumulative Timesteps: 152221388

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03158
Policy Entropy: 1.23416
Value Function Loss: 0.05263

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.05029
Value Function Update Magnitude: 0.05515

Collected Steps per Second: 14261.50646
Overall Steps per Second: 11379.21465

Timestep Collection Time: 3.50931
Timestep Consumption Time: 0.88889
PPO Batch Consumption Time: 0.05973
Total Iteration Time: 4.39819

Cumulative Model Updates: 9126
Cumulative Timesteps: 152271436

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 152271436...
Checkpoint 152271436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13534
Policy Entropy: 1.24281
Value Function Loss: 0.04822

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04961
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.05683

Collected Steps per Second: 12286.18204
Overall Steps per Second: 9271.82836

Timestep Collection Time: 4.07108
Timestep Consumption Time: 1.32354
PPO Batch Consumption Time: 0.19448
Total Iteration Time: 5.39462

Cumulative Model Updates: 9129
Cumulative Timesteps: 152321454

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07442
Policy Entropy: 1.23588
Value Function Loss: 0.04392

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06397
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.05174

Collected Steps per Second: 12556.14077
Overall Steps per Second: 9627.66381

Timestep Collection Time: 3.98546
Timestep Consumption Time: 1.21227
PPO Batch Consumption Time: 0.15037
Total Iteration Time: 5.19773

Cumulative Model Updates: 9132
Cumulative Timesteps: 152371496

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 152371496...
Checkpoint 152371496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00045
Policy Entropy: 1.23682
Value Function Loss: 0.04572

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.04706
Value Function Update Magnitude: 0.05405

Collected Steps per Second: 11628.13760
Overall Steps per Second: 9031.71729

Timestep Collection Time: 4.30129
Timestep Consumption Time: 1.23653
PPO Batch Consumption Time: 0.14332
Total Iteration Time: 5.53782

Cumulative Model Updates: 9135
Cumulative Timesteps: 152421512

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17910
Policy Entropy: 1.23361
Value Function Loss: 0.05010

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07582
Policy Update Magnitude: 0.05162
Value Function Update Magnitude: 0.06396

Collected Steps per Second: 12325.96401
Overall Steps per Second: 9947.72622

Timestep Collection Time: 4.05729
Timestep Consumption Time: 0.96999
PPO Batch Consumption Time: 0.07112
Total Iteration Time: 5.02728

Cumulative Model Updates: 9138
Cumulative Timesteps: 152471522

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 152471522...
Checkpoint 152471522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10290
Policy Entropy: 1.23370
Value Function Loss: 0.05241

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.07024

Collected Steps per Second: 12271.99212
Overall Steps per Second: 9301.42489

Timestep Collection Time: 4.07644
Timestep Consumption Time: 1.30188
PPO Batch Consumption Time: 0.14928
Total Iteration Time: 5.37832

Cumulative Model Updates: 9141
Cumulative Timesteps: 152521548

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05695
Policy Entropy: 1.21585
Value Function Loss: 0.05649

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.06473

Collected Steps per Second: 11944.65610
Overall Steps per Second: 8986.54008

Timestep Collection Time: 4.18748
Timestep Consumption Time: 1.37840
PPO Batch Consumption Time: 0.17838
Total Iteration Time: 5.56588

Cumulative Model Updates: 9144
Cumulative Timesteps: 152571566

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 152571566...
Checkpoint 152571566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02136
Policy Entropy: 1.21929
Value Function Loss: 0.04684

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.05552
Value Function Update Magnitude: 0.06862

Collected Steps per Second: 12476.82602
Overall Steps per Second: 10044.92310

Timestep Collection Time: 4.00935
Timestep Consumption Time: 0.97068
PPO Batch Consumption Time: 0.07160
Total Iteration Time: 4.98003

Cumulative Model Updates: 9147
Cumulative Timesteps: 152621590

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12282
Policy Entropy: 1.22869
Value Function Loss: 0.04900

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.05421
Value Function Update Magnitude: 0.07710

Collected Steps per Second: 11948.04826
Overall Steps per Second: 8912.71732

Timestep Collection Time: 4.18847
Timestep Consumption Time: 1.42643
PPO Batch Consumption Time: 0.18403
Total Iteration Time: 5.61490

Cumulative Model Updates: 9150
Cumulative Timesteps: 152671634

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 152671634...
Checkpoint 152671634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01003
Policy Entropy: 1.23470
Value Function Loss: 0.03971

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.07877

Collected Steps per Second: 11710.32201
Overall Steps per Second: 8965.88856

Timestep Collection Time: 4.27196
Timestep Consumption Time: 1.30763
PPO Batch Consumption Time: 0.15821
Total Iteration Time: 5.57959

Cumulative Model Updates: 9153
Cumulative Timesteps: 152721660

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01516
Policy Entropy: 1.22737
Value Function Loss: 0.04514

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.06610

Collected Steps per Second: 12726.67378
Overall Steps per Second: 10188.19112

Timestep Collection Time: 3.93001
Timestep Consumption Time: 0.97920
PPO Batch Consumption Time: 0.07371
Total Iteration Time: 4.90921

Cumulative Model Updates: 9156
Cumulative Timesteps: 152771676

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 152771676...
Checkpoint 152771676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07911
Policy Entropy: 1.23294
Value Function Loss: 0.04288

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.05159
Value Function Update Magnitude: 0.07152

Collected Steps per Second: 11344.52889
Overall Steps per Second: 8514.27795

Timestep Collection Time: 4.40741
Timestep Consumption Time: 1.46508
PPO Batch Consumption Time: 0.19208
Total Iteration Time: 5.87249

Cumulative Model Updates: 9159
Cumulative Timesteps: 152821676

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09298
Policy Entropy: 1.23570
Value Function Loss: 0.04840

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.05461
Value Function Update Magnitude: 0.06693

Collected Steps per Second: 12516.65931
Overall Steps per Second: 10159.84672

Timestep Collection Time: 3.99611
Timestep Consumption Time: 0.92699
PPO Batch Consumption Time: 0.07304
Total Iteration Time: 4.92311

Cumulative Model Updates: 9162
Cumulative Timesteps: 152871694

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 152871694...
Checkpoint 152871694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00889
Policy Entropy: 1.23990
Value Function Loss: 0.04716

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06257
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.06534

Collected Steps per Second: 11233.68061
Overall Steps per Second: 8546.09202

Timestep Collection Time: 4.45144
Timestep Consumption Time: 1.39989
PPO Batch Consumption Time: 0.15313
Total Iteration Time: 5.85133

Cumulative Model Updates: 9165
Cumulative Timesteps: 152921700

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10793
Policy Entropy: 1.22709
Value Function Loss: 0.05329

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.05361
Value Function Update Magnitude: 0.06208

Collected Steps per Second: 12328.45417
Overall Steps per Second: 9966.57993

Timestep Collection Time: 4.05631
Timestep Consumption Time: 0.96126
PPO Batch Consumption Time: 0.07179
Total Iteration Time: 5.01757

Cumulative Model Updates: 9168
Cumulative Timesteps: 152971708

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 152971708...
Checkpoint 152971708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09775
Policy Entropy: 1.22568
Value Function Loss: 0.05578

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.06192

Collected Steps per Second: 11306.61211
Overall Steps per Second: 8691.41453

Timestep Collection Time: 4.42325
Timestep Consumption Time: 1.33093
PPO Batch Consumption Time: 0.15821
Total Iteration Time: 5.75418

Cumulative Model Updates: 9171
Cumulative Timesteps: 153021720

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02262
Policy Entropy: 1.22247
Value Function Loss: 0.05474

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.07008

Collected Steps per Second: 12168.38368
Overall Steps per Second: 9715.19546

Timestep Collection Time: 4.11197
Timestep Consumption Time: 1.03831
PPO Batch Consumption Time: 0.07951
Total Iteration Time: 5.15028

Cumulative Model Updates: 9174
Cumulative Timesteps: 153071756

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 153071756...
Checkpoint 153071756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12477
Policy Entropy: 1.22603
Value Function Loss: 0.04915

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08448
Policy Update Magnitude: 0.05292
Value Function Update Magnitude: 0.06251

Collected Steps per Second: 11650.74426
Overall Steps per Second: 8892.31865

Timestep Collection Time: 4.29209
Timestep Consumption Time: 1.33142
PPO Batch Consumption Time: 0.15867
Total Iteration Time: 5.62351

Cumulative Model Updates: 9177
Cumulative Timesteps: 153121762

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02146
Policy Entropy: 1.23366
Value Function Loss: 0.04845

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06248
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.06021

Collected Steps per Second: 12654.06407
Overall Steps per Second: 10088.69152

Timestep Collection Time: 3.95478
Timestep Consumption Time: 1.00563
PPO Batch Consumption Time: 0.07008
Total Iteration Time: 4.96041

Cumulative Model Updates: 9180
Cumulative Timesteps: 153171806

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 153171806...
Checkpoint 153171806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07318
Policy Entropy: 1.23610
Value Function Loss: 0.04553

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06786
Policy Update Magnitude: 0.05676
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 11723.20119
Overall Steps per Second: 8927.99363

Timestep Collection Time: 4.26658
Timestep Consumption Time: 1.33580
PPO Batch Consumption Time: 0.16985
Total Iteration Time: 5.60238

Cumulative Model Updates: 9183
Cumulative Timesteps: 153221824

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07956
Policy Entropy: 1.23308
Value Function Loss: 0.04945

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07281
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.05685

Collected Steps per Second: 12449.22032
Overall Steps per Second: 9624.61257

Timestep Collection Time: 4.01696
Timestep Consumption Time: 1.17889
PPO Batch Consumption Time: 0.16777
Total Iteration Time: 5.19585

Cumulative Model Updates: 9186
Cumulative Timesteps: 153271832

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 153271832...
Checkpoint 153271832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01066
Policy Entropy: 1.22902
Value Function Loss: 0.04829

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.05886
Value Function Update Magnitude: 0.05293

Collected Steps per Second: 14035.03075
Overall Steps per Second: 11228.35168

Timestep Collection Time: 3.56522
Timestep Consumption Time: 0.89118
PPO Batch Consumption Time: 0.06466
Total Iteration Time: 4.45640

Cumulative Model Updates: 9189
Cumulative Timesteps: 153321870

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01866
Policy Entropy: 1.22631
Value Function Loss: 0.05531

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.05997
Value Function Update Magnitude: 0.05441

Collected Steps per Second: 11559.99108
Overall Steps per Second: 9060.74303

Timestep Collection Time: 4.32786
Timestep Consumption Time: 1.19376
PPO Batch Consumption Time: 0.14018
Total Iteration Time: 5.52162

Cumulative Model Updates: 9192
Cumulative Timesteps: 153371900

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 153371900...
Checkpoint 153371900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09062
Policy Entropy: 1.22244
Value Function Loss: 0.05339

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.05674
Value Function Update Magnitude: 0.05892

Collected Steps per Second: 14128.27467
Overall Steps per Second: 11317.14519

Timestep Collection Time: 3.54155
Timestep Consumption Time: 0.87971
PPO Batch Consumption Time: 0.06350
Total Iteration Time: 4.42126

Cumulative Model Updates: 9195
Cumulative Timesteps: 153421936

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00044
Policy Entropy: 1.22280
Value Function Loss: 0.05267

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.05621
Value Function Update Magnitude: 0.05235

Collected Steps per Second: 12841.57930
Overall Steps per Second: 9699.96939

Timestep Collection Time: 3.89625
Timestep Consumption Time: 1.26191
PPO Batch Consumption Time: 0.16667
Total Iteration Time: 5.15816

Cumulative Model Updates: 9198
Cumulative Timesteps: 153471970

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 153471970...
Checkpoint 153471970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11176
Policy Entropy: 1.22317
Value Function Loss: 0.04362

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10863
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.06005

Collected Steps per Second: 13564.16645
Overall Steps per Second: 11114.76594

Timestep Collection Time: 3.68707
Timestep Consumption Time: 0.81253
PPO Batch Consumption Time: 0.06593
Total Iteration Time: 4.49960

Cumulative Model Updates: 9201
Cumulative Timesteps: 153521982

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02973
Policy Entropy: 1.22514
Value Function Loss: 0.03803

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09093
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.06066

Collected Steps per Second: 13062.12818
Overall Steps per Second: 9857.66572

Timestep Collection Time: 3.82863
Timestep Consumption Time: 1.24458
PPO Batch Consumption Time: 0.16239
Total Iteration Time: 5.07321

Cumulative Model Updates: 9204
Cumulative Timesteps: 153571992

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 153571992...
Checkpoint 153571992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13971
Policy Entropy: 1.23091
Value Function Loss: 0.03719

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.05348
Value Function Update Magnitude: 0.06121

Collected Steps per Second: 13780.69391
Overall Steps per Second: 11142.89589

Timestep Collection Time: 3.62957
Timestep Consumption Time: 0.85921
PPO Batch Consumption Time: 0.06436
Total Iteration Time: 4.48878

Cumulative Model Updates: 9207
Cumulative Timesteps: 153622010

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02258
Policy Entropy: 1.22415
Value Function Loss: 0.04952

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.06406

Collected Steps per Second: 13234.70741
Overall Steps per Second: 9842.36100

Timestep Collection Time: 3.78051
Timestep Consumption Time: 1.30302
PPO Batch Consumption Time: 0.17737
Total Iteration Time: 5.08354

Cumulative Model Updates: 9210
Cumulative Timesteps: 153672044

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 153672044...
Checkpoint 153672044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11434
Policy Entropy: 1.21989
Value Function Loss: 0.05363

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.06257
Value Function Update Magnitude: 0.06598

Collected Steps per Second: 14055.85489
Overall Steps per Second: 11259.99049

Timestep Collection Time: 3.55752
Timestep Consumption Time: 0.88334
PPO Batch Consumption Time: 0.06317
Total Iteration Time: 4.44086

Cumulative Model Updates: 9213
Cumulative Timesteps: 153722048

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05379
Policy Entropy: 1.20799
Value Function Loss: 0.05255

Mean KL Divergence: 0.01698
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.06342
Value Function Update Magnitude: 0.06992

Collected Steps per Second: 12392.11268
Overall Steps per Second: 9723.97173

Timestep Collection Time: 4.03563
Timestep Consumption Time: 1.10733
PPO Batch Consumption Time: 0.14356
Total Iteration Time: 5.14296

Cumulative Model Updates: 9216
Cumulative Timesteps: 153772058

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 153772058...
Checkpoint 153772058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06882
Policy Entropy: 1.20799
Value Function Loss: 0.04372

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.14797
Policy Update Magnitude: 0.05935
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 13809.75761
Overall Steps per Second: 11070.10809

Timestep Collection Time: 3.62135
Timestep Consumption Time: 0.89622
PPO Batch Consumption Time: 0.06618
Total Iteration Time: 4.51757

Cumulative Model Updates: 9219
Cumulative Timesteps: 153822068

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12926
Policy Entropy: 1.21295
Value Function Loss: 0.04247

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 12912.62268
Overall Steps per Second: 9884.27863

Timestep Collection Time: 3.87435
Timestep Consumption Time: 1.18702
PPO Batch Consumption Time: 0.15031
Total Iteration Time: 5.06137

Cumulative Model Updates: 9222
Cumulative Timesteps: 153872096

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 153872096...
Checkpoint 153872096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12644
Policy Entropy: 1.22258
Value Function Loss: 0.03830

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.06628

Collected Steps per Second: 14014.35771
Overall Steps per Second: 11225.32923

Timestep Collection Time: 3.57020
Timestep Consumption Time: 0.88705
PPO Batch Consumption Time: 0.06266
Total Iteration Time: 4.45724

Cumulative Model Updates: 9225
Cumulative Timesteps: 153922130

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11347
Policy Entropy: 1.22756
Value Function Loss: 0.03578

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.05841
Value Function Update Magnitude: 0.06210

Collected Steps per Second: 12926.04163
Overall Steps per Second: 9776.12599

Timestep Collection Time: 3.86955
Timestep Consumption Time: 1.24679
PPO Batch Consumption Time: 0.15838
Total Iteration Time: 5.11634

Cumulative Model Updates: 9228
Cumulative Timesteps: 153972148

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 153972148...
Checkpoint 153972148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00841
Policy Entropy: 1.22088
Value Function Loss: 0.03639

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.05719
Value Function Update Magnitude: 0.06237

Collected Steps per Second: 12982.98843
Overall Steps per Second: 10482.42356

Timestep Collection Time: 3.85212
Timestep Consumption Time: 0.91892
PPO Batch Consumption Time: 0.06548
Total Iteration Time: 4.77103

Cumulative Model Updates: 9231
Cumulative Timesteps: 154022160

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13757
Policy Entropy: 1.22155
Value Function Loss: 0.03884

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.05625
Value Function Update Magnitude: 0.06122

Collected Steps per Second: 12768.11184
Overall Steps per Second: 9608.81298

Timestep Collection Time: 3.91851
Timestep Consumption Time: 1.28837
PPO Batch Consumption Time: 0.17842
Total Iteration Time: 5.20689

Cumulative Model Updates: 9234
Cumulative Timesteps: 154072192

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 154072192...
Checkpoint 154072192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14692
Policy Entropy: 1.21496
Value Function Loss: 0.04304

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.06352

Collected Steps per Second: 12075.30773
Overall Steps per Second: 9271.78129

Timestep Collection Time: 4.14184
Timestep Consumption Time: 1.25238
PPO Batch Consumption Time: 0.14329
Total Iteration Time: 5.39422

Cumulative Model Updates: 9237
Cumulative Timesteps: 154122206

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06749
Policy Entropy: 1.22332
Value Function Loss: 0.05218

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.07497

Collected Steps per Second: 11274.81351
Overall Steps per Second: 8942.80659

Timestep Collection Time: 4.43644
Timestep Consumption Time: 1.15689
PPO Batch Consumption Time: 0.13463
Total Iteration Time: 5.59332

Cumulative Model Updates: 9240
Cumulative Timesteps: 154172226

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 154172226...
Checkpoint 154172226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04589
Policy Entropy: 1.22478
Value Function Loss: 0.04458

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04719
Policy Update Magnitude: 0.05698
Value Function Update Magnitude: 0.07320

Collected Steps per Second: 12127.03359
Overall Steps per Second: 9766.04131

Timestep Collection Time: 4.12714
Timestep Consumption Time: 0.99776
PPO Batch Consumption Time: 0.07974
Total Iteration Time: 5.12490

Cumulative Model Updates: 9243
Cumulative Timesteps: 154222276

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12071
Policy Entropy: 1.22270
Value Function Loss: 0.05059

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05824
Policy Update Magnitude: 0.05560
Value Function Update Magnitude: 0.07243

Collected Steps per Second: 11778.36466
Overall Steps per Second: 8855.29083

Timestep Collection Time: 4.24745
Timestep Consumption Time: 1.40206
PPO Batch Consumption Time: 0.18439
Total Iteration Time: 5.64950

Cumulative Model Updates: 9246
Cumulative Timesteps: 154272304

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 154272304...
Checkpoint 154272304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06426
Policy Entropy: 1.21314
Value Function Loss: 0.03785

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08276
Policy Update Magnitude: 0.05153
Value Function Update Magnitude: 0.07473

Collected Steps per Second: 12710.48568
Overall Steps per Second: 10158.17279

Timestep Collection Time: 3.93423
Timestep Consumption Time: 0.98850
PPO Batch Consumption Time: 0.07328
Total Iteration Time: 4.92274

Cumulative Model Updates: 9249
Cumulative Timesteps: 154322310

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03620
Policy Entropy: 1.21900
Value Function Loss: 0.03772

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06919
Policy Update Magnitude: 0.04848
Value Function Update Magnitude: 0.06895

Collected Steps per Second: 11340.41238
Overall Steps per Second: 8584.27597

Timestep Collection Time: 4.41236
Timestep Consumption Time: 1.41667
PPO Batch Consumption Time: 0.18624
Total Iteration Time: 5.82903

Cumulative Model Updates: 9252
Cumulative Timesteps: 154372348

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 154372348...
Checkpoint 154372348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02273
Policy Entropy: 1.21865
Value Function Loss: 0.02927

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.05026
Value Function Update Magnitude: 0.06098

Collected Steps per Second: 12113.71134
Overall Steps per Second: 9369.05294

Timestep Collection Time: 4.13086
Timestep Consumption Time: 1.21013
PPO Batch Consumption Time: 0.16614
Total Iteration Time: 5.34099

Cumulative Model Updates: 9255
Cumulative Timesteps: 154422388

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08320
Policy Entropy: 1.22536
Value Function Loss: 0.04117

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.05661
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.06463

Collected Steps per Second: 12037.62846
Overall Steps per Second: 9006.15630

Timestep Collection Time: 4.15713
Timestep Consumption Time: 1.39929
PPO Batch Consumption Time: 0.16493
Total Iteration Time: 5.55642

Cumulative Model Updates: 9258
Cumulative Timesteps: 154472430

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 154472430...
Checkpoint 154472430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00981
Policy Entropy: 1.21886
Value Function Loss: 0.04358

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06861
Policy Update Magnitude: 0.06113
Value Function Update Magnitude: 0.07144

Collected Steps per Second: 11855.19374
Overall Steps per Second: 9147.22638

Timestep Collection Time: 4.21925
Timestep Consumption Time: 1.24908
PPO Batch Consumption Time: 0.13197
Total Iteration Time: 5.46832

Cumulative Model Updates: 9261
Cumulative Timesteps: 154522450

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03623
Policy Entropy: 1.22167
Value Function Loss: 0.04713

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.07027

Collected Steps per Second: 12389.37131
Overall Steps per Second: 9304.59173

Timestep Collection Time: 4.03765
Timestep Consumption Time: 1.33862
PPO Batch Consumption Time: 0.16245
Total Iteration Time: 5.37627

Cumulative Model Updates: 9264
Cumulative Timesteps: 154572474

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 154572474...
Checkpoint 154572474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09863
Policy Entropy: 1.21481
Value Function Loss: 0.04310

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08931
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.07358

Collected Steps per Second: 12051.91859
Overall Steps per Second: 9306.44257

Timestep Collection Time: 4.14971
Timestep Consumption Time: 1.22420
PPO Batch Consumption Time: 0.14666
Total Iteration Time: 5.37391

Cumulative Model Updates: 9267
Cumulative Timesteps: 154622486

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07458
Policy Entropy: 1.21779
Value Function Loss: 0.03670

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.06092
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 12381.87973
Overall Steps per Second: 9969.42083

Timestep Collection Time: 4.03913
Timestep Consumption Time: 0.97741
PPO Batch Consumption Time: 0.07032
Total Iteration Time: 5.01654

Cumulative Model Updates: 9270
Cumulative Timesteps: 154672498

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 154672498...
Checkpoint 154672498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04482
Policy Entropy: 1.21422
Value Function Loss: 0.04041

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.05802
Value Function Update Magnitude: 0.07050

Collected Steps per Second: 12014.65131
Overall Steps per Second: 8940.60384

Timestep Collection Time: 4.16458
Timestep Consumption Time: 1.43191
PPO Batch Consumption Time: 0.18332
Total Iteration Time: 5.59649

Cumulative Model Updates: 9273
Cumulative Timesteps: 154722534

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10342
Policy Entropy: 1.21112
Value Function Loss: 0.03957

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.05762
Value Function Update Magnitude: 0.06343

Collected Steps per Second: 11978.34195
Overall Steps per Second: 9707.49195

Timestep Collection Time: 4.17537
Timestep Consumption Time: 0.97673
PPO Batch Consumption Time: 0.07751
Total Iteration Time: 5.15210

Cumulative Model Updates: 9276
Cumulative Timesteps: 154772548

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 154772548...
Checkpoint 154772548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05682
Policy Entropy: 1.21458
Value Function Loss: 0.03929

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.05926
Value Function Update Magnitude: 0.06560

Collected Steps per Second: 11961.99169
Overall Steps per Second: 9224.27575

Timestep Collection Time: 4.18141
Timestep Consumption Time: 1.24102
PPO Batch Consumption Time: 0.16359
Total Iteration Time: 5.42243

Cumulative Model Updates: 9279
Cumulative Timesteps: 154822566

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17209
Policy Entropy: 1.21199
Value Function Loss: 0.04010

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.06094

Collected Steps per Second: 11848.36645
Overall Steps per Second: 8933.47774

Timestep Collection Time: 4.22404
Timestep Consumption Time: 1.37826
PPO Batch Consumption Time: 0.16734
Total Iteration Time: 5.60230

Cumulative Model Updates: 9282
Cumulative Timesteps: 154872614

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 154872614...
Checkpoint 154872614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17682
Policy Entropy: 1.21395
Value Function Loss: 0.04516

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.05568
Value Function Update Magnitude: 0.06293

Collected Steps per Second: 11784.91405
Overall Steps per Second: 9583.60149

Timestep Collection Time: 4.24271
Timestep Consumption Time: 0.97453
PPO Batch Consumption Time: 0.07385
Total Iteration Time: 5.21725

Cumulative Model Updates: 9285
Cumulative Timesteps: 154922614

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03319
Policy Entropy: 1.21680
Value Function Loss: 0.04815

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.06229

Collected Steps per Second: 10430.17780
Overall Steps per Second: 8132.23271

Timestep Collection Time: 4.79397
Timestep Consumption Time: 1.35465
PPO Batch Consumption Time: 0.15006
Total Iteration Time: 6.14862

Cumulative Model Updates: 9288
Cumulative Timesteps: 154972616

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 154972616...
Checkpoint 154972616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05280
Policy Entropy: 1.22101
Value Function Loss: 0.05253

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.05825
Value Function Update Magnitude: 0.07078

Collected Steps per Second: 13138.11230
Overall Steps per Second: 10625.82454

Timestep Collection Time: 3.80618
Timestep Consumption Time: 0.89990
PPO Batch Consumption Time: 0.07084
Total Iteration Time: 4.70608

Cumulative Model Updates: 9291
Cumulative Timesteps: 155022622

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11912
Policy Entropy: 1.23080
Value Function Loss: 0.04903

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07815
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 12609.17595
Overall Steps per Second: 9872.06202

Timestep Collection Time: 3.96806
Timestep Consumption Time: 1.10018
PPO Batch Consumption Time: 0.13438
Total Iteration Time: 5.06824

Cumulative Model Updates: 9294
Cumulative Timesteps: 155072656

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 155072656...
Checkpoint 155072656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16688
Policy Entropy: 1.22199
Value Function Loss: 0.05023

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.05927
Value Function Update Magnitude: 0.07757

Collected Steps per Second: 13738.85960
Overall Steps per Second: 10517.16808

Timestep Collection Time: 3.64237
Timestep Consumption Time: 1.11576
PPO Batch Consumption Time: 0.14163
Total Iteration Time: 4.75812

Cumulative Model Updates: 9297
Cumulative Timesteps: 155122698

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03042
Policy Entropy: 1.21403
Value Function Loss: 0.04607

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.11036
Policy Update Magnitude: 0.05569
Value Function Update Magnitude: 0.07950

Collected Steps per Second: 13601.27208
Overall Steps per Second: 11003.70875

Timestep Collection Time: 3.67701
Timestep Consumption Time: 0.86800
PPO Batch Consumption Time: 0.06829
Total Iteration Time: 4.54501

Cumulative Model Updates: 9300
Cumulative Timesteps: 155172710

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 155172710...
Checkpoint 155172710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10898
Policy Entropy: 1.21276
Value Function Loss: 0.05729

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.07556

Collected Steps per Second: 13090.98471
Overall Steps per Second: 9883.11693

Timestep Collection Time: 3.81942
Timestep Consumption Time: 1.23971
PPO Batch Consumption Time: 0.16193
Total Iteration Time: 5.05913

Cumulative Model Updates: 9303
Cumulative Timesteps: 155222710

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02256
Policy Entropy: 1.22264
Value Function Loss: 0.05535

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.07465

Collected Steps per Second: 13245.06499
Overall Steps per Second: 10599.80962

Timestep Collection Time: 3.77695
Timestep Consumption Time: 0.94256
PPO Batch Consumption Time: 0.07076
Total Iteration Time: 4.71952

Cumulative Model Updates: 9306
Cumulative Timesteps: 155272736

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 155272736...
Checkpoint 155272736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05466
Policy Entropy: 1.22724
Value Function Loss: 0.05880

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.05851
Value Function Update Magnitude: 0.07572

Collected Steps per Second: 13024.23400
Overall Steps per Second: 9892.49946

Timestep Collection Time: 3.83930
Timestep Consumption Time: 1.21543
PPO Batch Consumption Time: 0.15857
Total Iteration Time: 5.05474

Cumulative Model Updates: 9309
Cumulative Timesteps: 155322740

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02343
Policy Entropy: 1.21787
Value Function Loss: 0.05127

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.07337

Collected Steps per Second: 14122.84320
Overall Steps per Second: 10481.37407

Timestep Collection Time: 3.54277
Timestep Consumption Time: 1.23084
PPO Batch Consumption Time: 0.17427
Total Iteration Time: 4.77361

Cumulative Model Updates: 9312
Cumulative Timesteps: 155372774

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 155372774...
Checkpoint 155372774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18957
Policy Entropy: 1.21060
Value Function Loss: 0.05220

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.06004
Value Function Update Magnitude: 0.07278

Collected Steps per Second: 13790.66512
Overall Steps per Second: 10398.59149

Timestep Collection Time: 3.62695
Timestep Consumption Time: 1.18313
PPO Batch Consumption Time: 0.14795
Total Iteration Time: 4.81007

Cumulative Model Updates: 9315
Cumulative Timesteps: 155422792

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00958
Policy Entropy: 1.21833
Value Function Loss: 0.05420

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.06287
Value Function Update Magnitude: 0.07509

Collected Steps per Second: 13245.77690
Overall Steps per Second: 10035.61744

Timestep Collection Time: 3.77856
Timestep Consumption Time: 1.20867
PPO Batch Consumption Time: 0.17326
Total Iteration Time: 4.98724

Cumulative Model Updates: 9318
Cumulative Timesteps: 155472842

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 155472842...
Checkpoint 155472842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03726
Policy Entropy: 1.21892
Value Function Loss: 0.04878

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.07571

Collected Steps per Second: 13899.73423
Overall Steps per Second: 11137.53269

Timestep Collection Time: 3.59748
Timestep Consumption Time: 0.89220
PPO Batch Consumption Time: 0.06490
Total Iteration Time: 4.48968

Cumulative Model Updates: 9321
Cumulative Timesteps: 155522846

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01806
Policy Entropy: 1.21176
Value Function Loss: 0.04257

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.07690

Collected Steps per Second: 12613.19655
Overall Steps per Second: 9449.71776

Timestep Collection Time: 3.96521
Timestep Consumption Time: 1.32743
PPO Batch Consumption Time: 0.19090
Total Iteration Time: 5.29264

Cumulative Model Updates: 9324
Cumulative Timesteps: 155572860

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 155572860...
Checkpoint 155572860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09573
Policy Entropy: 1.21253
Value Function Loss: 0.04483

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.07204

Collected Steps per Second: 14068.95813
Overall Steps per Second: 11343.41805

Timestep Collection Time: 3.55591
Timestep Consumption Time: 0.85440
PPO Batch Consumption Time: 0.05959
Total Iteration Time: 4.41031

Cumulative Model Updates: 9327
Cumulative Timesteps: 155622888

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01627
Policy Entropy: 1.22315
Value Function Loss: 0.05806

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.05718
Value Function Update Magnitude: 0.06823

Collected Steps per Second: 13406.21727
Overall Steps per Second: 10089.34827

Timestep Collection Time: 3.73200
Timestep Consumption Time: 1.22689
PPO Batch Consumption Time: 0.15586
Total Iteration Time: 4.95889

Cumulative Model Updates: 9330
Cumulative Timesteps: 155672920

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 155672920...
Checkpoint 155672920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08486
Policy Entropy: 1.22052
Value Function Loss: 0.05565

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.06255
Value Function Update Magnitude: 0.07104

Collected Steps per Second: 13902.96304
Overall Steps per Second: 11340.50574

Timestep Collection Time: 3.59693
Timestep Consumption Time: 0.81275
PPO Batch Consumption Time: 0.06111
Total Iteration Time: 4.40968

Cumulative Model Updates: 9333
Cumulative Timesteps: 155722928

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00524
Policy Entropy: 1.22847
Value Function Loss: 0.05390

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.05944
Value Function Update Magnitude: 0.08037

Collected Steps per Second: 12822.75584
Overall Steps per Second: 9671.80749

Timestep Collection Time: 3.90010
Timestep Consumption Time: 1.27060
PPO Batch Consumption Time: 0.16906
Total Iteration Time: 5.17070

Cumulative Model Updates: 9336
Cumulative Timesteps: 155772938

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 155772938...
Checkpoint 155772938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02881
Policy Entropy: 1.22330
Value Function Loss: 0.03720

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.07577

Collected Steps per Second: 13691.35278
Overall Steps per Second: 11088.60961

Timestep Collection Time: 3.65428
Timestep Consumption Time: 0.85774
PPO Batch Consumption Time: 0.06486
Total Iteration Time: 4.51202

Cumulative Model Updates: 9339
Cumulative Timesteps: 155822970

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04298
Policy Entropy: 1.21277
Value Function Loss: 0.04082

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.07191

Collected Steps per Second: 11531.55748
Overall Steps per Second: 8830.38218

Timestep Collection Time: 4.33992
Timestep Consumption Time: 1.32756
PPO Batch Consumption Time: 0.13901
Total Iteration Time: 5.66748

Cumulative Model Updates: 9342
Cumulative Timesteps: 155873016

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 155873016...
Checkpoint 155873016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07151
Policy Entropy: 1.21576
Value Function Loss: 0.03854

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.07351

Collected Steps per Second: 12056.01940
Overall Steps per Second: 9751.44140

Timestep Collection Time: 4.15046
Timestep Consumption Time: 0.98089
PPO Batch Consumption Time: 0.07857
Total Iteration Time: 5.13134

Cumulative Model Updates: 9345
Cumulative Timesteps: 155923054

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05699
Policy Entropy: 1.21743
Value Function Loss: 0.04634

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.05457
Value Function Update Magnitude: 0.08111

Collected Steps per Second: 12169.48596
Overall Steps per Second: 9179.03615

Timestep Collection Time: 4.11160
Timestep Consumption Time: 1.33952
PPO Batch Consumption Time: 0.16251
Total Iteration Time: 5.45112

Cumulative Model Updates: 9348
Cumulative Timesteps: 155973090

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 155973090...
Checkpoint 155973090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15258
Policy Entropy: 1.21838
Value Function Loss: 0.05339

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.07761

Collected Steps per Second: 12488.57420
Overall Steps per Second: 9329.56504

Timestep Collection Time: 4.00414
Timestep Consumption Time: 1.35581
PPO Batch Consumption Time: 0.17679
Total Iteration Time: 5.35995

Cumulative Model Updates: 9351
Cumulative Timesteps: 156023096

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03729
Policy Entropy: 1.21070
Value Function Loss: 0.05312

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.07465

Collected Steps per Second: 11223.98064
Overall Steps per Second: 8612.18318

Timestep Collection Time: 4.45546
Timestep Consumption Time: 1.35120
PPO Batch Consumption Time: 0.15853
Total Iteration Time: 5.80666

Cumulative Model Updates: 9354
Cumulative Timesteps: 156073104

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 156073104...
Checkpoint 156073104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01582
Policy Entropy: 1.20615
Value Function Loss: 0.04918

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.05791
Value Function Update Magnitude: 0.07718

Collected Steps per Second: 12017.35144
Overall Steps per Second: 9639.15513

Timestep Collection Time: 4.16198
Timestep Consumption Time: 1.02685
PPO Batch Consumption Time: 0.11890
Total Iteration Time: 5.18884

Cumulative Model Updates: 9357
Cumulative Timesteps: 156123120

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01484
Policy Entropy: 1.20869
Value Function Loss: 0.04538

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.07695

Collected Steps per Second: 11271.51571
Overall Steps per Second: 8639.34866

Timestep Collection Time: 4.43933
Timestep Consumption Time: 1.35254
PPO Batch Consumption Time: 0.16804
Total Iteration Time: 5.79187

Cumulative Model Updates: 9360
Cumulative Timesteps: 156173158

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 156173158...
Checkpoint 156173158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05766
Policy Entropy: 1.21804
Value Function Loss: 0.04432

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.05813
Value Function Update Magnitude: 0.08747

Collected Steps per Second: 11946.47782
Overall Steps per Second: 8965.74696

Timestep Collection Time: 4.18617
Timestep Consumption Time: 1.39172
PPO Batch Consumption Time: 0.18091
Total Iteration Time: 5.57790

Cumulative Model Updates: 9363
Cumulative Timesteps: 156223168

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06714
Policy Entropy: 1.22456
Value Function Loss: 0.04609

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.08098

Collected Steps per Second: 12701.29455
Overall Steps per Second: 10127.38120

Timestep Collection Time: 3.93960
Timestep Consumption Time: 1.00126
PPO Batch Consumption Time: 0.07218
Total Iteration Time: 4.94086

Cumulative Model Updates: 9366
Cumulative Timesteps: 156273206

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 156273206...
Checkpoint 156273206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04881
Policy Entropy: 1.21957
Value Function Loss: 0.04417

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.07994

Collected Steps per Second: 11705.17205
Overall Steps per Second: 8869.05092

Timestep Collection Time: 4.27486
Timestep Consumption Time: 1.36700
PPO Batch Consumption Time: 0.17447
Total Iteration Time: 5.64187

Cumulative Model Updates: 9369
Cumulative Timesteps: 156323244

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16974
Policy Entropy: 1.21108
Value Function Loss: 0.04722

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.05438
Value Function Update Magnitude: 0.07170

Collected Steps per Second: 11918.96564
Overall Steps per Second: 9282.91236

Timestep Collection Time: 4.19600
Timestep Consumption Time: 1.19153
PPO Batch Consumption Time: 0.14686
Total Iteration Time: 5.38753

Cumulative Model Updates: 9372
Cumulative Timesteps: 156373256

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 156373256...
Checkpoint 156373256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10721
Policy Entropy: 1.21205
Value Function Loss: 0.05071

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.05400
Value Function Update Magnitude: 0.07090

Collected Steps per Second: 11941.24994
Overall Steps per Second: 8958.67936

Timestep Collection Time: 4.18884
Timestep Consumption Time: 1.39457
PPO Batch Consumption Time: 0.18361
Total Iteration Time: 5.58341

Cumulative Model Updates: 9375
Cumulative Timesteps: 156423276

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.24357
Policy Entropy: 1.21674
Value Function Loss: 0.05515

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.06569

Collected Steps per Second: 12255.20951
Overall Steps per Second: 9894.70047

Timestep Collection Time: 4.08365
Timestep Consumption Time: 0.97421
PPO Batch Consumption Time: 0.06948
Total Iteration Time: 5.05786

Cumulative Model Updates: 9378
Cumulative Timesteps: 156473322

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 156473322...
Checkpoint 156473322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00906
Policy Entropy: 1.21840
Value Function Loss: 0.05526

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07621
Policy Update Magnitude: 0.05675
Value Function Update Magnitude: 0.06488

Collected Steps per Second: 11951.84835
Overall Steps per Second: 9057.31840

Timestep Collection Time: 4.18345
Timestep Consumption Time: 1.33694
PPO Batch Consumption Time: 0.16705
Total Iteration Time: 5.52040

Cumulative Model Updates: 9381
Cumulative Timesteps: 156523322

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06362
Policy Entropy: 1.22074
Value Function Loss: 0.05307

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.06395

Collected Steps per Second: 12265.89210
Overall Steps per Second: 9267.99137

Timestep Collection Time: 4.07749
Timestep Consumption Time: 1.31894
PPO Batch Consumption Time: 0.14378
Total Iteration Time: 5.39642

Cumulative Model Updates: 9384
Cumulative Timesteps: 156573336

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 156573336...
Checkpoint 156573336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14710
Policy Entropy: 1.22609
Value Function Loss: 0.04973

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.05426
Value Function Update Magnitude: 0.06954

Collected Steps per Second: 11871.55257
Overall Steps per Second: 9014.94462

Timestep Collection Time: 4.21529
Timestep Consumption Time: 1.33572
PPO Batch Consumption Time: 0.18727
Total Iteration Time: 5.55100

Cumulative Model Updates: 9387
Cumulative Timesteps: 156623378

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08309
Policy Entropy: 1.22096
Value Function Loss: 0.03696

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.05419
Value Function Update Magnitude: 0.07335

Collected Steps per Second: 12278.87959
Overall Steps per Second: 9865.59452

Timestep Collection Time: 4.07431
Timestep Consumption Time: 0.99664
PPO Batch Consumption Time: 0.07278
Total Iteration Time: 5.07096

Cumulative Model Updates: 9390
Cumulative Timesteps: 156673406

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 156673406...
Checkpoint 156673406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08139
Policy Entropy: 1.21698
Value Function Loss: 0.04022

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.05385
Value Function Update Magnitude: 0.07263

Collected Steps per Second: 11330.98320
Overall Steps per Second: 8730.14913

Timestep Collection Time: 4.41444
Timestep Consumption Time: 1.31513
PPO Batch Consumption Time: 0.16008
Total Iteration Time: 5.72957

Cumulative Model Updates: 9393
Cumulative Timesteps: 156723426

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07783
Policy Entropy: 1.21767
Value Function Loss: 0.03593

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.05633
Value Function Update Magnitude: 0.07572

Collected Steps per Second: 14367.18600
Overall Steps per Second: 11470.41976

Timestep Collection Time: 3.48057
Timestep Consumption Time: 0.87899
PPO Batch Consumption Time: 0.06321
Total Iteration Time: 4.35956

Cumulative Model Updates: 9396
Cumulative Timesteps: 156773432

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 156773432...
Checkpoint 156773432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08155
Policy Entropy: 1.22581
Value Function Loss: 0.04209

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06001
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.07403

Collected Steps per Second: 13081.35723
Overall Steps per Second: 9961.56267

Timestep Collection Time: 3.82514
Timestep Consumption Time: 1.19797
PPO Batch Consumption Time: 0.14557
Total Iteration Time: 5.02311

Cumulative Model Updates: 9399
Cumulative Timesteps: 156823470

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03480
Policy Entropy: 1.22425
Value Function Loss: 0.03959

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.05281
Value Function Update Magnitude: 0.07877

Collected Steps per Second: 13000.13384
Overall Steps per Second: 9630.35548

Timestep Collection Time: 3.84827
Timestep Consumption Time: 1.34656
PPO Batch Consumption Time: 0.15967
Total Iteration Time: 5.19482

Cumulative Model Updates: 9402
Cumulative Timesteps: 156873498

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 156873498...
Checkpoint 156873498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06895
Policy Entropy: 1.22766
Value Function Loss: 0.04344

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07781
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.08174

Collected Steps per Second: 13562.06409
Overall Steps per Second: 10935.79893

Timestep Collection Time: 3.68734
Timestep Consumption Time: 0.88553
PPO Batch Consumption Time: 0.06242
Total Iteration Time: 4.57287

Cumulative Model Updates: 9405
Cumulative Timesteps: 156923506

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04711
Policy Entropy: 1.22962
Value Function Loss: 0.05230

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.07420

Collected Steps per Second: 12382.47344
Overall Steps per Second: 9277.16631

Timestep Collection Time: 4.04168
Timestep Consumption Time: 1.35285
PPO Batch Consumption Time: 0.19646
Total Iteration Time: 5.39454

Cumulative Model Updates: 9408
Cumulative Timesteps: 156973552

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 156973552...
Checkpoint 156973552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02645
Policy Entropy: 1.22614
Value Function Loss: 0.05313

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.05880
Value Function Update Magnitude: 0.06244

Collected Steps per Second: 13591.92639
Overall Steps per Second: 11129.99096

Timestep Collection Time: 3.68219
Timestep Consumption Time: 0.81449
PPO Batch Consumption Time: 0.06604
Total Iteration Time: 4.49668

Cumulative Model Updates: 9411
Cumulative Timesteps: 157023600

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18151
Policy Entropy: 1.22278
Value Function Loss: 0.05124

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.05734
Value Function Update Magnitude: 0.06620

Collected Steps per Second: 13686.94506
Overall Steps per Second: 10259.59221

Timestep Collection Time: 3.65326
Timestep Consumption Time: 1.22042
PPO Batch Consumption Time: 0.15528
Total Iteration Time: 4.87368

Cumulative Model Updates: 9414
Cumulative Timesteps: 157073602

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 157073602...
Checkpoint 157073602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02638
Policy Entropy: 1.21870
Value Function Loss: 0.05182

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08679
Policy Update Magnitude: 0.05879
Value Function Update Magnitude: 0.06265

Collected Steps per Second: 13452.98169
Overall Steps per Second: 10060.84740

Timestep Collection Time: 3.71769
Timestep Consumption Time: 1.25346
PPO Batch Consumption Time: 0.16177
Total Iteration Time: 4.97115

Cumulative Model Updates: 9417
Cumulative Timesteps: 157123616

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12019
Policy Entropy: 1.22727
Value Function Loss: 0.05362

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.05919
Value Function Update Magnitude: 0.06351

Collected Steps per Second: 13908.54429
Overall Steps per Second: 11167.64993

Timestep Collection Time: 3.59606
Timestep Consumption Time: 0.88259
PPO Batch Consumption Time: 0.06237
Total Iteration Time: 4.47865

Cumulative Model Updates: 9420
Cumulative Timesteps: 157173632

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 157173632...
Checkpoint 157173632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11578
Policy Entropy: 1.23411
Value Function Loss: 0.04974

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.06644

Collected Steps per Second: 12484.67260
Overall Steps per Second: 9438.27347

Timestep Collection Time: 4.00779
Timestep Consumption Time: 1.29360
PPO Batch Consumption Time: 0.17704
Total Iteration Time: 5.30139

Cumulative Model Updates: 9423
Cumulative Timesteps: 157223668

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04417
Policy Entropy: 1.22683
Value Function Loss: 0.03646

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07510
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.06928

Collected Steps per Second: 13840.37067
Overall Steps per Second: 11345.93190

Timestep Collection Time: 3.61378
Timestep Consumption Time: 0.79450
PPO Batch Consumption Time: 0.06098
Total Iteration Time: 4.40828

Cumulative Model Updates: 9426
Cumulative Timesteps: 157273684

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 157273684...
Checkpoint 157273684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01632
Policy Entropy: 1.22334
Value Function Loss: 0.04851

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07518

Collected Steps per Second: 12609.44497
Overall Steps per Second: 9671.42446

Timestep Collection Time: 3.96687
Timestep Consumption Time: 1.20507
PPO Batch Consumption Time: 0.14505
Total Iteration Time: 5.17194

Cumulative Model Updates: 9429
Cumulative Timesteps: 157323704

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07327
Policy Entropy: 1.22795
Value Function Loss: 0.05036

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.05097
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 13783.73293
Overall Steps per Second: 11164.54175

Timestep Collection Time: 3.62804
Timestep Consumption Time: 0.85114
PPO Batch Consumption Time: 0.06113
Total Iteration Time: 4.47918

Cumulative Model Updates: 9432
Cumulative Timesteps: 157373712

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 157373712...
Checkpoint 157373712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06944
Policy Entropy: 1.23350
Value Function Loss: 0.05128

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.08738

Collected Steps per Second: 12726.20424
Overall Steps per Second: 9802.79213

Timestep Collection Time: 3.92937
Timestep Consumption Time: 1.17183
PPO Batch Consumption Time: 0.13623
Total Iteration Time: 5.10120

Cumulative Model Updates: 9435
Cumulative Timesteps: 157423718

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07172
Policy Entropy: 1.24164
Value Function Loss: 0.04224

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06281
Policy Update Magnitude: 0.05895
Value Function Update Magnitude: 0.08324

Collected Steps per Second: 12679.61858
Overall Steps per Second: 9693.10010

Timestep Collection Time: 3.94412
Timestep Consumption Time: 1.21522
PPO Batch Consumption Time: 0.16264
Total Iteration Time: 5.15934

Cumulative Model Updates: 9438
Cumulative Timesteps: 157473728

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 157473728...
Checkpoint 157473728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01784
Policy Entropy: 1.23691
Value Function Loss: 0.03972

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.07234

Collected Steps per Second: 13523.71628
Overall Steps per Second: 11098.39070

Timestep Collection Time: 3.69839
Timestep Consumption Time: 0.80821
PPO Batch Consumption Time: 0.06557
Total Iteration Time: 4.50660

Cumulative Model Updates: 9441
Cumulative Timesteps: 157523744

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01361
Policy Entropy: 1.23303
Value Function Loss: 0.05124

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.06005

Collected Steps per Second: 12511.46024
Overall Steps per Second: 9436.10379

Timestep Collection Time: 3.99730
Timestep Consumption Time: 1.30277
PPO Batch Consumption Time: 0.18130
Total Iteration Time: 5.30007

Cumulative Model Updates: 9444
Cumulative Timesteps: 157573756

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 157573756...
Checkpoint 157573756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08185
Policy Entropy: 1.22801
Value Function Loss: 0.04977

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.06192

Collected Steps per Second: 13540.69934
Overall Steps per Second: 10972.60762

Timestep Collection Time: 3.69331
Timestep Consumption Time: 0.86440
PPO Batch Consumption Time: 0.06415
Total Iteration Time: 4.55771

Cumulative Model Updates: 9447
Cumulative Timesteps: 157623766

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00293
Policy Entropy: 1.21712
Value Function Loss: 0.04593

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.04975
Value Function Update Magnitude: 0.06361

Collected Steps per Second: 13739.49604
Overall Steps per Second: 10383.51178

Timestep Collection Time: 3.64278
Timestep Consumption Time: 1.17736
PPO Batch Consumption Time: 0.13437
Total Iteration Time: 4.82014

Cumulative Model Updates: 9450
Cumulative Timesteps: 157673816

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 157673816...
Checkpoint 157673816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04641
Policy Entropy: 1.21879
Value Function Loss: 0.03709

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.04932
Value Function Update Magnitude: 0.07341

Collected Steps per Second: 13618.96001
Overall Steps per Second: 10984.05036

Timestep Collection Time: 3.67165
Timestep Consumption Time: 0.88077
PPO Batch Consumption Time: 0.06458
Total Iteration Time: 4.55242

Cumulative Model Updates: 9453
Cumulative Timesteps: 157723820

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09509
Policy Entropy: 1.21358
Value Function Loss: 0.03509

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.07097

Collected Steps per Second: 12563.74099
Overall Steps per Second: 9583.69234

Timestep Collection Time: 3.98209
Timestep Consumption Time: 1.23823
PPO Batch Consumption Time: 0.16485
Total Iteration Time: 5.22033

Cumulative Model Updates: 9456
Cumulative Timesteps: 157773850

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 157773850...
Checkpoint 157773850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00785
Policy Entropy: 1.21648
Value Function Loss: 0.04356

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.07358

Collected Steps per Second: 14079.80359
Overall Steps per Second: 11311.04496

Timestep Collection Time: 3.55460
Timestep Consumption Time: 0.87011
PPO Batch Consumption Time: 0.06060
Total Iteration Time: 4.42470

Cumulative Model Updates: 9459
Cumulative Timesteps: 157823898

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05550
Policy Entropy: 1.22417
Value Function Loss: 0.04972

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.05410
Value Function Update Magnitude: 0.06765

Collected Steps per Second: 12412.72539
Overall Steps per Second: 9343.27697

Timestep Collection Time: 4.03119
Timestep Consumption Time: 1.32432
PPO Batch Consumption Time: 0.18308
Total Iteration Time: 5.35551

Cumulative Model Updates: 9462
Cumulative Timesteps: 157873936

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 157873936...
Checkpoint 157873936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00132
Policy Entropy: 1.22819
Value Function Loss: 0.04276

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06898
Policy Update Magnitude: 0.05622
Value Function Update Magnitude: 0.06795

Collected Steps per Second: 13320.85722
Overall Steps per Second: 10073.80553

Timestep Collection Time: 3.75516
Timestep Consumption Time: 1.21039
PPO Batch Consumption Time: 0.17774
Total Iteration Time: 4.96555

Cumulative Model Updates: 9465
Cumulative Timesteps: 157923958

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12591
Policy Entropy: 1.22237
Value Function Loss: 0.04721

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.05850
Value Function Update Magnitude: 0.07496

Collected Steps per Second: 13541.32823
Overall Steps per Second: 10900.01605

Timestep Collection Time: 3.69535
Timestep Consumption Time: 0.89547
PPO Batch Consumption Time: 0.06657
Total Iteration Time: 4.59082

Cumulative Model Updates: 9468
Cumulative Timesteps: 157973998

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 157973998...
Checkpoint 157973998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08073
Policy Entropy: 1.21727
Value Function Loss: 0.05195

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07055
Policy Update Magnitude: 0.05947
Value Function Update Magnitude: 0.08037

Collected Steps per Second: 13155.10243
Overall Steps per Second: 9964.83966

Timestep Collection Time: 3.80324
Timestep Consumption Time: 1.21761
PPO Batch Consumption Time: 0.15003
Total Iteration Time: 5.02085

Cumulative Model Updates: 9471
Cumulative Timesteps: 158024030

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00645
Policy Entropy: 1.21300
Value Function Loss: 0.06602

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.08295

Collected Steps per Second: 13966.02286
Overall Steps per Second: 11163.82702

Timestep Collection Time: 3.58355
Timestep Consumption Time: 0.89950
PPO Batch Consumption Time: 0.06305
Total Iteration Time: 4.48305

Cumulative Model Updates: 9474
Cumulative Timesteps: 158074078

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 158074078...
Checkpoint 158074078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04184
Policy Entropy: 1.22754
Value Function Loss: 0.07135

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.06512
Value Function Update Magnitude: 0.08233

Collected Steps per Second: 12478.29457
Overall Steps per Second: 9476.89318

Timestep Collection Time: 4.00888
Timestep Consumption Time: 1.26964
PPO Batch Consumption Time: 0.17002
Total Iteration Time: 5.27852

Cumulative Model Updates: 9477
Cumulative Timesteps: 158124102

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05607
Policy Entropy: 1.22328
Value Function Loss: 0.06801

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.06890
Value Function Update Magnitude: 0.09861

Collected Steps per Second: 13622.24123
Overall Steps per Second: 11206.27974

Timestep Collection Time: 3.67238
Timestep Consumption Time: 0.79173
PPO Batch Consumption Time: 0.06264
Total Iteration Time: 4.46410

Cumulative Model Updates: 9480
Cumulative Timesteps: 158174128

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 158174128...
Checkpoint 158174128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00840
Policy Entropy: 1.23201
Value Function Loss: 0.06052

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.07088
Value Function Update Magnitude: 0.10029

Collected Steps per Second: 11979.91438
Overall Steps per Second: 8750.88076

Timestep Collection Time: 4.17666
Timestep Consumption Time: 1.54117
PPO Batch Consumption Time: 0.17620
Total Iteration Time: 5.71782

Cumulative Model Updates: 9483
Cumulative Timesteps: 158224164

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05709
Policy Entropy: 1.23061
Value Function Loss: 0.05424

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.06817
Value Function Update Magnitude: 0.09646

Collected Steps per Second: 11575.29366
Overall Steps per Second: 8981.50902

Timestep Collection Time: 4.32196
Timestep Consumption Time: 1.24815
PPO Batch Consumption Time: 0.14469
Total Iteration Time: 5.57011

Cumulative Model Updates: 9486
Cumulative Timesteps: 158274192

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 158274192...
Checkpoint 158274192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10647
Policy Entropy: 1.22648
Value Function Loss: 0.04796

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08910
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.08918

Collected Steps per Second: 12500.66654
Overall Steps per Second: 9295.76977

Timestep Collection Time: 4.00011
Timestep Consumption Time: 1.37911
PPO Batch Consumption Time: 0.18170
Total Iteration Time: 5.37922

Cumulative Model Updates: 9489
Cumulative Timesteps: 158324196

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08101
Policy Entropy: 1.22166
Value Function Loss: 0.03915

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08013
Policy Update Magnitude: 0.06182
Value Function Update Magnitude: 0.08392

Collected Steps per Second: 11796.71785
Overall Steps per Second: 8897.86722

Timestep Collection Time: 4.24016
Timestep Consumption Time: 1.38141
PPO Batch Consumption Time: 0.15795
Total Iteration Time: 5.62157

Cumulative Model Updates: 9492
Cumulative Timesteps: 158374216

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 158374216...
Checkpoint 158374216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14412
Policy Entropy: 1.21872
Value Function Loss: 0.04174

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.06066
Value Function Update Magnitude: 0.07886

Collected Steps per Second: 11951.20437
Overall Steps per Second: 9701.61708

Timestep Collection Time: 4.18435
Timestep Consumption Time: 0.97026
PPO Batch Consumption Time: 0.07244
Total Iteration Time: 5.15460

Cumulative Model Updates: 9495
Cumulative Timesteps: 158424224

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03877
Policy Entropy: 1.21893
Value Function Loss: 0.05269

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.07596

Collected Steps per Second: 12279.01620
Overall Steps per Second: 9239.64771

Timestep Collection Time: 4.07443
Timestep Consumption Time: 1.34028
PPO Batch Consumption Time: 0.16494
Total Iteration Time: 5.41471

Cumulative Model Updates: 9498
Cumulative Timesteps: 158474254

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 158474254...
Checkpoint 158474254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02572
Policy Entropy: 1.23024
Value Function Loss: 0.05492

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.07694

Collected Steps per Second: 11914.66089
Overall Steps per Second: 8963.38661

Timestep Collection Time: 4.19953
Timestep Consumption Time: 1.38273
PPO Batch Consumption Time: 0.17658
Total Iteration Time: 5.58227

Cumulative Model Updates: 9501
Cumulative Timesteps: 158524290

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06887
Policy Entropy: 1.22357
Value Function Loss: 0.05330

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.07773

Collected Steps per Second: 11299.56525
Overall Steps per Second: 9238.67219

Timestep Collection Time: 4.42672
Timestep Consumption Time: 0.98748
PPO Batch Consumption Time: 0.06224
Total Iteration Time: 5.41420

Cumulative Model Updates: 9504
Cumulative Timesteps: 158574310

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 158574310...
Checkpoint 158574310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00434
Policy Entropy: 1.21610
Value Function Loss: 0.03825

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.05547
Value Function Update Magnitude: 0.07680

Collected Steps per Second: 11198.45376
Overall Steps per Second: 8662.79132

Timestep Collection Time: 4.46633
Timestep Consumption Time: 1.30733
PPO Batch Consumption Time: 0.15073
Total Iteration Time: 5.77366

Cumulative Model Updates: 9507
Cumulative Timesteps: 158624326

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08336
Policy Entropy: 1.21650
Value Function Loss: 0.04165

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.05375
Value Function Update Magnitude: 0.07637

Collected Steps per Second: 11625.34234
Overall Steps per Second: 8960.55045

Timestep Collection Time: 4.30215
Timestep Consumption Time: 1.27942
PPO Batch Consumption Time: 0.13867
Total Iteration Time: 5.58158

Cumulative Model Updates: 9510
Cumulative Timesteps: 158674340

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 158674340...
Checkpoint 158674340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03414
Policy Entropy: 1.22618
Value Function Loss: 0.03986

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06865
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.07565

Collected Steps per Second: 12670.35254
Overall Steps per Second: 10015.61596

Timestep Collection Time: 3.94875
Timestep Consumption Time: 1.04665
PPO Batch Consumption Time: 0.07135
Total Iteration Time: 4.99540

Cumulative Model Updates: 9513
Cumulative Timesteps: 158724372

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07487
Policy Entropy: 1.22058
Value Function Loss: 0.04017

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.07784

Collected Steps per Second: 10600.21678
Overall Steps per Second: 8095.21354

Timestep Collection Time: 4.72160
Timestep Consumption Time: 1.46106
PPO Batch Consumption Time: 0.18647
Total Iteration Time: 6.18267

Cumulative Model Updates: 9516
Cumulative Timesteps: 158774422

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 158774422...
Checkpoint 158774422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03054
Policy Entropy: 1.22144
Value Function Loss: 0.03956

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.07493

Collected Steps per Second: 11738.05658
Overall Steps per Second: 8964.28777

Timestep Collection Time: 4.26033
Timestep Consumption Time: 1.31825
PPO Batch Consumption Time: 0.18217
Total Iteration Time: 5.57858

Cumulative Model Updates: 9519
Cumulative Timesteps: 158824430

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06848
Policy Entropy: 1.22410
Value Function Loss: 0.04162

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.05958
Value Function Update Magnitude: 0.08257

Collected Steps per Second: 11453.10037
Overall Steps per Second: 9418.49447

Timestep Collection Time: 4.36965
Timestep Consumption Time: 0.94394
PPO Batch Consumption Time: 0.05334
Total Iteration Time: 5.31359

Cumulative Model Updates: 9522
Cumulative Timesteps: 158874476

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 158874476...
Checkpoint 158874476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04358
Policy Entropy: 1.22509
Value Function Loss: 0.04256

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.08201

Collected Steps per Second: 11754.10370
Overall Steps per Second: 8843.82292

Timestep Collection Time: 4.25417
Timestep Consumption Time: 1.39994
PPO Batch Consumption Time: 0.19070
Total Iteration Time: 5.65412

Cumulative Model Updates: 9525
Cumulative Timesteps: 158924480

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00423
Policy Entropy: 1.22494
Value Function Loss: 0.03991

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06015
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.07256

Collected Steps per Second: 12483.49328
Overall Steps per Second: 10009.29598

Timestep Collection Time: 4.00721
Timestep Consumption Time: 0.99054
PPO Batch Consumption Time: 0.07126
Total Iteration Time: 4.99775

Cumulative Model Updates: 9528
Cumulative Timesteps: 158974504

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 158974504...
Checkpoint 158974504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00200
Policy Entropy: 1.21878
Value Function Loss: 0.04123

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.05693
Value Function Update Magnitude: 0.08789

Collected Steps per Second: 10659.57864
Overall Steps per Second: 8092.84089

Timestep Collection Time: 4.69212
Timestep Consumption Time: 1.48816
PPO Batch Consumption Time: 0.19510
Total Iteration Time: 6.18028

Cumulative Model Updates: 9531
Cumulative Timesteps: 159024520

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06712
Policy Entropy: 1.21775
Value Function Loss: 0.03888

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06437
Policy Update Magnitude: 0.05368
Value Function Update Magnitude: 0.07476

Collected Steps per Second: 12004.86319
Overall Steps per Second: 9405.35277

Timestep Collection Time: 4.16648
Timestep Consumption Time: 1.15156
PPO Batch Consumption Time: 0.16316
Total Iteration Time: 5.31804

Cumulative Model Updates: 9534
Cumulative Timesteps: 159074538

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 159074538...
Checkpoint 159074538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15884
Policy Entropy: 1.21800
Value Function Loss: 0.04533

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.05909
Value Function Update Magnitude: 0.07456

Collected Steps per Second: 11899.40649
Overall Steps per Second: 9009.66578

Timestep Collection Time: 4.20441
Timestep Consumption Time: 1.34851
PPO Batch Consumption Time: 0.16560
Total Iteration Time: 5.55293

Cumulative Model Updates: 9537
Cumulative Timesteps: 159124568

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14669
Policy Entropy: 1.21267
Value Function Loss: 0.04798

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.06111
Value Function Update Magnitude: 0.08068

Collected Steps per Second: 12678.87607
Overall Steps per Second: 9847.99352

Timestep Collection Time: 3.94499
Timestep Consumption Time: 1.13402
PPO Batch Consumption Time: 0.13974
Total Iteration Time: 5.07900

Cumulative Model Updates: 9540
Cumulative Timesteps: 159174586

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 159174586...
Checkpoint 159174586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04985
Policy Entropy: 1.21445
Value Function Loss: 0.04601

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.06382
Value Function Update Magnitude: 0.08684

Collected Steps per Second: 13183.82450
Overall Steps per Second: 9991.88456

Timestep Collection Time: 3.79495
Timestep Consumption Time: 1.21231
PPO Batch Consumption Time: 0.10350
Total Iteration Time: 5.00726

Cumulative Model Updates: 9543
Cumulative Timesteps: 159224618

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.16074
Policy Entropy: 1.21943
Value Function Loss: 0.04228

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10990
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.08050

Collected Steps per Second: 10791.70739
Overall Steps per Second: 8533.05708

Timestep Collection Time: 4.63671
Timestep Consumption Time: 1.22731
PPO Batch Consumption Time: 0.11007
Total Iteration Time: 5.86402

Cumulative Model Updates: 9546
Cumulative Timesteps: 159274656

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 159274656...
Checkpoint 159274656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00453
Policy Entropy: 1.21973
Value Function Loss: 0.05462

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07853
Policy Update Magnitude: 0.06406
Value Function Update Magnitude: 0.07466

Collected Steps per Second: 9301.99287
Overall Steps per Second: 7886.07375

Timestep Collection Time: 5.38035
Timestep Consumption Time: 0.96602
PPO Batch Consumption Time: 0.02614
Total Iteration Time: 6.34638

Cumulative Model Updates: 9549
Cumulative Timesteps: 159324704

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01950
Policy Entropy: 1.22057
Value Function Loss: 0.05230

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07680
Policy Update Magnitude: 0.06194
Value Function Update Magnitude: 0.07371

Collected Steps per Second: 13189.39586
Overall Steps per Second: 10551.81977

Timestep Collection Time: 3.79396
Timestep Consumption Time: 0.94835
PPO Batch Consumption Time: 0.06576
Total Iteration Time: 4.74231

Cumulative Model Updates: 9552
Cumulative Timesteps: 159374744

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 159374744...
Checkpoint 159374744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02287
Policy Entropy: 1.21236
Value Function Loss: 0.04577

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.07216

Collected Steps per Second: 11993.51711
Overall Steps per Second: 9642.64432

Timestep Collection Time: 4.16959
Timestep Consumption Time: 1.01654
PPO Batch Consumption Time: 0.08860
Total Iteration Time: 5.18613

Cumulative Model Updates: 9555
Cumulative Timesteps: 159424752

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09494
Policy Entropy: 1.21846
Value Function Loss: 0.04877

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.06410

Collected Steps per Second: 13076.99672
Overall Steps per Second: 10765.36725

Timestep Collection Time: 3.82504
Timestep Consumption Time: 0.82134
PPO Batch Consumption Time: 0.06202
Total Iteration Time: 4.64638

Cumulative Model Updates: 9558
Cumulative Timesteps: 159474772

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 159474772...
Checkpoint 159474772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08612
Policy Entropy: 1.21113
Value Function Loss: 0.05712

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.05765
Value Function Update Magnitude: 0.06640

Collected Steps per Second: 11941.22599
Overall Steps per Second: 9718.40460

Timestep Collection Time: 4.18751
Timestep Consumption Time: 0.95778
PPO Batch Consumption Time: 0.06955
Total Iteration Time: 5.14529

Cumulative Model Updates: 9561
Cumulative Timesteps: 159524776

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00005
Policy Entropy: 1.21202
Value Function Loss: 0.06205

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.07795

Collected Steps per Second: 13208.47599
Overall Steps per Second: 10658.06667

Timestep Collection Time: 3.78605
Timestep Consumption Time: 0.90598
PPO Batch Consumption Time: 0.06762
Total Iteration Time: 4.69203

Cumulative Model Updates: 9564
Cumulative Timesteps: 159574784

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 159574784...
Checkpoint 159574784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03931
Policy Entropy: 1.21495
Value Function Loss: 0.05133

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.06085
Value Function Update Magnitude: 0.07354

Collected Steps per Second: 13338.26205
Overall Steps per Second: 10272.45541

Timestep Collection Time: 3.75131
Timestep Consumption Time: 1.11958
PPO Batch Consumption Time: 0.11380
Total Iteration Time: 4.87089

Cumulative Model Updates: 9567
Cumulative Timesteps: 159624820

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00247
Policy Entropy: 1.21806
Value Function Loss: 0.04378

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.07406

Collected Steps per Second: 10495.56867
Overall Steps per Second: 8040.99079

Timestep Collection Time: 4.76639
Timestep Consumption Time: 1.45498
PPO Batch Consumption Time: 0.12026
Total Iteration Time: 6.22137

Cumulative Model Updates: 9570
Cumulative Timesteps: 159674846

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 159674846...
Checkpoint 159674846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08289
Policy Entropy: 1.22461
Value Function Loss: 0.05145

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.06903

Collected Steps per Second: 9384.04729
Overall Steps per Second: 7647.33217

Timestep Collection Time: 5.32926
Timestep Consumption Time: 1.21028
PPO Batch Consumption Time: 0.12123
Total Iteration Time: 6.53954

Cumulative Model Updates: 9573
Cumulative Timesteps: 159724856

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11797
Policy Entropy: 1.21937
Value Function Loss: 0.06062

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.06258
Value Function Update Magnitude: 0.06502

Collected Steps per Second: 10078.19790
Overall Steps per Second: 8055.44247

Timestep Collection Time: 4.96120
Timestep Consumption Time: 1.24578
PPO Batch Consumption Time: 0.11914
Total Iteration Time: 6.20698

Cumulative Model Updates: 9576
Cumulative Timesteps: 159774856

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 159774856...
Checkpoint 159774856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05660
Policy Entropy: 1.21745
Value Function Loss: 0.05398

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.07697

Collected Steps per Second: 10698.55848
Overall Steps per Second: 8781.84343

Timestep Collection Time: 4.67502
Timestep Consumption Time: 1.02036
PPO Batch Consumption Time: 0.07057
Total Iteration Time: 5.69539

Cumulative Model Updates: 9579
Cumulative Timesteps: 159824872

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02013
Policy Entropy: 1.21885
Value Function Loss: 0.04938

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.06324
Value Function Update Magnitude: 0.08143

Collected Steps per Second: 11028.54721
Overall Steps per Second: 8831.12101

Timestep Collection Time: 4.53750
Timestep Consumption Time: 1.12905
PPO Batch Consumption Time: 0.09995
Total Iteration Time: 5.66655

Cumulative Model Updates: 9582
Cumulative Timesteps: 159874914

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 159874914...
Checkpoint 159874914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.25763
Policy Entropy: 1.22170
Value Function Loss: 0.03938

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.06330
Value Function Update Magnitude: 0.06870

Collected Steps per Second: 11556.45803
Overall Steps per Second: 9326.86192

Timestep Collection Time: 4.32814
Timestep Consumption Time: 1.03465
PPO Batch Consumption Time: 0.06934
Total Iteration Time: 5.36279

Cumulative Model Updates: 9585
Cumulative Timesteps: 159924932

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05710
Policy Entropy: 1.23082
Value Function Loss: 0.04170

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.05979
Value Function Update Magnitude: 0.06464

Collected Steps per Second: 10478.04429
Overall Steps per Second: 8600.18472

Timestep Collection Time: 4.77322
Timestep Consumption Time: 1.04224
PPO Batch Consumption Time: 0.08512
Total Iteration Time: 5.81546

Cumulative Model Updates: 9588
Cumulative Timesteps: 159974946

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 159974946...
Checkpoint 159974946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02866
Policy Entropy: 1.22122
Value Function Loss: 0.04450

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.05986

Collected Steps per Second: 11875.02315
Overall Steps per Second: 9280.51058

Timestep Collection Time: 4.21321
Timestep Consumption Time: 1.17787
PPO Batch Consumption Time: 0.10143
Total Iteration Time: 5.39108

Cumulative Model Updates: 9591
Cumulative Timesteps: 160024978

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03884
Policy Entropy: 1.21831
Value Function Loss: 0.04415

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.06058
Value Function Update Magnitude: 0.05724

Collected Steps per Second: 11366.76393
Overall Steps per Second: 8956.15448

Timestep Collection Time: 4.40055
Timestep Consumption Time: 1.18444
PPO Batch Consumption Time: 0.10810
Total Iteration Time: 5.58499

Cumulative Model Updates: 9594
Cumulative Timesteps: 160074998

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 160074998...
Checkpoint 160074998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02681
Policy Entropy: 1.21714
Value Function Loss: 0.05893

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.06033
Value Function Update Magnitude: 0.06087

Collected Steps per Second: 10771.95903
Overall Steps per Second: 8994.16607

Timestep Collection Time: 4.64391
Timestep Consumption Time: 0.91792
PPO Batch Consumption Time: 0.06220
Total Iteration Time: 5.56183

Cumulative Model Updates: 9597
Cumulative Timesteps: 160125022

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07009
Policy Entropy: 1.22554
Value Function Loss: 0.05519

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.06485
Value Function Update Magnitude: 0.07117

Collected Steps per Second: 10111.78276
Overall Steps per Second: 8019.97354

Timestep Collection Time: 4.94829
Timestep Consumption Time: 1.29064
PPO Batch Consumption Time: 0.09781
Total Iteration Time: 6.23892

Cumulative Model Updates: 9600
Cumulative Timesteps: 160175058

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 160175058...
Checkpoint 160175058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10562
Policy Entropy: 1.22895
Value Function Loss: 0.05187

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.07100

Collected Steps per Second: 11333.43057
Overall Steps per Second: 8983.62348

Timestep Collection Time: 4.41279
Timestep Consumption Time: 1.15423
PPO Batch Consumption Time: 0.09531
Total Iteration Time: 5.56702

Cumulative Model Updates: 9603
Cumulative Timesteps: 160225070

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08521
Policy Entropy: 1.23438
Value Function Loss: 0.05126

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.05912
Value Function Update Magnitude: 0.06996

Collected Steps per Second: 11291.18147
Overall Steps per Second: 9003.90620

Timestep Collection Time: 4.42823
Timestep Consumption Time: 1.12491
PPO Batch Consumption Time: 0.07628
Total Iteration Time: 5.55315

Cumulative Model Updates: 9606
Cumulative Timesteps: 160275070

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 160275070...
Checkpoint 160275070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00916
Policy Entropy: 1.24026
Value Function Loss: 0.04586

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.06059
Value Function Update Magnitude: 0.07577

Collected Steps per Second: 11099.87760
Overall Steps per Second: 8893.92724

Timestep Collection Time: 4.50546
Timestep Consumption Time: 1.11748
PPO Batch Consumption Time: 0.10123
Total Iteration Time: 5.62294

Cumulative Model Updates: 9609
Cumulative Timesteps: 160325080

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00619
Policy Entropy: 1.23685
Value Function Loss: 0.05308

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.07698

Collected Steps per Second: 11206.86974
Overall Steps per Second: 8965.77567

Timestep Collection Time: 4.46458
Timestep Consumption Time: 1.11597
PPO Batch Consumption Time: 0.12041
Total Iteration Time: 5.58055

Cumulative Model Updates: 9612
Cumulative Timesteps: 160375114

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 160375114...
Checkpoint 160375114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16244
Policy Entropy: 1.22590
Value Function Loss: 0.04593

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.08072

Collected Steps per Second: 11299.41874
Overall Steps per Second: 9077.77247

Timestep Collection Time: 4.42678
Timestep Consumption Time: 1.08339
PPO Batch Consumption Time: 0.08155
Total Iteration Time: 5.51016

Cumulative Model Updates: 9615
Cumulative Timesteps: 160425134

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01289
Policy Entropy: 1.22576
Value Function Loss: 0.05095

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.05629
Value Function Update Magnitude: 0.08272

Collected Steps per Second: 11379.45417
Overall Steps per Second: 9133.88793

Timestep Collection Time: 4.39476
Timestep Consumption Time: 1.08045
PPO Batch Consumption Time: 0.10181
Total Iteration Time: 5.47521

Cumulative Model Updates: 9618
Cumulative Timesteps: 160475144

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 160475144...
Checkpoint 160475144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10248
Policy Entropy: 1.22716
Value Function Loss: 0.03675

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07751
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.08711

Collected Steps per Second: 12032.06899
Overall Steps per Second: 9632.57519

Timestep Collection Time: 4.15805
Timestep Consumption Time: 1.03578
PPO Batch Consumption Time: 0.08894
Total Iteration Time: 5.19383

Cumulative Model Updates: 9621
Cumulative Timesteps: 160525174

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02515
Policy Entropy: 1.23358
Value Function Loss: 0.03364

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.08409

Collected Steps per Second: 12544.11947
Overall Steps per Second: 10165.91430

Timestep Collection Time: 3.98625
Timestep Consumption Time: 0.93254
PPO Batch Consumption Time: 0.07045
Total Iteration Time: 4.91879

Cumulative Model Updates: 9624
Cumulative Timesteps: 160575178

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 160575178...
Checkpoint 160575178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04124
Policy Entropy: 1.23040
Value Function Loss: 0.02644

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.07769

Collected Steps per Second: 12813.84263
Overall Steps per Second: 10309.40636

Timestep Collection Time: 3.90250
Timestep Consumption Time: 0.94802
PPO Batch Consumption Time: 0.09641
Total Iteration Time: 4.85052

Cumulative Model Updates: 9627
Cumulative Timesteps: 160625184

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08787
Policy Entropy: 1.22620
Value Function Loss: 0.03691

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.07139

Collected Steps per Second: 12948.72021
Overall Steps per Second: 10471.27033

Timestep Collection Time: 3.86216
Timestep Consumption Time: 0.91377
PPO Batch Consumption Time: 0.06181
Total Iteration Time: 4.77592

Cumulative Model Updates: 9630
Cumulative Timesteps: 160675194

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 160675194...
Checkpoint 160675194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02745
Policy Entropy: 1.22690
Value Function Loss: 0.05098

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.07066

Collected Steps per Second: 11856.85071
Overall Steps per Second: 9602.60634

Timestep Collection Time: 4.21798
Timestep Consumption Time: 0.99019
PPO Batch Consumption Time: 0.08172
Total Iteration Time: 5.20817

Cumulative Model Updates: 9633
Cumulative Timesteps: 160725206

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02260
Policy Entropy: 1.22740
Value Function Loss: 0.05212

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.05248
Value Function Update Magnitude: 0.07162

Collected Steps per Second: 12913.76583
Overall Steps per Second: 10462.07221

Timestep Collection Time: 3.87571
Timestep Consumption Time: 0.90824
PPO Batch Consumption Time: 0.06007
Total Iteration Time: 4.78395

Cumulative Model Updates: 9636
Cumulative Timesteps: 160775256

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 160775256...
Checkpoint 160775256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01750
Policy Entropy: 1.22483
Value Function Loss: 0.05025

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 11847.71223
Overall Steps per Second: 9638.26813

Timestep Collection Time: 4.22157
Timestep Consumption Time: 0.96774
PPO Batch Consumption Time: 0.07263
Total Iteration Time: 5.18931

Cumulative Model Updates: 9639
Cumulative Timesteps: 160825272

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03283
Policy Entropy: 1.22059
Value Function Loss: 0.04209

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.05685
Value Function Update Magnitude: 0.06854

Collected Steps per Second: 12801.64195
Overall Steps per Second: 10061.13238

Timestep Collection Time: 3.90997
Timestep Consumption Time: 1.06502
PPO Batch Consumption Time: 0.10931
Total Iteration Time: 4.97499

Cumulative Model Updates: 9642
Cumulative Timesteps: 160875326

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 160875326...
Checkpoint 160875326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04466
Policy Entropy: 1.22252
Value Function Loss: 0.04794

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.07316

Collected Steps per Second: 13380.87459
Overall Steps per Second: 10697.50924

Timestep Collection Time: 3.73772
Timestep Consumption Time: 0.93757
PPO Batch Consumption Time: 0.06622
Total Iteration Time: 4.67529

Cumulative Model Updates: 9645
Cumulative Timesteps: 160925340

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08535
Policy Entropy: 1.22528
Value Function Loss: 0.04356

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.05351
Value Function Update Magnitude: 0.07847

Collected Steps per Second: 11788.81631
Overall Steps per Second: 9416.46323

Timestep Collection Time: 4.24250
Timestep Consumption Time: 1.06884
PPO Batch Consumption Time: 0.08294
Total Iteration Time: 5.31134

Cumulative Model Updates: 9648
Cumulative Timesteps: 160975354

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 160975354...
Checkpoint 160975354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04522
Policy Entropy: 1.23899
Value Function Loss: 0.04598

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.05867
Value Function Update Magnitude: 0.07630

Collected Steps per Second: 13075.89981
Overall Steps per Second: 10451.24328

Timestep Collection Time: 3.82765
Timestep Consumption Time: 0.96125
PPO Batch Consumption Time: 0.09981
Total Iteration Time: 4.78890

Cumulative Model Updates: 9651
Cumulative Timesteps: 161025404

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.24919
Policy Entropy: 1.24249
Value Function Loss: 0.05613

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07848
Policy Update Magnitude: 0.06006
Value Function Update Magnitude: 0.06811

Collected Steps per Second: 13136.13796
Overall Steps per Second: 10436.19391

Timestep Collection Time: 3.80690
Timestep Consumption Time: 0.98488
PPO Batch Consumption Time: 0.08109
Total Iteration Time: 4.79179

Cumulative Model Updates: 9654
Cumulative Timesteps: 161075412

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 161075412...
Checkpoint 161075412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01390
Policy Entropy: 1.23895
Value Function Loss: 0.05033

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07157
Policy Update Magnitude: 0.05869
Value Function Update Magnitude: 0.07143

Collected Steps per Second: 12886.15325
Overall Steps per Second: 10069.25704

Timestep Collection Time: 3.88293
Timestep Consumption Time: 1.08626
PPO Batch Consumption Time: 0.11623
Total Iteration Time: 4.96918

Cumulative Model Updates: 9657
Cumulative Timesteps: 161125448

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01145
Policy Entropy: 1.23608
Value Function Loss: 0.04398

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.05540
Value Function Update Magnitude: 0.07301

Collected Steps per Second: 13357.97993
Overall Steps per Second: 10743.68473

Timestep Collection Time: 3.74323
Timestep Consumption Time: 0.91085
PPO Batch Consumption Time: 0.06747
Total Iteration Time: 4.65408

Cumulative Model Updates: 9660
Cumulative Timesteps: 161175450

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 161175450...
Checkpoint 161175450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00005
Policy Entropy: 1.23584
Value Function Loss: 0.03395

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06407
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.06980

Collected Steps per Second: 11629.14192
Overall Steps per Second: 9383.60124

Timestep Collection Time: 4.30195
Timestep Consumption Time: 1.02948
PPO Batch Consumption Time: 0.08700
Total Iteration Time: 5.33143

Cumulative Model Updates: 9663
Cumulative Timesteps: 161225478

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02133
Policy Entropy: 1.24613
Value Function Loss: 0.04443

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.05527
Value Function Update Magnitude: 0.06884

Collected Steps per Second: 13084.56486
Overall Steps per Second: 10432.57536

Timestep Collection Time: 3.82130
Timestep Consumption Time: 0.97138
PPO Batch Consumption Time: 0.10751
Total Iteration Time: 4.79268

Cumulative Model Updates: 9666
Cumulative Timesteps: 161275478

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 161275478...
Checkpoint 161275478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00483
Policy Entropy: 1.23873
Value Function Loss: 0.04978

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.05443
Value Function Update Magnitude: 0.06844

Collected Steps per Second: 13060.93186
Overall Steps per Second: 10411.56966

Timestep Collection Time: 3.83219
Timestep Consumption Time: 0.97515
PPO Batch Consumption Time: 0.07900
Total Iteration Time: 4.80734

Cumulative Model Updates: 9669
Cumulative Timesteps: 161325530

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12973
Policy Entropy: 1.23359
Value Function Loss: 0.05610

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.05543
Value Function Update Magnitude: 0.07642

Collected Steps per Second: 12652.90182
Overall Steps per Second: 10052.74422

Timestep Collection Time: 3.95625
Timestep Consumption Time: 1.02329
PPO Batch Consumption Time: 0.09882
Total Iteration Time: 4.97954

Cumulative Model Updates: 9672
Cumulative Timesteps: 161375588

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 161375588...
Checkpoint 161375588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10184
Policy Entropy: 1.22950
Value Function Loss: 0.04595

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.07745

Collected Steps per Second: 13504.91142
Overall Steps per Second: 10829.55952

Timestep Collection Time: 3.70250
Timestep Consumption Time: 0.91467
PPO Batch Consumption Time: 0.06236
Total Iteration Time: 4.61718

Cumulative Model Updates: 9675
Cumulative Timesteps: 161425590

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05233
Policy Entropy: 1.22976
Value Function Loss: 0.05104

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.05623
Value Function Update Magnitude: 0.07371

Collected Steps per Second: 12099.67995
Overall Steps per Second: 9357.82696

Timestep Collection Time: 4.13234
Timestep Consumption Time: 1.21078
PPO Batch Consumption Time: 0.12805
Total Iteration Time: 5.34312

Cumulative Model Updates: 9678
Cumulative Timesteps: 161475590

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 161475590...
Checkpoint 161475590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08394
Policy Entropy: 1.23216
Value Function Loss: 0.04338

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.05696
Value Function Update Magnitude: 0.06817

Collected Steps per Second: 12864.68954
Overall Steps per Second: 10394.51734

Timestep Collection Time: 3.88785
Timestep Consumption Time: 0.92392
PPO Batch Consumption Time: 0.08039
Total Iteration Time: 4.81177

Cumulative Model Updates: 9681
Cumulative Timesteps: 161525606

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08785
Policy Entropy: 1.23294
Value Function Loss: 0.04597

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08288
Policy Update Magnitude: 0.05644
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 12911.00556
Overall Steps per Second: 10074.79761

Timestep Collection Time: 3.87267
Timestep Consumption Time: 1.09021
PPO Batch Consumption Time: 0.10822
Total Iteration Time: 4.96288

Cumulative Model Updates: 9684
Cumulative Timesteps: 161575606

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 161575606...
Checkpoint 161575606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11494
Policy Entropy: 1.23781
Value Function Loss: 0.04058

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06133
Policy Update Magnitude: 0.05499
Value Function Update Magnitude: 0.06968

Collected Steps per Second: 12872.03013
Overall Steps per Second: 10474.20668

Timestep Collection Time: 3.88672
Timestep Consumption Time: 0.88977
PPO Batch Consumption Time: 0.06195
Total Iteration Time: 4.77650

Cumulative Model Updates: 9687
Cumulative Timesteps: 161625636

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01396
Policy Entropy: 1.23488
Value Function Loss: 0.04384

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.07226

Collected Steps per Second: 12425.30152
Overall Steps per Second: 9932.77563

Timestep Collection Time: 4.02711
Timestep Consumption Time: 1.01056
PPO Batch Consumption Time: 0.08263
Total Iteration Time: 5.03767

Cumulative Model Updates: 9690
Cumulative Timesteps: 161675674

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 161675674...
Checkpoint 161675674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01748
Policy Entropy: 1.23716
Value Function Loss: 0.04009

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09657
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.07378

Collected Steps per Second: 13171.84692
Overall Steps per Second: 10597.32024

Timestep Collection Time: 3.79871
Timestep Consumption Time: 0.92286
PPO Batch Consumption Time: 0.06155
Total Iteration Time: 4.72157

Cumulative Model Updates: 9693
Cumulative Timesteps: 161725710

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01552
Policy Entropy: 1.23558
Value Function Loss: 0.04138

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.05529
Value Function Update Magnitude: 0.07377

Collected Steps per Second: 11776.69880
Overall Steps per Second: 9570.75877

Timestep Collection Time: 4.24992
Timestep Consumption Time: 0.97955
PPO Batch Consumption Time: 0.10543
Total Iteration Time: 5.22947

Cumulative Model Updates: 9696
Cumulative Timesteps: 161775760

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 161775760...
Checkpoint 161775760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08899
Policy Entropy: 1.22637
Value Function Loss: 0.04169

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.05250
Value Function Update Magnitude: 0.07360

Collected Steps per Second: 13292.63219
Overall Steps per Second: 10557.29268

Timestep Collection Time: 3.76404
Timestep Consumption Time: 0.97524
PPO Batch Consumption Time: 0.06688
Total Iteration Time: 4.73928

Cumulative Model Updates: 9699
Cumulative Timesteps: 161825794

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00390
Policy Entropy: 1.21889
Value Function Loss: 0.03860

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.07527

Collected Steps per Second: 12900.85226
Overall Steps per Second: 10319.91647

Timestep Collection Time: 3.87773
Timestep Consumption Time: 0.96979
PPO Batch Consumption Time: 0.08578
Total Iteration Time: 4.84752

Cumulative Model Updates: 9702
Cumulative Timesteps: 161875820

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 161875820...
Checkpoint 161875820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06406
Policy Entropy: 1.22664
Value Function Loss: 0.04340

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05281
Policy Update Magnitude: 0.05040
Value Function Update Magnitude: 0.07049

Collected Steps per Second: 13259.80159
Overall Steps per Second: 10644.28354

Timestep Collection Time: 3.77396
Timestep Consumption Time: 0.92734
PPO Batch Consumption Time: 0.06399
Total Iteration Time: 4.70130

Cumulative Model Updates: 9705
Cumulative Timesteps: 161925862

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02425
Policy Entropy: 1.22901
Value Function Loss: 0.04241

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05441
Policy Update Magnitude: 0.05528
Value Function Update Magnitude: 0.07585

Collected Steps per Second: 12709.86129
Overall Steps per Second: 10249.62933

Timestep Collection Time: 3.93411
Timestep Consumption Time: 0.94431
PPO Batch Consumption Time: 0.06724
Total Iteration Time: 4.87842

Cumulative Model Updates: 9708
Cumulative Timesteps: 161975864

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 161975864...
Checkpoint 161975864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17337
Policy Entropy: 1.22981
Value Function Loss: 0.04442

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05796
Policy Update Magnitude: 0.05517
Value Function Update Magnitude: 0.07813

Collected Steps per Second: 12874.88537
Overall Steps per Second: 10588.13234

Timestep Collection Time: 3.88508
Timestep Consumption Time: 0.83907
PPO Batch Consumption Time: 0.06984
Total Iteration Time: 4.72416

Cumulative Model Updates: 9711
Cumulative Timesteps: 162025884

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03080
Policy Entropy: 1.22923
Value Function Loss: 0.03885

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.08119

Collected Steps per Second: 13133.51166
Overall Steps per Second: 10331.74086

Timestep Collection Time: 3.80721
Timestep Consumption Time: 1.03244
PPO Batch Consumption Time: 0.09983
Total Iteration Time: 4.83965

Cumulative Model Updates: 9714
Cumulative Timesteps: 162075886

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 162075886...
Checkpoint 162075886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02504
Policy Entropy: 1.23887
Value Function Loss: 0.03550

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06241
Policy Update Magnitude: 0.05093
Value Function Update Magnitude: 0.07429

Collected Steps per Second: 13163.99247
Overall Steps per Second: 10644.47544

Timestep Collection Time: 3.79915
Timestep Consumption Time: 0.89925
PPO Batch Consumption Time: 0.06661
Total Iteration Time: 4.69840

Cumulative Model Updates: 9717
Cumulative Timesteps: 162125898

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03591
Policy Entropy: 1.23998
Value Function Loss: 0.04471

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05760
Policy Update Magnitude: 0.05222
Value Function Update Magnitude: 0.06402

Collected Steps per Second: 12745.68550
Overall Steps per Second: 10214.85102

Timestep Collection Time: 3.92462
Timestep Consumption Time: 0.97237
PPO Batch Consumption Time: 0.07221
Total Iteration Time: 4.89699

Cumulative Model Updates: 9720
Cumulative Timesteps: 162175920

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 162175920...
Checkpoint 162175920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03609
Policy Entropy: 1.24189
Value Function Loss: 0.03937

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06530
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.06335

Collected Steps per Second: 12886.97963
Overall Steps per Second: 10239.37922

Timestep Collection Time: 3.88035
Timestep Consumption Time: 1.00334
PPO Batch Consumption Time: 0.07213
Total Iteration Time: 4.88369

Cumulative Model Updates: 9723
Cumulative Timesteps: 162225926

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00413
Policy Entropy: 1.23727
Value Function Loss: 0.03983

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.05139
Value Function Update Magnitude: 0.06483

Collected Steps per Second: 11647.49717
Overall Steps per Second: 9492.70071

Timestep Collection Time: 4.29620
Timestep Consumption Time: 0.97522
PPO Batch Consumption Time: 0.09954
Total Iteration Time: 5.27142

Cumulative Model Updates: 9726
Cumulative Timesteps: 162275966

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 162275966...
Checkpoint 162275966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00181
Policy Entropy: 1.24505
Value Function Loss: 0.03474

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.05041
Value Function Update Magnitude: 0.06545

Collected Steps per Second: 13257.05664
Overall Steps per Second: 10698.22724

Timestep Collection Time: 3.77354
Timestep Consumption Time: 0.90256
PPO Batch Consumption Time: 0.06367
Total Iteration Time: 4.67610

Cumulative Model Updates: 9729
Cumulative Timesteps: 162325992

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07992
Policy Entropy: 1.24582
Value Function Loss: 0.04196

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.06390

Collected Steps per Second: 11825.74381
Overall Steps per Second: 9438.79795

Timestep Collection Time: 4.23128
Timestep Consumption Time: 1.07003
PPO Batch Consumption Time: 0.10703
Total Iteration Time: 5.30131

Cumulative Model Updates: 9732
Cumulative Timesteps: 162376030

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 162376030...
Checkpoint 162376030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14243
Policy Entropy: 1.24846
Value Function Loss: 0.04418

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06899
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.06299

Collected Steps per Second: 13078.20224
Overall Steps per Second: 10045.23733

Timestep Collection Time: 3.82346
Timestep Consumption Time: 1.15442
PPO Batch Consumption Time: 0.12193
Total Iteration Time: 4.97788

Cumulative Model Updates: 9735
Cumulative Timesteps: 162426034

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03995
Policy Entropy: 1.24926
Value Function Loss: 0.03906

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07304
Policy Update Magnitude: 0.05336
Value Function Update Magnitude: 0.06720

Collected Steps per Second: 12898.05967
Overall Steps per Second: 10499.15265

Timestep Collection Time: 3.87857
Timestep Consumption Time: 0.88620
PPO Batch Consumption Time: 0.06594
Total Iteration Time: 4.76477

Cumulative Model Updates: 9738
Cumulative Timesteps: 162476060

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 162476060...
Checkpoint 162476060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10117
Policy Entropy: 1.25132
Value Function Loss: 0.03283

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.06336

Collected Steps per Second: 12213.94261
Overall Steps per Second: 9945.18212

Timestep Collection Time: 4.09368
Timestep Consumption Time: 0.93388
PPO Batch Consumption Time: 0.08956
Total Iteration Time: 5.02756

Cumulative Model Updates: 9741
Cumulative Timesteps: 162526060

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00386
Policy Entropy: 1.25240
Value Function Loss: 0.03496

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.04856
Value Function Update Magnitude: 0.06055

Collected Steps per Second: 11667.50969
Overall Steps per Second: 9232.10200

Timestep Collection Time: 4.28540
Timestep Consumption Time: 1.13048
PPO Batch Consumption Time: 0.07978
Total Iteration Time: 5.41588

Cumulative Model Updates: 9744
Cumulative Timesteps: 162576060

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 162576060...
Checkpoint 162576060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02231
Policy Entropy: 1.24728
Value Function Loss: 0.04344

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06241
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.05820

Collected Steps per Second: 11443.76089
Overall Steps per Second: 8989.57407

Timestep Collection Time: 4.36954
Timestep Consumption Time: 1.19290
PPO Batch Consumption Time: 0.10102
Total Iteration Time: 5.56244

Cumulative Model Updates: 9747
Cumulative Timesteps: 162626064

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11019
Policy Entropy: 1.24207
Value Function Loss: 0.04227

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06343
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.06327

Collected Steps per Second: 11536.30708
Overall Steps per Second: 8978.61021

Timestep Collection Time: 4.33501
Timestep Consumption Time: 1.23489
PPO Batch Consumption Time: 0.12448
Total Iteration Time: 5.56990

Cumulative Model Updates: 9750
Cumulative Timesteps: 162676074

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 162676074...
Checkpoint 162676074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03311
Policy Entropy: 1.24088
Value Function Loss: 0.03994

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.05847
Policy Update Magnitude: 0.05298
Value Function Update Magnitude: 0.06247

Collected Steps per Second: 11727.71377
Overall Steps per Second: 9451.13233

Timestep Collection Time: 4.26358
Timestep Consumption Time: 1.02701
PPO Batch Consumption Time: 0.07667
Total Iteration Time: 5.29058

Cumulative Model Updates: 9753
Cumulative Timesteps: 162726076

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03605
Policy Entropy: 1.24948
Value Function Loss: 0.03788

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06095
Policy Update Magnitude: 0.05177
Value Function Update Magnitude: 0.05841

Collected Steps per Second: 9765.55566
Overall Steps per Second: 7931.80814

Timestep Collection Time: 5.12290
Timestep Consumption Time: 1.18436
PPO Batch Consumption Time: 0.10310
Total Iteration Time: 6.30726

Cumulative Model Updates: 9756
Cumulative Timesteps: 162776104

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 162776104...
Checkpoint 162776104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00322
Policy Entropy: 1.25535
Value Function Loss: 0.04091

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.05115
Value Function Update Magnitude: 0.06300

Collected Steps per Second: 10853.50574
Overall Steps per Second: 8654.72879

Timestep Collection Time: 4.60699
Timestep Consumption Time: 1.17043
PPO Batch Consumption Time: 0.09590
Total Iteration Time: 5.77742

Cumulative Model Updates: 9759
Cumulative Timesteps: 162826106

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04701
Policy Entropy: 1.25663
Value Function Loss: 0.03447

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.05130
Value Function Update Magnitude: 0.06271

Collected Steps per Second: 11539.14323
Overall Steps per Second: 9428.28736

Timestep Collection Time: 4.33446
Timestep Consumption Time: 0.97042
PPO Batch Consumption Time: 0.07130
Total Iteration Time: 5.30489

Cumulative Model Updates: 9762
Cumulative Timesteps: 162876122

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 162876122...
Checkpoint 162876122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19276
Policy Entropy: 1.24900
Value Function Loss: 0.04460

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.05720
Value Function Update Magnitude: 0.06144

Collected Steps per Second: 11158.51430
Overall Steps per Second: 8826.39216

Timestep Collection Time: 4.48196
Timestep Consumption Time: 1.18423
PPO Batch Consumption Time: 0.11282
Total Iteration Time: 5.66619

Cumulative Model Updates: 9765
Cumulative Timesteps: 162926134

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04544
Policy Entropy: 1.25648
Value Function Loss: 0.04821

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.05656
Value Function Update Magnitude: 0.06650

Collected Steps per Second: 11184.38944
Overall Steps per Second: 9151.39127

Timestep Collection Time: 4.47052
Timestep Consumption Time: 0.99313
PPO Batch Consumption Time: 0.06638
Total Iteration Time: 5.46365

Cumulative Model Updates: 9768
Cumulative Timesteps: 162976134

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 162976134...
Checkpoint 162976134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02520
Policy Entropy: 1.26183
Value Function Loss: 0.04688

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.05941
Value Function Update Magnitude: 0.06934

Collected Steps per Second: 10225.86406
Overall Steps per Second: 8457.54061

Timestep Collection Time: 4.89171
Timestep Consumption Time: 1.02277
PPO Batch Consumption Time: 0.07832
Total Iteration Time: 5.91449

Cumulative Model Updates: 9771
Cumulative Timesteps: 163026156

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04785
Policy Entropy: 1.27204
Value Function Loss: 0.04256

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.06959

Collected Steps per Second: 11548.17512
Overall Steps per Second: 9251.66795

Timestep Collection Time: 4.32969
Timestep Consumption Time: 1.07474
PPO Batch Consumption Time: 0.07126
Total Iteration Time: 5.40443

Cumulative Model Updates: 9774
Cumulative Timesteps: 163076156

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 163076156...
Checkpoint 163076156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13000
Policy Entropy: 1.27097
Value Function Loss: 0.04464

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.07855
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.07038

Collected Steps per Second: 11395.09368
Overall Steps per Second: 9006.29543

Timestep Collection Time: 4.39101
Timestep Consumption Time: 1.16466
PPO Batch Consumption Time: 0.12345
Total Iteration Time: 5.55567

Cumulative Model Updates: 9777
Cumulative Timesteps: 163126192

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06733
Policy Entropy: 1.27088
Value Function Loss: 0.04761

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.06022
Value Function Update Magnitude: 0.07203

Collected Steps per Second: 11430.16696
Overall Steps per Second: 9267.76380

Timestep Collection Time: 4.37701
Timestep Consumption Time: 1.02127
PPO Batch Consumption Time: 0.08926
Total Iteration Time: 5.39828

Cumulative Model Updates: 9780
Cumulative Timesteps: 163176222

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 163176222...
Checkpoint 163176222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02797
Policy Entropy: 1.27231
Value Function Loss: 0.04816

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.06654

Collected Steps per Second: 11230.64887
Overall Steps per Second: 8944.49526

Timestep Collection Time: 4.45335
Timestep Consumption Time: 1.13825
PPO Batch Consumption Time: 0.06599
Total Iteration Time: 5.59160

Cumulative Model Updates: 9783
Cumulative Timesteps: 163226236

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04736
Policy Entropy: 1.27352
Value Function Loss: 0.04371

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.05593
Value Function Update Magnitude: 0.06384

Collected Steps per Second: 11566.91408
Overall Steps per Second: 9385.67260

Timestep Collection Time: 4.32302
Timestep Consumption Time: 1.00467
PPO Batch Consumption Time: 0.08241
Total Iteration Time: 5.32769

Cumulative Model Updates: 9786
Cumulative Timesteps: 163276240

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 163276240...
Checkpoint 163276240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00347
Policy Entropy: 1.27680
Value Function Loss: 0.04586

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.10582
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.07250

Collected Steps per Second: 10979.57452
Overall Steps per Second: 8585.47034

Timestep Collection Time: 4.55737
Timestep Consumption Time: 1.27085
PPO Batch Consumption Time: 0.11206
Total Iteration Time: 5.82822

Cumulative Model Updates: 9789
Cumulative Timesteps: 163326278

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06475
Policy Entropy: 1.26865
Value Function Loss: 0.04761

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.06800

Collected Steps per Second: 11581.43805
Overall Steps per Second: 9216.81415

Timestep Collection Time: 4.31984
Timestep Consumption Time: 1.10828
PPO Batch Consumption Time: 0.08868
Total Iteration Time: 5.42812

Cumulative Model Updates: 9792
Cumulative Timesteps: 163376308

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 163376308...
Checkpoint 163376308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04643
Policy Entropy: 1.27578
Value Function Loss: 0.04628

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.05081
Value Function Update Magnitude: 0.06984

Collected Steps per Second: 11414.93104
Overall Steps per Second: 9332.03407

Timestep Collection Time: 4.38216
Timestep Consumption Time: 0.97809
PPO Batch Consumption Time: 0.08579
Total Iteration Time: 5.36025

Cumulative Model Updates: 9795
Cumulative Timesteps: 163426330

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03618
Policy Entropy: 1.28876
Value Function Loss: 0.04348

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.06786

Collected Steps per Second: 11877.90137
Overall Steps per Second: 9618.98578

Timestep Collection Time: 4.21186
Timestep Consumption Time: 0.98911
PPO Batch Consumption Time: 0.07335
Total Iteration Time: 5.20096

Cumulative Model Updates: 9798
Cumulative Timesteps: 163476358

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 163476358...
Checkpoint 163476358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.21239
Policy Entropy: 1.28712
Value Function Loss: 0.04885

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.05110
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 12934.48617
Overall Steps per Second: 10615.16485

Timestep Collection Time: 3.86904
Timestep Consumption Time: 0.84535
PPO Batch Consumption Time: 0.06762
Total Iteration Time: 4.71439

Cumulative Model Updates: 9801
Cumulative Timesteps: 163526402

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07886
Policy Entropy: 1.28386
Value Function Loss: 0.06028

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.05444
Value Function Update Magnitude: 0.07203

Collected Steps per Second: 13141.18611
Overall Steps per Second: 10294.24941

Timestep Collection Time: 3.80559
Timestep Consumption Time: 1.05246
PPO Batch Consumption Time: 0.09707
Total Iteration Time: 4.85805

Cumulative Model Updates: 9804
Cumulative Timesteps: 163576412

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 163576412...
Checkpoint 163576412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08214
Policy Entropy: 1.28394
Value Function Loss: 0.05839

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.07877

Collected Steps per Second: 12818.99009
Overall Steps per Second: 10427.97546

Timestep Collection Time: 3.90202
Timestep Consumption Time: 0.89469
PPO Batch Consumption Time: 0.06556
Total Iteration Time: 4.79671

Cumulative Model Updates: 9807
Cumulative Timesteps: 163626432

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06531
Policy Entropy: 1.28428
Value Function Loss: 0.05403

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.05117
Value Function Update Magnitude: 0.07067

Collected Steps per Second: 11607.67306
Overall Steps per Second: 9347.20181

Timestep Collection Time: 4.30922
Timestep Consumption Time: 1.04212
PPO Batch Consumption Time: 0.12263
Total Iteration Time: 5.35133

Cumulative Model Updates: 9810
Cumulative Timesteps: 163676452

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 163676452...
Checkpoint 163676452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12435
Policy Entropy: 1.28559
Value Function Loss: 0.05052

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05493
Policy Update Magnitude: 0.04979
Value Function Update Magnitude: 0.07048

Collected Steps per Second: 12849.98265
Overall Steps per Second: 10448.85391

Timestep Collection Time: 3.89230
Timestep Consumption Time: 0.89444
PPO Batch Consumption Time: 0.06141
Total Iteration Time: 4.78675

Cumulative Model Updates: 9813
Cumulative Timesteps: 163726468

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07285
Policy Entropy: 1.27918
Value Function Loss: 0.04389

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07208
Policy Update Magnitude: 0.04965
Value Function Update Magnitude: 0.07199

Collected Steps per Second: 12415.25970
Overall Steps per Second: 9997.24774

Timestep Collection Time: 4.02924
Timestep Consumption Time: 0.97454
PPO Batch Consumption Time: 0.10660
Total Iteration Time: 5.00378

Cumulative Model Updates: 9816
Cumulative Timesteps: 163776492

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 163776492...
Checkpoint 163776492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01700
Policy Entropy: 1.28215
Value Function Loss: 0.04761

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.04959
Value Function Update Magnitude: 0.08252

Collected Steps per Second: 12792.64775
Overall Steps per Second: 10054.03469

Timestep Collection Time: 3.91147
Timestep Consumption Time: 1.06544
PPO Batch Consumption Time: 0.10440
Total Iteration Time: 4.97691

Cumulative Model Updates: 9819
Cumulative Timesteps: 163826530

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12519
Policy Entropy: 1.28207
Value Function Loss: 0.04889

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.07924

Collected Steps per Second: 13269.71270
Overall Steps per Second: 10740.61995

Timestep Collection Time: 3.77084
Timestep Consumption Time: 0.88792
PPO Batch Consumption Time: 0.06239
Total Iteration Time: 4.65876

Cumulative Model Updates: 9822
Cumulative Timesteps: 163876568

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 163876568...
Checkpoint 163876568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02596
Policy Entropy: 1.29031
Value Function Loss: 0.05080

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.04707
Policy Update Magnitude: 0.05132
Value Function Update Magnitude: 0.07839

Collected Steps per Second: 11746.55122
Overall Steps per Second: 9729.73345

Timestep Collection Time: 4.26031
Timestep Consumption Time: 0.88309
PPO Batch Consumption Time: 0.07267
Total Iteration Time: 5.14341

Cumulative Model Updates: 9825
Cumulative Timesteps: 163926612

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01097
Policy Entropy: 1.28493
Value Function Loss: 0.04475

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07052
Policy Update Magnitude: 0.04818
Value Function Update Magnitude: 0.07870

Collected Steps per Second: 12884.69155
Overall Steps per Second: 10436.75525

Timestep Collection Time: 3.88290
Timestep Consumption Time: 0.91073
PPO Batch Consumption Time: 0.06261
Total Iteration Time: 4.79364

Cumulative Model Updates: 9828
Cumulative Timesteps: 163976642

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 163976642...
Checkpoint 163976642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13038
Policy Entropy: 1.28494
Value Function Loss: 0.03465

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.07507

Collected Steps per Second: 12015.68655
Overall Steps per Second: 9665.96662

Timestep Collection Time: 4.16456
Timestep Consumption Time: 1.01237
PPO Batch Consumption Time: 0.10032
Total Iteration Time: 5.17693

Cumulative Model Updates: 9831
Cumulative Timesteps: 164026682

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.08211
Policy Entropy: 1.28031
Value Function Loss: 0.04395

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.04513
Value Function Update Magnitude: 0.06933

Collected Steps per Second: 13493.71319
Overall Steps per Second: 10832.69445

Timestep Collection Time: 3.70543
Timestep Consumption Time: 0.91023
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 4.61566

Cumulative Model Updates: 9834
Cumulative Timesteps: 164076682

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 164076682...
Checkpoint 164076682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08043
Policy Entropy: 1.28863
Value Function Loss: 0.04251

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.04560
Value Function Update Magnitude: 0.06266

Collected Steps per Second: 10658.46376
Overall Steps per Second: 8696.55153

Timestep Collection Time: 4.69148
Timestep Consumption Time: 1.05838
PPO Batch Consumption Time: 0.10374
Total Iteration Time: 5.74987

Cumulative Model Updates: 9837
Cumulative Timesteps: 164126686

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02617
Policy Entropy: 1.28388
Value Function Loss: 0.04267

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.06297

Collected Steps per Second: 12552.37751
Overall Steps per Second: 10443.43079

Timestep Collection Time: 3.98363
Timestep Consumption Time: 0.80445
PPO Batch Consumption Time: 0.06366
Total Iteration Time: 4.78808

Cumulative Model Updates: 9840
Cumulative Timesteps: 164176690

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 164176690...
Checkpoint 164176690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00534
Policy Entropy: 1.27029
Value Function Loss: 0.03963

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.11804
Policy Update Magnitude: 0.04814
Value Function Update Magnitude: 0.06604

Collected Steps per Second: 8347.99603
Overall Steps per Second: 6939.40851

Timestep Collection Time: 5.99090
Timestep Consumption Time: 1.21606
PPO Batch Consumption Time: 0.08105
Total Iteration Time: 7.20695

Cumulative Model Updates: 9843
Cumulative Timesteps: 164226702

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04935
Policy Entropy: 1.26856
Value Function Loss: 0.03729

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.06942

Collected Steps per Second: 5403.72168
Overall Steps per Second: 4794.37725

Timestep Collection Time: 9.25880
Timestep Consumption Time: 1.17675
PPO Batch Consumption Time: 0.04088
Total Iteration Time: 10.43556

Cumulative Model Updates: 9846
Cumulative Timesteps: 164276734

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 164276734...
Checkpoint 164276734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.11717
Policy Entropy: 1.27757
Value Function Loss: 0.03751

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.04995
Value Function Update Magnitude: 0.07505

Collected Steps per Second: 9524.48329
Overall Steps per Second: 7596.86480

Timestep Collection Time: 5.25236
Timestep Consumption Time: 1.33273
PPO Batch Consumption Time: 0.13566
Total Iteration Time: 6.58508

Cumulative Model Updates: 9849
Cumulative Timesteps: 164326760

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.21142
Policy Entropy: 1.28079
Value Function Loss: 0.03489

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.10815
Policy Update Magnitude: 0.05015
Value Function Update Magnitude: 0.07346

Collected Steps per Second: 12210.41550
Overall Steps per Second: 9738.53911

Timestep Collection Time: 4.09618
Timestep Consumption Time: 1.03971
PPO Batch Consumption Time: 0.08142
Total Iteration Time: 5.13588

Cumulative Model Updates: 9852
Cumulative Timesteps: 164376776

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 164376776...
Checkpoint 164376776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08327
Policy Entropy: 1.26273
Value Function Loss: 0.04498

Mean KL Divergence: 0.02079
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.07248

Collected Steps per Second: 11401.21086
Overall Steps per Second: 8819.18480

Timestep Collection Time: 4.38620
Timestep Consumption Time: 1.28416
PPO Batch Consumption Time: 0.15445
Total Iteration Time: 5.67037

Cumulative Model Updates: 9855
Cumulative Timesteps: 164426784

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04912
Policy Entropy: 1.26458
Value Function Loss: 0.04372

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.06388
Value Function Update Magnitude: 0.08027

Collected Steps per Second: 10479.94742
Overall Steps per Second: 8190.31763

Timestep Collection Time: 4.77483
Timestep Consumption Time: 1.33482
PPO Batch Consumption Time: 0.16911
Total Iteration Time: 6.10965

Cumulative Model Updates: 9858
Cumulative Timesteps: 164476824

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 164476824...
Checkpoint 164476824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02188
Policy Entropy: 1.26309
Value Function Loss: 0.04136

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.07327

Collected Steps per Second: 12439.58774
Overall Steps per Second: 9204.80835

Timestep Collection Time: 4.02119
Timestep Consumption Time: 1.41314
PPO Batch Consumption Time: 0.19541
Total Iteration Time: 5.43433

Cumulative Model Updates: 9861
Cumulative Timesteps: 164526846

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00006
Policy Entropy: 1.26759
Value Function Loss: 0.03472

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07520
Policy Update Magnitude: 0.06256
Value Function Update Magnitude: 0.06731

Collected Steps per Second: 12575.54286
Overall Steps per Second: 9625.27141

Timestep Collection Time: 3.97756
Timestep Consumption Time: 1.21917
PPO Batch Consumption Time: 0.13698
Total Iteration Time: 5.19674

Cumulative Model Updates: 9864
Cumulative Timesteps: 164576866

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 164576866...
Checkpoint 164576866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06058
Policy Entropy: 1.25380
Value Function Loss: 0.03210

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.06718

Collected Steps per Second: 12277.08294
Overall Steps per Second: 9840.38820

Timestep Collection Time: 4.07524
Timestep Consumption Time: 1.00912
PPO Batch Consumption Time: 0.07539
Total Iteration Time: 5.08435

Cumulative Model Updates: 9867
Cumulative Timesteps: 164626898

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.06688
Policy Entropy: 1.25491
Value Function Loss: 0.03845

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.06171
Value Function Update Magnitude: 0.06735

Collected Steps per Second: 10886.01160
Overall Steps per Second: 8463.32668

Timestep Collection Time: 4.59654
Timestep Consumption Time: 1.31579
PPO Batch Consumption Time: 0.17564
Total Iteration Time: 5.91233

Cumulative Model Updates: 9870
Cumulative Timesteps: 164676936

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 164676936...
Checkpoint 164676936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06469
Policy Entropy: 1.24389
Value Function Loss: 0.03272

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.06164
Value Function Update Magnitude: 0.06572

Collected Steps per Second: 11854.26708
Overall Steps per Second: 8953.22412

Timestep Collection Time: 4.22093
Timestep Consumption Time: 1.36767
PPO Batch Consumption Time: 0.17209
Total Iteration Time: 5.58860

Cumulative Model Updates: 9873
Cumulative Timesteps: 164726972

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04921
Policy Entropy: 1.24652
Value Function Loss: 0.04778

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.05793
Value Function Update Magnitude: 0.07225

Collected Steps per Second: 11460.62327
Overall Steps per Second: 8811.44686

Timestep Collection Time: 4.36573
Timestep Consumption Time: 1.31256
PPO Batch Consumption Time: 0.16815
Total Iteration Time: 5.67830

Cumulative Model Updates: 9876
Cumulative Timesteps: 164777006

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 164777006...
Checkpoint 164777006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16576
Policy Entropy: 1.24798
Value Function Loss: 0.04964

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.05408
Value Function Update Magnitude: 0.06740

Collected Steps per Second: 10694.81337
Overall Steps per Second: 8208.33672

Timestep Collection Time: 4.67535
Timestep Consumption Time: 1.41626
PPO Batch Consumption Time: 0.17894
Total Iteration Time: 6.09161

Cumulative Model Updates: 9879
Cumulative Timesteps: 164827008

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12271
Policy Entropy: 1.25403
Value Function Loss: 0.05554

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06578
Policy Update Magnitude: 0.05660
Value Function Update Magnitude: 0.07077

Collected Steps per Second: 10835.55985
Overall Steps per Second: 8404.24791

Timestep Collection Time: 4.61517
Timestep Consumption Time: 1.33515
PPO Batch Consumption Time: 0.14452
Total Iteration Time: 5.95032

Cumulative Model Updates: 9882
Cumulative Timesteps: 164877016

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 164877016...
Checkpoint 164877016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03433
Policy Entropy: 1.25065
Value Function Loss: 0.05454

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.06810

Collected Steps per Second: 6901.20333
Overall Steps per Second: 6223.62877

Timestep Collection Time: 7.25004
Timestep Consumption Time: 0.78932
PPO Batch Consumption Time: 0.02887
Total Iteration Time: 8.03936

Cumulative Model Updates: 9885
Cumulative Timesteps: 164927050

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05604
Policy Entropy: 1.25003
Value Function Loss: 0.05269

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.07259

Collected Steps per Second: 8205.97407
Overall Steps per Second: 6938.58808

Timestep Collection Time: 6.09653
Timestep Consumption Time: 1.11358
PPO Batch Consumption Time: 0.08760
Total Iteration Time: 7.21011

Cumulative Model Updates: 9888
Cumulative Timesteps: 164977078

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 164977078...
Checkpoint 164977078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08502
Policy Entropy: 1.25170
Value Function Loss: 0.06150

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.05871
Value Function Update Magnitude: 0.07713

Collected Steps per Second: 10056.59007
Overall Steps per Second: 8218.38310

Timestep Collection Time: 4.97226
Timestep Consumption Time: 1.11215
PPO Batch Consumption Time: 0.08448
Total Iteration Time: 6.08441

Cumulative Model Updates: 9891
Cumulative Timesteps: 165027082

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12958
Policy Entropy: 1.25381
Value Function Loss: 0.05822

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.06120
Value Function Update Magnitude: 0.07973

Collected Steps per Second: 8562.67182
Overall Steps per Second: 7289.73519

Timestep Collection Time: 5.84304
Timestep Consumption Time: 1.02031
PPO Batch Consumption Time: 0.08056
Total Iteration Time: 6.86335

Cumulative Model Updates: 9894
Cumulative Timesteps: 165077114

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 165077114...
Checkpoint 165077114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09554
Policy Entropy: 1.24977
Value Function Loss: 0.06377

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.06266
Value Function Update Magnitude: 0.08216

Collected Steps per Second: 11174.70007
Overall Steps per Second: 9119.54240

Timestep Collection Time: 4.47761
Timestep Consumption Time: 1.00906
PPO Batch Consumption Time: 0.06299
Total Iteration Time: 5.48668

Cumulative Model Updates: 9897
Cumulative Timesteps: 165127150

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02694
Policy Entropy: 1.24446
Value Function Loss: 0.06297

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.10439
Policy Update Magnitude: 0.06492
Value Function Update Magnitude: 0.08110

Collected Steps per Second: 10268.11875
Overall Steps per Second: 8258.63353

Timestep Collection Time: 4.87119
Timestep Consumption Time: 1.18526
PPO Batch Consumption Time: 0.12840
Total Iteration Time: 6.05645

Cumulative Model Updates: 9900
Cumulative Timesteps: 165177168

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 165177168...
Checkpoint 165177168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04159
Policy Entropy: 1.24123
Value Function Loss: 0.05482

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.06288
Value Function Update Magnitude: 0.08004

Collected Steps per Second: 12049.98041
Overall Steps per Second: 9738.02382

Timestep Collection Time: 4.15337
Timestep Consumption Time: 0.98607
PPO Batch Consumption Time: 0.07104
Total Iteration Time: 5.13944

Cumulative Model Updates: 9903
Cumulative Timesteps: 165227216

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04333
Policy Entropy: 1.23536
Value Function Loss: 0.04649

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.05929
Value Function Update Magnitude: 0.08231

Collected Steps per Second: 10083.41358
Overall Steps per Second: 8247.19833

Timestep Collection Time: 4.96280
Timestep Consumption Time: 1.10495
PPO Batch Consumption Time: 0.06810
Total Iteration Time: 6.06776

Cumulative Model Updates: 9906
Cumulative Timesteps: 165277258

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 165277258...
Checkpoint 165277258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01271
Policy Entropy: 1.22925
Value Function Loss: 0.04290

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.07198

Collected Steps per Second: 11700.53289
Overall Steps per Second: 9677.03432

Timestep Collection Time: 4.27604
Timestep Consumption Time: 0.89413
PPO Batch Consumption Time: 0.05730
Total Iteration Time: 5.17018

Cumulative Model Updates: 9909
Cumulative Timesteps: 165327290

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02117
Policy Entropy: 1.21906
Value Function Loss: 0.04156

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.06630

Collected Steps per Second: 11343.49804
Overall Steps per Second: 9294.13369

Timestep Collection Time: 4.40975
Timestep Consumption Time: 0.97235
PPO Batch Consumption Time: 0.07924
Total Iteration Time: 5.38210

Cumulative Model Updates: 9912
Cumulative Timesteps: 165377312

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 165377312...
Checkpoint 165377312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03417
Policy Entropy: 1.21957
Value Function Loss: 0.04037

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.05715
Value Function Update Magnitude: 0.07107

Collected Steps per Second: 11895.53899
Overall Steps per Second: 9932.45330

Timestep Collection Time: 4.20578
Timestep Consumption Time: 0.83125
PPO Batch Consumption Time: 0.06043
Total Iteration Time: 5.03702

Cumulative Model Updates: 9915
Cumulative Timesteps: 165427342

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04483
Policy Entropy: 1.22084
Value Function Loss: 0.04103

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.06032
Value Function Update Magnitude: 0.07095

Collected Steps per Second: 11804.32636
Overall Steps per Second: 9345.96182

Timestep Collection Time: 4.23929
Timestep Consumption Time: 1.11510
PPO Batch Consumption Time: 0.11215
Total Iteration Time: 5.35440

Cumulative Model Updates: 9918
Cumulative Timesteps: 165477384

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 165477384...
Checkpoint 165477384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01392
Policy Entropy: 1.21083
Value Function Loss: 0.05286

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12082
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.07075

Collected Steps per Second: 12687.85563
Overall Steps per Second: 10403.45382

Timestep Collection Time: 3.94346
Timestep Consumption Time: 0.86591
PPO Batch Consumption Time: 0.05621
Total Iteration Time: 4.80936

Cumulative Model Updates: 9921
Cumulative Timesteps: 165527418

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01992
Policy Entropy: 1.20813
Value Function Loss: 0.05538

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.06017
Value Function Update Magnitude: 0.07300

Collected Steps per Second: 10721.33341
Overall Steps per Second: 8359.65676

Timestep Collection Time: 4.66584
Timestep Consumption Time: 1.31814
PPO Batch Consumption Time: 0.08965
Total Iteration Time: 5.98398

Cumulative Model Updates: 9924
Cumulative Timesteps: 165577442

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 165577442...
Checkpoint 165577442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08598
Policy Entropy: 1.20564
Value Function Loss: 0.05576

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.16590
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.07901

Collected Steps per Second: 10604.60451
Overall Steps per Second: 8417.94449

Timestep Collection Time: 4.71606
Timestep Consumption Time: 1.22505
PPO Batch Consumption Time: 0.09894
Total Iteration Time: 5.94112

Cumulative Model Updates: 9927
Cumulative Timesteps: 165627454

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10915
Policy Entropy: 1.20723
Value Function Loss: 0.04915

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.07458

Collected Steps per Second: 11008.02711
Overall Steps per Second: 8924.00681

Timestep Collection Time: 4.54414
Timestep Consumption Time: 1.06119
PPO Batch Consumption Time: 0.09036
Total Iteration Time: 5.60533

Cumulative Model Updates: 9930
Cumulative Timesteps: 165677476

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 165677476...
Checkpoint 165677476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08623
Policy Entropy: 1.21494
Value Function Loss: 0.04968

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.07715

Collected Steps per Second: 10427.12005
Overall Steps per Second: 8406.63804

Timestep Collection Time: 4.79653
Timestep Consumption Time: 1.15282
PPO Batch Consumption Time: 0.07087
Total Iteration Time: 5.94935

Cumulative Model Updates: 9933
Cumulative Timesteps: 165727490

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05118
Policy Entropy: 1.20729
Value Function Loss: 0.04170

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.07511

Collected Steps per Second: 9509.86492
Overall Steps per Second: 7795.46964

Timestep Collection Time: 5.26106
Timestep Consumption Time: 1.15702
PPO Batch Consumption Time: 0.07873
Total Iteration Time: 6.41809

Cumulative Model Updates: 9936
Cumulative Timesteps: 165777522

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 165777522...
Checkpoint 165777522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02177
Policy Entropy: 1.20131
Value Function Loss: 0.04111

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.05848
Value Function Update Magnitude: 0.07450

Collected Steps per Second: 11494.62253
Overall Steps per Second: 9002.06980

Timestep Collection Time: 4.35160
Timestep Consumption Time: 1.20490
PPO Batch Consumption Time: 0.13165
Total Iteration Time: 5.55650

Cumulative Model Updates: 9939
Cumulative Timesteps: 165827542

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01119
Policy Entropy: 1.18704
Value Function Loss: 0.03893

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.05713
Value Function Update Magnitude: 0.07282

Collected Steps per Second: 12119.22622
Overall Steps per Second: 9714.94242

Timestep Collection Time: 4.12733
Timestep Consumption Time: 1.02144
PPO Batch Consumption Time: 0.06976
Total Iteration Time: 5.14877

Cumulative Model Updates: 9942
Cumulative Timesteps: 165877562

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 165877562...
Checkpoint 165877562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02336
Policy Entropy: 1.18833
Value Function Loss: 0.04398

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.06780

Collected Steps per Second: 11339.28385
Overall Steps per Second: 8888.89377

Timestep Collection Time: 4.41298
Timestep Consumption Time: 1.21652
PPO Batch Consumption Time: 0.10854
Total Iteration Time: 5.62950

Cumulative Model Updates: 9945
Cumulative Timesteps: 165927602

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10490
Policy Entropy: 1.19430
Value Function Loss: 0.04311

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.05703
Value Function Update Magnitude: 0.06855

Collected Steps per Second: 9120.21706
Overall Steps per Second: 7691.75371

Timestep Collection Time: 5.48540
Timestep Consumption Time: 1.01871
PPO Batch Consumption Time: 0.06971
Total Iteration Time: 6.50411

Cumulative Model Updates: 9948
Cumulative Timesteps: 165977630

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 165977630...
Checkpoint 165977630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03549
Policy Entropy: 1.19438
Value Function Loss: 0.04270

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.05637
Value Function Update Magnitude: 0.07167

Collected Steps per Second: 10514.95550
Overall Steps per Second: 8494.33759

Timestep Collection Time: 4.75722
Timestep Consumption Time: 1.13164
PPO Batch Consumption Time: 0.09309
Total Iteration Time: 5.88886

Cumulative Model Updates: 9951
Cumulative Timesteps: 166027652

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03151
Policy Entropy: 1.19467
Value Function Loss: 0.04767

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.06277
Value Function Update Magnitude: 0.07465

Collected Steps per Second: 9787.30838
Overall Steps per Second: 7886.30123

Timestep Collection Time: 5.10866
Timestep Consumption Time: 1.23145
PPO Batch Consumption Time: 0.07609
Total Iteration Time: 6.34011

Cumulative Model Updates: 9954
Cumulative Timesteps: 166077652

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 166077652...
Checkpoint 166077652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.24592
Policy Entropy: 1.18905
Value Function Loss: 0.04439

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.06482
Value Function Update Magnitude: 0.07194

Collected Steps per Second: 11158.43556
Overall Steps per Second: 8916.80532

Timestep Collection Time: 4.48414
Timestep Consumption Time: 1.12729
PPO Batch Consumption Time: 0.10157
Total Iteration Time: 5.61143

Cumulative Model Updates: 9957
Cumulative Timesteps: 166127688

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02722
Policy Entropy: 1.17347
Value Function Loss: 0.04606

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.06081
Value Function Update Magnitude: 0.06876

Collected Steps per Second: 11117.45021
Overall Steps per Second: 8960.23140

Timestep Collection Time: 4.49941
Timestep Consumption Time: 1.08326
PPO Batch Consumption Time: 0.12498
Total Iteration Time: 5.58267

Cumulative Model Updates: 9960
Cumulative Timesteps: 166177710

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 166177710...
Checkpoint 166177710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.18212
Policy Entropy: 1.17437
Value Function Loss: 0.04374

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.06183
Value Function Update Magnitude: 0.07096

Collected Steps per Second: 10227.00872
Overall Steps per Second: 8579.05074

Timestep Collection Time: 4.89078
Timestep Consumption Time: 0.93947
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 5.83025

Cumulative Model Updates: 9963
Cumulative Timesteps: 166227728

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05356
Policy Entropy: 1.17777
Value Function Loss: 0.04928

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.06445
Value Function Update Magnitude: 0.07309

Collected Steps per Second: 10609.36781
Overall Steps per Second: 8361.87924

Timestep Collection Time: 4.71564
Timestep Consumption Time: 1.26746
PPO Batch Consumption Time: 0.12387
Total Iteration Time: 5.98310

Cumulative Model Updates: 9966
Cumulative Timesteps: 166277758

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 166277758...
Checkpoint 166277758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06274
Policy Entropy: 1.19652
Value Function Loss: 0.04520

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06885
Policy Update Magnitude: 0.06752
Value Function Update Magnitude: 0.07884

Collected Steps per Second: 8795.78294
Overall Steps per Second: 7474.62265

Timestep Collection Time: 5.68864
Timestep Consumption Time: 1.00548
PPO Batch Consumption Time: 0.07691
Total Iteration Time: 6.69412

Cumulative Model Updates: 9969
Cumulative Timesteps: 166327794

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08087
Policy Entropy: 1.16783
Value Function Loss: 0.04147

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.07215
Value Function Update Magnitude: 0.06914

Collected Steps per Second: 9482.30110
Overall Steps per Second: 7740.80009

Timestep Collection Time: 5.27720
Timestep Consumption Time: 1.18725
PPO Batch Consumption Time: 0.10417
Total Iteration Time: 6.46445

Cumulative Model Updates: 9972
Cumulative Timesteps: 166377834

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 166377834...
Checkpoint 166377834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06692
Policy Entropy: 1.16006
Value Function Loss: 0.03684

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.17087
Policy Update Magnitude: 0.07281
Value Function Update Magnitude: 0.06446

Collected Steps per Second: 10768.32011
Overall Steps per Second: 8745.47921

Timestep Collection Time: 4.64492
Timestep Consumption Time: 1.07438
PPO Batch Consumption Time: 0.08476
Total Iteration Time: 5.71930

Cumulative Model Updates: 9975
Cumulative Timesteps: 166427852

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13981
Policy Entropy: 1.15601
Value Function Loss: 0.04708

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.16523
Policy Update Magnitude: 0.06709
Value Function Update Magnitude: 0.06436

Collected Steps per Second: 8693.97234
Overall Steps per Second: 7354.16849

Timestep Collection Time: 5.75571
Timestep Consumption Time: 1.04859
PPO Batch Consumption Time: 0.06529
Total Iteration Time: 6.80430

Cumulative Model Updates: 9978
Cumulative Timesteps: 166477892

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 166477892...
Checkpoint 166477892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09855
Policy Entropy: 1.16887
Value Function Loss: 0.05069

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.06085

Collected Steps per Second: 9249.50680
Overall Steps per Second: 7827.93304

Timestep Collection Time: 5.40959
Timestep Consumption Time: 0.98240
PPO Batch Consumption Time: 0.07155
Total Iteration Time: 6.39198

Cumulative Model Updates: 9981
Cumulative Timesteps: 166527928

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.20156
Policy Entropy: 1.16345
Value Function Loss: 0.05810

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.06210
Value Function Update Magnitude: 0.05743

Collected Steps per Second: 9070.54911
Overall Steps per Second: 7774.32457

Timestep Collection Time: 5.51631
Timestep Consumption Time: 0.91974
PPO Batch Consumption Time: 0.06999
Total Iteration Time: 6.43606

Cumulative Model Updates: 9984
Cumulative Timesteps: 166577964

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 166577964...
Checkpoint 166577964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00189
Policy Entropy: 1.15741
Value Function Loss: 0.05350

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.06128

Collected Steps per Second: 10661.24721
Overall Steps per Second: 8689.39716

Timestep Collection Time: 4.69270
Timestep Consumption Time: 1.06489
PPO Batch Consumption Time: 0.09250
Total Iteration Time: 5.75759

Cumulative Model Updates: 9987
Cumulative Timesteps: 166627994

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07768
Policy Entropy: 1.16672
Value Function Loss: 0.05268

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.05371

Collected Steps per Second: 12829.13814
Overall Steps per Second: 10455.52300

Timestep Collection Time: 3.90018
Timestep Consumption Time: 0.88542
PPO Batch Consumption Time: 0.05999
Total Iteration Time: 4.78560

Cumulative Model Updates: 9990
Cumulative Timesteps: 166678030

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 166678030...
Checkpoint 166678030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06817
Policy Entropy: 1.17622
Value Function Loss: 0.05201

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06000
Policy Update Magnitude: 0.06481
Value Function Update Magnitude: 0.05782

Collected Steps per Second: 11854.55413
Overall Steps per Second: 9639.85846

Timestep Collection Time: 4.21948
Timestep Consumption Time: 0.96940
PPO Batch Consumption Time: 0.06891
Total Iteration Time: 5.18887

Cumulative Model Updates: 9993
Cumulative Timesteps: 166728050

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07748
Policy Entropy: 1.16436
Value Function Loss: 0.04473

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.16270
Policy Update Magnitude: 0.06728
Value Function Update Magnitude: 0.05916

Collected Steps per Second: 12444.28913
Overall Steps per Second: 10113.11835

Timestep Collection Time: 4.01984
Timestep Consumption Time: 0.92661
PPO Batch Consumption Time: 0.06056
Total Iteration Time: 4.94645

Cumulative Model Updates: 9996
Cumulative Timesteps: 166778074

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 166778074...
Checkpoint 166778074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17774
Policy Entropy: 1.15307
Value Function Loss: 0.03942

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.18851
Policy Update Magnitude: 0.06407
Value Function Update Magnitude: 0.06091

Collected Steps per Second: 11977.97198
Overall Steps per Second: 9593.62591

Timestep Collection Time: 4.17500
Timestep Consumption Time: 1.03763
PPO Batch Consumption Time: 0.11540
Total Iteration Time: 5.21263

Cumulative Model Updates: 9999
Cumulative Timesteps: 166828082

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00244
Policy Entropy: 1.17415
Value Function Loss: 0.03104

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.06317

Collected Steps per Second: 12523.18901
Overall Steps per Second: 10169.81851

Timestep Collection Time: 3.99307
Timestep Consumption Time: 0.92403
PPO Batch Consumption Time: 0.06350
Total Iteration Time: 4.91710

Cumulative Model Updates: 10002
Cumulative Timesteps: 166878088

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 166878088...
Checkpoint 166878088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01111
Policy Entropy: 1.16556
Value Function Loss: 0.03477

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.05928
Value Function Update Magnitude: 0.05835

Collected Steps per Second: 12609.02985
Overall Steps per Second: 9894.43005

Timestep Collection Time: 3.96874
Timestep Consumption Time: 1.08885
PPO Batch Consumption Time: 0.10939
Total Iteration Time: 5.05759

Cumulative Model Updates: 10005
Cumulative Timesteps: 166928130

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07770
Policy Entropy: 1.16744
Value Function Loss: 0.04281

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.05810
Value Function Update Magnitude: 0.06765

Collected Steps per Second: 12857.89802
Overall Steps per Second: 10399.26917

Timestep Collection Time: 3.89270
Timestep Consumption Time: 0.92033
PPO Batch Consumption Time: 0.05882
Total Iteration Time: 4.81303

Cumulative Model Updates: 10008
Cumulative Timesteps: 166978182

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 166978182...
Checkpoint 166978182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07524
Policy Entropy: 1.17704
Value Function Loss: 0.04773

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.06301
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 11512.79578
Overall Steps per Second: 9309.58212

Timestep Collection Time: 4.34699
Timestep Consumption Time: 1.02876
PPO Batch Consumption Time: 0.07973
Total Iteration Time: 5.37575

Cumulative Model Updates: 10011
Cumulative Timesteps: 167028228

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10197
Policy Entropy: 1.16520
Value Function Loss: 0.04915

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.06131
Value Function Update Magnitude: 0.08021

Collected Steps per Second: 12521.15681
Overall Steps per Second: 10337.51953

Timestep Collection Time: 3.99356
Timestep Consumption Time: 0.84358
PPO Batch Consumption Time: 0.06132
Total Iteration Time: 4.83714

Cumulative Model Updates: 10014
Cumulative Timesteps: 167078232

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 167078232...
Checkpoint 167078232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04142
Policy Entropy: 1.17200
Value Function Loss: 0.04211

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.07848

Collected Steps per Second: 11827.33537
Overall Steps per Second: 9403.60930

Timestep Collection Time: 4.22851
Timestep Consumption Time: 1.08987
PPO Batch Consumption Time: 0.10059
Total Iteration Time: 5.31838

Cumulative Model Updates: 10017
Cumulative Timesteps: 167128244

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01724
Policy Entropy: 1.18025
Value Function Loss: 0.04952

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.05815
Value Function Update Magnitude: 0.06845

Collected Steps per Second: 12827.38883
Overall Steps per Second: 10418.86432

Timestep Collection Time: 3.90181
Timestep Consumption Time: 0.90198
PPO Batch Consumption Time: 0.05800
Total Iteration Time: 4.80379

Cumulative Model Updates: 10020
Cumulative Timesteps: 167178294

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 167178294...
Checkpoint 167178294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14133
Policy Entropy: 1.18038
Value Function Loss: 0.04464

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07786
Policy Update Magnitude: 0.05836
Value Function Update Magnitude: 0.07595

Collected Steps per Second: 12093.24173
Overall Steps per Second: 9590.91767

Timestep Collection Time: 4.13752
Timestep Consumption Time: 1.07950
PPO Batch Consumption Time: 0.09363
Total Iteration Time: 5.21702

Cumulative Model Updates: 10023
Cumulative Timesteps: 167228330

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10255
Policy Entropy: 1.16766
Value Function Loss: 0.04873

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.07819

Collected Steps per Second: 12270.82898
Overall Steps per Second: 10055.24195

Timestep Collection Time: 4.07829
Timestep Consumption Time: 0.89862
PPO Batch Consumption Time: 0.05953
Total Iteration Time: 4.97691

Cumulative Model Updates: 10026
Cumulative Timesteps: 167278374

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 167278374...
Checkpoint 167278374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01735
Policy Entropy: 1.16910
Value Function Loss: 0.04669

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.06652

Collected Steps per Second: 11774.20859
Overall Steps per Second: 9315.34953

Timestep Collection Time: 4.24861
Timestep Consumption Time: 1.12145
PPO Batch Consumption Time: 0.12003
Total Iteration Time: 5.37006

Cumulative Model Updates: 10029
Cumulative Timesteps: 167328398

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11152
Policy Entropy: 1.18195
Value Function Loss: 0.04762

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.06060
Value Function Update Magnitude: 0.06713

Collected Steps per Second: 12993.23930
Overall Steps per Second: 10536.28835

Timestep Collection Time: 3.85216
Timestep Consumption Time: 0.89828
PPO Batch Consumption Time: 0.05862
Total Iteration Time: 4.75044

Cumulative Model Updates: 10032
Cumulative Timesteps: 167378450

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 167378450...
Checkpoint 167378450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.15171
Policy Entropy: 1.16851
Value Function Loss: 0.05172

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.05952
Value Function Update Magnitude: 0.06817

Collected Steps per Second: 11649.50543
Overall Steps per Second: 9558.11377

Timestep Collection Time: 4.29306
Timestep Consumption Time: 0.93936
PPO Batch Consumption Time: 0.06587
Total Iteration Time: 5.23241

Cumulative Model Updates: 10035
Cumulative Timesteps: 167428462

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06584
Policy Entropy: 1.17988
Value Function Loss: 0.04963

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.05818
Value Function Update Magnitude: 0.06840

Collected Steps per Second: 12563.18987
Overall Steps per Second: 10358.15166

Timestep Collection Time: 3.98275
Timestep Consumption Time: 0.84785
PPO Batch Consumption Time: 0.06063
Total Iteration Time: 4.83059

Cumulative Model Updates: 10038
Cumulative Timesteps: 167478498

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 167478498...
Checkpoint 167478498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05968
Policy Entropy: 1.17851
Value Function Loss: 0.04576

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.06454
Value Function Update Magnitude: 0.07220

Collected Steps per Second: 11487.43961
Overall Steps per Second: 9039.08563

Timestep Collection Time: 4.35502
Timestep Consumption Time: 1.17961
PPO Batch Consumption Time: 0.11152
Total Iteration Time: 5.53463

Cumulative Model Updates: 10041
Cumulative Timesteps: 167528526

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02442
Policy Entropy: 1.16717
Value Function Loss: 0.03761

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.06175
Value Function Update Magnitude: 0.07110

Collected Steps per Second: 12727.26689
Overall Steps per Second: 10373.12816

Timestep Collection Time: 3.93124
Timestep Consumption Time: 0.89218
PPO Batch Consumption Time: 0.06121
Total Iteration Time: 4.82342

Cumulative Model Updates: 10044
Cumulative Timesteps: 167578560

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 167578560...
Checkpoint 167578560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01365
Policy Entropy: 1.15546
Value Function Loss: 0.03957

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.05721
Value Function Update Magnitude: 0.06204

Collected Steps per Second: 11851.23634
Overall Steps per Second: 9366.39461

Timestep Collection Time: 4.22066
Timestep Consumption Time: 1.11971
PPO Batch Consumption Time: 0.10549
Total Iteration Time: 5.34037

Cumulative Model Updates: 10047
Cumulative Timesteps: 167628580

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03507
Policy Entropy: 1.16786
Value Function Loss: 0.05666

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.05784
Value Function Update Magnitude: 0.06177

Collected Steps per Second: 12605.09845
Overall Steps per Second: 10279.21228

Timestep Collection Time: 3.96697
Timestep Consumption Time: 0.89761
PPO Batch Consumption Time: 0.06221
Total Iteration Time: 4.86458

Cumulative Model Updates: 10050
Cumulative Timesteps: 167678584

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 167678584...
Checkpoint 167678584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.14939
Policy Entropy: 1.17065
Value Function Loss: 0.05355

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.06079
Value Function Update Magnitude: 0.06127

Collected Steps per Second: 11260.30416
Overall Steps per Second: 9060.18349

Timestep Collection Time: 4.44109
Timestep Consumption Time: 1.07845
PPO Batch Consumption Time: 0.11307
Total Iteration Time: 5.51954

Cumulative Model Updates: 10053
Cumulative Timesteps: 167728592

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12275
Policy Entropy: 1.16131
Value Function Loss: 0.05119

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.06646
Value Function Update Magnitude: 0.06542

Collected Steps per Second: 12394.62663
Overall Steps per Second: 10105.64511

Timestep Collection Time: 4.03723
Timestep Consumption Time: 0.91445
PPO Batch Consumption Time: 0.06193
Total Iteration Time: 4.95169

Cumulative Model Updates: 10056
Cumulative Timesteps: 167778632

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 167778632...
Checkpoint 167778632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01301
Policy Entropy: 1.16332
Value Function Loss: 0.05357

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.06519
Value Function Update Magnitude: 0.06483

Collected Steps per Second: 11761.95528
Overall Steps per Second: 9537.94933

Timestep Collection Time: 4.25456
Timestep Consumption Time: 0.99206
PPO Batch Consumption Time: 0.07162
Total Iteration Time: 5.24662

Cumulative Model Updates: 10059
Cumulative Timesteps: 167828674

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01811
Policy Entropy: 1.17552
Value Function Loss: 0.05353

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11125
Policy Update Magnitude: 0.06940
Value Function Update Magnitude: 0.05904

Collected Steps per Second: 12885.64121
Overall Steps per Second: 10371.65356

Timestep Collection Time: 3.88184
Timestep Consumption Time: 0.94092
PPO Batch Consumption Time: 0.06425
Total Iteration Time: 4.82276

Cumulative Model Updates: 10062
Cumulative Timesteps: 167878694

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 167878694...
Checkpoint 167878694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06990
Policy Entropy: 1.19009
Value Function Loss: 0.05259

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.07231
Value Function Update Magnitude: 0.06197

Collected Steps per Second: 12083.10486
Overall Steps per Second: 9394.21031

Timestep Collection Time: 4.14099
Timestep Consumption Time: 1.18527
PPO Batch Consumption Time: 0.12645
Total Iteration Time: 5.32626

Cumulative Model Updates: 10065
Cumulative Timesteps: 167928730

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08884
Policy Entropy: 1.18300
Value Function Loss: 0.03867

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.06841
Value Function Update Magnitude: 0.07534

Collected Steps per Second: 12196.54374
Overall Steps per Second: 10116.73729

Timestep Collection Time: 4.10198
Timestep Consumption Time: 0.84329
PPO Batch Consumption Time: 0.06376
Total Iteration Time: 4.94527

Cumulative Model Updates: 10068
Cumulative Timesteps: 167978760

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 167978760...
Checkpoint 167978760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10657
Policy Entropy: 1.18380
Value Function Loss: 0.03509

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 12738.14180
Overall Steps per Second: 9929.28120

Timestep Collection Time: 3.92852
Timestep Consumption Time: 1.11132
PPO Batch Consumption Time: 0.10542
Total Iteration Time: 5.03984

Cumulative Model Updates: 10071
Cumulative Timesteps: 168028802

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04336
Policy Entropy: 1.18983
Value Function Loss: 0.03058

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.07302

Collected Steps per Second: 12675.94701
Overall Steps per Second: 10347.09173

Timestep Collection Time: 3.94606
Timestep Consumption Time: 0.88815
PPO Batch Consumption Time: 0.06158
Total Iteration Time: 4.83421

Cumulative Model Updates: 10074
Cumulative Timesteps: 168078822

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 168078822...
Checkpoint 168078822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06348
Policy Entropy: 1.19581
Value Function Loss: 0.04460

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.06211
Value Function Update Magnitude: 0.07191

Collected Steps per Second: 12300.01357
Overall Steps per Second: 9714.01958

Timestep Collection Time: 4.06666
Timestep Consumption Time: 1.08260
PPO Batch Consumption Time: 0.10343
Total Iteration Time: 5.14926

Cumulative Model Updates: 10077
Cumulative Timesteps: 168128842

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09263
Policy Entropy: 1.17839
Value Function Loss: 0.05164

Mean KL Divergence: 0.01976
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.06484
Value Function Update Magnitude: 0.08100

Collected Steps per Second: 10098.58081
Overall Steps per Second: 8420.98638

Timestep Collection Time: 4.95476
Timestep Consumption Time: 0.98707
PPO Batch Consumption Time: 0.06104
Total Iteration Time: 5.94182

Cumulative Model Updates: 10080
Cumulative Timesteps: 168178878

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 168178878...
Checkpoint 168178878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09558
Policy Entropy: 1.17273
Value Function Loss: 0.06335

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.06727
Value Function Update Magnitude: 0.08552

Collected Steps per Second: 10013.61000
Overall Steps per Second: 8510.24434

Timestep Collection Time: 4.99620
Timestep Consumption Time: 0.88260
PPO Batch Consumption Time: 0.03025
Total Iteration Time: 5.87880

Cumulative Model Updates: 10083
Cumulative Timesteps: 168228908

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05739
Policy Entropy: 1.16673
Value Function Loss: 0.05209

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.06690
Value Function Update Magnitude: 0.08384

Collected Steps per Second: 11467.09420
Overall Steps per Second: 9331.51710

Timestep Collection Time: 4.36397
Timestep Consumption Time: 0.99872
PPO Batch Consumption Time: 0.06426
Total Iteration Time: 5.36269

Cumulative Model Updates: 10086
Cumulative Timesteps: 168278950

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 168278950...
Checkpoint 168278950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04208
Policy Entropy: 1.16641
Value Function Loss: 0.04662

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.06280
Value Function Update Magnitude: 0.08380

Collected Steps per Second: 12852.50223
Overall Steps per Second: 10478.48004

Timestep Collection Time: 3.89185
Timestep Consumption Time: 0.88174
PPO Batch Consumption Time: 0.05758
Total Iteration Time: 4.77359

Cumulative Model Updates: 10089
Cumulative Timesteps: 168328970

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09153
Policy Entropy: 1.17881
Value Function Loss: 0.03644

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.07561

Collected Steps per Second: 11994.27899
Overall Steps per Second: 9632.12801

Timestep Collection Time: 4.16932
Timestep Consumption Time: 1.02247
PPO Batch Consumption Time: 0.11779
Total Iteration Time: 5.19179

Cumulative Model Updates: 10092
Cumulative Timesteps: 168378978

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 168378978...
Checkpoint 168378978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05937
Policy Entropy: 1.18872
Value Function Loss: 0.03658

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.07390

Collected Steps per Second: 12008.17464
Overall Steps per Second: 9814.57753

Timestep Collection Time: 4.16450
Timestep Consumption Time: 0.93078
PPO Batch Consumption Time: 0.06760
Total Iteration Time: 5.09528

Cumulative Model Updates: 10095
Cumulative Timesteps: 168428986

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.19961
Policy Entropy: 1.18113
Value Function Loss: 0.04058

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07794
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.07288

Collected Steps per Second: 12717.76313
Overall Steps per Second: 10227.70108

Timestep Collection Time: 3.93214
Timestep Consumption Time: 0.95733
PPO Batch Consumption Time: 0.06363
Total Iteration Time: 4.88947

Cumulative Model Updates: 10098
Cumulative Timesteps: 168478994

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 168478994...
Checkpoint 168478994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05820
Policy Entropy: 1.17589
Value Function Loss: 0.04634

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.05785
Value Function Update Magnitude: 0.07166

Collected Steps per Second: 13126.26263
Overall Steps per Second: 10577.50600

Timestep Collection Time: 3.81144
Timestep Consumption Time: 0.91841
PPO Batch Consumption Time: 0.05860
Total Iteration Time: 4.72985

Cumulative Model Updates: 10101
Cumulative Timesteps: 168529024

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09701
Policy Entropy: 1.18597
Value Function Loss: 0.05937

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11307
Policy Update Magnitude: 0.05735
Value Function Update Magnitude: 0.07126

Collected Steps per Second: 11470.09207
Overall Steps per Second: 9185.52311

Timestep Collection Time: 4.36282
Timestep Consumption Time: 1.08510
PPO Batch Consumption Time: 0.09663
Total Iteration Time: 5.44792

Cumulative Model Updates: 10104
Cumulative Timesteps: 168579066

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 168579066...
Checkpoint 168579066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09280
Policy Entropy: 1.18299
Value Function Loss: 0.05043

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.05904
Value Function Update Magnitude: 0.07511

Collected Steps per Second: 12924.47972
Overall Steps per Second: 10570.72160

Timestep Collection Time: 3.87188
Timestep Consumption Time: 0.86214
PPO Batch Consumption Time: 0.05742
Total Iteration Time: 4.73402

Cumulative Model Updates: 10107
Cumulative Timesteps: 168629108

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09672
Policy Entropy: 1.18474
Value Function Loss: 0.05212

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.06043
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 11779.66050
Overall Steps per Second: 9536.59646

Timestep Collection Time: 4.24647
Timestep Consumption Time: 0.99880
PPO Batch Consumption Time: 0.08230
Total Iteration Time: 5.24527

Cumulative Model Updates: 10110
Cumulative Timesteps: 168679130

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 168679130...
Checkpoint 168679130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.13255
Policy Entropy: 1.18506
Value Function Loss: 0.04861

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.06046
Value Function Update Magnitude: 0.06994

Collected Steps per Second: 12662.69938
Overall Steps per Second: 10142.40296

Timestep Collection Time: 3.95066
Timestep Consumption Time: 0.98170
PPO Batch Consumption Time: 0.06515
Total Iteration Time: 4.93236

Cumulative Model Updates: 10113
Cumulative Timesteps: 168729156

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.07752
Policy Entropy: 1.18909
Value Function Loss: 0.05306

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.06980

Collected Steps per Second: 11839.79869
Overall Steps per Second: 9548.99644

Timestep Collection Time: 4.22338
Timestep Consumption Time: 1.01319
PPO Batch Consumption Time: 0.07037
Total Iteration Time: 5.23657

Cumulative Model Updates: 10116
Cumulative Timesteps: 168779160

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 168779160...
Checkpoint 168779160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05639
Policy Entropy: 1.19283
Value Function Loss: 0.05538

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.06741
Value Function Update Magnitude: 0.07172

Collected Steps per Second: 12803.48808
Overall Steps per Second: 10382.36914

Timestep Collection Time: 3.90862
Timestep Consumption Time: 0.91147
PPO Batch Consumption Time: 0.06396
Total Iteration Time: 4.82009

Cumulative Model Updates: 10119
Cumulative Timesteps: 168829204

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02257
Policy Entropy: 1.18951
Value Function Loss: 0.04665

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.06663
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 11432.58151
Overall Steps per Second: 9023.31422

Timestep Collection Time: 4.37539
Timestep Consumption Time: 1.16825
PPO Batch Consumption Time: 0.12335
Total Iteration Time: 5.54364

Cumulative Model Updates: 10122
Cumulative Timesteps: 168879226

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 168879226...
Checkpoint 168879226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03872
Policy Entropy: 1.19061
Value Function Loss: 0.04601

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.05917
Value Function Update Magnitude: 0.06932

Collected Steps per Second: 13336.26540
Overall Steps per Second: 10714.26359

Timestep Collection Time: 3.75053
Timestep Consumption Time: 0.91783
PPO Batch Consumption Time: 0.06013
Total Iteration Time: 4.66836

Cumulative Model Updates: 10125
Cumulative Timesteps: 168929244

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03254
Policy Entropy: 1.19999
Value Function Loss: 0.04636

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.05590
Value Function Update Magnitude: 0.07079

Collected Steps per Second: 12229.73500
Overall Steps per Second: 9783.43733

Timestep Collection Time: 4.08872
Timestep Consumption Time: 1.02236
PPO Batch Consumption Time: 0.09283
Total Iteration Time: 5.11109

Cumulative Model Updates: 10128
Cumulative Timesteps: 168979248

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 168979248...
Checkpoint 168979248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06589
Policy Entropy: 1.20057
Value Function Loss: 0.04834

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.07889

Collected Steps per Second: 12695.62400
Overall Steps per Second: 10527.18062

Timestep Collection Time: 3.94010
Timestep Consumption Time: 0.81160
PPO Batch Consumption Time: 0.05785
Total Iteration Time: 4.75170

Cumulative Model Updates: 10131
Cumulative Timesteps: 169029270

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09282
Policy Entropy: 1.19470
Value Function Loss: 0.04558

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.07385

Collected Steps per Second: 11734.74708
Overall Steps per Second: 9571.82853

Timestep Collection Time: 4.26426
Timestep Consumption Time: 0.96358
PPO Batch Consumption Time: 0.06633
Total Iteration Time: 5.22784

Cumulative Model Updates: 10134
Cumulative Timesteps: 169079310

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 169079310...
Checkpoint 169079310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00079
Policy Entropy: 1.19696
Value Function Loss: 0.04007

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.05913
Value Function Update Magnitude: 0.07463

Collected Steps per Second: 12101.88930
Overall Steps per Second: 9816.68032

Timestep Collection Time: 4.13324
Timestep Consumption Time: 0.96217
PPO Batch Consumption Time: 0.06647
Total Iteration Time: 5.09541

Cumulative Model Updates: 10137
Cumulative Timesteps: 169129330

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02341
Policy Entropy: 1.20191
Value Function Loss: 0.04008

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.07104

Collected Steps per Second: 12953.34207
Overall Steps per Second: 10249.19098

Timestep Collection Time: 3.86340
Timestep Consumption Time: 1.01932
PPO Batch Consumption Time: 0.07994
Total Iteration Time: 4.88273

Cumulative Model Updates: 10140
Cumulative Timesteps: 169179374

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 169179374...
Checkpoint 169179374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00708
Policy Entropy: 1.19961
Value Function Loss: 0.04120

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.05396
Value Function Update Magnitude: 0.06914

Collected Steps per Second: 12445.65781
Overall Steps per Second: 10097.85756

Timestep Collection Time: 4.02036
Timestep Consumption Time: 0.93475
PPO Batch Consumption Time: 0.05791
Total Iteration Time: 4.95511

Cumulative Model Updates: 10143
Cumulative Timesteps: 169229410

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01377
Policy Entropy: 1.20207
Value Function Loss: 0.04861

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.05463
Value Function Update Magnitude: 0.06743

Collected Steps per Second: 11548.04758
Overall Steps per Second: 9570.99182

Timestep Collection Time: 4.33285
Timestep Consumption Time: 0.89503
PPO Batch Consumption Time: 0.06928
Total Iteration Time: 5.22788

Cumulative Model Updates: 10146
Cumulative Timesteps: 169279446

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 169279446...
Checkpoint 169279446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03042
Policy Entropy: 1.20109
Value Function Loss: 0.04451

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.05586
Value Function Update Magnitude: 0.07317

Collected Steps per Second: 12821.68149
Overall Steps per Second: 10370.41182

Timestep Collection Time: 3.90183
Timestep Consumption Time: 0.92228
PPO Batch Consumption Time: 0.06192
Total Iteration Time: 4.82411

Cumulative Model Updates: 10149
Cumulative Timesteps: 169329474

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01957
Policy Entropy: 1.19295
Value Function Loss: 0.03685

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.05732
Value Function Update Magnitude: 0.07483

Collected Steps per Second: 11089.49717
Overall Steps per Second: 9012.27248

Timestep Collection Time: 4.51039
Timestep Consumption Time: 1.03959
PPO Batch Consumption Time: 0.08051
Total Iteration Time: 5.54999

Cumulative Model Updates: 10152
Cumulative Timesteps: 169379492

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 169379492...
Checkpoint 169379492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01747
Policy Entropy: 1.19378
Value Function Loss: 0.03932

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.07089

Collected Steps per Second: 12278.30775
Overall Steps per Second: 10171.54003

Timestep Collection Time: 4.07450
Timestep Consumption Time: 0.84393
PPO Batch Consumption Time: 0.06214
Total Iteration Time: 4.91843

Cumulative Model Updates: 10155
Cumulative Timesteps: 169429520

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05584
Policy Entropy: 1.19151
Value Function Loss: 0.04143

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.05639
Value Function Update Magnitude: 0.07032

Collected Steps per Second: 12015.62486
Overall Steps per Second: 9556.19097

Timestep Collection Time: 4.16141
Timestep Consumption Time: 1.07100
PPO Batch Consumption Time: 0.09940
Total Iteration Time: 5.23242

Cumulative Model Updates: 10158
Cumulative Timesteps: 169479522

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 169479522...
Checkpoint 169479522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.12760
Policy Entropy: 1.20721
Value Function Loss: 0.05595

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.06401
Value Function Update Magnitude: 0.07412

Collected Steps per Second: 12953.24410
Overall Steps per Second: 10533.96743

Timestep Collection Time: 3.86112
Timestep Consumption Time: 0.88676
PPO Batch Consumption Time: 0.05780
Total Iteration Time: 4.74788

Cumulative Model Updates: 10161
Cumulative Timesteps: 169529536

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.16659
Policy Entropy: 1.20212
Value Function Loss: 0.04744

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07770
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.07366

Collected Steps per Second: 12253.12603
Overall Steps per Second: 9576.08137

Timestep Collection Time: 4.08369
Timestep Consumption Time: 1.14162
PPO Batch Consumption Time: 0.11748
Total Iteration Time: 5.22531

Cumulative Model Updates: 10164
Cumulative Timesteps: 169579574

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 169579574...
Checkpoint 169579574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11618
Policy Entropy: 1.20190
Value Function Loss: 0.05102

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07317
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.07187

Collected Steps per Second: 12563.98503
Overall Steps per Second: 10239.04062

Timestep Collection Time: 3.98329
Timestep Consumption Time: 0.90447
PPO Batch Consumption Time: 0.06115
Total Iteration Time: 4.88776

Cumulative Model Updates: 10167
Cumulative Timesteps: 169629620

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01412
Policy Entropy: 1.19592
Value Function Loss: 0.03956

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.07573

Collected Steps per Second: 11893.15245
Overall Steps per Second: 9791.82647

Timestep Collection Time: 4.20460
Timestep Consumption Time: 0.90231
PPO Batch Consumption Time: 0.07495
Total Iteration Time: 5.10691

Cumulative Model Updates: 10170
Cumulative Timesteps: 169679626

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 169679626...
Checkpoint 169679626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04972
Policy Entropy: 1.19450
Value Function Loss: 0.05071

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.05801
Value Function Update Magnitude: 0.06695

Collected Steps per Second: 12819.47480
Overall Steps per Second: 10403.02109

Timestep Collection Time: 3.90094
Timestep Consumption Time: 0.90613
PPO Batch Consumption Time: 0.06388
Total Iteration Time: 4.80707

Cumulative Model Updates: 10173
Cumulative Timesteps: 169729634

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05746
Policy Entropy: 1.18230
Value Function Loss: 0.04159

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08095
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.06745

Collected Steps per Second: 11814.38490
Overall Steps per Second: 9648.45221

Timestep Collection Time: 4.23501
Timestep Consumption Time: 0.95070
PPO Batch Consumption Time: 0.06784
Total Iteration Time: 5.18570

Cumulative Model Updates: 10176
Cumulative Timesteps: 169779668

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 169779668...
Checkpoint 169779668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.13148
Policy Entropy: 1.17958
Value Function Loss: 0.04164

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.09667
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.07089

Collected Steps per Second: 12673.91982
Overall Steps per Second: 10177.78599

Timestep Collection Time: 3.94685
Timestep Consumption Time: 0.96798
PPO Batch Consumption Time: 0.05853
Total Iteration Time: 4.91482

Cumulative Model Updates: 10179
Cumulative Timesteps: 169829690

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04556
Policy Entropy: 1.18976
Value Function Loss: 0.03739

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.05873
Value Function Update Magnitude: 0.07677

Collected Steps per Second: 11427.08754
Overall Steps per Second: 9202.78087

Timestep Collection Time: 4.37854
Timestep Consumption Time: 1.05829
PPO Batch Consumption Time: 0.10002
Total Iteration Time: 5.43683

Cumulative Model Updates: 10182
Cumulative Timesteps: 169879724

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 169879724...
Checkpoint 169879724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08278
Policy Entropy: 1.18317
Value Function Loss: 0.04227

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.05829
Value Function Update Magnitude: 0.07134

Collected Steps per Second: 13005.04543
Overall Steps per Second: 10666.51250

Timestep Collection Time: 3.84728
Timestep Consumption Time: 0.84348
PPO Batch Consumption Time: 0.06508
Total Iteration Time: 4.69076

Cumulative Model Updates: 10185
Cumulative Timesteps: 169929758

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.08610
Policy Entropy: 1.18021
Value Function Loss: 0.04540

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.05751
Value Function Update Magnitude: 0.07248

Collected Steps per Second: 12964.11205
Overall Steps per Second: 10207.17211

Timestep Collection Time: 3.85865
Timestep Consumption Time: 1.04222
PPO Batch Consumption Time: 0.09393
Total Iteration Time: 4.90087

Cumulative Model Updates: 10188
Cumulative Timesteps: 169979782

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 169979782...
Checkpoint 169979782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.09346
Policy Entropy: 1.16793
Value Function Loss: 0.04672

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 0.05842
Value Function Update Magnitude: 0.07200

Collected Steps per Second: 12827.66341
Overall Steps per Second: 10479.54928

Timestep Collection Time: 3.89798
Timestep Consumption Time: 0.87341
PPO Batch Consumption Time: 0.05967
Total Iteration Time: 4.77139

Cumulative Model Updates: 10191
Cumulative Timesteps: 170029784

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.11483
Policy Entropy: 1.17114
Value Function Loss: 0.04353

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.06049
Value Function Update Magnitude: 0.07327

Collected Steps per Second: 11838.91413
Overall Steps per Second: 9298.84721

Timestep Collection Time: 4.22573
Timestep Consumption Time: 1.15430
PPO Batch Consumption Time: 0.10955
Total Iteration Time: 5.38002

Cumulative Model Updates: 10194
Cumulative Timesteps: 170079812

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 170079812...
Checkpoint 170079812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17805
Policy Entropy: 1.16536
Value Function Loss: 0.04537

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08550
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.07592

Collected Steps per Second: 12924.46880
Overall Steps per Second: 10527.77079

Timestep Collection Time: 3.86863
Timestep Consumption Time: 0.88071
PPO Batch Consumption Time: 0.05911
Total Iteration Time: 4.74934

Cumulative Model Updates: 10197
Cumulative Timesteps: 170129812

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04082
Policy Entropy: 1.16911
Value Function Loss: 0.04313

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.07798

Collected Steps per Second: 12246.57688
Overall Steps per Second: 9886.25184

Timestep Collection Time: 4.08310
Timestep Consumption Time: 0.97483
PPO Batch Consumption Time: 0.09204
Total Iteration Time: 5.05793

Cumulative Model Updates: 10200
Cumulative Timesteps: 170179816

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 170179816...
Checkpoint 170179816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.12050
Policy Entropy: 1.16751
Value Function Loss: 0.04347

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.05890
Value Function Update Magnitude: 0.08512

Collected Steps per Second: 13168.52446
Overall Steps per Second: 10616.38024

Timestep Collection Time: 3.79860
Timestep Consumption Time: 0.91317
PPO Batch Consumption Time: 0.05987
Total Iteration Time: 4.71178

Cumulative Model Updates: 10203
Cumulative Timesteps: 170229838

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02563
Policy Entropy: 1.17401
Value Function Loss: 0.03670

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.06094
Value Function Update Magnitude: 0.07944

Collected Steps per Second: 12142.51053
Overall Steps per Second: 9539.65695

Timestep Collection Time: 4.12155
Timestep Consumption Time: 1.12455
PPO Batch Consumption Time: 0.12520
Total Iteration Time: 5.24610

Cumulative Model Updates: 10206
Cumulative Timesteps: 170279884

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 170279884...
Checkpoint 170279884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04496
Policy Entropy: 1.16867
Value Function Loss: 0.03695

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.07351

Collected Steps per Second: 12153.66380
Overall Steps per Second: 9919.56234

Timestep Collection Time: 4.11497
Timestep Consumption Time: 0.92678
PPO Batch Consumption Time: 0.06377
Total Iteration Time: 5.04175

Cumulative Model Updates: 10209
Cumulative Timesteps: 170329896

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.28879
Policy Entropy: 1.17558
Value Function Loss: 0.04682

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.05945
Value Function Update Magnitude: 0.06747

Collected Steps per Second: 12111.61760
Overall Steps per Second: 9708.41648

Timestep Collection Time: 4.12909
Timestep Consumption Time: 1.02211
PPO Batch Consumption Time: 0.08259
Total Iteration Time: 5.15120

Cumulative Model Updates: 10212
Cumulative Timesteps: 170379906

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 170379906...
Checkpoint 170379906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.17565
Policy Entropy: 1.18382
Value Function Loss: 0.05106

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.07135

Collected Steps per Second: 11592.81713
Overall Steps per Second: 9662.73107

Timestep Collection Time: 4.31474
Timestep Consumption Time: 0.86185
PPO Batch Consumption Time: 0.05711
Total Iteration Time: 5.17659

Cumulative Model Updates: 10215
Cumulative Timesteps: 170429926

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03176
Policy Entropy: 1.18537
Value Function Loss: 0.05019

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.08325

Collected Steps per Second: 10835.32752
Overall Steps per Second: 8919.06336

Timestep Collection Time: 4.61657
Timestep Consumption Time: 0.99187
PPO Batch Consumption Time: 0.08608
Total Iteration Time: 5.60844

Cumulative Model Updates: 10218
Cumulative Timesteps: 170479948

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 170479948...
Checkpoint 170479948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.10855
Policy Entropy: 1.18228
Value Function Loss: 0.04596

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.07713

Collected Steps per Second: 12637.57612
Overall Steps per Second: 10274.38941

Timestep Collection Time: 3.95772
Timestep Consumption Time: 0.91031
PPO Batch Consumption Time: 0.06034
Total Iteration Time: 4.86803

Cumulative Model Updates: 10221
Cumulative Timesteps: 170529964

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.14969
Policy Entropy: 1.18361
Value Function Loss: 0.04224

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.07003

Collected Steps per Second: 11946.13529
Overall Steps per Second: 9687.44605

Timestep Collection Time: 4.18880
Timestep Consumption Time: 0.97665
PPO Batch Consumption Time: 0.07535
Total Iteration Time: 5.16545

Cumulative Model Updates: 10224
Cumulative Timesteps: 170580004

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 170580004...
Checkpoint 170580004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07143
Policy Entropy: 1.19233
Value Function Loss: 0.04482

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.08380

Collected Steps per Second: 11343.20602
Overall Steps per Second: 9244.30510

Timestep Collection Time: 4.41075
Timestep Consumption Time: 1.00145
PPO Batch Consumption Time: 0.06647
Total Iteration Time: 5.41220

Cumulative Model Updates: 10227
Cumulative Timesteps: 170630036

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01334
Policy Entropy: 1.19813
Value Function Loss: 0.05078

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06573
Policy Update Magnitude: 0.05661
Value Function Update Magnitude: 0.07172

Collected Steps per Second: 11136.07631
Overall Steps per Second: 9338.13739

Timestep Collection Time: 4.49368
Timestep Consumption Time: 0.86520
PPO Batch Consumption Time: 0.06071
Total Iteration Time: 5.35888

Cumulative Model Updates: 10230
Cumulative Timesteps: 170680078

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 170680078...
Checkpoint 170680078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07291
Policy Entropy: 1.19825
Value Function Loss: 0.05371

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.07642

Collected Steps per Second: 10366.97952
Overall Steps per Second: 8516.92741

Timestep Collection Time: 4.82397
Timestep Consumption Time: 1.04787
PPO Batch Consumption Time: 0.08319
Total Iteration Time: 5.87184

Cumulative Model Updates: 10233
Cumulative Timesteps: 170730088

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.06784
Policy Entropy: 1.18898
Value Function Loss: 0.04921

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.07725

Collected Steps per Second: 10683.15835
Overall Steps per Second: 8929.77088

Timestep Collection Time: 4.68157
Timestep Consumption Time: 0.91924
PPO Batch Consumption Time: 0.05386
Total Iteration Time: 5.60082

Cumulative Model Updates: 10236
Cumulative Timesteps: 170780102

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 170780102...
Checkpoint 170780102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00427
Policy Entropy: 1.18149
Value Function Loss: 0.04138

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.05666
Value Function Update Magnitude: 0.07091

Collected Steps per Second: 12230.10483
Overall Steps per Second: 9556.79314

Timestep Collection Time: 4.08974
Timestep Consumption Time: 1.14402
PPO Batch Consumption Time: 0.12067
Total Iteration Time: 5.23376

Cumulative Model Updates: 10239
Cumulative Timesteps: 170830120

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10280
Policy Entropy: 1.17819
Value Function Loss: 0.03717

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.05797
Value Function Update Magnitude: 0.07055

Collected Steps per Second: 11182.04392
Overall Steps per Second: 9144.22332

Timestep Collection Time: 4.47163
Timestep Consumption Time: 0.99652
PPO Batch Consumption Time: 0.06423
Total Iteration Time: 5.46815

Cumulative Model Updates: 10242
Cumulative Timesteps: 170880122

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 170880122...
Checkpoint 170880122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.07987
Policy Entropy: 1.19292
Value Function Loss: 0.03843

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07863
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.06998

Collected Steps per Second: 10964.09354
Overall Steps per Second: 9131.14744

Timestep Collection Time: 4.56308
Timestep Consumption Time: 0.91597
PPO Batch Consumption Time: 0.08601
Total Iteration Time: 5.47905

Cumulative Model Updates: 10245
Cumulative Timesteps: 170930152

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.09282
Policy Entropy: 1.19159
Value Function Loss: 0.04695

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07130
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.08100

Collected Steps per Second: 11642.63062
Overall Steps per Second: 9551.90078

Timestep Collection Time: 4.29645
Timestep Consumption Time: 0.94041
PPO Batch Consumption Time: 0.06661
Total Iteration Time: 5.23686

Cumulative Model Updates: 10248
Cumulative Timesteps: 170980174

Timesteps Collected: 50022
--------END ITERATION REPORT--------


Saving checkpoint 170980174...
Checkpoint 170980174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03944
Policy Entropy: 1.19570
Value Function Loss: 0.04316

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.06285
Value Function Update Magnitude: 0.07371

Collected Steps per Second: 11491.90655
Overall Steps per Second: 9349.72007

Timestep Collection Time: 4.35089
Timestep Consumption Time: 0.99687
PPO Batch Consumption Time: 0.07495
Total Iteration Time: 5.34775

Cumulative Model Updates: 10251
Cumulative Timesteps: 171030174

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Paused, press any key to resume
